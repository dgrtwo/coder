
@article{Abrahamsen2009,
  title = {Excess Mortality Following Hip Fracture: {{A}} Systematic Epidemiological Review},
  author = {Abrahamsen, B. and Staa, T. Van and Ariely, R. and Olson, M. and Cooper, C.},
  year = {2009},
  volume = {20},
  pages = {1633--1650},
  issn = {0937941X},
  doi = {10.1007/s00198-009-0920-3},
  abstract = {Abstract: Summary This systematic literature review has shown that patients experiencing hip fracture after low-impact trauma are at considerable excess risk for death compared with nonhip fracture/community control populations. The increased mortality risk may persist for several years thereafter, highlighting the need for interventions to reduce this risk. Patients experiencing hip fracture after low-impact trauma are at considerable risk for subsequent osteoporotic fractures and premature death. We conducted a systematic review of the literature to identify all studies that reported unadjusted and excess mortality rates for hip fracture. Although a lack of consistent study design precluded any formal meta-analysis or pooled analysis of the data, we have shown that hip fracture is associated with excess mortality (over and above mortality rates in nonhip fracture/community control populations) during the first year after fracture ranging from 8.4\% to 36\%. In the identified studies, individuals experienced an increased relative risk for mortality following hip fracture that was at least double that for the age-matched control population, became less pronounced with advancing age, was higher among men than women regardless of age, was highest in the days and weeks following the index fracture, and remained elevated for months and perhaps even years following the index fracture. These observations show that patients are at increased risk for premature death for many years after a fragility-related hip fracture and highlight the need to identify those patients who are candidates for interventions to reduce their risk.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NK9NUF6D\\Abrahamsen et al. - 2009 - Excess mortality following hip fracture A systema.pdf},
  isbn = {0937941X14332965},
  journal = {Osteoporosis International},
  keywords = {Excess mortality,Femoral neck fracture,Fragility-related fracture,Hip fracture,Osteoporotic hip fracture,Systematic review},
  number = {10},
  pmid = {18703700}
}

@article{Acquadro2008,
  title = {Literature Review of Methods to Translate Health-Related Quality of Life Questionnaires for Use in Multinational Clinical Trials},
  author = {Acquadro, Catherine and Conway, Katrin and Hareendran, Asha and Aaronson, Neil},
  year = {2008},
  volume = {11},
  pages = {509--521},
  publisher = {{International Society for Pharmacoeconomics and Outcomes Research (ISPOR)}},
  issn = {15244733},
  doi = {10.1111/j.1524-4733.2007.00292.x},
  abstract = {OBJECTIVES: We conducted a literature review to respond to regulatory concerns about the quality of translated patient-reported outcome questionnaires. Our main objective was to answer two questions: What do the methods have in common (and how do they differ)? Is there evidence of the superiority of one method over another?: We identified 891 references by searching MEDLINE, Embase, and the Mapi Research Trust's database with "quality-of-life,"questionnaires,"health status indicators" matched with "translating,"translation issues,"cross-cultural research," and "cross-cultural comparison." Articles were included if they proposed, compared or criticized translation methods.: Forty-five articles met our inclusion criteria: 23 representing 17 sets of methods, and 22 reviews. Most articles recommend a multistep approach involving a centralized review process. Nevertheless, each group proposes its own sequence of translation events and weights each step differently. There is evidence demonstrating that a rigorous and a multistep procedure leads to better translations. Nevertheless, there is no empirical evidence in favor of one specific method.: We need more empirical research on translation methodologies. Several points emerge from this review. First, producing high-quality translations is labor-intensive. Second, the availability of standardized guidelines and centralized review procedures improves the efficiency of the production of translations. Although we did not find evidence in favor of one method, we strongly advise researchers to adopt a multistep approach. In line with the recent Food and Drug Administration recommendations, we developed a checklist summarizing the steps used for translations, which can be used to evaluate the rigor of the applied methodologies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DVKTBYF3\\Acquadro et al. - 2008 - Literature review of methods to translate health-r.pdf},
  isbn = {1524-4733 (Electronic){\r  }1098-3015 (Linking)},
  journal = {Value in Health},
  keywords = {Clinical trials,Cross-cultural research,Health-related quality of life,Patient-reported outcomes,PRO questionnaires,Review,Translation issues},
  number = {3},
  pmid = {18179659}
}

@article{agostinoTutorialBiostatisticsPropensity1998,
  title = {Tutorial in Biostatistics Propensity Score Methods for Bias Reduction in the Comparison of a Treatment to a Non-Randomized Control Group},
  author = {'agostino, Ralph B D},
  year = {1998},
  volume = {17},
  pages = {2265--2281},
  issn = {02776715},
  doi = {10.1002/(SICI)1097-0258(19981015)17:19<2265::AID-SIM918>3.0.CO;2-B},
  abstract = {SUMMARY In observational studies, investigators have no control over the treatment assignment. The treated and non-treated (that is, control) groups may have large differences on their observed covariates, and these differences can lead to biased estimates of treatment effects. Even traditional covariance analysis adjust-ments may be inadequate to eliminate this bias. The propensity score, defined as the conditional probability of being treated given the covariates, can be used to balance the covariates in the two groups, and therefore reduce this bias. In order to estimate the propensity score, one must model the distribution of the treatment indicator variable given the observed covariates. Once estimated the propensity score can be used to reduce bias through matching, stratification (subclassification), regression adjustment, or some combination of all three. In this tutorial we discuss the uses of propensity score methods for bias reduction, give references to the literature and illustrate the uses through applied examples.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6UDR8H25\\'agostino - 1998 - Tutorial in biostatistics propensity score methods.pdf},
  isbn = {0277-6715 (Print){\r  }0277-6715 (Linking)},
  journal = {STATISTICS IN MEDICINE Statist. Med},
  pmid = {9802183}
}

@book{Agresti1996,
  title = {An Introduction to Categorical Data Analysis},
  author = {Agresti, Alan},
  year = {1996},
  volume = {22},
  issn = {15391604},
  doi = {10.1198/jasa.2008.s251},
  abstract = {Concise, complete, nontechnicalthe ideal introduction to an increasingly important topic In recent years, the use of statistical methods for categorical data has increased dramatically in a variety of areas and applications. This book provides an applied introduction to the most important methods for analyzing categorical data. It summarizes methods that have long played a prominent role, such as chi-squared tests, but places special emphasis on logistic regression and loglinear modeling techniques. Special features of the book include: Emphasis on logistic regression modeling of binary data and Poisson regression modeling of count data A unified perspective, based on generalized linear models, that connects these methods with standard regression methods for normally-distributed data An appendix showing the use of a new SAS procedure (GENMOD) for generalized linear modeling that can conduct nearly all methods presented in the book An entertaining historical perspective of the development of the methods Specialized methods for ordinal data, small samples, multicategory data, and matched pairs More than 100 examples of real data sets and more than 200 exercises Writing in an applied, nontechnical style, Alan Agresti illustrates methods using a wide variety of real data, including alcohol, cigarette, and marijuana use by teenagers; AZT use and delay of AIDS; space shuttle launches and O-ring failure; passive smoking and lung cancer; and much more. An Introduction to Categorical Data Analysis is an invaluable tool for social, behavioral, and biomedical scientists, as well as researchers in public health, marketing, education, biological and agricultural sciences, and industrial quality control.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8HEPZ9NT\\Agresti - 1996 - An introduction to categorical data analysis.pdf},
  isbn = {978-0-471-22618-5},
  keywords = {9780470114742},
  pmid = {14562513}
}

@generic{Agresti1996,
  title = {An Introduction to Categorical Data Analysis: {{R}} Manual},
  author = {Agresti, A},
  year = {1996},
  pages = {290},
  isbn = {9780471226185},
  journal = {Wiley Series in Probability and Statistics},
  keywords = {\#nosource}
}

@article{Ahmad1998,
  title = {Age Standardization of Rates: A New {{WHO}} World Standard},
  author = {Ahmad, O B and {Boschi-Pinto}, C and Lopez, A D and Murray, C and Lozano, R and Inque, M},
  year = {1998},
  volume = {31},
  issn = {01406736},
  doi = {10.1161/HYPERTENSIONAHA.114.04394},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8GR43GGW\\Ahmad et al. - 1998 - Age standardization of rates a new WHO world stan.pdf},
  isbn = {No 31},
  journal = {GPE Discussion Paper Series},
  pmid = {26445632}
}

@article{Ahmed2018,
  title = {Class-Imbalanced Subsampling Lasso Algorithm for Discovering Adverse Drug Reactions},
  author = {Ahmed, Isma{\"i}l and Pariente, Antoine and {Tubert-Bitter}, Pascale},
  year = {2018},
  month = mar,
  volume = {27},
  pages = {785--797},
  publisher = {{SAGE PublicationsSage UK: London, England}},
  doi = {10.1177/0962280216643116},
  abstract = {BackgroundAll methods routinely used to generate safety signals from pharmacovigilance databases rely on disproportionality analyses of counts aggregating patients' spontaneous reports. Recently, i...},
  journal = {Statistical Methods in Medical Research},
  keywords = {\#nosource},
  number = {3}
}

@article{Ai2003,
  title = {Interaction Terms in Logit and Probit Models},
  author = {Ai, Chunrong and Norton, Edward C.},
  year = {2003},
  volume = {80},
  pages = {123--129},
  issn = {01651765},
  doi = {10.1016/S0165-1765(03)00032-6},
  abstract = {The magnitude of the interaction effect in nonlinear models does not equal the marginal effect of the interaction term, can be of opposite sign, and its statistical significance is not calculated by standard software. We present the correct way to estimate the magnitude and standard errors of the interaction effect in nonlinear models. \textcopyright{} 2003 Elsevier Science B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MWAQZWVN\\Ai and Norton - 2003 - Interaction terms in logit and probit models.pdf},
  isbn = {0165-1765},
  journal = {Economics Letters},
  keywords = {Interaction effect,Interaction term,Logit,Nonlinear models,Probit},
  number = {1},
  pmid = {22091735}
}

@article{Akritas1986,
  title = {Bootstrapping the Kaplan-Me Er Estimator},
  author = {Akritas, Michael G},
  year = {1986},
  volume = {81},
  pages = {1032--1038},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {396}
}

@article{Akritas2000,
  title = {The Central Limit Theorem under Censoring},
  author = {Akritas, Michael G.},
  year = {2000},
  volume = {6},
  pages = {1109--1120},
  issn = {13507265},
  doi = {10.2307/3318473},
  abstract = {The central limit theorem for integrals of the Kaplan-Meier estimator is obtained. The basic tools are the martingale methods developed by Gill and the identities and inequalities of Efron and Johnstone. The assumptions needed are both weaker and more transparent than those in the recent literature, and the resulting variance expression is simpler, especially for distributions with atoms. \textcopyright{} 2000 ISI/BS.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XT4B4VCF\\Akritas - 2000 - The central limit theorem under censoring.pdf},
  journal = {Bernoulli},
  keywords = {Distributions with atoms,I.i.d. Representation,Kaplan-meier integrals,Martingales for counting processes},
  number = {6}
}

@article{Alam1979,
  title = {Distribution of Sample Correlation Coefficients},
  author = {Alam, Kursheed},
  year = {1979},
  volume = {26},
  pages = {237--330},
  isbn = {0001475045},
  journal = {Naval Research Logistics Quarterl},
  keywords = {\#nosource}
}

@article{Alegre-Lopez2005,
  title = {Factors Associated with Mortality and Functional Disability after Hip Fracture: {{An}} Inception Cohort Study},
  author = {{Alegre-L{\'o}pez}, Javier and {Cordero-Guevara}, Jos{\'e} and {Alonso-Valdivielso}, Jos{\'e} L. and {Fern{\'a}ndez-Mel{\'o}n}, Julia},
  year = {2005},
  volume = {16},
  pages = {729--736},
  issn = {0937941X},
  doi = {10.1007/s00198-004-1740-0},
  abstract = {Hip fracture results in excess mortality and functional disability. This study sought to identify predictors of mortality and limited functional ability 1 year after hip fracture. We conducted a 1-year follow-up of a prospective population-based inception cohort of 218 hip fracture patients who had been consecutively admitted and discharged from hospital during the previous year. Mortality was observed to be independently associated with poor mental status (relative risk [RR]=6.96; 95\% confidence interval [95\% CI], 1.73-28.00), prefracture limited functional ability (RR=4.35; 95\% CI, 1.32-14.36), institutionalized disposition at discharge (RR = 2.92; 95\% CI, 1.02-8.38), and male gender (RR = 2.44; 95\% CI, 1.01-5.93). Independent predictors of limited functional ability were prefracture functional disability (RR = 34.14; 95\% CI, 3.13-372.33), poor mental status (RR = 9.71; 95\% CI, 1.57-59.82), age \textquestiondown 80 years (RR = 4.03; 95\% CI, 1.48-11.00), and female gender (RR = 3.57; 95\% CI, 0.08-0.98). On discharge, special attention and care should thus be given to all patients displaying any of the above predictive factors.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JQ2IV4RJ\\Alegre-López et al. - 2005 - Factors associated with mortality and functional d.pdf},
  isbn = {0937-941X (Print)},
  journal = {Osteoporosis International},
  keywords = {Functional disability,Hip fractures,Mortality,Osteoporosis,Predictors},
  number = {7},
  pmid = {15526089}
}

@article{Alf2002,
  title = {A New Maximum Likelihood Estimator for the Population Squared Multiple Correlation},
  author = {Alf, E. F. and Graf, R. G.},
  year = {2002},
  volume = {27},
  pages = {223--235},
  issn = {1076-9986},
  doi = {10.3102/10769986027003223},
  abstract = {Using maximum likelihood estimation as described by R. A. Fisher (1912), a new estimator for the population squared multiple correlation was developed. This estimator ( \{rho\}circ;2(ML) ) was derived by examining all possible values of the population squared multiple correlation for a given sample size and number of predictors, and finding the one for which the observed sample value had the highest probability of occurring. The new estimator is shown to have greater accuracy than other estimators and to generate values that always fall within the parameter space. The utility of \{rho\}circ; 2 (ML) in terms of providing the basis for the development of small sample significance tests is demonstrated. A Microsoft Excel workbook for computing \{rho\}circ; 2(ML) and its regions of nonsignificance and for computing a normal transformation for R2 is offered.},
  isbn = {1076-9986},
  journal = {Journal of Educational and Behavioral Statistics},
  keywords = {-variate,\#nosource,1,a,correction for shrinkage,has been obtained from,maximum likelihood estimator,multiple correlation,multiple regression,n,normal distribution in which,population validity,sample of size n,significance tests,squared multiple correlation between,suppose that a random,the first,ρ 2 is the},
  number = {3}
}

@article{alfaro-adrianOneTwostageBilateral1999,
  title = {One- or Two-Stage Bilateral Total Hip Replacement.},
  author = {{Alfaro-Adri{\'a}n}, J and Bayona, F and Rech, J A and Murray, D W},
  year = {1999},
  month = jun,
  volume = {14},
  pages = {439--45},
  publisher = {{Elsevier}},
  issn = {0883-5403},
  doi = {10.1016/S0883-5403(99)90099-2},
  abstract = {It is not clear whether bilateral hip replacement should be done in 1 or 2 stages. The total number of total hip replacements (THRs) done in our center between 1989 and 1995 was approximately 4,000. The number of hips that were bilateral was 404, or 9\% of the total number of THRs performed during this time period. Of these bilateral hip replacements, 190 (95 patients) were done as a 1-stage procedure, whereas 214 (107 patients) were done in 2 stages with 2 to 24 months in between the operations. In contrast to previous studies, there were no significant preoperative differences between the 2 groups of patients having 1-stage or 2-stage THRs, and, in particular, the comorbidity assessed by the American Society of Anesthesiologists (ASA) grade was not significantly different. Our results demonstrate that, in our patient population, bilateral THR was equally safe whether performed as a 1-stage or 2-stage procedure. This was the case in the low-risk (ASA 1 and 2) and high-risk (ASA 3 and 4) patient subgroups. One-stage bilateral THR is cheaper and involves less time in the hospital.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\99KBTADD\\Alfaro-Adrián et al. - 1999 - One- or two-stage bilateral total hip replacement..pdf},
  journal = {The Journal of arthroplasty},
  keywords = {bilateral total hip replacement,total hip replacement},
  number = {4},
  pmid = {10428224}
}

@article{Algina1999,
  title = {A Comparison of Methods for Constructing Confidence Intervals for the Squared Multiple Correlation Coefficient},
  author = {Algina, James},
  year = {1999},
  volume = {34},
  pages = {493--504},
  issn = {0027-3171},
  doi = {10.1207/S15327906MBR3404_5},
  abstract = {Four methods for constructing 100(1 - alpha)\% confidence intervalsthe population squared multiple correlation coefficient (rho(2))compared. In one method the confidence interval was constructedusing the distribution of R-2. Provided rho(2) \textquestiondown{} 0 the coveragefor this method is exactly 1 - alpha when the data arenormal. The other three methods are based on resultsOlkin and Finn (1995) and are approximate. Results show that eachthe approximate methods works very poorly for some combinationsrho(2). The method based on the distribution of R-2 is recommended.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RMQMCJEK\\Algina - 1999 - A comparison of methods for constructing confidenc.pdf},
  journal = {Multivariate Behavioral Research},
  number = {4}
}

@article{Algina2001,
  title = {Sample Sizes for Confidence Intervals on the Increase in the Squared Multiple Correlation Coefficient},
  author = {Algina, James and Moulder, Bradley C.},
  year = {2001},
  volume = {61},
  pages = {633--649},
  issn = {00131644},
  doi = {10.1177/00131640121971400},
  abstract = {The increase in the squared multiple correlation coefficient (DeltaR(2))with a variable in a regression equation is a commonlymeasure of importance in regression analysis. The probabilityan asymptotic confidence interval will include Delta rho (2)investigated. With sample sizes typically used in regression, when Delta rho (2) = 0.00 and the confidence level is .95greater, the probability will be at least .999. For Delta rho(2) greater than or equal to .01 and a confidence level of .95 or, the probability will be smaller than the nominal confidence. For Delta rho (2) greater than or equal to .05 and a confidenceof .95, tables are provided for the sample size necessary forprobability to be at least .925 and to be at least .94.},
  isbn = {0013-1644},
  journal = {Educational and Psychological Measurement},
  keywords = {\#nosource},
  number = {4}
}

@article{Alluri2016,
  title = {Surgical Research Using National Databases},
  author = {Alluri, Ram K. and Leland, Hyuma and Heckmann, Nathanael},
  year = {2016},
  volume = {4},
  pages = {393--393},
  issn = {23055839},
  doi = {10.21037/atm.2016.10.49},
  abstract = {Recent changes in healthcare and advances in technology have increased the use of large-volume national databases in surgical research. These databases have been used to develop perioperative risk stratification tools, assess postoperative complications, calculate costs, and investigate numerous other topics across multiple surgical specialties. The results of these studies contain variable information but are subject to unique limitations. The use of large-volume national databases is increasing in popularity, and thorough understanding of these databases will allow for a more sophisticated and better educated interpretation of studies that utilize such databases. This review will highlight the composition, strengths, and weaknesses of commonly used national databases in surgical research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2DY6SXHG\\Alluri et al. - 2016 - Surgical research using national databases.pdf},
  journal = {Annals of Translational Medicine},
  keywords = {09,10,2016,21037,49,accepted for publication oct,atm,database,doi,dx,http,national,org,research,submitted jul 27,surgery,view this article at},
  number = {20},
  pmid = {27867945}
}

@inproceedings{Altman2000,
  title = {What Do We Mean by Validating a Prognostic Model?},
  author = {Altman, Douglas G. and Royston, Patrick},
  year = {2000},
  issn = {02776715},
  doi = {10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.0.CO;2-5},
  abstract = {Prognostic models are used in medicine for investigating patient outcome in relation to patient and disease characteristics. Such models do not always work well in practice, so it is widely recommended that they need to be validated. The idea of validating a prognostic model is generally taken to mean establishing that it works satisfactorily for patients other than those from whose data it was derived. In this paper we examine what is meant by validation and review why it is necessary. We consider how to validate a model and suggest that it is desirable to consider two rather different aspects - statistical and clinical validity - and examine some general approaches to validation. We illustrate the issues using several case studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GA37SI9Q\\Altman and Royston - 2000 - What do we mean by validating a prognostic model.pdf},
  isbn = {0277-6715 (Print) 0277-6715 (Linking)},
  pmid = {10694730},
  series = {Statistics in {{Medicine}}}
}

@article{Altman2000,
  title = {What Do We Mean by Validating a Prognistic Model?},
  author = {Altman, Douglas G and Royston, Patrick},
  year = {2000},
  volume = {19},
  pages = {453--473},
  issn = {02776715},
  doi = {10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.0.CO;2-5},
  abstract = {Prognostic models are used in medicine for investigating patient outcome{\r  }relation to patient and disease characteristics. Such models do{\r  }always work well in practice, so it is widely recommended that{\r  }need to be validated. The idea of validating a prognostic model{\r  }generally taken to mean establishing that it works satisfactorily{\r  }patients other than those from whose data it was derived. In{\r  }paper we examine what is meant by validation and review why{\r  }is necessary. We consider how to validate a model and suggest{\r  }it is desirable to consider two rather di!erent aspects - statistical{\r  }clinical validity - and examine some general approaches to validation.{\r  }illustrate the issues using several case studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8Y9QE5AD\\Altman and Royston - 2000 - What do we mean by validating a prognistic model.pdf},
  isbn = {0277-6715 (Print)},
  journal = {Statistics in medicine},
  pmid = {10694730}
}

@article{Altman2006,
  title = {The Cost of Dichotomising Continuous Variables.},
  author = {Altman, Douglas G and Royston, Patrick},
  year = {2006},
  month = may,
  volume = {332},
  pages = {1080},
  issn = {1756-1833},
  doi = {10.1136/bmj.332.7549.1080},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Q53INUFN\\Altman and Royston - 2006 - The cost of dichotomising continuous variables..pdf},
  journal = {BMJ (Clinical research ed.)},
  number = {7549},
  pmid = {16675816}
}

@article{Altman2009,
  title = {Prognosis and Prognostic Research: Validating a Prognostic Model},
  author = {Altman, Douglas G and Vergouwe, Yvonne and Royston, Patrick and Moons, Karel G M},
  year = {2009},
  month = may,
  volume = {338},
  abstract = {Prognostic models are of little clinical value unless they are shown to work in other samples. Douglas Altman and colleagues describe how to validate models and discuss some of the problemsPrognostic models, like the one we developed in the previous article in this series,1 yield scores to enable the prediction of the risk of future events in individual patients or groups and the stratification of patients by these risks.2 A good model may allow the reasonably reliable classification of patients into risk groups with different prognoses. To show that a prognostic model is valuable, however, it is not sufficient to show that it successfully predicts outcome in the initial development data. We need evidence that the model performs well for other groups of patients.1 3 In this article, we discuss how to evaluate the performance of a prognostic model in new data.4 5Summary pointsUnvalidated models should not be used in clinical practiceWhen validating a prognostic model, calibration and discrimination should be evaluatedValidation should be done on a different data from that used to develop the model, preferably from patients in other centresModels may not perform well in practice because of deficiencies in the development methods or because the new sample is too different from the originalVarious statistical or clinical factors may lead a prognostic model to perform poorly when applied to other patients.4 6 The model's predictions may not be reproducible because of deficiencies in the design or modelling methods used in the study to derive the model, if the model was overfitted, or if an important predictor is absent from the model (which may be hard to know).1 Poor performance in new patients can also arise from differences between the setting of patients in the new and derivation \ldots},
  journal = {BMJ: British Medical Journal},
  keywords = {\#nosource}
}

@article{Alvares2018,
  title = {{{SemiCompRisks}}: {{An}} r Package for Independent and Cluster-Correlated Analyses of Semi-Competing Risks Data},
  author = {Alvares, D and Haneuse, S and Lee, C and Lee, K.H.},
  year = {2018},
  month = jan,
  journal = {ArXiv e-prints},
  keywords = {\#nosource,Statistics - Computation}
}

@book{Analysis2003,
  title = {Springer Series in Statistics Springer Series in Statistics},
  author = {Analysis, Intelligent Data and {Anderson-Cook}, Christine M and Applied, Sa and Using, Statistics and Brillinger, D and Gani, J and Hartigan, J and Krickeberg, K and Casella, George and Fienberg, Stephen and Olkin, Ingram and Dalgaard, Peter and Boeck, Paul De and Wilson, Mark and Eddy, W and Hardle, W and Physics, Fundamental and Reynolds, Jim and Robert, Christian P. and Casella, George and Sahai, Hardea and Ojeda, Maria Miguel and Simar, Hardie and Toutenburg, Helge and Winkler, Gerhard},
  year = {2003},
  volume = {53},
  issn = {1098-6596},
  doi = {10.1007/b98966},
  abstract = {applicability for this approach.},
  isbn = {978-1-4757-1906-2},
  keywords = {\#nosource,icle},
  pmid = {25246403}
}

@article{Andersen2003,
  title = {Generalised Linear Models for Correlated Pseudo-Observations, with Applications to Multi-State Models},
  author = {Andersen, Per Kragh and Klein, John P. and Rosth\o j, Susanne},
  year = {2003},
  volume = {90},
  pages = {15--27},
  issn = {00063444},
  doi = {10.1093/biomet/90.1.15},
  abstract = {In multi-state models regression analysis typically involves the modelling of each transition intensity separately. Each probability of interest, namely the probability that a subject will be in a given state at some time, is a complex nonlinear function of the intensity regression coefficients. We present a technique which models the state probabilities directly. This method is based on the pseudo-values from a jackknife statistic constructed from simple summary statistic estimates of the state probabilities. These pseudo-values are then used in a generalised estimating equation to obtain estimates of the model parameters. We illustrate how this technique works by studying examples of common regression problems. We apply the technique to model acute graft-versus-host disease in bone marrow transplants.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PTJRJ9BX\\Andersen et al. - 2003 - Generalised linear models for correlated pseudo-ob.pdf},
  journal = {Biometrika},
  keywords = {Generalised estimating equation,Generalised linear model,Jackknife pseudo-value,Logistic regression,Markov model,Multi-state model},
  number = {1}
}

@inproceedings{Andersen2004,
  title = {Regression Analysis of Restricted Mean Survival Time Based on Pseudo-Observations},
  author = {Andersen, Per Kragh and Hansen, Mette Gerster and Klein, John P.},
  year = {2004},
  month = dec,
  volume = {10},
  pages = {335--350},
  issn = {13807870},
  doi = {10.1007/s10985-004-4771-0},
  abstract = {Regression models for survival data are often specified from the hazard function while classical regression analysis of quantitative outcomes focuses on the mean value (possibly after suitable transformations). Methods for regression analysis of mean survival time and the related quantity, the restricted mean survival time, are reviewed and compared to a method based on pseudo-observations. Both Monte Carlo simulations and two real data sets are studied. It is concluded that while existing methods may be superior for analysis of the mean, pseudo-observations seem well suited when the restricted mean is studied. \textcopyright{} 2005 Kluwer Academic Publishers.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JIKXGB2J\\Andersen et al. - 2004 - Regression analysis of restricted mean survival ti.pdf},
  issue = {4},
  keywords = {Censoring,Hazard function,Health economics,Mean survival time,Pseudo-observations,Regression model,Restricted mean survival time,Survival analysis},
  pmid = {15690989},
  series = {Lifetime {{Data Analysis}}}
}

@article{Andersen2010,
  title = {Pseudo-Observations in Survival Analysis},
  author = {Andersen, Per Kragh and Perme, Maja Pohar},
  year = {2010},
  month = feb,
  volume = {19},
  pages = {71--99},
  issn = {0962-2802},
  doi = {10.1177/0962280209105020},
  journal = {Statistical Methods in Medical Research},
  keywords = {\#nosource},
  number = {1}
}

@article{Andersen2012,
  title = {Competing Risks in Epidemiology: {{Possibilities}} and Pitfalls},
  author = {Andersen, Per Kragh and Geskus, Ronald B. and {witte}, Theo De and Putter, Hein},
  year = {2012},
  volume = {41},
  pages = {861--870},
  issn = {03005771},
  doi = {10.1093/ije/dyr213},
  abstract = {BACKGROUND: In studies of all-cause mortality, the fundamental epidemiological concepts of rate and risk are connected through a well-defined one-to-one relation. An important consequence of this relation is that regression models such as the proportional hazards model that are defined through the hazard (the rate) immediately dictate how the covariates relate to the survival function (the risk).: This introductory paper reviews the concepts of rate and risk and their one-to-one relation in all-cause mortality studies and introduces the analogous concepts of rate and risk in the context of competing risks, the cause-specific hazard and the cause-specific cumulative incidence function.: The key feature of competing risks is that the one-to-one correspondence between cause-specific hazard and cumulative incidence, between rate and risk, is lost. This fact has two important implications. First, the na\"ive Kaplan-Meier that takes the competing events as censored observations, is biased. Secondly, the way in which covariates are associated with the cause-specific hazards may not coincide with the way these covariates are associated with the cumulative incidence. An example with relapse and non-relapse mortality as competing risks in a stem cell transplantation study is used for illustration.: The two implications of the loss of one-to-one correspondence between cause-specific hazard and cumulative incidence should be kept in mind when deciding on how to make inference in a competing risks situation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BPZ8RM6R\\Andersen et al. - 2012 - Competing risks in epidemiology Possibilities and.pdf},
  journal = {International Journal of Epidemiology},
  keywords = {Censored data,Competing risks,Regression models,Survival analysis},
  number = {3}
}

@book{Andersen2012,
  title = {Statistical Models Based on Counting Processes},
  author = {Andersen, Per K and Borgan, Ornulf and Gill, Richard D and Keiding, Niels},
  year = {2012},
  publisher = {{Springer Science \& Business Media}},
  isbn = {1-4612-4348-3},
  keywords = {\#nosource}
}

@article{Andersen2013,
  title = {Cause-Specific Measures of Life Years Lost},
  author = {Andersen, Per Kragh and {Canudas-Romo}, Vladimir and Keiding, Niels},
  year = {2013},
  volume = {29},
  pages = {1127--1152},
  doi = {10.4054/demres.2013.29.41},
  abstract = {Background: A new measure of the number of life years lost due to specific causes of death is introduced. Methods: This measure is based on the cumulative incidence of death, it does not require "independence" of causes, and it satisfies simple balance equations: "total number of life years lost = sum of cause-specific life years lost", and "total number of life years lost before age x + temporary life expectancy between birth and age x = x". Results: The measure is contrasted to alternatives suggested in the demographic literature and all methods are illustrated using Danish and Russian multiple decrement life-tables.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZCJWZ7TL\\Andersen et al. - 2013 - Cause-specific measures of life years lost.pdf},
  journal = {Demographic Research},
  number = {December}
}

@article{Andersen2013,
  title = {Decomposition of Number of Life Years Lost According to Causes of Death},
  author = {Andersen, P. K.},
  year = {2013},
  volume = {32},
  pages = {5278--5285},
  issn = {10970258},
  doi = {10.1002/sim.5903},
  abstract = {We study the competing risks model and show that the cause j cumulative incidence function integrated from 0 to {$\tau$} has a natural interpretation as the expected number of life years lost due to cause j before time {$\tau$}. This is analogous to the {$\tau$}-restricted mean lifetime, which is the survival function integrated from 0 to {$\tau$}. It is discussed how the number of years lost may be related to subject-specific explanatory variables in a regression model based on pseudo-observations, and the method is exemplified using data from a bone marrow transplantation study. Finally, inclusion of standard mortality rates is discussed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6M2E79GZ\\Andersen - 2013 - Decomposition of number of life years lost accordi.pdf},
  journal = {Statistics in Medicine},
  keywords = {Competing risks,Life expectancy,Pseudo-observations,Restricted mean,Standard mortality rates,Survival analysis},
  number = {30}
}

@article{Andersen2017,
  title = {Life Years Lost among Patients with a given Disease},
  author = {Andersen, Per Kragh},
  year = {2017},
  volume = {36},
  pages = {3573--3582},
  issn = {10970258},
  doi = {10.1002/sim.7357},
  abstract = {A number of suggested measures of life years lost among patients with a given disease are reviewed, and some new ones are proposed. The methods are all phrased in the framework of a (Markov or non-Markov) illness-death model in combination with a population life table. The methods are illustrated using data on Danish male patients with bipolar disorder, and some recommendations are given. Copyright \textcopyright{} 2017 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WTTTPWGI\\Andersen - 2017 - Life years lost among patients with a given diseas.pdf},
  journal = {Statistics in Medicine},
  keywords = {illness-death model,life years lost,population life table,restricted mean lifetime},
  number = {22}
}

@article{Anderson2016,
  title = {Assessment of Scientific Communication Self-Efficacy, Interest, and Outcome Expectations for Career Development in Academic Medicine},
  author = {Anderson, C. B. and Lee, H. Y. and {Byars-Winston}, A. and Baldwin, C. D. and Cameron, C. and Chang, S.},
  year = {2016},
  volume = {24},
  pages = {182--196},
  issn = {1069-0727},
  doi = {10.1177/1069072714565780},
  abstract = {Competency in forms of scientific communication, both written and spoken, is essential for success in academic science. This study examined the psychometric properties of three new measures, based on social cognitive career theory, that are relevant to assessment of skill and perseverance in scientific communication. Pre- and postdoctoral trainees in biomedical science (N{$\frac{1}{4}$}411) completed online questionnaires assessing self-efficacy in scientific communication, career outcome expecta- tions, and interest in performing tasks in scientific writing, oral presentation, and impromptu scien- tific discourse. Structural equation modeling was used to evaluate factor structures and model relations. Confirmatory factor analysis supported a 22-item, 3-factor measure of self-efficacy; an 11-item, 2-factor measure of outcome expectations; and a 12-item, 3-factor measure of interest in scientific communication activities. Construct validity was further demonstrated by theory- consistent inter-factor relations and relations with typical communications performance behaviors (e.g., writing manuscripts, abstracts, and presenting at national meetings)},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TE3KARQK\\Anderson et al. - 2016 - Assessment of scientific communication self-effica.pdf},
  journal = {Journal of Career Assessment},
  keywords = {academic medicine,career development,LISREL,measurement,scale development,SCCT,scientific communication,social cognitive theory},
  number = {1}
}

@article{Anderson2017,
  title = {Hosting Data Packages via Drat: {{A}} Case Study with Hurricane Exposure Data},
  author = {Anderson, G Brooke and Eddelbuettel, Dirk},
  year = {2017},
  volume = {9},
  abstract = {Data-only packages offer a way to provide extended functionality for other R users. However, such packages can be large enough to exceed the package size limit (5 megabytes) for the Comprehen-sive R Archive Network (CRAN). As an alternative, large data packages can be posted to additional repostiories beyond CRAN itself in a way that allows smaller code packages on CRAN to access and use the data. The drat package facilitates creation and use of such alternative repositories and makes it particularly simple to host them via GitHub. CRAN packages can draw on packages posted to drat repositories through the use of the 'Additonal\textsubscript{r}epositories' field in the DESCRIPTION file. This paper describes how R users can create a suite of coordinated packages, in which larger data packages are hosted in an alternative repository created with drat, while a smaller code package that interacts with this data is created that can be submitted to CRAN.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CTHUVFFI\\Anderson and Eddelbuettel - 2017 - Hosting data packages via drat A case study with .pdf},
  journal = {The R Journal},
  number = {1}
}

@generic{Andersson2001,
  title = {Formelsamling F\"or Kursen Overlevnadsanalys},
  author = {Andersson, Mikael and Kontinuerlig, X},
  year = {2001},
  pages = {1--8},
  keywords = {\#nosource}
}

@book{anesthesiologists.Anesthesiology1941,
  title = {Anesthesiology.},
  author = {of Anesthesiologists., Meyer American Society},
  year = {1941},
  month = may,
  volume = {2},
  publisher = {{[American Society of Anesthesiologists, etc.]}},
  issn = {0003-3022},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CPU2XY2Z\\Anesthesiologists. - 1941 - Anesthesiology..pdf}
}

@article{Angeles2009,
  title = {Multi-State Models for the Analysis of Time-to-Event Data},
  author = {Angeles, Los and Delhi, New and {Meira-Machado}, Lu{\'i}s},
  year = {2009},
  volume = {18},
  pages = {195--222},
  issn = {0962-2802},
  doi = {10.1177/0962280208092301},
  abstract = {The experience of a patient in a survival study may be modelled as a process with two states and one possible transition from an " alive " state to a " dead " state. In some studies, however, the " alive " state may be partitioned into two or more intermediate (transient) states, each of which corresponding to a particular stage of the illness. In such studies, multi-state models can be used to model the movement of patients among the various states. In these models issues, of interest include the estimation of progression rates, assessing the effects of individual risk factors, survival rates or prognostic forecasting. In this article, we review modelling approaches for multi-state models, and we focus on the estimation of quantities such as the transition probabilities and survival probabilities. Differences between these approaches are discussed, focussing on possible advantages and disadvantages for each method. We also review the existing software currently available to fit the various models and present new software developed in the form of an R library to analyse such models. Different approaches and software are illustrated using data from the Stanford heart transplant study and data from a study on breast cancer conducted in Galicia, Spain.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JBBAXJFI\\Angeles et al. - 2009 - Multi-state models for the analysis of time-to-eve.pdf},
  isbn = {0962280208},
  journal = {Statistical Methods in Medical Research},
  pmid = {18562394}
}

@article{Angervall2015,
  title = {The Excellent Researcher},
  author = {Angervall, Petra},
  year = {2015},
  volume = {14},
  pages = {225--237},
  issn = {14782103},
  doi = {10.1177/1478210315614747},
  abstract = {The neo-liberal university not only changes systems of governance but also impacts on how subject positions are valued. These changes justify critical questions on how academics manoeuvre in academia. In this study focus is on the told experiences of 18 researchers who describe how they made an excellent career in academia. The results show that most of the researchers express awareness about a performative culture in terms of how it is affecting their careers and how they should make mindful and rewarding choices. Accordingly, the ``excellent researcher'' is expected to know how to use specific locations in order to move in a profitable way. Some express that they move as they like, due to their individual competence. The results also illustrate how women more than men express uncertainties and complex self-images that create barriers (mental and physical). Men seem to think less about their conditions than women, and express clear views about where to go and how to move. Women move less distinctly and less collaborative, but also seem less rewarded. Many of the women appear anxious, especially in relation to the boundaries between private- and work-life, which partly could disable them in using their capacity of making distinct choices in their career},
  journal = {Policy Futures in Education},
  keywords = {\#nosource,Academic career,Excellence,Gender,Subjectivity},
  number = {2}
}

@article{Antoni2016,
  title = {An Assessment of {{GLOBOCAN}} Methods for Deriving National Estimates of Cancer Incidence.},
  author = {Antoni, Sebastien and Soerjomataram, Isabelle and M\o ller, Bj\o rn and Bray, Freddie and Ferlay, Jacques},
  year = {2016},
  volume = {94},
  pages = {174--84},
  issn = {1564-0604},
  doi = {10.2471/BLT.15.164384},
  abstract = {OBJECTIVE To assess the validity of the GLOBOCAN methods for deriving national estimates of cancer incidence. METHODS We obtained incidence and mortality data from Norway by region, year of diagnosis, cancer site, sex and 5-year age group for the period 1983-2012 from the NORDCAN database. Estimates for the year 2010 were derived using nine different methods from GLOBOCAN. These included the projection of national historical rates, the use of regional proxies and the combination of national mortality data with mortality to incidence ratios or relative survival proportions. We then compared the national estimates with recorded cancer incidence data. FINDINGS Differences between the estimates derived using different methods varied by cancer site and sex. Methods based on projections performed better where major changes in recent trends were absent. Methods based on mortality data performed less well for cancers associated with small numbers of deaths and for cancers detectable by screening. In countries with longstanding cancer registries of high quality, regional-based, or trends-based incidence estimates perform reasonably well in comparison with recorded incidence. CONCLUSION Although the performance of the GLOBOCAN methods varies by cancer site and sex in this study, the results emphasize a need for more high-quality population-based cancer registries - either regional or, where practical and feasible, national registries - to describe cancer patterns and trends for planning cancer control priorities. Abstract available from the publisher. Abstract available from the publisher. Abstract available from the publisher. Abstract available from the publisher. Abstract available from the publisher.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EJQN89QC\\Antoni et al. - 2016 - An assessment of GLOBOCAN methods for deriving nat.pdf},
  journal = {Bulletin of the World Health Organization},
  number = {3},
  pmid = {26966328}
}

@article{Antoniou2014,
  title = {Comparison of Comorbidity Classification Methods for Predicting Outcomes in a Population-Based Cohort of Adults with Human Immunodeficiency Virus Infection},
  author = {Antoniou, Tony and Ng, Ryan and Glazier, Richard H. and Kopp, Alexander and Austin, Peter C.},
  year = {2014},
  volume = {24},
  pages = {532--537},
  publisher = {{Elsevier Inc}},
  issn = {18732585},
  doi = {10.1016/j.annepidem.2014.04.002},
  abstract = {Purpose: We compared the John's Hopkins' Aggregated Diagnosis Groups (ADGs), which are derived using inpatient and outpatient records, with the hospital record-derived Charlson and Elixhauser comorbidity indices for predicting outcomes in human immunodeficiency virus (HIV)-infected patients. Methods: We used a validated algorithm to identify HIV-infected adults (n=14,313) in Ontario, Canada, and randomly divided the sample into derivation and validation samples 100 times. The primary outcome was all-cause mortality within 1 year, and secondary outcomes included hospital admission and all-cause mortality within 1-2 years. Results: The ADG, Elixhauser, and Charlson methods had comparable discriminative performance for predicting 1-year mortality, with median c-statistics of 0.785, 0.767, and 0.788, respectively, across the 100 validation samples. All methods had lower predictive accuracy for all-cause mortality within 1-2 years. For hospital admission, the ADG method had greater discriminative performance than either the Elixhauser or Charlson methods, with median c-statistics of 0.727, 0.678, and 0.668, respectively. All models displayed poor calibration for each outcome. Conclusions: In patients with HIV, the ADG, Charlson, and Elixhauser methods are comparable for predicting 1-year mortality. However, poor calibration limits the use of these methods for provider profiling and clinical application. \textcopyright{} 2014 Elsevier Inc.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\39W4PNDG\\Antoniou et al. - 2014 - Comparison of comorbidity classification methods f.pdf},
  journal = {Annals of Epidemiology},
  keywords = {Comorbidity,Databases,Diagnosis-related groups,Factual,HIV,Logistic models,Predictive value of tests,Risk adjustment,ROC curve},
  number = {7},
  pmid = {24837611}
}

@article{Aram2018,
  title = {Estimating an Individual's Probability of Revision Surgery after Knee Replacement: {{A}} Comparison of Modeling Approaches Using a National Data Set.},
  author = {Aram, Parham and {Trela-Larsen}, Lea and Sayers, Adrian and Hills, Andrew F and Blom, Ashley W and McCloskey, Eugene V and Kadirkamanathan, Visakan and Wilkinson, Jeremy M},
  year = {2018},
  month = oct,
  volume = {187},
  pages = {2252--2262},
  publisher = {{Oxford University Press}},
  issn = {1476-6256},
  doi = {10.1093/aje/kwy121},
  abstract = {Tools that provide personalized risk prediction of outcomes after surgical procedures help patients make preference-based decisions among the available treatment options. However, it is unclear which modeling approach provides the most accurate risk estimation. We constructed and compared several parametric and nonparametric models for predicting prosthesis survivorship after knee replacement surgery for osteoarthritis. We used 430,455 patient-procedure episodes between April 2003 and September 2015 from the National Joint Registry for England, Wales, Northern Ireland, and the Isle of Man. The flexible parametric survival and random survival forest models most accurately captured the observed probability of remaining event-free. The concordance index for the flexible parametric model was the highest (0.705, 95\% confidence interval (CI): 0.702, 0.707) for total knee replacement and was 0.639 (95\% CI: 0.634, 0.643) for unicondylar knee replacement and 0.589 (95\% CI: 0.586, 0.592) for patellofemoral replacement. The observed-to-predicted ratios for both the flexible parametric and the random survival forest approaches indicated that models tended to underestimate the risks for most risk groups. Our results show that the flexible parametric model has a better overall performance compared with other tested parametric methods and has better discrimination compared with the random survival forest approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JKAZIQJD\\Aram et al. - 2018 - Estimating an individual's probability of revision.pdf},
  journal = {American journal of epidemiology},
  number = {10},
  pmid = {29893799}
}

@article{Arem2015,
  title = {Reproductive and Hormonal Factors and Mortality among Women with Colorectal Cancer in the {{NIH}}-{{AARP Diet}} and {{Health Study}}},
  author = {Arem, H and Park, Y and Felix, A S and Zervoudakis, A and Brinton, L A and Matthews, C E and Gunter, M J},
  year = {2015},
  month = jul,
  volume = {113},
  pages = {562--568},
  publisher = {{Nature Publishing Group}},
  issn = {0007-0920},
  doi = {10.1038/bjc.2015.224},
  abstract = {Reproductive and hormonal factors and mortality among women with colorectal cancer in the NIH-AARP Diet and Health Study},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NSPZNQPB\\Arem et al. - 2015 - Reproductive and hormonal factors and mortality am.pdf},
  journal = {British Journal of Cancer},
  keywords = {Colorectal cancer,Hormonal therapies,Risk factors},
  number = {3}
}

@techreport{arinoBenchmarkingPredictiveModels2016,
  title = {Benchmarking Predictive Models a Note from the Author},
  author = {Ari{\~n}o, Eduardo and Rubia, De},
  year = {2016},
  keywords = {\#nosource}
}

@article{Ariza-Vega2015,
  title = {Predictors of Long-Term Mortality in Older People with Hip Fracture},
  author = {{Ariza-Vega}, Patrocinio and Kristensen, Morten Tange and {Mart{\'i}n-Mart{\'i}n}, Lydia and {Jim{\'e}nez-Mole{\'o}n}, Jose Juan},
  year = {2015},
  volume = {96},
  pages = {1215--1221},
  issn = {1532821X},
  doi = {10.1016/j.apmr.2015.01.023},
  abstract = {Abstract Objectives To determine 1-year mortality and predisposing factors in older people who had surgery after a hip fracture. Design Prospective cohort study. Setting Public acute hospital, trauma service. Participants Patients (N=281) aged {$\geq$}65 years who were admitted to the hospital with a hip fracture from January 2009 to January 2010, and followed up for 1 year thereafter. Interventions Not applicable. Main Outcome Measures Cumulative survival probability up to 1 year from surgery was calculated by means of Kaplan-Meier charts, and Cox regression models were performed to analyze the factors associated with mortality. Data were collected from medical charts and by interviews. Health status was evaluated using the American Society of Anesthesiologists rating, prefracture functional level with the FIM, and cognitive status with the Pfeiffer score. Results The 1-year mortality for the 281 patients who were followed up was 21\% (95\% confidence interval [CI], 16.1\%-25.9\%). A non-weight-bearing status was associated with increased mortality in unadjusted analyses (hazard ratio [HR]=1.99; 95\% CI, 1.16-3.43), but 5 other factors were identified when entered into the multiple Cox regression model: age (HR=1.05; 95\% CI, 1-1.09), male sex (HR=2.92; 95\% CI, 1.58-5.39), low health status (HR=2.8; 95\% CI, 1.29-6.09), low prefracture function (HR=.98; 95\% CI,.97-.99), and change of residence (HR=3.21; 95\% CI, 1.43-7.17). Conclusions The overall 1-year mortality rate was 21\%. Change of residence is the only potentially modifiable risk factor, independent of the following other traditional risk factors that were found: age, sex, health status, and prefracture functional level. Furthermore, 2 to 4 weeks of non-weight-bearing status, which is considered modifiable, is also associated with increased mortality rates in unadjusted analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XGV8CYBJ\\Ariza-Vega et al. - 2015 - Predictors of long-term mortality in older people .pdf},
  isbn = {9780874216561},
  journal = {Archives of Physical Medicine and Rehabilitation},
  keywords = {Hip fracture,Mortality,Rehabilitation,Risk factors},
  number = {7},
  pmid = {25701641}
}

@article{Arlot2009,
  title = {A Survey of Cross-Validation Procedures for Model Selection},
  author = {Arlot, Sylvain and Celisse, Alain},
  year = {2009},
  volume = {4},
  pages = {40--79},
  issn = {1935-7516},
  doi = {10.1214/09-SS054},
  abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its apparent universality. Many results exist on the model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WXSYAZ7G\\Arlot and Celisse - 2009 - A survey of cross-validation procedures for model .pdf},
  isbn = {1935-7516},
  keywords = {and phrases,cross-validation,leave-one-out,model selection},
  pmid = {1000183221}
}

@article{Armitage2010,
  title = {Identifying Co-Morbidity in Surgical Patients Using Administrative Data with the {{Royal College}} of {{Surgeons Charlson Score}}},
  author = {Armitage, J. N. and {van der Meulen}, J. H.},
  year = {2010},
  month = mar,
  volume = {97},
  pages = {772--781},
  publisher = {{John Wiley \& Sons, Ltd.}},
  doi = {10.1002/bjs.6930},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DEVXZVMT\\Armitage and van der Meulen - 2010 - Identifying co-morbidity in surgical patients usin.pdf},
  journal = {British Journal of Surgery},
  number = {5}
}

@book{armitageEncyclopediaBiostatistics2005,
  title = {Encyclopedia of Biostatistics},
  author = {Armitage, Peter and Colton, Theodore},
  year = {2005},
  doi = {10.1002/0470011815},
  isbn = {978-0-470-01181-2},
  keywords = {\#nosource},
  number = {1}
}

@article{assessmentStralbehandlingVidCancer2003,
  title = {Str\aa lbehandling Vid Cancer: {{En}} Systematisk Litteratur\"oversikt {{SBU}}:S Styrelse Och R\aa d ({{SBU}})},
  author = {Assessment), Statens beredning f{\"o}r medicinsk utv{\"a}rdering (Swedish Council on Health Technology},
  year = {2003},
  keywords = {\#nosource}
}

@article{Asuero2006,
  title = {The Correlation Coefficient: {{An}} Overview},
  author = {Asuero, a. G. and Sayago, A. and Gonz{\'a}lez, a. G.},
  year = {2006},
  volume = {36},
  pages = {41--59},
  issn = {10408347},
  doi = {10.1080/10408340500526766},
  abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PEGAV467\\Asuero et al. - 2006 - The correlation coefficient An overview.pdf},
  isbn = {1040-8347},
  journal = {Critical Reviews in Analytical Chemistry},
  keywords = {cause and effect,Cause and effect inference,correlation coefficient,Correlation coefficient,covariance,Covariance,inference,lineariy,Lineariy,multiple correlation coefficient,Multiple correlation coefficient,significance tests,Significance tests},
  number = {1},
  pmid = {19702027}
}

@article{atifBenignTumoursTumour2018,
  title = {Benign Tumours and Tumour like Lesions of Bone},
  author = {Atif, Muhammad and Hasan, Obada Hussein Ali and Ashraf, Umair and Mustafa, Mohammad and Umer, Masood},
  year = {2018},
  volume = {68},
  abstract = {Over the last century, there has been a remarkable development in the study of benign bone tumours. This is primarily due to the improved knowledge of the nature of these lesions and improved imaging technology. They present as a diverse group of clinical and pathological entities, which vary in their clinical behaviour and aggressiveness and, hence, multidisciplinary approach is necessary in their management. Combined opinion from an orthopaedic surgeon, radiologist and a pathologist is therefore required. Incidence of these tumours is debatable because they are often asymptomatic. Many protocols have been reported in studies with respect to the management of these tumours based on the experience of different centres and different surgeons with no set guidelines. English-language studies, including case reports, case series and systemic reviews, from PubMed, ERIC, MEDLINE, EMBASE and Cochrane Reviews databases from 2002 to 2016 were included in the current. Articles reporting all levels of evidence-Level I to V-were included.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QQXA4KPI\\Atif et al. - 2018 - Benign tumours and tumour like lesions of bone.pdf},
  journal = {Journal of the Pakistan Medical Association},
  number = {10}
}

@article{Austin2004,
  title = {Bootstrap Methods for Developing Predictive Models},
  author = {Austin, Peter C and Tu, Jack V},
  year = {2004},
  month = may,
  volume = {58},
  pages = {131--137},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/0003130043277},
  abstract = {Researchers frequently use automated model selection methods such as backwards elimination to identify variables that are independent predictors of an outcome under consideration. We propose using ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VSSK5QRT\\Austin and Tu - 2004 - Bootstrap methods for developing predictive models.pdf},
  journal = {The American Statistician},
  number = {2}
}

@article{Austin2011,
  title = {An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies},
  author = {Austin, Peter C.},
  year = {2011},
  volume = {46},
  pages = {399--424},
  issn = {00273171},
  doi = {10.1080/00273171.2011.568786},
  abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IAPF9TD2\\Austin - 2011 - An introduction to propensity score methods for re.pdf},
  isbn = {0027-3171},
  journal = {Multivariate Behavioral Research},
  number = {3},
  pmid = {21818162}
}

@article{Austin2014,
  title = {The Use of Propensity Score Methods with Survival or Time-to-Event Outcomes: Reporting Measures of Effect Similar to Those Used in Randomized Experiments: {{Propensity}} Scores and Survival Analysis},
  shorttitle = {The Use of Propensity Score Methods with Survival or Time-to-Event Outcomes},
  author = {Austin, Peter C.},
  year = {2014},
  month = mar,
  volume = {33},
  pages = {1242--1258},
  issn = {02776715},
  doi = {10.1002/sim.5984},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5Q2WABQU\\Austin - 2014 - The use of propensity score methods with survival .pdf},
  journal = {Statistics in Medicine},
  keywords = {simonsson},
  language = {en},
  number = {7}
}

@article{Austin2015,
  title = {Why Summary Comorbidity Measures Such as the Charlson Comorbidity Index and Elixhauser Score Work},
  author = {Austin, Steven R and Wong, Yu-ning and Uzzo, Robert G and Beck, J Robert and Egleston, Brian L},
  year = {2015},
  volume = {53},
  pages = {65--72},
  journal = {Medical Care},
  keywords = {\#nosource,53,charlson comorbidity index,comorbidity adjustment,comorbidity summary,e65,e72,elixhauser score,kidney cancer,measures,med care 2015,prognostic models,seer-medicare},
  number = {9}
}

@article{Austin2016,
  title = {Introduction to the Analysis of Survival Data in the Presence of Competing Risks},
  author = {Austin, Peter C and Lee, Douglas S and Fine, Jason P},
  year = {2016},
  month = feb,
  edition = {2016/02/08},
  volume = {133},
  pages = {601--609},
  publisher = {{Lippincott Williams \& Wilkins}},
  issn = {1524-4539},
  doi = {10.1161/CIRCULATIONAHA.115.017719},
  abstract = {Competing risks occur frequently in the analysis of survival data. A competing risk is an event whose occurrence precludes the occurrence of the primary event of interest. In a study examining time to death attributable to cardiovascular causes, death attributable to noncardiovascular causes is a competing risk. When estimating the crude incidence of outcomes, analysts should use the cumulative incidence function, rather than the complement of the Kaplan-Meier survival function. The use of the Kaplan-Meier survival function results in estimates of incidence that are biased upward, regardless of whether the competing events are independent of one another. When fitting regression models in the presence of competing risks, researchers can choose from 2 different families of models: modeling the effect of covariates on the cause-specific hazard of the outcome or modeling the effect of covariates on the cumulative incidence function. The former allows one to estimate the effect of the covariates on the rate of occurrence of the outcome in those subjects who are currently event free. The latter allows one to estimate the effect of covariates on the absolute risk of the outcome over time. The former family of models may be better suited for addressing etiologic questions, whereas the latter model may be better suited for estimating a patient's clinical prognosis. We illustrate the application of these methods by examining cause-specific mortality in patients hospitalized with heart failure. Statistical software code in both R and SAS is provided.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TQJ73JVJ\\Austin et al. - 2016 - Introduction to the analysis of survival data in t.pdf},
  journal = {Circulation},
  number = {6}
}

@article{Austin2017,
  title = {A Tutorial on Multilevel Survival Analysis: {{Methods}}, Models and Applications},
  author = {Austin, Peter C.},
  year = {2017},
  month = aug,
  volume = {85},
  pages = {185--203},
  issn = {03067734},
  doi = {10.1111/insr.12214},
  abstract = {Data that have a multilevel structure occur frequently across a range of disciplines, including epidemiology, health services research, public health, education and sociology. We describe three families of regression models for the analysis of multilevel survival data. First, Cox proportional hazards models with mixed effects incorporate cluster-specific random effects that modify the baseline hazard function. Second, piecewise exponential survival models partition the duration of follow-up into mutually exclusive intervals and fit a model that assumes that the hazard function is constant within each interval. This is equivalent to a Poisson regression model that incorporates the duration of exposure within each interval. By incorporating cluster-specific random effects, generalised linear mixed models can be used to analyse these data. Third, after partitioning the duration of follow-up into mutually exclusive intervals, one can use discrete time survival models that use a complementary log\textendash log generalised linear model to model the occurrence of the outcome of interest within each interval. Random effects can be incorporated to account for within-cluster homogeneity in outcomes. We illustrate the application of these methods using data consisting of patients hospitalised with a heart attack. We illustrate the application of these methods using three statistical programming languages (R, SAS and Stata).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B7VVSPIB\\Austin - 2017 - A tutorial on multilevel survival analysis Method.pdf},
  journal = {International Statistical Review},
  keywords = {Clustered data,Cox proportional hazards model,Event history models,Frailty models,Health services research,Hierarchical regression model,Multilevel models,Statistical software,Survival analysis},
  number = {2},
  pmid = {29307954}
}

@article{Austin2017,
  title = {Events per Variable ({{EPV}}) and the Relative Performance of Different Strategies for Estimating the out-of-Sample Validity of Logistic Regression Models.},
  author = {Austin, Peter C and Steyerberg, Ewout W},
  year = {2017},
  volume = {26},
  pages = {796--808},
  publisher = {{SAGE Publications}},
  issn = {1477-0334},
  doi = {10.1177/0962280214558972},
  abstract = {We conducted an extensive set of empirical analyses to examine the effect of the number of events per variable (EPV) on the relative performance of three different methods for assessing the predictive accuracy of a logistic regression model: apparent performance in the analysis sample, split-sample validation, and optimism correction using bootstrap methods. Using a single dataset of patients hospitalized with heart failure, we compared the estimates of discriminatory performance from these methods to those for a very large independent validation sample arising from the same population. As anticipated, the apparent performance was optimistically biased, with the degree of optimism diminishing as the number of events per variable increased. Differences between the bootstrap-corrected approach and the use of an independent validation sample were minimal once the number of events per variable was at least 20. Split-sample assessment resulted in too pessimistic and highly uncertain estimates of model performance. Apparent performance estimates had lower mean squared error compared to split-sample estimates, but the lowest mean squared error was obtained by bootstrap-corrected optimism estimates. For bias, variance, and mean squared error of the performance estimates, the penalty incurred by using split-sample validation was equivalent to reducing the sample size by a proportion equivalent to the proportion of the sample that was withheld for model validation. In conclusion, split-sample validation is inefficient and apparent performance is too optimistic for internal validation of regression-based prediction models. Modern validation methods, such as bootstrap-based optimism correction, are preferable. While these findings may be unsurprising to many statisticians, the results of the current study reinforce what should be considered good statistical practice in the development and validation of clinical prediction models.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EDSHJ5JQ\\Austin and Steyerberg - 2017 - Events per variable (EPV) and the relative perform.pdf},
  journal = {Statistical methods in medical research},
  keywords = {bootstrap,c-statistic,clinical prediction models,data splitting,discrimination,logistic regression,model validation,receiver operating characteristic curve},
  number = {2},
  pmid = {25411322}
}

@article{authoritySyfteOchBakgrund2011,
  title = {Syfte Och Bakgrund till Fr\aa gorna i Nationella Folkh\"alsoenk\"aten},
  author = {Authority, Swedish Public Health},
  year = {2011},
  pages = {110},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R7HCQ2HE\\Authority - 2011 - Syfte och bakgrund till frågorna i nationella folk.pdf},
  isbn = {9789172578432},
  keywords = {folkhälsoenkät,hälsa på lika villkor,nationell}
}

@article{Azarang2015,
  title = {The {{Jackknife}} Estimate of Covariance of Two {{Kaplan}}\textendash{{Meier}} Integrals with Covariables},
  author = {Azarang, Leyla and {de U{\~n}a-{\'A}lvarez}, Jacobo and Stute, Winfried},
  year = {2015},
  volume = {49},
  pages = {1005--1025},
  issn = {10294910},
  doi = {10.1080/02331888.2014.960871},
  abstract = {In this paper the Jackknife estimate of covariance of two Kaplan\textendash Meier integrals with covariates is introduced. Its strong consistency is established under mild conditions. Several applications of the estimator are discussed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\N6DQ8F4H\\Azarang et al. - 2015 - The Jackknife estimate of covariance of two Kaplan.pdf},
  journal = {Statistics},
  keywords = {censored data,Kaplan–Meier,reverse-time submartingale,strong consistency,survival analysis},
  number = {5}
}

@article{Baadsgaard2011,
  title = {Danish Registers on Personal Income and Transfer Payments},
  author = {Baadsgaard, Mikkel and Quitzau, Jarl},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {103--105},
  issn = {14034948},
  doi = {10.1177/1403494811405098},
  abstract = {Introduction: The Income Statistics Register provided by Statistics Denmark is the key register describing the income composition of the entire Danish population starting in 1970. Content: The register contains more than 160 variables including salaries, entrepreneurial income, taxes, public transfer payments, capital income, private pension contributions, and payouts. In addition, Statistics Denmark provide more detailed registers on specific income transfers, including sickness benefit, old age pension, disability pension, and cash and unemployment benefits. Validity and coverage: The income data are generally of high quality, but for variables not relevant for administrators the quality may be lower. Conclusion: The registers on income and transfer payments include many variables on the income composition. \textcopyright{} 2011 the Nordic Societies of Public Health.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5VPIUZZY\\Baadsgaard and Quitzau - 2011 - Danish registers on personal income and transfer p.pdf},
  journal = {Scandinavian Journal of Public Health},
  keywords = {Denmark,disability benefits,income,living conditions,public transfers,socioeconomic status},
  number = {7}
}

@inproceedings{Bach2008,
  title = {Bolasso},
  author = {Bach, Francis R. and R., Francis},
  year = {2008},
  pages = {33--40},
  publisher = {{ACM Press}},
  doi = {10.1145/1390156.1390161},
  city = {New York, New York, USA},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2NYVXXG6\\Bach and R. - 2008 - Bolasso.pdf},
  isbn = {978-1-60558-205-4},
  series = {Proceedings of the 25th International Conference on {{Machine}} Learning - {{ICML}} '08}
}

@article{Baharev2008,
  title = {On the Computation of the Noncentral {{F}} and Noncentral Beta Distribution},
  author = {Baharev, Ali and Kem{\'e}ny, S{\'a}ndor},
  year = {2008},
  volume = {18},
  pages = {333--340},
  issn = {1573-1375},
  doi = {10.1007/s11222-008-9061-3},
  abstract = {Unfortunately many of the numerous algorithms for computing the comulative distribution function (cdf) and noncentrality parameter of the noncentral F and beta distributions can produce completely incorrect results as demonstrated in the paper by examples. Existing algorithms are scrutinized and those parts that involve numerical difficulties are identified. As a result, a pseudo code is presented in which all the known numerical problems are resolved. This pseudo code can be easily implemented in programming language C or FORTRAN without understanding the complicated mathematical background.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A57QDGZM\\Baharev and Kemény - 2008 - On the computation of the noncentral F and noncent.pdf},
  journal = {Statistics and Computing},
  number = {3}
}

@book{Balakrishan2007,
  title = {Advanced in Statistical Methods for the Helth Sciences},
  author = {Balakrishan, N. and Auget, J and Meshbah, M. and Molenberghs, G},
  year = {2007},
  isbn = {978-0-8176-4368-3},
  keywords = {\#nosource}
}

@article{Bangdiwala2010,
  title = {At Odds with Ratios},
  author = {Bangdiwala, Shrikant I.},
  year = {2010},
  month = mar,
  volume = {17},
  pages = {73--76},
  publisher = {{Taylor \& Francis}},
  issn = {1745-7300},
  doi = {10.1080/17457301003588229},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3M4N9JJ4\\Bangdiwala - 2010 - At odds with ratios.pdf;C\:\\Users\\erik_\\Zotero\\storage\\FV7299RM\\17457301003588229.html},
  journal = {International Journal of Injury Control and Safety Promotion},
  number = {1},
  pmid = {20182941}
}

@article{Baranowski2020,
  title = {Ranking-Based Variable Selection for High-Dimensional Data},
  author = {Baranowski, Rafal and Chen, Yining and Fryzlewicz, Piotr},
  year = {2020},
  issn = {10170405},
  doi = {10.5705/ss.202017.0139},
  abstract = {We propose Ranking-Based Variable Selection (RBVS), a technique aiming to identify vari-ables affecting the response in high-dimensional data. The RBVS algorithm uses subsampling to identify the set of covariates which non-spuriously appears at the top of a chosen variable rank-ing. We study the conditions under which such set is unique and show that it can be successfully recovered from the data by our procedure. Unlike the majority of the existing high-dimensional variable selection techniques, RBVS does not depend on any thresholding or regularity param-eters. Moreover, RBVS does not require any model restrictions on the relationship between the response and covariates, it is therefore widely applicable, both in a parametric and non-parametric context. We illustrate its good practical performance in a comparative simulation study and on real data. The RBVS algorithm is implemented in the publicly available R package rbvs.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UTRTRKZ6\\Baranowski et al. - 2020 - Ranking-based variable selection for high-dimensio.pdf},
  journal = {Statistica Sinica}
}

@article{Barbiero2016,
  title = {An {{R}} Package for the Simulation of Correlated Discrete Variables},
  author = {Barbiero, Alessandro and Ferrari, Pier Alda},
  year = {2016},
  volume = {46},
  pages = {0--0},
  issn = {15324141},
  doi = {10.1080/03610918.2016.1146758},
  abstract = {A package for the stochastic simulation of discrete variables with assigned marginal distributions and correlation matrix is presented and discussed. The simulating mechanism relies upon the Gaussian copula, linking the discrete distributions together, and an iterative scheme recovering the correlation matrix for the copula that ensures the desired correlations among the discrete variables. Examples of its use are provided as well as three possible applications (related to probability, sampling, and inference), which illustrate the utility of the package as an efficient and easy-to-use tool both in statistical research and for didactic purposes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3YT5M6FU\\Barbiero and Ferrari - 2016 - An R package for the simulation of correlated disc.pdf},
  journal = {Communications in Statistics: Simulation and Computation},
  keywords = {Correlation matrix,Gaussian copula,Multivariate discrete distribution},
  number = {7}
}

@article{barclay-goddardResponseShiftBrief2009,
  title = {Response Shift: {{A}} Brief Overview and Proposed Research Priorities},
  author = {{Barclay-Goddard}, Ruth and Epstein, Joshua D. and Mayo, Nancy E.},
  year = {2009},
  volume = {18},
  pages = {335--346},
  issn = {09629343},
  doi = {10.1007/s11136-009-9450-x},
  abstract = {AIM: The objective of this overview is to review current methodologies of response shift research in patient-reported outcomes to facilitate and stimulate further research in this area. METHODS: This paper is a narrative overview of research in response shift. RESULTS: The following research priorities emerged: (1) obtain a consensus on terminology and theoretical models used, to ensure that all researchers and clinicians are at the same starting point; (2) determine the clinical importance of response shift; (3) determine the best way to measure and adjust for response shift as a clinically important confounder; (4) ascertain how response shift can best be identified when response shift is the focus of clinical treatment; and (5) establish what methods can be used to translate response shift knowledge into real-world settings. CONCLUSIONS: With the adoption of these research priorities, we anticipate that the theories and processes of response shift will be better understood, current methods to analyze this phenomenon will be improved while new ones may also be developed, and the clinical importance and impact of response shift in measuring changes in health-related quality of life (HRQL) will be determined.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EDTG5VT3\\Barclay-Goddard et al. - 2009 - Response shift A brief overview and proposed rese.pdf},
  isbn = {0962-9343 (Print)0962-9343 (Linking)},
  journal = {Quality of Life Research},
  keywords = {Patient-reported outcomes,Quality of life,Response shift},
  number = {3},
  pmid = {19241143}
}

@article{Barenius2018,
  title = {A Randomized Controlled Trial of Cemented versus Cementless Arthroplasty in Patients with a Displaced Femoral Neck Fracture},
  author = {Barenius, B and Inngul, C and Alagic, Z and Enocson, A and Enocson, A},
  year = {2018},
  volume = {100},
  pages = {1087--93},
  issn = {2049-4408},
  doi = {10.1302/0301-620X.100B8},
  abstract = {Aims The aim of this study was to compare the functional and radiological outcomes in patients with a displaced fracture of the hip who were treated with a cemented or a cementless femoral stem. Patients and Methods A four-year follow-up of a randomized controlled study included 141 patients who underwent surgery for a displaced femoral neck fracture. Patients were randomized to receive either a cemented (n = 67) or a cementless (n = 74) stem at hemiarthroplasty (HA; n = 83) or total hip arthroplasty (THA; n = 58). Results Early differences in functional outcome, assessed using the Harris Hip Score, the Short Musculoskeletal Functional Assessment score and EuroQol-5D, with better results in cemented group, deteriorated over time and there were no statistically significant differences at 48 months. Two (3\%) patients in the cemented group and five (6.8\%) in the cementless group underwent further surgery for a periprosthetic fracture. This difference was statistically significant (p = 0.4). No patient underwent further surgery for instability or infection between one and four years postoperatively. The mortality and the radiological outcomes were similar in both groups. Conclusion Patients with a displaced femoral neck fracture treated with an arthroplasty using a cemented or cementless stem had good function and few complications up to four years postoperatively. However, due to the poor short-term functional outcomes in the cementless group, the findings do not support their routine use in the treatment of these elderly patients.},
  isbn = {2049-4408 (Electronic)},
  journal = {Bone Joint J},
  keywords = {\#nosource},
  number = {8},
  pmid = {26530648}
}

@article{Barlow2009,
  title = {The Completeness of the {{Swedish Cancer Register}} \textendash{} a Sample Survey for Year 1998},
  author = {Barlow, Lotti and Westergren, Kerstin and Holmberg, Lars and Talb{\"a}ck, Mats},
  year = {2009},
  month = jan,
  volume = {48},
  pages = {27--33},
  publisher = {{Taylor \& Francis}},
  issn = {0284-186X},
  doi = {10.1080/02841860802247664},
  abstract = {Introduction. The Swedish Cancer Register (SCR) is used extensively for monitoring cancer incidence and survival and for research purposes. Completeness and reliability of cancer registration are thus of great importance for all types of use of the cancer register. The aim of the study was to estimate the overall coverage of malignant cancer cases in 1998 and to reveal possible reasons behind non-reporting. Methods. We selected all malignant cancer cases in the Hospital Discharge Register (HDR) from 1998 and compared these records to those reported to the SCR. There were 43 761 discharges for 42 010 individuals of whom 3 429 individuals were not recorded in the SCR. From these 3 429 records we randomly selected 202 patients for review of their medical records to determine whether they should have been registered on the SCR as incident cases in 1998. Results. About half of the 202 cases (93 malignant and 8 benign) should have been reported, which translates into an additional 1 579 malignant cases (95\% CI ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JB26R9HC\\Barlow et al. - 2009 - The completeness of the Swedish Cancer Register – .pdf},
  journal = {Acta Oncologica},
  number = {1}
}

@article{Barrett1974,
  title = {The Coefficient of {{Determination}}\textemdash{{Some}} Limitations},
  author = {Barrett, James P},
  year = {1974},
  month = feb,
  volume = {28},
  pages = {19--20},
  issn = {0003-1305},
  doi = {10.1080/00031305.1974.10479056},
  abstract = {Many scientists find the coefficient of determination (squared multiple correlation coefficient) a useful index in regression analyses. As with most indices, however, too much can be read into the coefficient of determination. Some scientists use it as a measure of ``usefulness'' or ``goodness of fit'' of a regression equation. Actuzlly the coefficient of determination only partially measures the usefulness of a regression equation; it also only partially measures goodness of fit in the sense of how close data points fit the regression surface. Examples are given illustrating the limits of the coefficient of determination and suggesting that graphs and confidence intervals me needed in a more complete evaluation of a regression equation.},
  isbn = {00031305},
  journal = {The American Statistician},
  keywords = {\#nosource},
  number = {1}
}

@article{Barrett1974,
  title = {The Coefficient of Determination-Some Limitations},
  author = {Barrett, James P},
  year = {1974},
  volume = {28},
  pages = {19--20},
  journal = {The Am},
  keywords = {\#nosource},
  number = {1}
}

@article{Barrowman2019,
  title = {How Unmeasured Confounding in a Competing Risks Setting Can Affect Treatment Effect Estimates in Observational Studies},
  author = {Barrowman, Michael Andrew and Peek, Niels and Lambie, Mark and Martin, Glen Philip and Sperrin, Matthew},
  year = {2019},
  month = jul,
  volume = {19},
  pages = {166},
  publisher = {{NLM (Medline)}},
  issn = {14712288},
  doi = {10.1186/s12874-019-0808-7},
  abstract = {BACKGROUND: Analysis of competing risks is commonly achieved through a cause specific or a subdistribution framework using Cox or Fine \& Gray models, respectively. The estimation of treatment effects in observational data is prone to unmeasured confounding which causes bias. There has been limited research into such biases in a competing risks framework. METHODS: We designed simulations to examine bias in the estimated treatment effect under Cox and Fine \& Gray models with unmeasured confounding present. We varied the strength of the unmeasured confounding (i.e. the unmeasured variable's effect on the probability of treatment and both outcome events) in different scenarios. RESULTS: In both the Cox and Fine \& Gray models, correlation between the unmeasured confounder and the probability of treatment created biases in the same direction (upward/downward) as the effect of the unmeasured confounder on the event-of-interest. The association between correlation and bias is reversed if the unmeasured confounder affects the competing event. These effects are reversed for the bias on the treatment effect of the competing event and are amplified when there are uneven treatment arms. CONCLUSION: The effect of unmeasured confounding on an event-of-interest or a competing event should not be overlooked in observational studies as strong correlations can lead to bias in treatment effect estimates and therefore cause inaccurate results to lead to false conclusions. This is true for cause specific perspective, but moreso for a subdistribution perspective. This can have ramifications if real-world treatment decisions rely on conclusions from these biased results. Graphical visualisation to aid in understanding the systems involved and potential confounders/events leading to sensitivity analyses that assumes unmeasured confounders exists should be performed to assess the robustness of results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6LLK5TFL\\Barrowman et al. - 2019 - How unmeasured confounding in a competing risks se.pdf},
  journal = {BMC medical research methodology},
  keywords = {Competing risks,Observation studies,Simulation study,Unmeasured confounding},
  number = {1}
}

@article{Barsom2016,
  title = {Systematic Review on the Effectiveness of Augmented Reality Applications in Medical Training},
  author = {Barsom, E. Z. and Graafland, M. and Schijven, M. P.},
  year = {2016},
  month = oct,
  volume = {30},
  pages = {4174--4183},
  publisher = {{Springer US}},
  issn = {0930-2794},
  doi = {10.1007/s00464-016-4800-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AYE9CSMN\\Barsom et al. - 2016 - Systematic review on the effectiveness of augmente.pdf},
  journal = {Surgical Endoscopy},
  number = {10}
}

@article{Bartko1966,
  title = {The Intraclass Correlation Coefficient as a Measure of Reliability.},
  author = {Bartko, John J.},
  year = {1966},
  volume = {19},
  pages = {3--11},
  issn = {0033-2941},
  doi = {10.2466/pr0.1966.19.1.3},
  abstract = {Discusses a procedure for estimating the reliability of sets of ratings in terms of the intraclass correlation coefficient, based upon analysis of variance and estimation of variance components. For the 1-way classification the intraclass correlation coefficient defined as the ratio of variances can be interpreted as a correlation coefficient. Caution, however, is urged in the application of the definition to a 2-way model, i.e., one in which between-rater variance is removed. It is maintained that the frequent use of the standard definition of the 1-way intraclass correlation coefficient applied to the 1-way classification is not a proper procedure if in fact the coefficient is to be interpreted as a correlation coefficient. Definitions for reliability obtained from the 2-way models are given which can legitimately be considered correlation coefficients. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  isbn = {0031-5125},
  journal = {Psychological reports},
  keywords = {\#nosource},
  number = {1},
  pmid = {5942109}
}

@article{Bayliss2017,
  title = {The Effect of Patient Age at Intervention on Risk of Implant Revision after Total Replacement of the Hip or Knee: A Population-Based Cohort Study},
  author = {Bayliss, Lee E and Culliford, David and Monk, A Paul and {Glyn-Jones}, Sion and {Prieto-Alhambra}, Daniel and Judge, Andrew and Cooper, Cyrus and Carr, Andrew J and Arden, Nigel K and Beard, David J and Price, Andrew J},
  year = {2017},
  month = apr,
  volume = {389},
  pages = {1424--1430},
  publisher = {{Elsevier}},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(17)30059-4},
  abstract = {BACKGROUND Total joint replacements for end-stage osteoarthritis of the hip and knee are cost-effective and demonstrate significant clinical improvement. However, robust population based lifetime-risk data for implant revision are not available to aid patient decision making, which is a particular problem in young patient groups deciding on best-timing for surgery. METHODS We did implant survival analysis on all patients within the Clinical Practice Research Datalink who had undergone total hip replacement or total knee replacement. These data were adjusted for all-cause mortality with data from the Office for National Statistics and used to generate lifetime risks of revision surgery based on increasing age at the time of primary surgery. FINDINGS We identified 63 158 patients who had undergone total hip replacement and 54 276 who had total knee replacement between Jan 1, 1991, and Aug 10, 2011, and followed up these patients to a maximum of 20 years. For total hip replacement, 10-year implant survival rate was 95{$\cdot$}6\% (95\% CI 95{$\cdot$}3\textendash 95{$\cdot$}9) and 20-year rate was 85{$\cdot$}0\% (83{$\cdot$}2\textendash 86{$\cdot$}6). For total knee replacement, 10-year implant survival rate was 96{$\cdot$}1\% (95{$\cdot$}8\textendash 96{$\cdot$}4), and 20-year implant survival rate was 89{$\cdot$}7\% (87{$\cdot$}5\textendash 91{$\cdot$}5). The lifetime risk of requiring revision surgery in patients who had total hip replacement or total knee replacement over the age of 70 years was about 5\% with no difference between sexes. For those who had surgery younger than 70 years, however, the lifetime risk of revision increased for younger patients, up to 35\% (95\% CI 30{$\cdot$}9\textendash 39{$\cdot$}1) for men in their early 50s, with large differences seen between male and female patients (15\% lower for women in same age group). The median time to revision for patients who had surgery younger than age 60 was 4{$\cdot$}4 years. INTERPRETATION Our study used novel methodology to investigate and offer new insight into the importance of young age and risk of revision after total hip or knee replacement. Our evidence challenges the increasing trend for more total hip replacements and total knee replacements to be done in the younger patient group, and these data should be offered to patients as part of the shared decision making process. FUNDING Oxford Musculoskeletal Biomedical Research Unit, National Institute for Health Research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GA8VW4DY\\Bayliss et al. - 2017 - The effect of patient age at intervention on risk .pdf},
  journal = {The Lancet},
  number = {10077}
}

@article{beaulieu-jonesReproducibilityComputationalWorkflows2017,
  title = {Reproducibility of Computational Workflows Is Automated Using Continuous Analysis},
  author = {{Beaulieu-Jones}, Brett K and Greene, Casey S},
  year = {2017},
  month = apr,
  volume = {35},
  pages = {342--346},
  publisher = {{Nature Publishing Group}},
  issn = {1087-0156},
  doi = {10.1038/nbt.3780},
  abstract = {The application of continuous integration, an approach common in software development, enables the automatic reproduction of computational analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MNTFL5K9\\Beaulieu-Jones and Greene - 2017 - Reproducibility of computational workflows is auto.pdf},
  journal = {Nature Biotechnology},
  keywords = {Data publication and archiving,Publishing,Software},
  number = {4}
}

@article{Becker1994,
  title = {A Brief History of s},
  author = {Becker, Richard A},
  year = {1994},
  institution = {{AT\&T Bell Laboratories}},
  city = {New Jersey},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GBF9RSVG\\Becker - 1994 - A brief history of s.pdf}
}

@article{Bell1997,
  title = {The ``Independent Components'' of Natural Scenes Are Edge Filters},
  author = {Bell, Anthony J. and Sejnowski, Terrence J.},
  year = {1997},
  month = dec,
  volume = {37},
  pages = {3327--3338},
  issn = {00426989},
  doi = {10.1016/S0042-6989(97)00121-1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\49J6DUQK\\Bell and Sejnowski - 1997 - The “independent components” of natural scenes are.pdf},
  journal = {Vision Research},
  number = {23}
}

@article{Bellera2010,
  title = {Variables with Time-Varying Effects and the {{Cox}} Model: Some Statistical Concepts Illustrated with a Prognostic Factor Study in Breast Cancer.},
  author = {a Bellera, Carine and MacGrogan, Ga{\"e}tan and Debled, Marc and {de Lara}, Christine Tunon and Brouste, V{\'e}ronique and {Mathoulin-P{\'e}lissier}, Simone},
  year = {2010},
  volume = {10},
  pages = {20},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-10-20},
  abstract = {BACKGROUND: The Cox model relies on the proportional hazards (PH) assumption, implying that the factors investigated have a constant impact on the hazard - or risk - over time. We emphasize the importance of this assumption and the misleading conclusions that can be inferred if it is violated; this is particularly essential in the presence of long follow-ups. METHODS: We illustrate our discussion by analyzing prognostic factors of metastases in 979 women treated for breast cancer with surgery. Age, tumour size and grade, lymph node involvement, peritumoral vascular invasion (PVI), status of hormone receptors (HRec), Her2, and Mib1 were considered. RESULTS: Median follow-up was 14 years; 264 women developed metastases. The conventional Cox model suggested that all factors but HRec, Her2, and Mib1 status were strong prognostic factors of metastases. Additional tests indicated that the PH assumption was not satisfied for some variables of the model. Tumour grade had a significant time-varying effect, but although its effect diminished over time, it remained strong. Interestingly, while the conventional Cox model did not show any significant effect of the HRec status, tests provided strong evidence that this variable had a non-constant effect over time. Negative HRec status increased the risk of metastases early but became protective thereafter. This reversal of effect may explain non-significant hazard ratios provided by previous conventional Cox analyses in studies with long follow-ups. CONCLUSIONS: Investigating time-varying effects should be an integral part of Cox survival analyses. Detecting and accounting for time-varying effects provide insights on some specific time patterns, and on valuable biological information that could be missed otherwise.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S5RXTVYP\\Bellera et al. - 2010 - Variables with time-varying effects and the Cox mo.pdf},
  isbn = {1471-2288},
  journal = {BMC medical research methodology},
  pmid = {20233435}
}

@article{Benchimol2015,
  title = {The {{REporting}} of Studies Conducted Using Observational Routinely-Collected Health Data ({{RECORD}}) Statement},
  author = {Benchimol, Eric I. and Smeeth, Liam and Guttmann, Astrid and Harron, Katie and Moher, David and Petersen, Irene and S\o rensen, Henrik T. and {von Elm}, Erik and Langan, Sin{\'e}ad M.},
  year = {2015},
  volume = {12},
  pages = {1--22},
  issn = {15491676},
  doi = {10.1371/journal.pmed.1001885},
  abstract = {Routinely collected health data, obtained for administrative and clinical purposes without specific a priori research goals, are increasingly used for research. The rapid evolution and availability of these data have revealed issues not addressed by existing reporting guidelines, such as Strengthening the Reporting of Observational Studies in Epidemiology (STROBE). The REporting of studies Conducted using Observational Routinely collected health Data (RECORD) statement was created to fill these gaps. RECORD was created as an extension to the STROBE statement to address reporting items specific to observational studies using routinely collected health data. RECORD consists of a checklist of 13 items related to the title, abstract, introduction, methods, results, and discussion section of articles, and other information required for inclusion in such research reports. This document contains the checklist and explanatory and elaboration information to enhance the use of the checklist. Examples of good reporting for each RECORD checklist item are also included herein. This document, as well as the accompanying website and message board (http://www.record-statement.org), will enhance the implementation and understanding of RECORD. Through implementation of RECORD, authors, journals editors, and peer reviewers can encourage transparency of research reporting.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\59QU4DWU\\Benchimol et al. - 2015 - The REporting of studies conducted using observati.pdf},
  isbn = {1549-1676 (Electronic)1549-1277 (Linking)},
  journal = {PLoS Medicine},
  number = {10},
  pmid = {26440803}
}

@article{Bengtsson2017,
  title = {Consistency in Patient-Reported Outcomes after Total Hip Replacement {{Consistency}} in Patient-Reported Outcomes after Total Hip {{A}} 6-Year Registry Follow-up of 15 , 755 Patients},
  author = {Bengtsson, Albin and Donahue, Gabrielle S and Nemes, Szilard and Garellick, G{\"o}ran},
  year = {2017},
  volume = {0},
  pages = {0--1},
  publisher = {{Informa UK Limited, trading as Taylor \& Francis Group}},
  issn = {1745-3674},
  doi = {10.1080/17453674.2017.1339541},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9MKI3K55\\Bengtsson et al. - 2017 - Consistency in patient-reported outcomes after tot.pdf},
  journal = {Acta Orthopaedica},
  number = {0}
}

@article{Benichou1990,
  title = {Estimates of Absolute Cause-Specific Risk in Cohort Studies},
  author = {Benichou, J and Gail, Mitchell H},
  year = {1990},
  volume = {46},
  pages = {813--826},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006341X, 15410420},
  doi = {10.2307/2532098},
  abstract = {In this paper we study methods for estimating the absolute risk of an event c1 in a time interval [t1, t2), given that the individual is at risk at t1 and given the presence of competing risks. We discuss some advantages of absolute risk for measuring the prognosis of an individual patient and some difficulties of interpretation for comparing two treatment groups. We also discuss the importance of the concept of absolute risk in evaluating public health measures to prevent disease. Variance calculations permit one to gauge the relative importance of random and systematic errors in estimating absolute risk. Efficiency calculations were also performed to determine how much precision is lost in estimating absolute risk with a nonparametric approach or with a flexible piecewise exponential model rather than a simple exponential model, and other calculations indicate the extent of bias that arises with the simple exponential model when that model is invalid. Such calculations suggest that the more flexible models will be useful in practice. Simulations confirm that asymptotic methods yield reliable variance estimates and confidence interval coverages in samples of practical size.},
  journal = {Biometrics},
  keywords = {\#nosource},
  number = {3}
}

@article{Berbari2012,
  title = {The {{Mayo Prosthetic Joint Infection Risk Score}}: {{Implication}} for {{Surgical Site Infection Reporting}} and {{Risk Stratification}}},
  shorttitle = {The {{Mayo Prosthetic Joint Infection Risk Score}}},
  author = {Berbari, Elie F. and Osmon, Douglas R. and Lahr, Brian and {Eckel-Passow}, Jeanette E. and Tsaras, Geoffrey and Hanssen, Arlen D. and Mabry, Tad and Steckelberg, James and Thompson, Rodney},
  year = {2012},
  month = aug,
  volume = {33},
  pages = {774--781},
  issn = {0899-823X, 1559-6834},
  doi = {10.1086/666641},
  abstract = {Objective.
              The goal of this study was to develop a prognostic scoring system for the development of prosthetic joint infection (PJI) that could risk-stratify patients undergoing total hip (THA) or total knee (TKA) arthroplasties.
            
            
              Design.
              Previously reported case-control study.
            
            
              Setting.
              Tertiary referral care setting from 2001 through 2006.
            
            
              Methods.
              A derivation data set of 339 cases and 339 controls was used to develop 2 scores. A baseline score and a 1-month-postsurgery risk score were computed as a function of the relative contributions of risk factors for each model. Points were assigned for the presence of each factor and then summed to get a subject's risk score.
            
            
              Results.
              
                The following risk factors were detected from multivariable modeling and incorporated into the baseline Mayo PJI risk score: body mass index, prior other operation on the index joint, prior arthroplasty, immunosuppression, ASA score, and procedure duration (c index, 0.722). The 1-month-postsurgery risk score contained the same variables in addition to postoperative wound drainage (
                c
                index, 0.716).
              
            
            
              Conclusion.
              The baseline score might help with risk stratification in relation to public reporting and reimbursement as well as targeted prevention strategies in patients undergoing THA or TKA. The application of the 1-month-postsurgery PJI risk score to patients undergoing THA or TKA might benefit those undergoing workup for PJI.},
  journal = {Infection Control \& Hospital Epidemiology},
  language = {en},
  number = {8}
}

@article{Berend2005,
  title = {Simultaneous Bilateral versus Unilateral Total Hip Arthroplasty: {{An}} Outcomes Analysis},
  author = {Berend, Michael E. and Ritter, Merrill A. and Harty, Leesa D. and Davis, Kenneth E. and Keating, E. Michael and Meding, John B. and Thong, Alan E.},
  year = {2005},
  month = jun,
  volume = {20},
  pages = {421--426},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2004.09.062},
  abstract = {This study compared the morbidity, mortality, and outcomes of 900 simultaneous bilateral total hip arthroplasties in 450 patients and 450 unilateral total hip arthroplasties. Pulmonary complications were significantly higher in the simultaneous bilateral group (1.6\% vs 0.7\%; P \textexclamdown{} .0312). Fourteen (3.1\%) patients in the simultaneous bilateral group and 18 (4\%) patients in the unilateral group died within the first postoperative year. Patients with mortality in the first postoperative year were significantly older (69.8 vs 62.3 years; P \textexclamdown{} .0012). Long-term patient survival, the prosthetic survival, and functional outcomes were not significantly different between groups. Simultaneous bilateral total hip arthroplasty has advantages where both hips are symptomatic and has less risk in younger patients with understanding of the increased risk of pulmonary complications.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GIQG6M7Q\\Berend et al. - 2005 - Simultaneous bilateral versus unilateral total hip.pdf},
  journal = {The Journal of Arthroplasty},
  number = {4}
}

@article{Berg2018,
  title = {No Increase in Readmissions or Adverse Events after Implementation of Fast-Track Program in Total Hip and Knee Replacement at 8 {{Swedish}} Hospitals: {{An}} Observational before-and-after Study of 14,148 Total Joint Replacements 2011\textendash 2015},
  shorttitle = {No Increase in Readmissions or Adverse Events after Implementation of Fast-Track Program in Total Hip and Knee Replacement at 8 {{Swedish}} Hospitals},
  author = {Berg, Urban and B{\"u}Low, Erik and Sundberg, Martin and Rolfson, Ola},
  year = {2018},
  month = sep,
  volume = {89},
  pages = {522--527},
  issn = {1745-3674, 1745-3682},
  doi = {10.1080/17453674.2018.1492507},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DGEL3HMS\\Berg m. fl. - 2018 - No increase in readmissions or adverse events afte.pdf},
  journal = {Acta Orthopaedica},
  keywords = {coder},
  language = {en},
  number = {5}
}

@article{Berliner2016,
  title = {Preoperative Patient-Reported Outcome Measures Predict Clinically Meaningful Improvement in Function after {{THA}}},
  author = {Berliner, Jonathan L and Ba, Dane J Brodke and Mph, Vanessa Chan and Soohoo, Nelson F and Bozic, Kevin J and Berliner, J L and Brodke, D J and Chan, V and Lee, Philip R and Soohoo, N F and Bozic, K J},
  year = {2016},
  volume = {474},
  pages = {321--329},
  publisher = {{Springer US}},
  doi = {10.1007/s11999-015-4350-6},
  abstract = {Background Despite the overall effectiveness of total hip arthroplasty (THA), a subset of patients remain dissatisfied with their results because of persistent pain or functional limitations. It is therefore important to develop predictive tools capable of identifying patients at risk for poor out-comes before surgery. Questions/purposes The purpose of this study was to use preoperative patient-reported outcome measure (PROM) scores to predict which patients undergoing THA are most likely to experience a clinically meaningful change in functional outcome 1 year after surgery. Methods A retrospective cohort study design was used to evaluate preoperative and 1-year postoperative SF-12 ver-sion 2 (SF12v2) and Hip Disability and Osteoarthritis Outcome Score (HOOS) scores from 537 selected patients who underwent primary unilateral THA. Minimum clini-cally important differences (MCIDs) were calculated using a distribution-based method. A receiver operating charac-teristic analysis was used to calculate threshold values, defined as the levels at which substantial changes occurred, and their predictive ability. MCID values for HOOS and SF12v2 physical component summary (PCS) scores were calculated to be 9.1 and 4.6, respectively. We analyzed the effect of SF12v2 mental component summary (MCS) scores, which measure mental and emotional health, on SF12v2 PCS and HOOS threshold values. Results Threshold values for preoperative HOOS and PCS scores were a maximum of 51.0 (area under the curve [AUC], 0.74; p  0.001) and 32.5 (AUC, 0.62; p  0.001), respectively. As preoperative mental and emotional health improved, which was reflected by a higher MCS score, HOOS and PCS threshold values also increased. When preoperative mental and emotional health were taken into},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GVM7BL9E\\Berliner et al. - 2016 - Preoperative patient-reported outcome measures pre.pdf},
  isbn = {0009-921x},
  journal = {Clinical Orthopaedics and Related Research},
  pmid = {26201420}
}

@article{Bernardini2016,
  title = {Comorbidity Indices Disillusion},
  author = {Bernardini, Bruno and Fracchia, Stefania},
  year = {2016},
  volume = {71},
  pages = {114--115},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2015.05.014},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YT7MN4LD\\Bernardini and Fracchia - 2016 - Comorbidity indices disillusion.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@article{Betensky2015,
  title = {Measures of {{Follow}}-up in {{Time}}-to-{{Event Studies}}: {{Why}} Provide Them and What Should They Be?},
  author = {Betensky, Rebecca A},
  year = {2015},
  volume = {12},
  pages = {403--408},
  doi = {10.1016/S2214-109X(16)30265-0.Cost-effectiveness},
  isbn = {1740774515},
  journal = {Clinical Trials},
  keywords = {\#nosource},
  number = {4}
}

@article{Bhan2006,
  title = {One- or Two-Stage Bilateral Total Hip Arthroplasty},
  author = {Bhan, S. and Pankaj, A. and Malhotra, R.},
  year = {2006},
  month = mar,
  volume = {88-B},
  pages = {298--303},
  publisher = {{The British Editorial Society of Bone and Joint Surgery}},
  issn = {0301-620X},
  doi = {10.1302/0301-620X.88B3.17048},
  abstract = {We compared the safety and outcome of one-stage bilateral total hip arthroplasty with those of a two-stage procedure during different admissions in a prospective, randomised controlled trial in an Asian population. Of 168 patients included in the study, 83 had a single- and 85 a two-stage procedure. Most of the patients (59.9\%) suffered from inflammatory arthritis.The intra-operative complications, early systemic complications, the operating time, positioning of the components, the functional score, restoration of limb length and survival rates at 96 months were similar in the two groups. The total estimated blood loss was significantly lower in patients undergoing a one-stage procedure than in patients who had a two-stage procedure, but the transfusion requirements were significantly higher in the former group (p = 0.001). The hospital stay was significantly shorter in the one-stage group, 7.25 days (sd 1.30; 5 to 20) compared with 10 days (sd 1.65; 8 to 24) in the two-stage group (p = 0.023). We believe...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WGVE4JZJ\\Bhan et al. - 2006 - One- or two-stage bilateral total hip arthroplasty.pdf},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  number = {3}
}

@book{Bickel2005,
  title = {Permutation, Parametric and Bootstrap Tests of Hypotheses},
  author = {Bickel, P and Diggle, P and Fienberg, S and Gather, U and Olkin, I and Zeger, S},
  year = {2005},
  issn = {0162-1459},
  doi = {10.1007/b138696},
  abstract = {Review From the reviews of the third edition: "All told, Permutation, Parametric, and Bootstrap Tests of Hypotheses garners high marks for its scope and clarity. Graduate students will appreciate its rigorous treatment of diverse topics and ample exercises to reinforce ideas...this text deserves a place in any scientific library." Journal of the American Statistical Association, December 2005 "The book provides a good overview of hypotheses testing and decision theory. a The book is well-written, concise and clearly organized. Many examples and figures illustrate the text. Each chapter is concluded by numerous exercises a to make the fundamental concepts more comprehensive. a My overall impression of the book is very positive. a the book is a valuable supplement to the existing literature and can be recommended to both practitioners and researchers in statistics." (Bernd Droge, Metrika, Vol. 64, 2006) "This is the third edition of a well known and respected book by Good. a provides a very good overview on decision theory and hypothesis testing. It is well written and does cover permutation, parametric and bootstrap techniques very effectively. I would recommend this book for the statisticians as well as biostatisticians to practice the methodologies provided in this book. This book will be of interest to graduate students in statistics and biostatistics. In addition, this book would be a valuable asset for the library." (B. M. Golam Kibria, Statistical Papers, Vol. 47, 2006) "Although this third edition has only 45 more pages a the change in title suggests a change in focus from mainly dealing with permutation tests to put equal weight on parametric and bootstraptests of hypotheses. a It would be excellent as a supplemental text on testing hypotheses and decision theory a . it is excellent for those who want to learn about or to apply permutation methods a . It also has a good general overview of hypotheses testing and decision theory." (Andreas Karlsson, Journal of the Royal Statistical Society, Vol. 169 (1), 2006) "This is the third edition of a well known and highly praised book. a It a also includes material on parametric and bootstrap tests but permutation tests take the centerstage. This revised edition has been enlarged by about 25 pages. a The number of exercises has been greatly increased. More interestingly, some of the essential results have now been given in the form of exercises." (Arup Bose, Sankhya, Vol. 67 (1), 2005) "From the start of the journey into testing hypotheses a the book refers to the authora (TM)s personal experience. a This is supposed to benefit the students, instructors and autodidacts a . the book is intended for a two-semester graduate course on hypotheses testing and decision theory. a to the best of judgment, it is a very interesting, profound, modern and useful book." (Gaj Vidmar, ISCB News, Vol. 144 (2), 2007) "In this book the author explores the use of computational methods for hypothesis testing, and he describes the great advantages that make these methods the most powerful tools among statistical procedures. a The book is clear, readable and very well focused a . This is a book for graduate students and scientists. Practitioners can also take great advantage of it a . In my view, this book should be present in all statistics departments and university libraries." (AnaF. Militino, Journal of Applied Statistics, Vol. 34 (10), 2007) Product Description Explains the necessary background in testing hypothesis and decision theory to enable innumerable practical applications of statistics. This book includes many real-world illustrations from biology, business, clinical trials, economics, geology, law, medicine, social science and engineering along with twice the number of exercises.},
  isbn = {0-387-20279-X},
  keywords = {\#nosource},
  pmid = {13591773}
}

@article{Bilder2007,
  title = {Modeling Association between Two or More Categorical Variables That Allow for Multiple Category Choices},
  author = {Bilder, Christopher R. and Loughin, Thomas M.},
  year = {2007},
  volume = {36},
  pages = {433--451},
  issn = {03610926},
  doi = {10.1080/03610920600974419},
  abstract = {Multiple-response (or pick any/c) categorical variables summarize responses to survey questions that ask ``pick any'' from a set of item responses. Extensions to loglinear model methodology are proposed to model associations between these variables across all their items simultaneously. Because individual item responses to a multiple-response categorical variable are likely to be correlated, the usual chi-square distributional approximations for model-comparison statistics are not appropriate. Adjusted statistics and a new bootstrap procedure are developed to facilitate distributional approximations. Odds ratio and standardized Pearson residual measures are also developed to estimate specific associations and examine deviations from a specified model.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AIQ6JCAG\\Bilder and Loughin - 2007 - Modeling association between two or more categoric.pdf},
  journal = {Communications in Statistics - Theory and Methods},
  keywords = {Bootstrap,Correlated binary data,Generalized loglinear model,Marginal model,Multiple-response categorical variable,Pick any/c},
  number = {2}
}

@article{Bind2016,
  title = {Causal Mediation Analysis for Longitudinal Data with Exogenous Exposure},
  author = {Bind, M. A.C. and Vanderweele, T. J. and Coull, B. A. and Schwartz, J. D.},
  year = {2016},
  volume = {17},
  pages = {122--134},
  issn = {14684357},
  doi = {10.1093/biostatistics/kxv029},
  abstract = {Mediation analysis is a valuable approach to examine pathways in epidemiological research. Prospective cohort studies are often conducted to study biological mechanisms and often collect longitudinal measurements on each participant. Mediation formulae for longitudinal data have been developed. Here, we formalize the natural direct and indirect effects using a causal framework with potential outcomes that allows for an interaction between the exposure and the mediator. To allow different types of longitudinal measures of the mediator and outcome, we assume two generalized mixed-effects models for both the mediator and the outcome. The model for the mediator has subject-specific random intercepts and random exposure slopes for each cluster, and the outcome model has random intercepts and random slopes for the exposure, the mediator, and their interaction. We also expand our approach to settings with multiple mediators and derive the mediated effects, jointly through all mediators. Our method requires the absence of time-varying confounding with respect to the exposure and the mediator. This assumption is achieved in settings with exogenous exposure and mediator, especially when exposure and mediator are not affected by variables measured at earlier time points. We apply the methodology to data from the Normative Aging Study and estimate the direct and indirect effects, via DNA methylation, of air pollution, and temperature on intercellular adhesion molecule 1 (ICAM-1) protein levels. Our results suggest that air pollution and temperature have a direct effect on ICAM-1 protein levels (i.e. not through a change in ICAM-1 DNA methylation) and that temperature has an indirect effect via a change in ICAM-1 DNA methylation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YKMG5N3X\\Bind et al. - 2016 - Causal mediation analysis for longitudinal data wi.pdf},
  isbn = {1465-4644},
  journal = {Biostatistics},
  keywords = {Causal mediation analysis,Generalized mixed-effects model,Longitudinal data.},
  number = {1},
  pmid = {26272993}
}

@article{Bjorgul2010,
  title = {Evaluating Comorbidities in Total Hip and Knee Arthroplasty: Available Instruments.},
  author = {Bjorgul, Kristian and Novicoff, Wendy M. and Saleh, Khaled J.},
  year = {2010},
  volume = {11},
  pages = {203--209},
  issn = {15909999},
  doi = {10.1007/s10195-010-0115-x},
  abstract = {Each year millions of patients are treated for joint pain with total joint arthroplasty, and the numbers are expected to rise. Comorbid disease is known to influence the outcome of total joint arthroplasty, and its documentation is therefore of utmost importance in clinical evaluation of the individual patient as well as in research. In this paper, we examine the various methods for obtaining and assessing comorbidity information for patients undergoing joint replacement. Multiple instruments are reliable and validated for this purpose, such as the Charlson Index, Index of Coexistent Disease, and the Functional Comorbidity Index. In orthopedic studies, the Charnley classification and the American Society of Anesthesiologists physical function score (ASA) are widely used. We recommend that a well-documented comorbidity index that incorporates some aspect of mental health is used along with other appropriate instruments to objectively assess the preoperative status of the patient.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NCQLUSNW\\Bjorgul et al. - 2010 - Evaluating comorbidities in total hip and knee art.pdf},
  isbn = {1590-9999},
  journal = {Journal of orthopaedics and traumatology},
  keywords = {hip á knee á,replacement á comorbidity á},
  number = {4},
  pmid = {21076850}
}

@article{bjorkWeightingExerciseSwedish1999,
  title = {The Weighting Exercise for the {{Swedish}} Version of the {{EuroQol}}},
  author = {Bj{\"o}rk, Stefan and Norinder, Anna},
  year = {1999},
  volume = {8},
  pages = {117--126},
  issn = {10579230},
  doi = {10.1002/(SICI)1099-1050(199903)8:2<117::AID-HEC402>3.0.CO;2-A},
  abstract = {The EuroQol weighting exercise consists of three parts. In the first, the respondents state their own health using five dimensions with three levels in each, and then they rate their own health state on a visual analogue scale. In the second part, respondents attach weights to some of the possible health states. The last part contains questions about background information. The present article presents such weights derived from a sample of the Swedish population. The sample of 1000 Swedish citizens was drawn randomly from a national address register. The overall response rate was 54.2\%, though 315 (31.5\%) of the responses were ultimately deemed usable. Most of the health states included in the weighting exercise were well-chosen. Most of them were represented by at least one of the respondents. The respondent characteristics that had any influence on the valuation of health states in the weighting exercise was rating of own health, age and level of education, where a higher rating of own health, higher age and lower level of education resulted in higher valuations.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NY5MRU2X\\Björk and Norinder - 1999 - The weighting exercise for the Swedish version of .pdf},
  isbn = {1057-9230 (Print){\r  }1057-9230 (Linking)},
  journal = {Health Economics},
  keywords = {EuroQol,Exercise,Sweden,Weighting},
  number = {2},
  pmid = {10342725}
}

@article{Blanche2013,
  title = {Estimating and Comparing Time-Dependent Areas under Receiver Operating Characteristic Curves for Censored Event Times with Competing Risks},
  author = {Blanche, Paul and Dartigues, Jean Fran{\c c}ois and {Jacqmin-Gadda}, H{\'e}l{\`e}ne},
  year = {2013},
  volume = {32},
  pages = {5381--5397},
  issn = {10970258},
  doi = {10.1002/sim.5958},
  abstract = {The area under the time-dependent ROC curve (AUC) may be used to quantify the ability of a marker to predict the onset of a clinical outcome in the future. For survival analysis with competing risks, two alternative definitions of the specificity may be proposed depending of the way to deal with subjects who undergo the competing events. In this work, we propose nonparametric inverse probability of censoring weighting estimators of the AUC corresponding to these two definitions, and we study their asymptotic properties. We derive confidence intervals and test statistics for the equality of the AUCs obtained with two markers measured on the same subjects. A simulation study is performed to investigate the finite sample behaviour of the test and the confidence intervals. The method is applied to the French cohort PAQUID to compare the abilities of two psychometric tests to predict dementia onset in the elderly accounting for death without dementia competing risk. The 'timeROC' R package is provided to make the methodology easily usable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3TCM2FP7\\Blanche et al. - 2013 - Estimating and comparing time-dependent areas unde.pdf},
  isbn = {0277-6715},
  journal = {Statistics in Medicine},
  keywords = {AUC,Competing risks,Discrimination,Inverse probability of censoring weighting,Prognosis,Survival analysis},
  number = {30},
  pmid = {24027076}
}

@generic{Bland1994,
  title = {Statistics {{Notes}}: {{Some}} Examples of Regression towards the Mean},
  author = {Bland, J. M. and Altman, D. G.},
  year = {1994},
  volume = {309},
  pages = {780},
  issn = {14685833},
  doi = {10.1136/bmj.309.6957.780},
  abstract = {We have previously shown that regression towards the mean occurs whenever we select an extreme group based on one variable and then measure another variable for that group (4 June, p 1499).1 The second group mean will be closer to the mean for all subjects than is the first, and the weaker the correlation between the two variables the bigger the effect will be. Regression towards the mean happens in many types of study. The study of heredity1 is just one. Once one becomes aware of the regression effect it seems to be everywhere. The following are just a few examples.to reduce high levels of a measurement - In clinical practice there are many measurements, such as weight, serum cholesterol concentration, or blood pressure, for which particularly high or low values are signs of underlying disease or risk factors for disease. People with extreme values of the measurement, such as high blood pressure, may be treated to bring their values closer to the mean. If they are measured again we will observe that the mean of the extreme group is now closer to the mean of the whole population - that is, it \ldots},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VZYELY4A\\Bland and Altman - 1994 - Statistics Notes Some examples of regression towa.pdf},
  isbn = {0959-8138 (Print)},
  journal = {Bmj},
  number = {6957},
  pmid = {7950567}
}

@article{Bland2007,
  title = {Misleading Confidence Intervals},
  author = {Bland, Martin},
  year = {2007},
  volume = {370},
  pages = {653},
  issn = {01406736},
  doi = {10.1016/S0140-6736(07)61333-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EZJMYAXQ\\Bland - 2007 - Misleading confidence intervals.pdf},
  journal = {Lancet},
  number = {9588},
  pmid = {17720008}
}

@article{Bleyer1990,
  title = {The Impact of Childhood Cancer on the {{United States}} and the World},
  author = {Bleyer, W A},
  year = {1990},
  month = nov,
  volume = {40},
  pages = {355--367},
  issn = {0007-9235},
  doi = {10.3322/canjclin.40.6.355},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3E68JMNX\\Bleyer - 1990 - The impact of childhood cancer on the United State.pdf},
  isbn = {0007-9235 (Print)0007-9235 (Linking)},
  journal = {CA: A Cancer Journal for Clinicians},
  keywords = {Adolescent,Child,Clinical Trials as Topic,Female,Humans,Infant,Life Expectancy,Medical Oncology,Neoplasms/epidemiology/*mortality,Preschool,Regression Analysis,Survival Analysis,United States/epidemiology},
  number = {6},
  pmid = {2121321}
}

@article{Bliemel2016,
  title = {Pre-Fracture Quality of Life Predicts 1-Year Survival in Elderly Patients with Hip Fracture\textemdash Development of a New Scoring System},
  author = {Bliemel, C. and Sielski, R. and Doering, B. and Dodel, R. and {Balzer-Geldsetzer}, M. and Ruchholtz, S. and Buecking, B.},
  year = {2016},
  volume = {27},
  pages = {1979--1987},
  publisher = {{Osteoporosis International}},
  issn = {14332965},
  doi = {10.1007/s00198-015-3472-8},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PEC8K3ZQ\\Bliemel et al. - 2016 - Pre-fracture quality of life predicts 1-year survi.pdf},
  journal = {Osteoporosis International},
  keywords = {1-year survival,Hip fracture,Prognostic score,Quality of life},
  number = {6}
}

@article{Bliese2013,
  title = {Multilevel Modeling in r (2.5)},
  author = {Bliese, Paul},
  year = {2013},
  pages = {88},
  issn = {0269-2163},
  doi = {10.1177/0269216316671280},
  abstract = {A Brief Introduction to R, the multilevel package and the nlme package},
  isbn = {0269216316},
  journal = {An Introduction to R Notes on R: A Programming Environment for Data Analysis and Graphics},
  keywords = {\#nosource},
  pmid = {27683475}
}

@book{Bobko2001,
  title = {A Review of the Correlation Coefficient and Its Properties},
  author = {Bobko, Philip},
  year = {2001},
  doi = {10.4135/9781412983815},
  abstract = {After reading this chapter, you should be able to : Explain what a correlation coefficient measures. Recognize a scatterplot and understand the direction or sign of the relationship. Understand the formula for the Pearson correlation, including where the important information is and the purpose of the denominator. Provide at least two situations where r not appropriate for describing a relationship. Given any particular value of r and the raw data, multiply one or both scales by 38.2 and still know the value of the correlation. Give examples of how outliers can increase or decrease a correlation. Critique the following statement: ``The correlation of .82 demonstrates that good supervisors cause increased worker productivity.'' Explain why range restriction generally reduces the magnitude of r . Discuss how different levels of analysis can affect r . Recognize factors that are important in interpreting the magnitude of r . Explain what r 2 Define ...},
  isbn = {Print ISBN: 9780761923039ISBN: 9781412983815},
  keywords = {\#nosource}
}

@article{Bodner2008,
  title = {What Improves with Increased Missing Data Imputations?},
  author = {Bodner, Todd E.},
  year = {2008},
  volume = {15},
  pages = {651--675},
  issn = {10705511},
  doi = {10.1080/10705510802339072},
  abstract = {http://www.informaworld.com/10.1080/10705510802339072using multiple imputation in the analysis of incomplete data, a prominent guideline suggestsmore than 10 imputed data values are seldom needed. This article calls into question theof this guideline and illustrates that important quantities (e.g., p values, confidencehalf-widths, and estimated fractions of missing information) suffer from substantialwith a small number of imputations. Substantively, a researcher can draw categoricallyconclusions about null hypothesis rejection, estimation precision, and missing informationdistinct multiple imputation runs for the same data and analysis with few imputations. Thisexplores the factors associated with this imprecision, demonstrates that precision improvesincreasing the number of imputations, and provides practical guidelines for choosing a reasonableof imputations to reduce imprecision for each of these quantities.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JMQGQ2CT\\Bodner - 2008 - What improves with increased missing data imputati.pdf},
  isbn = {1070-5511},
  journal = {Structural Equation Modeling},
  number = {4}
}

@article{Bohl2014,
  title = {Nationwide Inpatient Sample and National Surgical Quality Improvement Program Give Different Results in Hip Fracture Studies},
  author = {Bohl, Daniel D. and Basques, Bryce A. and Golinvaux, Nicholas S. and Baumgaertner, Michael R. and Grauer, Jonathan N.},
  year = {2014},
  volume = {472},
  pages = {1672--1680},
  issn = {15281132},
  doi = {10.1007/s11999-014-3559-0},
  abstract = {BACKGROUND: National databases are being used with increasing frequency to conduct orthopaedic research. However, there are important differences in these databases, which could result in different answers to similar questions; this important potential limitation pertaining to database research in orthopaedic surgery has not been adequately explored./PURPOSES: The purpose of this study was to explore the interdatabase reliability of two commonly used national databases, the Nationwide Inpatient Sample (NIS) and the National Surgical Quality Improvement Program (NSQIP), in terms of (1) demographics; (2) comorbidities; and (3) adverse events. In addition, using the NSQIP database, we identified (4) adverse events that had a higher prevalence after rather than before discharge, which has important implications for interpretation of studies conducted in the NIS.: A retrospective cohort study of patients undergoing operative stabilization of transcervical and intertrochanteric hip fractures during 2009 to 2011 was performed in the NIS and NSQIP. Totals of 122,712 and 5021 patients were included from the NIS and NSQIP, respectively. Age, sex, fracture type, and lengths of stay were compared. Comorbidities common to both databases were compared in terms of more or less than twofold difference between the two databases. Similar comparisons were made for adverse events. Finally, adverse events that had a greater postdischarge prevalence were identified from the NSQIP database. Tests for statistical difference were thought to be of little value given the large sample size and the resulting fact that statistical differences would have been identified even for small, clinically inconsequential differences resulting from the associated high power. Because it is of greater clinical importance to focus on the magnitude of differences, the databases were compared by absolute differences.: Demographics and hospital lengths of stay were not different between the two databases. In terms of comorbidities, the prevalences of nonmorbid obesity, coagulopathy, and anemia in found in the NSQIP were more than twice those in the NIS; the prevalence of peripheral vascular disease in the NIS was more than twice that in the NSQIP. Four other comorbidities had prevalences that were not different between the two databases. In terms of inpatient adverse events, the frequencies of acute kidney injury and urinary tract infection in the NIS were more than twice those in the NSQIP. Ten other inpatient adverse events had frequencies that were not different between the two databases. Because it does not collect data after patient discharge, it can be implied from the NSQIP data that the NIS does not capture more than {$\frac{1}{2}$} of the deaths and surgical site infections occurring during the first 30 postoperative days.: This study shows that two databases commonly used in orthopaedic research can identify similar populations of operative patients but may generate very different results for specific commonly studied comorbidities and adverse events. The NSQIP identified higher rates of morbid obesity, coagulopathy, and anemia. The NIS identified higher rates of peripheral vascular disease, acute kidney injury, and urinary tract infection.OF EVIDENCE: Level II, prognostic study. See the Instructions for Authors for a complete description of levels of evidence.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XHDMRKSC\\Bohl et al. - 2014 - Nationwide inpatient sample and national surgical .pdf},
  isbn = {0009-921x},
  journal = {Clinical Orthopaedics and Related Research},
  number = {6},
  pmid = {24615426}
}

@article{Bohl2014,
  title = {Variations in Data Collection Methods between National Databases Affect Study Results: {{A}} Comparison of the Nationwide Inpatient Sample and National Surgical Quality Improvement Program Databases for Lumbar Spine Fusion Procedures},
  author = {Bohl, D D and Russo, G S and Basques, B A and Golinvaux, N S and Fu, M C and Long, W D and Grauer, J N},
  year = {2014},
  volume = {96},
  pages = {e193},
  issn = {1535-1386; 0021-9355},
  doi = {10.2106/JBJS.M.01490},
  abstract = {Background: There has been an increasing use of national databases to conduct orthopaedic research. Questions regarding the validity and consistency of these studies have not been fully addressed. The purpose of this study was to test for similarity in reported measures between two national databases commonly used for orthopaedic research. Methods: A retrospective cohort study of patients undergoing lumbar spinal fusion procedures during 2009 to 2011 was performed in two national databases: the Nationwide Inpatient Sample and the National Surgical Quality Improvement Program. Demographic characteristics, comorbidities, and inpatient adverse events were directly compared between databases. Results: The total numbers of patients included were 144,098 from the Nationwide Inpatient Sample and 8434 from the National Surgical Quality Improvement Program. There were only small differences in demographic characteristics between the two databases. There were large differences between databases in the rates at which specific comorbidities were documented. Non-morbid obesity was documented at rates of 9.33\% in the Nationwide Inpatient Sample and 36.93\% in the National Surgical Quality Improvement Program (relative risk, 0.25; p \textexclamdown{} 0.05). Peripheral vascular disease was documented at rates of 2.35\% in the Nationwide Inpatient Sample and 0.60\% in the National Surgical Quality Improvement Program (relative risk, 3.89; p \textexclamdown{} 0.05). Similarly, there were large differences between databases in the rates at which specific inpatient adverse events were documented. Sepsis was documented at rates of 0.38\% in the Nationwide Inpatient Sample and 0.81\% in the National Surgical Quality Improvement Program (relative risk, 0.47; p \textexclamdown{} 0.05). Acute kidney injury was documented at rates of 1.79\% in the Nationwide Inpatient Sample and 0.21\% in the National Surgical Quality Improvement Program (relative risk, 8.54; p \textexclamdown{} 0.05). continued Conclusions: As database studies becomemore prevalent in orthopaedic surgery, authors, reviewers, and readers should view these studies with caution. This study shows that two commonly used databases can identify demographically similar patients undergoing a common orthopaedic procedure; however, the databases document markedly different rates of comorbidities and inpatient adverse events. The differences are likely the result of the very differentmechanisms through which the databases collect their comorbidity and adverse event data. Findings highlight concerns regarding the validity of orthopaedic database research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YESEH5WR\\Bohl et al. - 2014 - Variations in data collection methods between nati.pdf},
  isbn = {1535-1386 (Electronic)},
  journal = {Journal of Bone and Joint Surgery - American Volume},
  keywords = {acute kidney failure,adult,aged,article,cohort analysis,comorbidity,data base,data collection method,demography,female,follow up,hospital patient,human,lumbar spine,major clinical study,male,morbid obesity,peripheral vascular disease,retrospective study,risk factor,sepsis,spine fusion,surgical infection,total quality management,urinary tract infection,wound dehiscence},
  number = {23},
  pmid = {25471919}
}

@article{Bohl2016,
  title = {Nationwide Databases in Orthopaedic Surgery Research},
  author = {Bohl, Daniel D. and Singh, Kern and Grauer, Jonathan N.},
  year = {2016},
  month = oct,
  volume = {24},
  pages = {673--682},
  issn = {1067-151X},
  doi = {10.5435/JAAOS-D-15-00217},
  journal = {Journal of the American Academy of Orthopaedic Surgeons},
  keywords = {\#nosource},
  number = {10}
}

@book{Bohlin2011,
  title = {Evidensens M\aa nga Ansikten : Evidensbaserad Praktik i Praktiken},
  author = {Bohlin, Ingemar and Sager, Morten},
  year = {2011},
  publisher = {{Arkiv}},
  abstract = {Indhold: Indledning : evidensbaserad praktik i praktiken / Ingemar Bohlin \& Morten Sager. Evidensbaserat beslutsfattande i ett vetenskapsbaserat samh\"alle : om evidensr\"orelsens ursprung, utbredning och gr\"anser / Ingemar Bohlin. Avst\aa nd och datatv\"att i stora kliniska l\"akemedelspr\"ovningar : om tv\aa{} f\"orbisedda f\"oreteelser som \"okar pr\"ovningarnas trov\"ardighet / Claes-Fredrik Helgesson. Evidens i administrativt limbo : den implanterbara defibrillatorn mellan forskning och klinik / Morten Sager. Kunskapsstyrningens praktik : kunskaper, verksamhetsrationaliteter och vikten av organisation / Karin Fernler. Evidensbaserad praktik i svenskt socialt arbete : om ett programs mottagande, f\"or\"andring och m\"ojligheter i en ny omgivning / Anders Bergmark \& Tommy Lundstr\"om. Evidenspolitik : fallet Danmark / Hanne Foss Hansen \& Olaf Rieper. Avslutning : evidensens \"ode avg\"ors i detaljerna},
  isbn = {978-91-7924-228-2},
  keywords = {\#nosource}
}

@generic{Bonnet2014,
  title = {Physiological and Medical Findings in Insomnia: {{Implications}} for Diagnosis Andcare},
  author = {Bonnet, Michael H. and Burton, George G. and Arand, Donna L.},
  year = {2014},
  volume = {18},
  pages = {111--122},
  issn = {10870792},
  doi = {10.1016/j.smrv.2013.02.003},
  abstract = {This review will examine objective physiological abnormalities and medical comorbidities associated with insomnia and assess the need to measure parameters associated with these abnormalities fordiagnosis and to monitor treatment outcomes. Findings are used to develop a decision tree for the work-up of insomnia patients. Currently available measures and those with possible future predictive value will be discussed. Costs, advantages, and the development of screening laboratory tests will bepresented. It is concluded that there is a need to differentially evaluate insomnia patients based upontheir comorbidities and the presence of objectively decreased total sleep time to direct optimal treatment. The development of objective diagnostic criteria and treatment outcome goals beyond subjective symptomatic relief will establish insomnia as a true medical problem and improve patient care. \textcopyright{} 2013 Elsevier Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F4EKHKMN\\Bonnet et al. - 2014 - Physiological and medical findings in insomnia Im.pdf},
  isbn = {1532-2955 (Electronic){\r  }1087-0792 (Linking)},
  journal = {Sleep Medicine Reviews},
  keywords = {Depression,Diabetes,Hyperarousal,Hypertension,Insomnia,Pain,Sleep disorders},
  number = {2},
  pmid = {23751272}
}

@book{Bonnett2019,
  title = {Guide to Presenting Clinical Prediction Models for Use in Clinical Settings},
  author = {Bonnett, Laura J. and Snell, Kym I.E. and Collins, Gary S. and Riley, Richard D.},
  year = {2019},
  volume = {365},
  publisher = {{BMJ Publishing Group}},
  issn = {17561833},
  doi = {10.1136/bmj.l737},
  abstract = {Clinical prediction models estimate the risk of existing disease or future outcome for an individual, which is conditional on the values of multiple predictors such as age, sex, and biomarkers. In this article, Bonnett and colleagues provide a guide to presenting clinical prediction models so that they can be implemented in practice, if appropriate. They describe how to create four presentation formats and discuss the advantages and disadvantages of each format. A key message is the need for stakeholder engagement to determine the best presentation option in relation to the clinical context of use and the intended users.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8BXV6TB8\\Bonnett et al. - 2019 - Guide to presenting clinical prediction models for.pdf}
}

@article{Boorjian2013,
  title = {Comparative Performance of Comorbidity Indices for Estimating Perioperative and 5-{{Year}} All Cause Mortality Following Radical Cystectomy for Bladder Cancer},
  author = {Boorjian, Stephen A. and Kim, Simon P. and Tollefson, Matthew K. and Carrasco, Alonso and Cheville, John C. and Thompson, R. Houston and Thapa, Prabin and Frank, Igor},
  year = {2013},
  volume = {190},
  pages = {55--60},
  issn = {00225347},
  doi = {10.1016/j.juro.2013.01.010},
  abstract = {PURPOSE Radical cystectomy continues to be associated with a nonnegligible risk of perioperative death and all cause mortality in the years after surgery remains relatively high. We investigated the comparative ability of various comorbidity indices to predict perioperative and 5-year all cause mortality after radical cystectomy. MATERIALS AND METHODS We evaluated 891 patients who underwent radical cystectomy between 1994 and 2005. The associations of American Society of Anesthesiologists (ASA) score, Charlson comorbidity index, Elixhauser index and ECOG (Eastern Cooperative Oncology Group) performance status with outcomes were assessed using Cox regression models. Model performance was compared with area under receiver operating curves. RESULTS A total of 33 (3.7\%) patients died within 90 days of radical cystectomy. On multivariate analysis locally advanced pathological tumor stage (HR 4.86, p = 0.002) as well as Elixhauser index (HR 1.48, p = 0.002), ASA score (HR 3.17, p = 0.001) and ECOG (HR 2.40, p \textexclamdown 0.0001) were significantly associated with 90-day perioperative mortality. Median followup after radical cystectomy was 10.1 years, during which time 576 patients died. Charlson comorbidity index (HR 1.23, p \textexclamdown 0.0001), Elixhauser index (HR 1.28, p \textexclamdown 0.0001), ASA score (HR 1.44, p = 0.007) and ECOG (HR 1.97, p \textexclamdown 0.0001) were independent predictors of 5-year all cause mortality. Moreover Charlson comorbidity index (AUC 0.798, p \textexclamdown 0.0001), Elixhauser index (AUC 0.770, p = 0.03) and ECOG (AUC 0.769, p = 0.03) significantly enhanced the performance of a base model which did not include comorbidity status (AUC 0.757) to predict 5-year all cause mortality. CONCLUSIONS Comorbidity status is predictive of perioperative death and 5-year all cause mortality after radical cystectomy and, therefore, should be incorporated into patient counseling and risk stratification models. Further prospective studies are warranted to overcome the retrospective limitations in determining the relative prognostic value of various comorbidity indices.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5HR52DCM\\Boorjian et al. - 2013 - Comparative performance of comorbidity indices for.pdf},
  journal = {The Journal of Urology},
  number = {1}
}

@book{Borcard2011,
  title = {Numerical Ecology with r},
  author = {Borcard, Daniel and Gillet, Fran{\c c}ois and {Legendre} and Legendre, Pierre},
  year = {2011},
  issn = {16130073},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \AA{} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MBG2CB4F\\Borcard et al. - 2011 - Numerical ecology with r.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {Mobile,Named entity disambiguation,Natural language processing,News,Recommender system},
  pmid = {25246403}
}

@article{Boren2000,
  title = {Thinking Aloud: {{Reconciling}} Theory and Practice},
  author = {Boren, M. Ted and Ramey, Judith},
  year = {2000},
  volume = {43},
  pages = {261--278},
  issn = {03611434},
  doi = {10.1109/47.867942},
  abstract = {Thinking-aloud protocols may be the most widely used method in usability testing, but the descriptions of this practice in the usability literature and the work habits of practitioners do not conform to the theoretical basis most often cited for it: Ericsson and Simon's seminal work PROTOCOL ANALYSIS: VERBAL REPORTS AS DATA [1]. After reviewing Ericsson and Simon's theoretical basis for thinking aloud, we review the ways in which actual usability practice diverges from this model. We then explore the concept of SPEECH GENRE as an alternative theoretical framework. We first consider uses of this new framework that are consistent with Simon and Ericsson's goal of eliciting a verbal report that is as undirected, undisturbed, and constant as possible. We then go on to consider how the proposed new approach might handle problems that arise in usability testing that appear to require interventions not supported in the older model.},
  isbn = {9781605582467},
  journal = {IEEE Transactions on Professional Communication},
  keywords = {\#nosource},
  number = {3}
}

@article{Bostr2004,
  title = {Vad Betyder Bortfallet F\"or Resultatet i Folkh\"alsoenk\"ater?},
  author = {Bostr, Gunnel},
  year = {2004},
  keywords = {\#nosource}
}

@article{Bottle2011,
  title = {Comorbidity Scores for Administrative Data Benefited from Adaptation to Local Coding and Diagnostic Practices},
  author = {Bottle, Alex and Aylin, Paul},
  year = {2011},
  volume = {64},
  pages = {1426--1433},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2011.04.004},
  abstract = {OBJECTIVE The Charlson and Elixhauser indices are the most commonly used comorbidity indices with risk prediction models using administrative data. Our objective was to compare the original Charlson index, a modified set of Charlson codes after advice from clinical coders, and a published modified Elixhauser index in predicting in-hospital mortality. STUDY DESIGN AND SETTING Logistic regression using two separate years of administrative hospital data for all acute nonspecialist public hospitals in England. RESULTS For all admissions combined, discrimination was similar for the Charlson index using the original codes and weights and the Charlson index using the original codes but England-calibrated weights (c=0.73), although model fit was superior for the latter. The new Charlson codes improved discrimination (c=0.76), model fit, and consistency of recording between admissions. The modified Elixhauser had the best performance (c=0.80). For admissions for acute myocardial infarction and chronic obstructive pulmonary disease, the weights often differed, although the patterns were broadly similar. CONCLUSION Recalibration of the original Charlson index yielded only modest benefits overall. The modified Charlson codes and weights offer better fit and discrimination for English data over the original version. The modified Elixhauser performed best of all, but its weights were perhaps less consistent across the different patient groups considered here.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4Z77HRP5\\Bottle and Aylin - 2011 - Comorbidity scores for administrative data benefit.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {12}
}

@article{Bottle2019,
  title = {Risk Factors for Early Revision after Total Hip and Knee Arthroplasty: {{National}} Observational Study from a Surgeon and Population Perspective},
  author = {Bottle, Alex and Parikh, Sunny and Aylin, Paul and Loeffler, Mark},
  editor = {Wang, Yuanyuan},
  year = {2019},
  month = apr,
  volume = {14},
  pages = {e0214855},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0214855},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PWSUQSHU\\Bottle et al. - 2019 - Risk factors for early revision after total hip an.pdf},
  journal = {PLOS ONE},
  number = {4}
}

@article{Bowling2005,
  title = {Mode of Questionnaire Administration Can Have Serious Effects on Data Quality},
  author = {Bowling, Ann},
  year = {2005},
  volume = {27},
  pages = {281--291},
  issn = {17413842},
  doi = {10.1093/pubmed/fdi031},
  abstract = {BACKGROUND: One of the main primary data collection instruments in social, health and epidemiological research is the survey questionnaire. Modes of data collection by questionnaire differ in several ways, including the method of contacting respondents, the medium of delivering the questionnaire to respondents, and the administration of the questions. These are likely to have different effects on the quality of the data collected. METHODS: This paper is based on a narrative review of systematic and non-systematic searches of the literature on the effects of mode of questionnaire administration on data quality. RESULTS: Within different modes of questionnaire administration, there were many documented potential, biasing influences on the responses obtained. These were greatest between different types of mode (e.g. self-administered versus interview modes), rather than within modes. It can be difficult to separate out the effects of the different influences, at different levels. CONCLUSIONS: The biasing effects of mode of questionnaire administration has important implications for research methodology, the validity of the results of research, and for the soundness of public policy developed from evidence using questionnaire-based research. All users of questionnaires need to be aware of these potential effects on their data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZA4EITQX\\Bowling - 2005 - Mode of questionnaire administration can have seri.pdf},
  isbn = {1741-3842 (Print)},
  journal = {Journal of Public Health},
  keywords = {Data collection bias,Mode of questionnaire administration},
  number = {3},
  pmid = {15870099}
}

@article{Boyce2020,
  title = {Bills of {{Mortality}}: Tracking Disease in Early Modern {{London}}},
  shorttitle = {Bills of {{Mortality}}},
  author = {Boyce, Niall},
  year = {2020},
  month = apr,
  volume = {395},
  pages = {1186--1187},
  issn = {01406736},
  doi = {10.1016/S0140-6736(20)30725-X},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MZSHYZWB\\Boyce - 2020 - Bills of Mortality tracking disease in early mode.pdf},
  journal = {The Lancet},
  language = {en},
  number = {10231}
}

@article{Bozic2012,
  title = {Patient-Related Risk Factors for Periprosthetic Joint Infection and Postoperative Mortality Following Total Hip Arthroplasty in Medicare Patients},
  author = {Bozic, Kevin J. and Lau, Edmund and Kurtz, Steven and Ong, Kevin and Rubash, Harry and Vail, Thomas P. and Berry, Daniel J.},
  year = {2012},
  volume = {94},
  pages = {794--800},
  publisher = {{Journal of Bone and Joint Surgery Inc.}},
  issn = {0021-9355},
  doi = {10.2106/JBJS.K.00072},
  abstract = {BACKGROUND: The patient-related risk factors for periprosthetic joint infection and postoperative mortality in elderly patients undergoing total hip arthroplasty are poorly understood. The purpose of this study was to identify the specific patient comorbidities that are associated with an increased risk of periprosthetic joint infection and of ninety-day postoperative mortality in U.S. Medicare patients undergoing total hip arthroplasty. METHODS: The Medicare 5\% sample claims database was used to calculate the relative risk of periprosthetic joint infection and of ninety-day postoperative mortality as a function of preexisting comorbidities in 40,919 patients who underwent primary total hip arthroplasty between 1998 and 2007. The impact of twenty-nine comorbid conditions on periprosthetic joint infection and on postoperative mortality was examined with use of Cox regression, controlling for age, sex, census region, public assistance, and all other baseline comorbidities. The adjusted hazard ratios for all comorbid conditions were evaluated, and the Wald chi-square statistic was used to rank the degree of association of each condition with periprosthetic joint infection and with postoperative mortality. The Bonferroni-Holm method was used to adjust for the multiple comparisons resulting from the number of comorbid conditions analyzed. RESULTS: Comorbid conditions associated with an increased adjusted risk of periprosthetic joint infection (in decreasing order of significance, p \textexclamdown{} 0.05 for all comparisons) were rheumatologic disease (hazard ratio [HR] = 1.71), obesity (HR = 1.73), coagulopathy (HR = 1.58), and preoperative anemia (HR = 1.36). Comorbid conditions associated with an increased adjusted risk of ninety-day postoperative mortality (in decreasing order of significance, p \textexclamdown{} 0.05 for all comparisons) were congestive heart failure (HR = 2.11), metastatic cancer (HR = 3.14), psychosis (HR = 1.85), renal disease (HR = 1.98), dementia (HR = 2.04), hemiplegia or paraplegia (HR = 2.62), cerebrovascular disease (HR = 1.40), and chronic pulmonary disease (HR = 1.32). CONCLUSIONS: We identified specific patient comorbidities that were independently associated with an increased risk of periprosthetic joint infection and of ninety-day postoperative mortality in Medicare patients who had undergone total hip arthroplasty. This information is important when counseling elderly patients regarding the risks of periprosthetic joint infection and mortality following total hip arthroplasty, as well as for risk adjustment of publicly reported total hip arthroplasty outcomes.},
  journal = {The Journal of Bone and Joint Surgery (American)},
  keywords = {\#nosource,JBJS-A,The Journal of Bone and Joint Surgery},
  number = {9},
  pmid = {22552668}
}

@article{Bozic2013,
  title = {Is Administratively Coded Comorbidity and Complication Data in Total Joint Arthroplasty Valid?},
  author = {Bozic, Kevin J and Bashyal, Ravi K and Anthony, Shawn G and Chiu, Vanessa and Shulman, Brandon and Rubash, Harry E},
  year = {2013},
  month = jan,
  volume = {471},
  pages = {201--5},
  issn = {1528-1132},
  doi = {10.1007/s11999-012-2352-1},
  abstract = {BACKGROUND Administrative claims data are increasingly being used in public reporting of provider performance and health services research. However, the concordance between administrative claims data and the clinical record in lower extremity total joint arthroplasty (TJA) is unknown. QUESTIONS/PURPOSES We evaluated the concordance between administrative claims and the clinical record for 13 commonly reported comorbidities and complications in patients undergoing TJA. METHODS We compared 13 administratively coded comorbidities and complications derived from hospital billing records with clinical documentation from a consecutive series of 1350 primary and revision TJAs performed at three high-volume institutions during 2009. RESULTS Concordance between administrative claims and the clinical record varied across comorbidities and complications. Concordance between diabetes and postoperative myocardial infarction was reflected by a kappa value \textquestiondown{} 0.80; chronic lung disease, coronary artery disease, and postoperative venous thromboembolic events by kappa values between 0.60 and 0.79; and for congestive heart failure, obesity, prior myocardial infarction, peripheral arterial disease, bleeding complications, history of venous thromboembolism, prosthetic-related complications, and postoperative renal failure by kappa values between 0.40 and 0.59. All comorbidities and complications had a high degree of specificity (\textquestiondown{} 92\%) but lower sensitivity (29\%-100\%). CONCLUSIONS The data suggest administratively coded comorbidities and complications correlate reasonably well with the clinical record. However, the specificity of administrative claims is much higher than the sensitivity, indicating that comorbidities and complications coded in the administrative record were accurate but often incomplete.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MV8GCQDH\\Bozic et al. - 2013 - Is administratively coded comorbidity and complica.pdf},
  journal = {Clinical orthopaedics and related research},
  number = {1},
  pmid = {22528384}
}

@article{Bozic2013a,
  title = {Estimating Risk in Medicare Patients with {{THA}}: {{An}} Electronic Risk Calculator for Periprosthetic Joint Infection and Mortality},
  author = {Bozic, Kevin J. and Ong, Kevin and Lau, Edmund and Berry, Daniel J. and Vail, Thomas P. and Kurtz, Steven M. and Rubash, Harry E.},
  year = {2013},
  month = feb,
  volume = {471},
  pages = {574--583},
  publisher = {{Springer-Verlag}},
  issn = {0009-921X},
  doi = {10.1007/s11999-012-2605-z},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IKLRU7VE\\Bozic et al. - 2013 - Estimating risk in medicare patients with THA An .pdf},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  number = {2}
}

@article{Bozic2013b,
  title = {Orthopaedic Healthcare Worldwide: {{Shared}} Medical Decision Making in Orthopaedics},
  author = {Bozic, Kevin J.},
  year = {2013},
  month = may,
  volume = {471},
  pages = {1412--1414},
  publisher = {{Springer-Verlag}},
  issn = {0009-921X},
  doi = {10.1007/s11999-013-2838-5},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZUDKKMX4\\Bozic - 2013 - Orthopaedic healthcare worldwide Shared medical d.pdf},
  journal = {Clinical Orthopaedics and Related Research},
  number = {5}
}

@article{braga-netoCrossvalidationValidSmallsample2004,
  title = {Is Cross-Validation Valid for Small-Sample Microarray Classification?},
  author = {{Braga-Neto}, Ulisses M. and Dougherty, Edward R.},
  year = {2004},
  volume = {20},
  pages = {374--380},
  issn = {13674803},
  doi = {10.1093/bioinformatics/btg419},
  abstract = {Motivation: Microarray classification typically possesses two striking attributes: (1) classifier design and error estimation are based on remarkably small samples and (2) cross-validation error estimation is employed in the majority of the papers. Thus, it is necessary to have a quantifiable understanding of the behavior of cross-validation in the context of very small samples.: An extensive simulation study has been per- formed comparing cross-validation, resubstitution and boot- strap estimation for three popular classification rules\textemdash{} linear discriminant analysis, 3-nearest-neighbor and decision trees (CART)\textemdash using both synthetic and real breast-cancer patient data. Comparison is via the distribution of differ- ences between the estimated and true errors. Various stat- istics for the deviation distribution have been computed: mean (for estimator bias), variance (for estimator preci- sion), root-mean square error (for composition of bias and variance) and quartile ranges, including outlier behavior. In general, while cross-validation error estimation is much less biased than resubstitution, it displays excessive vari- ance, which makes individual estimates unreliable for small samples. Bootstrap methods provide improved performance relative to variance, but at a high computational cost and often with increased bias (albeit, much less than with resubstitution).and Supplementary information: A compan- ion web site can be accessed at the URL http://ee.tamu.edu/ {$\sim$}edward/cv\textsubscript{p}aper. The companion web site contains: (1) the complete set of tables and plots regarding the simulation study; (2) additional figures; (3) a compilation of references for microarray classification studies and (4) the source code used, with full documentation and examples.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\M7JLM6LB\\Braga-Neto and Dougherty - 2004 - Is cross-validation valid for small-sample microar.pdf},
  isbn = {1367-4803},
  journal = {Bioinformatics},
  number = {3},
  pmid = {14960464}
}

@article{Brakes2005,
  title = {Exposure of Non-Target Small Mammals to Rodenticides: {{Short}}-Term Effects, Recovery and Implications for Secondary Poisoning},
  author = {Brakes, C. R. and Smith, R. H.},
  year = {2005},
  volume = {42},
  pages = {118--128},
  issn = {00218901},
  doi = {10.1111/j.1365-2664.2005.00997.x},
  abstract = {Monitoring of exposure to pesticides in many countries shows extensive exposure of predators to anticoagulant rodenticides, which are used to control rats. Many predators and scavengers are declining in numbers, and exposure to rodenticides might therefore be of importance in conservation biology. Predators and scavengers of poisoned rats are at most risk of secondary poisoning. However, several predatory species of conservation concern rarely eat rats, implicating non-target small mammals as the major route of exposure. For the first time, this research investigated the importance of non-target small mammals as routes of exposure to rodenticide for predators and scavengers in the UK. Exposure studies of non-target small mammals were carried out alongside routine rat control at five sites, around agricultural buildings (n = 2) and feed hoppers for game birds (n = 3). Three non-target rodent species fed on rodenticide from bait boxes during routine rat control treatments. A large proportion (48{$\cdot$}6\%) of individuals in local populations ate the bait: woodmice Apodemus sylvaticus were most exposed, followed by bank voles Clethrionomys glareolus then field voles Microtus agrestis. Local populations of non-target small mammals declined significantly following rodenticidal rat control but their relative proportions did not change significantly. Populations recovered partially after 3 months, depending on the time of the year relative to the breeding cycle. Synthesis and applications. Our results clearly demonstrate that routine rat control reduced local populations of non-target small mammals. This may limit the food supply of some specialist predators. Most importantly, this demonstrates a significant route of exposure of predators and scavengers of small mammals to secondary poisoning. Rodenticides are applied on farms and game estates across the UK. Hence the results of this study are indicative of non-target rodenticide exposure nationally. Mitigation requires a shift from the current reliance on rodenticides to ecologically based rodent management, involving improvements in site management and the adoption of good farming practice. Journal of Applied Ecology (2005) 42, 118 2013128doi: 10.1111/j.1365-2664.2005.00997.x},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AG6IEFB9\\Brakes and Smith - 2005 - Exposure of non-target small mammals to rodenticid.pdf},
  isbn = {1365-2664},
  journal = {Journal of Applied Ecology},
  keywords = {Anticoagulant,Coumatetralyl,Farms,Game feeders,Predators,Rat control,Scavengers},
  number = {1}
}

@article{Brambor2006,
  title = {Understanding Interaction Models: {{Improving}} Empirical Analyses},
  author = {Brambor, Thomas and Clark, William Roberts and Golder, Matt},
  year = {2006},
  volume = {14},
  pages = {63--82},
  issn = {10471987},
  doi = {10.1093/pan/mpi014},
  abstract = {Multiplicative interaction models are common in the quantitative political science literature. This is so for good reason. Institutional arguments frequently imply that the relationship between political inputs and outcomes varies depending on the institutional context. Models of strategic interaction typically produce conditional hypotheses as well. Although conditional hypotheses are ubiquitous in political science and multiplicative interaction models have been found to capture their intuition quite well, a survey of the top three political science journals from 1998 to 2002 suggests that the execution of these models is often flawed and inferential errors are common. We believe that considerable progress in our understanding of the political world can occur if scholars follow the simple checklist of dos and don'ts for using multiplicative interaction models presented in this article. Only 10\% of the articles in our survey followed the checklist.},
  isbn = {1047198714764},
  journal = {Political Analysis},
  keywords = {\#nosource},
  number = {1},
  pmid = {20124917}
}

@article{Bray2006,
  title = {Predicting the Future Burden of Cancer},
  author = {Bray, Freddie and Moller, B and M\o ller, Bj\o rn},
  year = {2006},
  volume = {6},
  pages = {63--74},
  issn = {1474-175X},
  doi = {10.1038/nrc1781},
  abstract = {As observations in the past do not necessarily hold into the future, predicting future cancer occurrence is fraught with uncertainty. Nevertheless, predictions can aid health planners in allocating resources and allow scientists to explore the consequence of interventions aimed at reducing the impact of cancer. Simple statistical models have been refined over the past few decades and often provide reasonable predictions when applied to recent trends. Intrinsic to their interpretation, however, is an understanding of the forces that drive time trends. We explain how and why cancer predictions are made, with examples to illustrate the concepts in practice},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6623XDPV\\Bray et al. - 2006 - Predicting the future burden of cancer.pdf},
  journal = {Nat.Rev.Cancer},
  keywords = {Cancer,Cost of Illness,Epidemiologic Methods,Epidemiology,Forecasting,Forecasting: methods,Humans,Incidence,methods,Neoplasms,Neoplasms: epidemiology,Norway,Occurrence,Registries,Time,trends},
  number = {1474-175X (Print)},
  pmid = {16372017}
}

@article{Breiman2001,
  title = {Statistical Modeling: The Two Cultures},
  author = {Breiman, Leo},
  year = {2001},
  volume = {16},
  pages = {199--215},
  doi = {10.1214/ss/1009213726},
  abstract = {There are two cultures in the use of statistical modeling to reachfrom data. One assumes that the data are generated bygiven stochastic data model. The other uses algorithmic modelstreats the data mechanism as unknown. The statistical communitybeen committed to the almost exclusive use of data models. Thishas led to irrelevant theory, questionable conclusions,has kept statisticians from working on a large range of interestingproblems. Algorithmic modeling, both in theory and practice,developed rapidly in fields outside statistics. It can be usedon large complex data sets and as a more accurate and informativeto data modeling on smaller data sets. If our goal asfield is to use data to solve problems, then we need to move awayexclusive dependence on data models and adopt a more diverseof tools.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\I9TW28FB\\Breiman - 2001 - Statistical modeling the two cultures.pdf},
  journal = {Statistical Science},
  number = {3}
}

@article{Breiman2001a,
  title = {Random Forests},
  author = {Breiman, Leo},
  year = {2001},
  volume = {45},
  pages = {5--32},
  publisher = {{Kluwer Academic Publishers}},
  issn = {08856125},
  doi = {10.1023/A:1010933404324},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IZMF6VD4\\Breiman - 2001 - Random forests.pdf},
  journal = {Machine Learning},
  number = {1}
}

@article{Brennan2012,
  title = {The Importance of Knowing Context of Hospital Episode Statistics When Reconfiguring the {{NHS}}},
  author = {Brennan, Lauren and Watson, Mando and Klaber, Robert and Charles, Tagore},
  year = {2012},
  month = apr,
  volume = {344},
  issn = {17561833},
  doi = {10.1136/bmj.e2432},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HB845R5X\\Brennan et al. - 2012 - The importance of knowing context of hospital epis.pdf},
  journal = {BMJ (Online)},
  number = {7851}
}

@article{Brooke2017,
  title = {The {{Swedish}} Cause of Death Register},
  author = {Brooke, Hannah Louise and Talb{\"a}ck, Mats and H{\"o}rnblad, Jesper and Johansson, Lars Age and Ludvigsson, Jonas Filip and Druid, Henrik and Feychting, Maria and Ljung, Rickard},
  year = {2017},
  volume = {32},
  pages = {765--773},
  issn = {15737284},
  doi = {10.1007/s10654-017-0316-1},
  abstract = {Sweden has a long tradition of recording cause of death data. The Swedish cause of death register is a high quality virtually complete register of all deaths in Sweden since 1952. Although originally created for official statistics, it is a highly important data source for medical research since it can be linked to many other national registers, which contain data on social and health factors in the Swedish population. For the appropriate use of this register, it is fundamental to understand its origins and composition. In this paper we describe the origins and composition of the Swedish cause of death register, set out the key strengths and weaknesses of the register, and present the main causes of death across age groups and over time in Sweden. This paper provides a guide and reference to individuals and organisations interested in data from the Swedish cause of death register.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6GVJSIAZ\\Brooke et al. - 2017 - The Swedish cause of death register.pdf},
  journal = {European Journal of Epidemiology},
  keywords = {Cause of death,Death certificates,Epidemiology,Mortality,Register,Sweden},
  number = {9},
  pmid = {28983736}
}

@article{Brookhart2010,
  title = {Confounding Control in Healthcare Database Research: Challenges and Potential Approaches},
  author = {Brookhart, MA and Sturmer, T and Glynn, RJ and Rassen, J and Schneeweiss, S},
  year = {2010},
  volume = {48},
  pages = {114--120},
  doi = {10.1097/MLR.0b013e3181dbebe3.Confounding},
  journal = {Medical Care},
  keywords = {\#nosource,confounding,pharmacoepidemiology,propensity scores,unmeasured confounding,variable selection},
  number = {60}
}

@book{Brooks2003,
  title = {The Measurement and Valuation of Health Status Using {{EQ}}-{{5D}}: {{A}} European Perspective},
  author = {Brooks, Richard. and Rabin, Rosalind. and Charro, Frank.},
  year = {2003},
  publisher = {{Springer Netherlands}},
  doi = {10.1007/978-94-017-0233-1},
  abstract = {EQ-5D from the EuroQol Group is a standardised, non-disease-specific instrument for describing and valuing health. It is in widespread use in many countries and has been applied in many different settings. EQ-5D is now an integral feature of many clinical trials and is increasingly used in population health surveys. This book reports on the results of the European Union-funded EQ-net project which furthered the development of EQ-5D in the key areas of valuation, application and translation. The primary effort concentrated on harmonising and integrating the results of the various EuroQol valuation projects. Most importantly, the book includes a set of VAS- based preference weights for all the EQ-5D health states based on cross-European EQ-5D data. This book provides the most comprehensive account to date of the EuroQol Group endeavour. It will appeal to clinicians, nurses, health services researchers, health economists, those responsible for audit and quality assurance, public health specialists and managers in health care institutions, and the pharmaceutical industry.},
  isbn = {978-90-481-6261-1},
  keywords = {\#nosource}
}

@article{Brophy2006,
  title = {Methodological Issues in the Identification of Hip Fractures Using Routine Hospital Data: {{A}} Database Study},
  author = {Brophy, Sinead and John, Gareth and Evans, Emma and Lyons, Ronan A.},
  year = {2006},
  month = mar,
  volume = {17},
  pages = {405--409},
  issn = {0937941X},
  doi = {10.1007/s00198-005-2038-6},
  abstract = {The proportion of the population over the age of retirement has risen in many countries, and this means there is a corresponding rise in the incidence of hip fractures. However, in order to reliably investigate the ability of interventions to prevent fracture, there needs to be a reliable measure of the incidence of hip fracture. The purpose of this study was to examine the inclusion and exclusion criteria used to identify hip fracture from hospital admission data and to examine the impact that these criteria have on estimated incidence of hip fracture. We examine the influence of: individual compared to consultant episode data; primary data compared to any diagnosis of hip fracture; emergency compared to elective admissions; and the influence of type and rate of surgery on incidence estimates. The results showed that classifying hip fractures by use of consultant episodes overestimated the rate of hip fracture by 6-31\%, and this overestimation has increased in recent years. The use of primary diagnosis as opposed to any diagnosis under-estimates hip fracture by 5\%. Two percent (2\%) of the people studied had an operation for a hip fracture but did not have a hip fracture diagnosis (many had a multiple fracture diagnosis), and 5.5\% of the people studied had an elective admission for the hip fracture (perhaps falling in hospital during an elective admission). We conclude that the selection criteria can have a great influence on the number of hip fractures identified using routine data. There should be a standardized selection procedure for the identification of hip fracture, as this would enable interventions and preventive measures to be evaluated over time and facilitate comparisons of rates in different regions and countries, in order to examine factors associated with hip fracture. \textcopyright{} International Osteoporosis Foundation and National Osteoporosis Foundation 2005.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MIBZGL3U\\Brophy et al. - 2006 - Methodological issues in the identification of hip.pdf},
  journal = {Osteoporosis International},
  keywords = {Hip fracture,Incidence,Neck of femur,Selection criteria},
  number = {3}
}

@article{Brunet2004,
  title = {Metagenes and Molecular Pattern Discovery Using Matrix Factorization},
  author = {Brunet, J.-P. and Tamayo, P. and Golub, T. R. and Mesirov, J. P.},
  year = {2004},
  month = mar,
  volume = {101},
  pages = {4164--4169},
  issn = {0027-8424},
  doi = {10.1073/pnas.0308531101},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7SH9HGYA\\Brunet et al. - 2004 - Metagenes and molecular pattern discovery using ma.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {12}
}

@article{Brusselaers2017,
  title = {The Charlson Comorbidity Index in Registry-Based Research},
  author = {Brusselaers, Nele and Lagergren, Jesper},
  year = {2017},
  month = jan,
  volume = {56},
  pages = {401--406},
  issn = {0026-1270},
  doi = {10.3414/ME17-01-0051},
  abstract = {Background: Comorbidities may have an important impact on survival, and comorbidity scores are often implemented in studies assessing prognosis. The Charlson Comorbidity index is most widely used, yet several adaptations have been published, all using slightly different conversions of the International Classification of Diseases (ICD) coding.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZWNFHP43\\Brusselaers and Lagergren - 2017 - The charlson comorbidity index in registry-based r.pdf},
  journal = {Methods of Information in Medicine},
  number = {05}
}

@article{Bryant2006,
  title = {How Many Patients? {{How}} Many Limbs? {{Analysis}} of Patients or Limbs in the Orthopaedic Literature: A Systematic Review.},
  author = {Bryant, Dianne and Havey, Thomas C. and Roberts, Robin and Guyatt, Gordon},
  year = {2006},
  volume = {88},
  pages = {41--5},
  issn = {0021-9355},
  doi = {10.2106/JBJS.E.00272},
  abstract = {BACKGROUND: Clinical studies assessing orthopaedic interventions often include data from two limbs or multiple joints within single individuals. Without appropriate design or statistical approaches to address within-individual correlations, this practice may contribute to false precision and possible bias in estimates of treatment effect. We conducted a systematic review of the orthopaedic literature to determine the frequency of inappropriate inclusion of nonindependent limb or joint observations in clinical studies.: We identified seven orthopaedic journals with high Science Citation Index impact factors and retrieved all clinical studies for 2003 for any intervention on any limb or joint.: We identified 288 clinical studies, 143 of which involved two limbs or multiple joint observations from single individuals. These studies included nineteen randomized clinical trials (13\%) fifty-eight two-group cohort studies (41\%), and sixty-six one-group cohort studies (46\%). Seventy-six (53\%) of the 143 studies involved statistical comparisons between patient groups with use of tests of association, and an additional sixty studies (42\%) presented estimates of proportions without statistical comparisons. Only sixteen of the seventy-six studies involving statistical comparisons involved the use of any technique or methodological approach to account for multiple, nonindependent observations. A median of approximately 13\% of the patients in these studies contributed more than one observation. The median proportion of nonindependent observations to total observations (the unit of analysis) was approximately 23\%.: Our findings suggest that a high proportion (42\%) of clinical studies in high-impact-factor orthopaedic journals involve the inappropriate use of multiple observations from single individuals, potentially biasing results. Orthopaedic researchers should attend to this issue when reporting results.},
  isbn = {0021-9355 (Print)},
  journal = {The Journal of bone and joint surgery. American volume},
  keywords = {\#nosource,Bias (Epidemiology),Cohort Studies,Data Interpretation,Extremities,Humans,Joints,Orthopedics,Patients,Randomized Controlled Trials as Topic,Research Design,Statistical},
  number = {1},
  pmid = {16391248}
}

@article{Buchsbaum2002,
  title = {Color Categories Revealed by Non-Negative Matrix Factorization of {{Munsell}} Color Spectra},
  author = {Buchsbaum, Gershon and Bloch, Orin},
  year = {2002},
  month = mar,
  volume = {42},
  pages = {559--563},
  issn = {00426989},
  doi = {10.1016/S0042-6989(01)00303-0},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\D2937HDS\\Buchsbaum and Bloch - 2002 - Color categories revealed by non-negative matrix f.pdf},
  journal = {Vision Research},
  number = {5}
}

@article{Bujang2017,
  title = {Guidelines of the Minimum Sample Size Requirements for {{Cohen}}'s {{Kappa}}},
  author = {Bujang, Mohamad Adam and Baharum, Nurakmal},
  year = {2017},
  volume = {14},
  pages = {e12267-1-e12267-10},
  issn = {22820930},
  doi = {10.2427/12267},
  abstract = {Background: To estimate sample size for Cohen's kappa agreement test can be challenging especially when dealing with various effect sizes. This study aimed to present minimum sample size determination for Cohen's kappa under different scenarios when certain assumptions are held. Methods: The sample size formula was introduced by Flack and colleagues (1988). The power was pre-specified to be at least 80\% and 90\% while alpha was set at less than 0.05. The effect sizes were derived from several prespecified estimates such as the pattern of the true marginal rating frequencies and the difference between the two kappa coefficients in the hypothesis testing. Results: When the true marginal rating frequencies are the same, the minimum sample size determination ranges from 2 to 927 depending on the actual value of the effect size. When the true marginal rating frequencies are not the same, then the majority of the minimum sample size required for this condition is more than double than that required sample size when the true marginal rating frequencies are the same. Conclusion: Concerning that the sample size formula could produce a very extreme small sample size, the determination of K1 and K2 should be based on reasonable estimates. We recommend for all sample size determinations for Cohen's kappa agreement test, the true marginal rating frequencies can be assumed to be the same. Otherwise, it will be necessary to multiply the estimated minimum sample size by two to accommodate if the true marginal rating frequencies are not the same.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NIJ8HTYX\\Bujang and Baharum - 2017 - Guidelines of the minimum sample size requirements.pdf},
  journal = {Epidemiology Biostatistics and Public Health},
  keywords = {Agreement,Guidelines,Kappa,Sample size},
  number = {2}
}

@article{Bulow2017,
  title = {Comorbidity Does Not Predict Long-Term Mortality after Total Hip Arthroplasty},
  author = {B{\"u}low, Erik and Rolfson, Ola and Cnudde, Peter and Rogmark, Cecilia and Garellick, G{\"o}ran and Nemes, Szil{\'a}rd},
  year = {2017},
  volume = {88},
  pages = {1--6},
  issn = {17453682},
  doi = {10.1080/17453674.2017.1341243},
  abstract = {Background and purpose - In-hospital death following total hip arthroplasty (THA) is related to comorbidity. The long-term effect of comorbidity on all-cause mortality is, however, unknown for this group of patients and it was investigated in this study. Patients and methods - We used data from the Swedish Hip Arthroplasty Register, linked to the National Patient Register from the National Board of Health and Welfare, for patients operated on with THA in 1999-2012. We identified 120,836 THAs that could be included in the study. We evaluated the predictive power of the Charlson and Elixhauser comorbidity indices on mortality, using concordance indices calculated after 5, 8, and 14 years after THA. Results - All comorbidity indices performed poorly as predictors, in fact worse than a base model with age and sex only. Elixhauser was, however, the least bad choice and it predicted mortality with concordance indices 0.59, 0.58, and 0.56 for 5, 8, and 14 years after THA. Interpretation - Comorbidity indices are poor predictors of long-term mortality after THA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VBSQHDXZ\\Bülow et al. - 2017 - Comorbidity does not predict long-term mortality a.pdf},
  journal = {Acta Orthopaedica},
  keywords = {coder},
  number = {July},
  pmid = {28657407}
}

@article{Bulow2019,
  title = {Low Predictive Power of Comorbidity Indices Identified for Mortality after Acute Arthroplasty Surgery Undertaken for Femoral Neck Fracture},
  author = {B{\"u}low, E. and Cnudde, P. and Rogmark, C. and Rolfson, O. and Nemes, S.},
  year = {2019},
  volume = {101-B},
  pages = {104--112},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.101B1.BJJ-2018-0894.R1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5LYEIKR7\\Bülow m. fl. - 2019 - Low predictive power of comorbidity indices identi.pdf},
  journal = {The Bone \& Joint Journal},
  keywords = {\#nosource,coder},
  number = {1}
}

@article{Bulow2020,
  title = {Are the First or the Second Hips of Staged Bilateral {{THAs}} More Similar to Unilateral Procedures? {{A}} Study from the Swedish Hip Arthroplasty Register},
  author = {B{\"u}low, Erik and Nemes, Szilard and Rolfson, Ola},
  year = {2020},
  month = mar,
  pages = {1},
  issn = {0009-921X},
  doi = {10.1097/CORR.0000000000001210},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HERD3BUN\\bülow_et_al_2020_are_the_first_or_the_second_hips_of_staged_bilateral_thas_more_similar_to.pdf},
  journal = {Clinical Orthopaedics and Related Research},
  keywords = {\#nosource,coder}
}

@techreport{Burgette2020,
  title = {Propensity Scores for Multiple Treatments: {{A}} Tutorial for the Mnps Function in the Twang Package},
  author = {Burgette, Lane and Griffin, Beth Ann and McCaffrey, Dan and Corporation, RAND},
  year = {2020},
  month = feb,
  pages = {22},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B32E2NPR\\Burgette m. fl. - Propensity scores for multiple treatments A tutor.pdf},
  keywords = {simonsson},
  language = {en}
}

@article{Burman2009,
  title = {A Recycling Framework for the Construction of {{Bonferroni}}-Based Multiple Tests.},
  author = {Burman, C-F and Sonesson, C and Guilbaud, O},
  year = {2009},
  month = feb,
  volume = {28},
  pages = {739--61},
  issn = {0277-6715},
  doi = {10.1002/sim.3513},
  abstract = {In this paper we describe Bonferroni-based multiple testing procedures (MTPs) as strategies to split and recycle test mass. Here, 'test mass' refers to (parts of) the nominal level alpha at which the family-wise error rate is controlled. Briefly, test mass is split between different null hypotheses, and whenever a null hypothesis is rejected, the part of alpha allocated to it may be recycled to the testing of other hypotheses. These recycling MTPs are closed testing procedures based on raw p-values associated with testing the individual null hypotheses, and the class of such MTPs includes, for example, serial and parallel gatekeeping, fallback and Holm procedures. Graphical displays and a concise algebraic notation are provided for such MTPs. This recycling approach has pedagogical advantages and may facilitate the tailoring of MTPs for different purposes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WTX3A56Q\\Burman et al. - 2009 - A recycling framework for the construction of Bonf.pdf},
  journal = {Statistics in medicine},
  keywords = {Algorithms,Bias (Epidemiology),Biometry,Biometry: methods,Clinical Trials as Topic,False Positive Reactions,Humans,Models,Statistical},
  number = {5},
  pmid = {19142850}
}

@article{Burns2012,
  title = {Systematic Review of Discharge Coding Accuracy},
  author = {Burns, E. M. and Rigby, E. and Mamidanna, R. and Bottle, A. and Aylin, P. and Ziprin, P. and Faiz, O. D.},
  year = {2012},
  month = mar,
  volume = {34},
  pages = {138--148},
  issn = {1741-3842},
  doi = {10.1093/pubmed/fdr054},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VFZB8FWG\\Burns et al. - 2012 - Systematic review of discharge coding accuracy.pdf},
  journal = {Journal of Public Health},
  number = {1}
}

@article{Burr1994,
  title = {A Comparison of Certain Bootstrap Confidence Intervals in the {{Cox}} Model},
  author = {Burr, Deborah},
  year = {1994},
  volume = {89},
  pages = {1290--1302},
  issn = {1537274X},
  doi = {10.1080/01621459.1994.10476869},
  abstract = {We study bootstrap confidence intervals for three types of parameters in Cox's proportional hazards model: the regression parameter, the survival function at fixed time points, and the median survival time at fixed values of a covariate. Several types of bootstrap confidence intervals are studied, and the type of interval is determined by two factors. One factor is the method of drawing the bootstrap sample. We consider three such methods: (1) ordinary resampling from the empirical cumulative distribution function, (2) resampling conditional on the covariates, and (3) resampling conditional on the covariates and the censoring pattern. Another factor is the method of forming the confidence interval from a given sample; the methods considered are the percentile, hybrid, and bootstrap-t. All the methods of forming confidence intervals are compared to each other and to the standard asymptotic method via a Monte Carlo study. The data sets for this Monte Carlo study are simulated conditionally on the covariates and the censoring pattern, the situation appropriate for the third method of resampling. One conclusion drawn from the Monte Carlo study is that the asymptotic method is best for the regression parameter, but not for the survival function or the median survival time. Conclusions about the bootstrap methods include the surprising result that, overall, the second method of drawing the samples outperforms the third method. Also, there is an interaction effect between the two factors, method of drawing the sample and method of forming the interval, especially for estimation of the regression parameter. Finally, the bootstrap-t intervals are consistently outperformed by at least one of the two more rudimentary types of bootstrap interval. \textcopyright{} 1994 Taylor \& Francis Group, LLC.},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource,Ancillarity principle,Bootstrap-t,Hybrid interval,Percentile interval,Proportional hazards model},
  number = {428}
}

@article{Burstrom2014,
  title = {Swedish Experience-Based Value Sets for {{EQ}}-{{5D}} Health States},
  author = {Burstr{\"o}m, Kristina and Sun, Sun and Gerdtham, Ulf-G and Henriksson, Martin and Johannesson, Magnus and Levin, Lars-\AA ke and Zethraeus, Niklas},
  year = {2014},
  volume = {23},
  pages = {431--442},
  issn = {13100351},
  isbn = {1626008914},
  journal = {Quality of Life Research},
  keywords = {\#nosource},
  number = {2}
}

@article{Burstrom2020,
  title = {Experience-{{Based Swedish TTO}} and {{VAS Value Sets}} for {{EQ}}-{{5D}}-{{5L Health States}}},
  author = {Burstr{\"o}m, Kristina and Teni, Fitsum Sebsibe and Gerdtham, Ulf-G. and Leidl, Reiner and Helgesson, Gert and Rolfson, Ola and Henriksson, Martin},
  year = {2020},
  month = apr,
  issn = {1170-7690, 1179-2027},
  doi = {10.1007/s40273-020-00905-7},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CTE3UZHR\\Burström m. fl. - 2020 - Experience-Based Swedish TTO and VAS Value Sets fo.pdf},
  journal = {PharmacoEconomics},
  language = {en}
}

@article{Burton2006,
  title = {The Design of Simulation Studies in Medical Statistics},
  author = {Burton, Andrea and Altman, Douglas G. and Royston, Patrick and Holder, Roger L.},
  year = {2006},
  volume = {25},
  pages = {4279--4292},
  issn = {02776715},
  doi = {10.1002/sim.2673},
  abstract = {Simulation studies use computer intensive procedures to assess the performance of a variety of statistical methods in relation to a known truth. Such evaluation cannot be achieved with studies of real data alone. Designing high-quality simulations that reflect the complex situations seen in practice, such as in prognostic factors studies, is not a simple process. Unfortunately, very few published simulation studies provide sufficient details to allow readers to understand fully all the processes required to design a simulation study. When planning a simulation study, it is recommended that a detailed protocol be produced, giving full details of how the study will be performed, analysed and reported. This paper details the important considerations necessary when designing any simulation study, including defining specific objectives of the study, determining the procedures for generating the data sets and the number of simulations to perform. A checklist highlighting the important considerations when designing a simulation study is provided. A small review of the literature identifies the current practices within published simulation studies. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NF93JU5U\\Burton et al. - 2006 - The design of simulation studies in medical statis.pdf},
  isbn = {2007090091480},
  journal = {Statistics in Medicine},
  keywords = {Bias,Coverage,Design,Mean square error,Protocol,Simulation study},
  pmid = {16947139}
}

@article{Burton2006,
  title = {The Design of Simulation Studies in Medical Statistics {{Andrea}}},
  author = {Burton, Andreas and Altman, Douglas D and Royston, Patrick and Holder, Roger L},
  year = {2006},
  volume = {25},
  pages = {4267--4278},
  doi = {10.1002/sim},
  abstract = {Although sample size calculations have become an important element in the design of research projects, such methods for studies involving current status data are scarce. Here, we propose a method for calculating power and sample size for studies using current status data. This method is based on a Weibull survival model for a two-group comparison. The Weibull model allows the investigator to specify a group difference in terms of a hazards ratio or a failure time ratio. We consider exponential, Weibull and uniformly distributed censoring distributions. We base our power calculations on a parametric approach with the Wald test because it is easy for medical investigators to conceptualize and specify the required input variables. As expected, studies with current status data have substantially less power than studies with the usual right-censored failure time data. Our simulation results demonstrate the merits of these proposed power calculations.},
  journal = {Statistics in Medicine},
  keywords = {\#nosource,publication bias,selection bias,selection model,sensitivity analysis,unpublished studies}
}

@article{Buuren2011,
  title = {Mice : {{Multivariate}} Imputation by Chained Equations in r},
  author = {{van Buuren}, Stef and {Groothuis-Oudshoorn}, Karin},
  year = {2011},
  volume = {45},
  issn = {1548-7660},
  doi = {10.18637/jss.v045.i03},
  abstract = {The R package mice imputes incomplete multivariate data by chained equations. The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. mice 1.0 introduced predictor selection, passive imputation and automatic pooling. This article documents mice 2.9, which extends the functionality of mice 1.0 in several ways. In mice 2.9, the analysis of imputed data is made completely general, whereas the range ofmodels under which pooling works is substantially extended. mice 2.9 adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs. Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. mice 2.9 can be downloaded from the Comprehensive R Archive Network. This article provides a hands-on, stepwise approach to solve applied incomplete data problems.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WIYK2Q9V\\van_buuren_groothuis-oudshoorn_2011_mice.pdf},
  isbn = {9067436771},
  journal = {Journal of Statistical Software},
  keywords = {chained equations,fully conditional specification,gibbs sampler,mice,multiple imputation,passive imputation,predictor selection,r},
  number = {3},
  pmid = {22289957}
}

@article{Cade2015,
  title = {Model Averaging and Muddled Multimodel Inferences},
  author = {Cade, Brian S.},
  year = {2015},
  month = sep,
  volume = {96},
  pages = {2370--2382},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0012-9658},
  doi = {10.1890/14-1639.1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9WLMC6LD\\Cade - 2015 - Model averaging and muddled multimodel inferences.pdf},
  journal = {Ecology},
  keywords = {generalized linear models,Greater Sage,Grouse,model averaging,multicollinearity,multimodel inference,partial effects,partial standard deviations,regression coefficients,relative importance of predictors,species distribution models,truncated Poisson regression,zero},
  number = {9}
}

@article{Cafri2016,
  title = {Sparsely Clustered Survival Data: Application to the Evaluation of the Safety and Effectiveness of Medical Devices},
  author = {Cafri, Guy},
  year = {2016},
  volume = {43},
  pages = {3004--3014},
  issn = {13600532},
  doi = {10.1080/02664763.2016.1157143},
  abstract = {The effectiveness and safety of implantable medical devices is apublic health concern. We consider analysis of data in which it{$\nis$}of interest to compare devices but some individuals may be implantedtwo or more devices. Our motivating example is based on orthopedic, where the same individual can be implanted with as many as twofor the same joint but on different sides of the body, referredas bilateral cases. Different methods of analysis are considered in astudy and real data example, including both marginal andsurvival models, fitting single and separate models forand non-bilateral cases, and combining estimates from thesemodels. The results of simulations suggest that in the context ofdevices, where implants failures are rare, models fit on bothand non-bilateral cases simultaneously could be quite, and that combined estimates from fitting two separate modelsbetter under homogeneity. A real data example illustrates thesurrounding analysis of orthopedic device data with bilateral. Our findings suggest that research studies of orthopedic devicesat minimum consider fitting separate models to bilateral and-bilateral cases.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E26YBCD8\\cafri_2016_sparsely_clustered_survival_data.pdf},
  journal = {Journal of Applied Statistics},
  keywords = {failure,frailty models,medical devices,orthopedic,Survival analysis},
  number = {16}
}

@techreport{Cancerfonden2019,
  title = {Cancerfondsrapporten 2019 Forskning},
  author = {{Cancerfonden}},
  year = {2019},
  keywords = {\#nosource}
}

@article{Cancienne2015,
  title = {Does {{Timing}} of {{Previous Intra}}-{{Articular Steroid Injection Affect}} the {{Post}}-{{Operative Rate}} of {{Infection}} in {{Total Knee Arthroplasty}}?},
  author = {Cancienne, Jourdan M. and Werner, Brian C. and Luetkemeyer, Luke M. and Browne, James A.},
  year = {2015},
  month = nov,
  volume = {30},
  pages = {1879--1882},
  issn = {08835403},
  doi = {10.1016/j.arth.2015.05.027},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {11}
}

@article{Candes2007,
  title = {The {{Dantzig}} Selector: {{Statistical}} Estimation When p Is Much Larger than n},
  author = {Candes, Emmanuel and Tao, Terence},
  year = {2007},
  month = dec,
  volume = {35},
  pages = {2313--2351},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00905364},
  doi = {10.1214/009053606000001523},
  abstract = {In many important statistical applications, the number of variables or parameters p is much larger than the number of observations n. Suppose then that we have observations y=X{$\beta$}+z, where {$\beta\in\lbrace$}R\vphantom\{\}\textsuperscript{p} is a parameter vector of interest, X is a data matrix with possibly far fewer rows than columns, n{$\ll$}p, and the z\textsubscript{i}'s are i.i.d. N(0,{$\sigma^2$}). Is it possible to estimate {$\beta$} reliably based on the noisy data y? To estimate {$\beta$}, we introduce a new estimator\textendash we call it the Dantzig selector\textendash which is a solution to the {$_1$}-regularization problem [\textsubscript{\{\vphantom\}}{\~ }\{eta\}{$\in\lbrace$}R\vphantom\{\}\textsuperscript{p}\vphantom\{\}|{\~ }\{{$\beta\rbrace$}|\vphantom\}\textsubscript{\{\vphantom\}}{$_{1}\rbrace\quad$}subject to\hspace{1em}|X\textsuperscript{*}r|\textsubscript{\{\vphantom\}}\textsubscript{\{\vphantom\}}{$\infty\rbrace\rbrace\leq$}(1+t\textsuperscript{\{\vphantom\}}-1\vphantom\{\})\{2p\}{$\cdot\sigma$},] where r is the residual vector y-X{\~ }\{{$\beta\rbrace$} and t is a positive scalar. We show that if X obeys a uniform uncertainty principle (with unit-normed columns) and if the true parameter vector {$\beta$} is sufficiently sparse (which here roughly guarantees that the model is identifiable), then with very large probability, [|{\^ }\{{$\beta\rbrace$}-{$\beta$}|\vphantom{\}\}}\textsubscript{\{\vphantom\}}{$_{2}\rbrace^{2}\leq$}C{$^{2}\cdot$}2p{$\cdot$}({$\sigma^2$}+{$\sum$}\textsubscript{i}({$\beta$}\textsubscript{i}{$^2$},{$\sigma^2$})).] Our results are nonasymptotic and we give values for the constant C. Even though n may be much smaller than p, our estimator achieves a loss within a logarithmic factor of the ideal mean squared error one would achieve with an oracle which would supply perfect information about which coordinates are nonzero, and which were above the noise level. In multivariate regression and from a model selection viewpoint, our result says that it is possible nearly to select the best subset of variables by solving a very simple convex program, which, in fact, can easily be recast as a convenient linear program (LP).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8BLN3VBY\\candes_tao_2007_the_dantzig_selector.pdf},
  journal = {Annals of Statistics},
  keywords = {geometry in high dimensions,Geometry in high dimensions,ideal estimation,Ideal estimation,ℓ1- minimization,ℓ₁-minimization,linear programming,Linear programming,model selection,Model selection,oracle inequalities,Oracle inequalities,random matrices,Random matrices,restricted orthonormality,Restricted orthonormality,sparse solutions to underdetermined systems,Sparse solutions to underdetermined systems,Statistical linear model},
  number = {6}
}

@article{Carney2014,
  title = {Abnormal {{CA}}-125 Levels in Menopausal Women without Ovarian Cancer},
  author = {Carney, Michael and Ahn, Hyeong Jun and Elia, Jennifer and Terada, Keith Y. and Kim, Robert},
  year = {2014},
  volume = {135},
  pages = {34--37},
  publisher = {{Elsevier Inc.}},
  issn = {00908258},
  doi = {10.1016/j.ygyno.2014.08.008},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RCKPXWG2\\carney_et_al_2014_abnormal_ca-125_levels_in_menopausal_women_without_ovarian_cancer.pdf},
  journal = {Gynecologic Oncology},
  keywords = {CA-125,Ovarian cancer screening,PLCO},
  number = {1}
}

@article{Carpenter2000,
  title = {Bootstrap Confidence Intervals: {{When}}, Which, What? {{A}} Practical Guide for Medical Statisticians},
  author = {Carpenter, James and Bithell, John},
  year = {2000},
  volume = {19},
  pages = {1141--1164},
  issn = {02776715},
  doi = {10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F},
  abstract = {Since the early 1980s, a bewildering array of methods for constructing bootstrap confidence intervals have been proposed. In this article, we address the following questions. First, when should bootstrap confidence intervals be used. Secondly, which method should be chosen, and thirdly, how should it be implemented. In order to do this, we review the common algorithms for resampling and methods for constructing bootstrap confidence intervals, together with some less well known ones, highlighting their strengths and weaknesses. We then present a simulation study, a flow chart for choosing an appropriate method and a survival analysis example.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B7KGL6NE\\carpenter_bithell_2000_bootstrap_confidence_intervals.pdf},
  isbn = {0277-6715},
  journal = {Statistics in Medicine},
  number = {9},
  pmid = {10797513}
}

@article{Casella2002,
  title = {Solutions Manual for Statistical Inference},
  author = {Casella, George and Berger, Roger L. and Santana, Damaris},
  year = {2002},
  pages = {195},
  issn = {0307-4463},
  doi = {10.1057/pt.2010.23},
  abstract = {This solutions manual contains solutions for all odd numbered problems plus a large number of solutions for even numbered problems. Of the 624 exercises in Statistical Inference, Second Edition, this manual gives solutions for 484 (78\%) of them. There is an obtuse pattern as to which solutions were included in this manual. We assembled all of the solutions that we had from the first edition, and filled in so that all odd-numbered problems were done. In the passage from the first to the second edition, problems were shuffled with no attention paid to numbering (hence no attention paid to minimize the new effort), but rather we tried to put the problems in logical order. A major change from the first edition is the use of the computer, both symbolically through Mathematicatm and numerically using R. Some solutions are given as code in either of these lan- guages. Mathematicatm can be purchased from Wolfram Research, and R is a free download from http://www.r-project.org/.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TRGZBG46\\casella_et_al_2002_solutions_manual_for_statistical_inference.pdf},
  isbn = {0534243126},
  journal = {Statistical Inference},
  pmid = {20927031}
}

@book{Casella2006,
  title = {An Introduction to Statistical Learning},
  author = {Casella, George and Fienberg, Stephen and Olkin, Ingram},
  year = {2006},
  volume = {102},
  issn = {01621459},
  doi = {10.1016/j.peva.2007.06.006},
  abstract = {Review From the reviews: .,."There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006 "The reader sees not only how measure theory is used to develop probability theory, but also how probability theory is used in applications. a The discourse is delivered in a theorem proof format and thus is better suited for classroom a . The authors prose is generally well thought out a . will make an attractive choice for a two-semester course on measure and probability, or as a second course for students with a semester of measure or probability theory under their belt." (Peter C. Kiessler, Journal of the American Statistical Association, Vol. 102 (479), 2007) "The book is a well written self-contained textbook on measure and probability theory. It consists of 18 chapters. Every chapter contains many well chosen examples and ends with several problems related to the earlier developed theory (some with hints). a At the very end of the book there is an appendix collecting necessary facts from set theory, calculus and metric spaces. The authors suggest a few possibilities on how to use their book." (Kazimierz Musial, Zentralblatt MATH, Vol. 1125 (2), 2008) "The title of the book consists of the names of its two basic parts. The booka (TM)s third part is comprised of some special topics from probability theory. a The authors suggest using the book intwo-semester graduate programs in statistics or a one-semester seminar on special topics. The material of the book is standard a is clear, comprehensive and a  without being intimidatinga (TM)." (Rimas NorvaiAa, Mathematical Reviews, Issue 2007 f) Product Description This is a graduate level textbook on measure theory and probability theory. The book can be used as a text for a two semester sequence of courses in measure theory and probability theory, with an option to include supplemental material on stochastic processes and special topics. It is intended primarily for first year Ph.D. students in mathematics and statistics although mathematically advanced students from engineering and economics would also find the book useful. Prerequisites are kept to the minimal level of an understanding of basic real analysis concepts such as limits, continuity, differentiability, Riemann integration, and convergence of sequences and series. A review of this material is included in the appendix. The book starts with an informal introduction that provides some heuristics into the abstract concepts of measure and integration theory, which are then rigorously developed. The first part of the book can be used for a standard real analysis course for both mathematics and statistics Ph.D. students as it provides full coverage of topics such as the construction of Lebesgue-Stieltjes measures on real line and Euclidean spaces, the basic convergence theorems, L p spaces, signed measures, Radon-Nikodym theorem, Lebesgue's decomposition theorem and the fundamental theorem of Lebesgue integration on R, product spaces and product measures, and Fubini-Tonelli theorems. It also provides an elementary introduction to Banach and Hilbert spaces, convolutions, Fourier series and Fourier and Plancherel transforms. Thus part I would be particularly useful for students in a typical Statistics Ph.D. program if a separate course on real analysis is not a standard requirement. Part II (chapters 6-13) provides full coverage of standard graduate level probability theory. It starts with Kolmogorov's probability model and Kolmogorov's existence theorem. It then treats thoroughly the laws of large numbers including renewal theory and ergodic theorems with applications and then weak convergence of probability distributions, characteristic functions, the Levy-Cramer continuity theorem and the central limit theorem as well as stable laws. It ends with conditional expectations and conditional probability, and an introduction to the theory of discrete time martingales. Part III (chapters 14-18) provides a modest coverage of discrete time Markov chains with countable and general state spaces, MCMC, continuous time discrete space jump Markov processes, Brownian motion, mixing sequences, bootstrap methods, and branching processes. It could be used for a topics/seminar course or as an introduction to stochastic processes. From the reviews: "...There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YI7MD6U7\\casella_et_al_2006_an_introduction_to_statistical_learning.pdf},
  isbn = {978-0-387-78188-4},
  pmid = {10911016}
}

@article{castro-condeSgofPackageMultiple2014,
  title = {Sgof: {{An R}} Package for Multiple Testing Problems},
  author = {{Castro-Conde}, Irene and {de U{\~n}a-{\'A}lvarez}, Jacobo},
  year = {2014},
  volume = {6},
  pages = {96--113},
  issn = {20734859},
  journal = {The R Journal},
  keywords = {\#nosource},
  number = {2}
}

@article{Castronuovo2011,
  title = {Early and Late Mortality in Elderly Patients after Hip Fracture: A Cohort Study Using Administrative Health Databases in the {{Lazio}} Region, {{Italy}}},
  author = {Castronuovo, Esmeralda and Pezzotti, Patrizio and Franzo, Antonella and Lallo, Domenico Di and Guasticchi, Gabriella},
  year = {2011},
  volume = {11},
  pages = {37},
  issn = {1471-2318},
  doi = {10.1186/1471-2318-11-37},
  abstract = {BACKGROUND Hip fractures represent one of the most important causes of morbidity and mortality in elderly people. We evaluated the risk and the potential determinants of early, mid and long term mortality, in a population-based cohort of subjects aged {$\geq$} 65 years old. METHODS Using hospital discharge database we identified all hospitalized hip fracture cases of 2006, among residents in Lazio Region aged {$\geq$} 65 years old. The mortality follow-up was performed through a deterministic record-linkage between the cohort and the death registry for the years 2006 and 2007. Kaplan-Meier method was used to calculate cumulative survival probability after admission. Shared frailties Cox regression model was used to estimate adjusted hazard ratios (HRs) for early (within 1 month), mid (1-6 months) and long term (6-24 months) mortality. As possible cofactors we considered age, gender, marital status, education degree, comorbidities, surgical intervention, and hospital volume of surgical treatment for hip fracture. RESULTS We identified 6,896 patients; 78\% were females, median age was 83 and 9\% had two or more comorbidities. Five percent died during hospital stay; the cumulative probability of dying at 30, 180 days, and at 2 years was 7\%, 18\% and 30\%. In the first month following admission, we found a significantly increased HR with older age, male sex, not married status, history of hearth disease, chronic pulmonary and renal disease; for those who had surgery there was a significantly increased HR within two days after surgical intervention and a significantly decreased HR thereafter compared to those who received a conservative management. Between 1 and 6 months significantly increased HRs were for older age, male sex and higher hospital volume of surgical treatment. After six months, significantly increased HRs were for older age, male sex, presence of dementia and other low prevalence diseases. CONCLUSION In Lazio region the risk of dying after hip fracture is similar to that found in high-income countries. Both clinical and organizational factors of acute care are associated with the risk of early mortality. As time passes, some of these factors tend to become less important while older age, male gender, the presence of cognitive problems and the presence of other comorbidities remain significant.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\78HGXG2B\\castronuovo_et_al_2011_early_and_late_mortality_in_elderly_patients_after_hip_fracture.pdf},
  isbn = {1471-2318},
  journal = {BMC Geriatrics},
  number = {1},
  pmid = {21819551}
}

@article{Cattin1980,
  title = {Estimation of the Predictive Power of a Regression Model},
  author = {Cattin, Philippe},
  year = {1980},
  volume = {65},
  pages = {407--414},
  issn = {0021-9010},
  doi = {10.1037//0021-9010.65.4.407},
  abstract = {There are two ways to estimate the predictive power of a regression model: a cross-validation procedure and a formula. A number of formulas have been derived. A review of the literature leads to four (unbiased or least biased) formulas, each one appropriate depending on whether the predictor variables are fixed or random and on the measure needed, that is, a measure of the absolute error (the mean squared error of prediction) or of the relative error (the cross-validated multiple correlation). The advantages of these formulas over cross-validation are that they are less cumbersome to use and that they produce more precise estimates. The conditions under which it is appropriate to use these formulas are discussed as well as their use for comparing the predictive power of regression, subjective and equal weights. [ABSTRACT FROM AUTHOR]},
  journal = {Journal of Applied Psychology},
  keywords = {\#nosource,ANALYSIS of variance,CORRELATION (Statistics),MATHEMATICAL statistics,REGRESSION analysis},
  number = {4}
}

@article{Caughey2010,
  title = {Comorbidity in the Elderly with Diabetes: {{Identification}} of Areas of Potential Treatment Conflicts},
  author = {Caughey, Gillian E. and Roughead, Elizabeth E. and Vitry, Agnes I. and McDermott, Robyn A. and Shakib, Sepehr and Gilbert, Andrew L.},
  year = {2010},
  month = mar,
  volume = {87},
  pages = {385--393},
  issn = {01688227},
  doi = {10.1016/j.diabres.2009.10.019},
  abstract = {Aims: To investigate the prevalence of comorbid conditions in the elderly with diabetes and the prescribing of potentially inappropriate medicines or treatment conflicts. Methods: A cross-sectional study of diabetics aged {$\geq$}65 years, using prescription dispensing data from the Australian Department of Veterans' Affairs. Comorbidities were determined using the comorbidity index Rx-Risk-V. Potentially inappropriate prescribing or treatment conflicts specific for the elderly were determined from guidelines or reference compendia, in addition to the 2003 updated Beers criteria. Results: Of 18,968 diabetics, the median number of comorbidities was 5 (IQR 3-8). Diabetes and associated cardiovascular medicines accounted for 41.9\% of all medicine use. Associated cardiovascular diseases were highly prevalent comorbidities. 46\% had gastro-oesophageal reflux disease, 25\% depression, 20\% chronic airways disease or chronic pain and 15\% also had heart failure or inflammation-pain. At least 16\% were dispensed a medicine associated with adverse effects in patients with diabetes and 22.7\% were dispensed at least one potentially inappropriate medicine. Conclusion: Significant comorbid conditions in elderly diabetic patients with potential for inappropriate prescribing or treatment conflicts include arthritis, heart failure, chronic airways diseases and diseases treatable with systemic corticosteroids. Appropriate management of comorbidity should be included in guidelines for the elderly with diabetes. \textcopyright{} 2009 Elsevier Ireland Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NE9CINVX\\caughey_et_al_2010_comorbidity_in_the_elderly_with_diabetes.pdf},
  journal = {Diabetes Research and Clinical Practice},
  keywords = {Comorbidity,Diabetes,Elderly,Inappropriate prescribing,Polypharmacy},
  number = {3}
}

@book{Chambers2008,
  title = {Software for Data Analysis: {{Programming}} with r},
  author = {Chambers, John M.},
  year = {2008},
  abstract = {, except for brief excerpts in connection with reviews or scholarly analysis. Use in connection with any form of information storage and retrieval, electronic adaptation, computer software, not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.},
  isbn = {978-0-387-75935-7},
  keywords = {\#nosource}
}

@article{Charles1997,
  title = {Shared Decision-Making in the Medical Encounter: {{What}} Does It Mean? ({{Or}} It Takes, at Least Two to Tango)},
  author = {Charles, Cathy and Gafni, Amiram and Whelan, Tim},
  year = {1997},
  volume = {44},
  pages = {681--692},
  issn = {02779536},
  doi = {10.1016/S0277-9536(96)00221-3},
  abstract = {Shared decision-making is increasingly advocated as an ideal model of treatment decision-making in the medical encounter. To date, the concept has been rather poorly and loosely defined. This paper attempts to provide greater conceptual clarity about shared treatment decision-making, identify some key characteristics of this model, and discuss measurement issues. The particular decision-making context that we focus on is potentially life threatening illnesses, where there are important decisions to be made at key points in the disease process, and several treatment options exist with different possible outcomes and substantial uncertainty. We suggest as key characteristics of shared decision-making (1) that at least two participants-physician and patient be involved; (2) that both parties share information; (3) that both parties take steps to build a consensus about the preferred treatment; and (4) that an agreement is reached on the treatment to implement. Some challenges to measuring shared decision-making are discussed as well as potential benefits of a shared decision-making model for both physicians and patients.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RP25CTKH\\charles_et_al_1997_shared_decision-making_in_the_medical_encounter.pdf},
  isbn = {0277-9536 (Print){\r  }0277-9536 (Linking)},
  journal = {Social Science and Medicine},
  keywords = {Physician/Patient communication,Shared treatment decision-making},
  number = {5},
  pmid = {9032835}
}

@article{Charlson1987,
  title = {A New Method of Classifying Prognostic Comorbidity in Longitudinal Studies: {{Development}} and Validation},
  author = {Charlson, Mary E. and Pompei, Peter and Ales, Kathy L. and MacKenzie, C. Ronald},
  year = {1987},
  volume = {40},
  pages = {373--383},
  issn = {00219681},
  doi = {10.1016/0021-9681(87)90171-8},
  abstract = {The objective of this study was to develop a prospectively applicable method for classifying comorbid conditions which might alter the risk of mortality for use in longitudinal studies. A weighted index that takes into account the number and the seriousness of comorbid disease was developed in a cohort of 559 medical patients. The 1-yr mortality rates for the different scores were: "0", 12\% (181); "1-2", 26\% (225); "3-4", 52\% (71); and "??? 5", 85\% (82). The index was tested for its ability to predict risk of death from comorbid disease in the second cohort of 685 patients during a 10-yr follow-up. The percent of patients who died of comorbid disease for the different scores were: "0", 8\% (588); "1", 25\% (54); "2", 48\% (25); " ??? 3", 59\% (18). With each increased level of the comorbidity index, there were stepwise increases in the cumulative mortality attributable to comorbid disease (log rank ??2 = 165; p \textexclamdown{} 0.0001). In this longer follow-up, age was also a predictor of mortality (p \textexclamdown{} 0.001). The new index performed similarly to a previous system devised by Kaplan and Feinstein. The method of classifying comorbidity provides a simple, readily applicable and valid method of estimating risk of death from comorbid disease for use in longitudinal studies. Further work in larger populations is still required to refine the approach because the number of patients with any given condition in this study was relatively small. ?? 1987.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZXGYWWJN\\charlson_et_al_1987_a_new_method_of_classifying_prognostic_comorbidity_in_longitudinal_studies.pdf},
  isbn = {0021-9681 (Print)0021-9681 (Linking)},
  journal = {Journal of Chronic Diseases},
  keywords = {coder},
  number = {5},
  pmid = {3558716}
}

@article{Charlson1987a,
  title = {Why Predictive Indexes Perform Less Well in Validation Studies: {{Is}} It Magic or Methods?},
  author = {Charlson, ME and Ales, KL and Simon, R and MacKenzie, R},
  year = {1987},
  month = dec,
  volume = {147},
  pages = {2155--2161},
  issn = {0003-9926},
  abstract = {\textbullet{} When prognostic indexes have been tested in a second population, they have often performed less well. Since this is believed to be inevitable, methodologic differences that may explain the discrepancies have been overlooked. Data from a prospective study of 232 patients undergoing noncardiac surgery were used to examine the effect of methodologic differences in assembly of population, postoperative surveillance, and the criteria for cardiac complications on the performance of Goldman's cardiac risk index. Our prospective population was used to simulate the methods used in Goldman's study and in three other studies using the risk index to demonstrate the potential impact of differences in population, surveillance, and outcome criteria for cardiac complications. If Goldman's detection and outcome criteria were employed and only the eligibility criteria used for assembly of the populations differed, the overall complication rates would be between 5.2\% and 6.9\%; and the complication rates for the different Goldman classes were similar. When both different detection strategies and different outcome criteria were used, however, important discrepancies in cardiac complication rates emerged. For example, complication rates in class 2 varied from 2\% to 23\%. In conclusion, important discrepancies in performance of prognostic indexes may arise from differences in surveillance strategies and definitions of outcome. With sufficient attention to methodologic consistency, the performance of predictive indexes may not inevitably deteriorate in subsequent studies.(Arch Intern Med 1987;147:2155-2161)},
  journal = {Archives of Internal Medicine},
  keywords = {\#nosource},
  number = {12}
}

@article{Charlson2016,
  title = {Comment by {{M}}.{{E}}. Charlson and m. {{Wells}}},
  author = {Charlson, Mary E. and Wells, Martin},
  year = {2016},
  month = nov,
  volume = {79},
  pages = {29},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2016.11.006},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NCYBDB9U\\charlson_wells_2016_comment_by_m.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@article{Chatziagorou2018,
  ids = {Chatziagorou2019},
  title = {Incidence and Demographics of 1751 Surgically Treated Periprosthetic Femoral Fractures around a Primary Hip Prosthesis},
  author = {Chatziagorou, Georgios and Lindahl, Hans and Garellick, G{\"o}ran and K{\"a}rrholm, Johan},
  year = {2018},
  pages = {112070001877955},
  issn = {1120-7000},
  doi = {10.1177/1120700018779558},
  journal = {HIP International},
  keywords = {\#nosource,16 november 2017,3 april 2018,accepted,date received,femoral,Femoral,fractures,periprosthetic,total hip replacement}
}

@article{Chatziagorou2019,
  title = {The Design of the Cemented Stem Influences the Risk of {{Vancouver}} Type {{B}} Fractures, but Not of Type {{C}}: An Analysis of 82,837 {{Lubinus SPII}} and {{Exeter Polished}} Stems},
  author = {Chatziagorou, Georgios and Lindahl, Hans and K{\"a}rrholm, Johan},
  year = {2019},
  volume = {90},
  pages = {135--142},
  issn = {17453682},
  doi = {10.1080/17453674.2019.1574387},
  abstract = {Background and purpose \textemdash{} In total hip replacements, stem design may affect the occurrence of periprosthetic femoral fracture. We studied risk factors for fractures around and distal to the 2 most used cemented femoral stems in Sweden. Patients and methods \textemdash{} This is a register study including all standard primary Lubinus SPII and Exeter Polished stems operated in Sweden between 2001 and 2009. The outcome was any kind of reoperation due to fracture around (Vancouver type B) or distal to the stem (Vancouver type C), with use of age, sex, diagnosis at primary THR, and year of index operation as covariates in a Cox regression analysis. A separate analysis of the primary osteoarthritis patient group was done in order to evaluate eventual influence of the surgical approach (lateral versus posterior) on the risk for Vancouver type B fractures. Results \textemdash{} The Exeter stem had a 10-times (95\% CI 7\textendash 13) higher risk for type B fractures, compared with the Lubinus, while no statistically significant difference was noticed for type C fractures. The elderly, and patients with hip fracture or idiopathic femoral head necrosis, had a higher risk for both fracture types. Inflammatory arthritis was a risk factor only for type C fractures. Type B fractures were more common in men, and type C in women. A lateral approach was associated with decreased risk for Type B fracture. Interpretation \textemdash{} Stem design influenced the risk for type B, but not for type C fracture. The influence of surgical approach on the risk for periprosthetic femoral fracture should be studied further.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Y43GHYW2\\chatziagorou_et_al_2019_the_design_of_the_cemented_stem_influences_the_risk_of_vancouver_type_b.pdf},
  journal = {Acta Orthopaedica},
  number = {2}
}

@article{Chatziagorou2019,
  title = {Lower Reoperation Rate with Locking Plates Compared with Conventional Plates in {{Vancouver}} Type {{C}} Periprosthetic Femoral Fractures: {{A}} Register Study of 639 Cases in {{Sweden}}},
  author = {Chatziagorou, Georgios and Lindahl, Hans and K{\"a}rrholm, Johan},
  year = {2019},
  volume = {50},
  pages = {2292--2300},
  publisher = {{Elsevier Ltd}},
  issn = {18790267},
  doi = {10.1016/j.injury.2019.10.029},
  abstract = {Aim: To investigate demographics and outcomes of Vancouver type C periprosthetic femoral fractures (PPFF) treated with open reduction and internal fixation. Methods: Patient data were obtained from medical charts of cases reported to the Swedish Hip Arthroplasty Register and/or from the National Patient Register. Vancouver type C fractures undergoing surgery between 2001 and 2011, in patients who had received their primary THR between 1979 and 2011, were included. Any further reoperation performed between 2001 and 2013 and related to the PPFF constituted the primary outcome. Results: A total of 632 patients with 639 Vancouver type C fractures were identified. The majority of the patients were women (84\%) and they had a fracture distal to a cemented stem (95\%). The mean age at the time of fracture was 72 years. Treatment was performed with a locking plate (363 cases), a conventional plate (184 cases), an intramedullary nail (62 cases), or with double plating (30 cases). The overall reoperation rate was 17\%, and mortality within one year of the operation was 16\%. Locking plates had a significantly lower reoperation rate than conventional plates (p\textexclamdown 0.001) and intramedullary nailing (p = 0.005). Interprosthetic femoral fractures did not have a statistically different outcome compared with non-IPFFs. Conclusions: The lowest reoperation rate was observed using locking plates in Vancouver type C fractures when compared with conventional plates or intramedullary nailing. The presence of an ipsilateral knee prosthesis did not influence the outcome of the surgical treatment.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WJNJI68Q\\chatziagorou_et_al_2019_lower_reoperation_rate_with_locking_plates_compared_with_conventional_plates_in.pdf},
  journal = {Injury},
  keywords = {Femoral fracture,Hip,Interprosthetic fracture,Locking plate,Mortality,Outcomes,Periprosthetic fracture},
  number = {12}
}

@article{Chatziagorou2019,
  title = {Surgical Treatment of {{Vancouver}} Type {{B}} Periprosthetic Femoral Fractures: {{Patient}} Characteristics and Outcomes of 1381 Fractures Treated in {{Sweden}} between 2001 and 2011},
  author = {Chatziagorou, G. and Lindahl, H. and K{\"a}rrholm, J.},
  year = {2019},
  volume = {101-B},
  pages = {1447--1458},
  issn = {20494408},
  doi = {10.1302/0301-620X.101B11.BJJ-2019-0480.R2},
  abstract = {Aims We investigated patient characteristics and outcomes of Vancouver type B periprosthetic fractures treated with femoral component revision and/or osteosynthesis. Patients and Methods The study utilized data from the Swedish Hip Arthroplasty Register (SHAR) and information from patient records. We included all primary total hip arthroplasties (THAs) performed in Sweden since 1979, and undergoing further surgery due to Vancouver type B periprosthetic femoral fracture between 2001 and 2011. The primary outcome measure was any further reoperation between 2001 and 2013. Cross-referencing with the National Patient Register was performed in two stages, in order to identify all surgical procedures not recorded on the SHAR. Results Out of 1381 Vancouver type B fractures that fulfilled the inclusion criteria, 257 underwent further reoperation by the end of 2013. Interprosthetic and Type B1 fractures had a higher risk for reoperation. For B1 fractures, the rate of reoperation did not differ (p = 0.322) after use of conventional (26\%) or locking plate osteosynthesis (19\%). No significant differences were observed between cemented, cementless monoblock, and cementless modular revision components for the treatment of type B2 and B3 fractures. Conclusion In this country-specific study, the choice of locking or conventional plates for the treatment of type B1, and cemented or cementless femoral components fixation for B2 and B3 fractures, had no significant influence on risk for reoperation. Interprosthetic fractures adversely affected the outcome of treatment of type B fractures. Differences in the patient characteristics of the compared groups were observed.},
  journal = {Bone and Joint Journal},
  keywords = {\#nosource},
  number = {11}
}

@article{Cheek2018,
  title = {Application of a Causal Discovery Algorithm to the Analysis of Arthroplasty Registry Data},
  author = {Cheek, Camden and Zheng, Huiyong and Hallstrom, Brian R and Hughes, Richard E},
  year = {2018},
  volume = {9},
  pages = {117959721875689},
  issn = {1179-5972},
  doi = {10.1177/1179597218756896},
  abstract = {Improving the quality of care for hip arthroplasty (replacement) patients requires the systematic evaluation of clinical performance of implants and the identification of ``outlier'' devices that have an especially high risk of reoperation (``revision''). Postmarket surveillance of arthroplasty implants, which rests on the analysis of large patient registries, has been effective in identifying outlier implants such as the ASR metal-on-metal hip resurfacing device that was recalled. Although identifying an implant as an outlier implies a causal relationship between the implant and revision risk, traditional signal detection methods use classical biostatistical methods. The field of probabilistic graphical modeling of causal relationships has developed tools for rigorous analysis of causal relationships in observational data. The purpose of this study was to evaluate one causal discovery algorithm (PC) to determine its suitability for hip arthroplasty implant signal detection. Simulated data were generated usin...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WMBMFETA\\cheek_et_al_2018_application_of_a_causal_discovery_algorithm_to_the_analysis_of_arthroplasty.pdf},
  journal = {Biomedical Engineering and Computational Biology},
  keywords = {arthroplasty,Causal discovery,hip,probabilistic graphical models}
}

@article{Chen2015,
  title = {Probability Cheatsheet},
  author = {Chen, William},
  year = {2015},
  pages = {14},
  abstract = {Compiled by William Chen (http://wzchen.com) with contributions from Sebastian Chiu, Yuan Jiang, Yuqi Hou, and Jessy Hwang. Material based off of Joe Blitzstein's (@stat110) lectures (http://stat110.net) and Blitzstein/Hwang's Intro to Probability textbook (http://bit.ly/introprobability). Licensed under CC BY-NC-SA 4.0. Please share comments, suggestions, and errors at http://github.com/wzchen/probability\textsubscript{c}heatsheet.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2PGKH82P\\chen_2015_probability_cheatsheet.pdf},
  journal = {Iclr}
}

@generic{Christodoulou2019,
  title = {A Systematic Review Shows No Performance Benefit of Machine Learning over Logistic Regression for Clinical Prediction Models},
  author = {Christodoulou, Evangelia and Ma, Jie and Collins, Gary S. and Steyerberg, Ewout W. and Verbakel, Jan Y. and Calster, Ben Van},
  year = {2019},
  month = jun,
  volume = {110},
  pages = {12--22},
  publisher = {{Elsevier USA}},
  issn = {18785921},
  doi = {10.1016/j.jclinepi.2019.02.004},
  abstract = {Objectives: The objective of this study was to compare performance of logistic regression (LR) with machine learning (ML) for clinical prediction modeling in the literature. Study Design and Setting: We conducted a Medline literature search (1/2016 to 8/2017) and extracted comparisons between LR and ML models for binary outcomes. Results: We included 71 of 927 studies. The median sample size was 1,250 (range 72\textendash 3,994,872), with 19 predictors considered (range 5\textendash 563) and eight events per predictor (range 0.3\textendash 6,697). The most common ML methods were classification trees, random forests, artificial neural networks, and support vector machines. In 48 (68\%) studies, we observed potential bias in the validation procedures. Sixty-four (90\%) studies used the area under the receiver operating characteristic curve (AUC) to assess discrimination. Calibration was not addressed in 56 (79\%) studies. We identified 282 comparisons between an LR and ML model (AUC range, 0.52\textendash 0.99). For 145 comparisons at low risk of bias, the difference in logit(AUC) between LR and ML was 0.00 (95\% confidence interval, -0.18 to 0.18). For 137 comparisons at high risk of bias, logit(AUC) was 0.34 (0.20\textendash 0.47) higher for ML. Conclusion: We found no evidence of superior performance of ML over LR. Improvements in methodology and reporting are needed for studies that compare modeling algorithms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9GDIPZHZ\\christodoulou_et_al_2019_a_systematic_review_shows_no_performance_benefit_of_machine_learning_over.pdf},
  journal = {Journal of Clinical Epidemiology},
  keywords = {AUC,Calibration,Clinical prediction models,Logistic regression,Machine learning,Reporting}
}

@article{Clark2003,
  title = {Survival Analysis Part {{I}}: {{Basic}} Concepts and First Analyses},
  author = {Clark, T. G. and Bradburn, M. J. and Love, S. B. and Altman, D. G.},
  year = {2003},
  volume = {89},
  pages = {232--238},
  issn = {00070920},
  doi = {10.1038/sj.bjc.6601118},
  abstract = {In many cancer studies, the main outcome under assessment is the time to an event of interest. The generic name for the time is survival time, although it may be applied to the time survived from complete remission to relapse or progression as equally as to the time from diagnosis to death. If the event occurred in all individuals,manymethods of analysis would be applicable. However, it is usual that at the end of follow-up some of the individuals have not had the event of interest, and thus their true time to event is unknown. Further, survival data are rarely Normally distributed, but are skewed and comprise typically of many early events and relatively few late ones. It is these features of the data that make the special methods called survival analysis necessary. This paper is the first of a series of four articles that aim to introduce and explain the basic concepts of survival analysis. Most survival analyses in cancer journals use some or all of Kaplan Meier (KM) plots, logrank tests, and Cox (proportional hazards) regression. We will discuss the background to, and interpretation of, each of these methods but also other approaches to analysis that deserve to be used more often. In this first article, we will present the basic concepts of survival analysis, including how to produce and interpret survival curves, and how to quantify and test survival differences between two or more groups of patients. Future papers in the series cover multivariate analysis and the last paper introduces some more advanced concepts in a brief question and answer format. More detailed accounts of these methods can be found in books written specifically about survival analysis, for example, Collett (1994), Parmar and Machin (1995) and Kleinbaum (1996). In addition, individual references for the methods are presented throughout the series. Several introductory texts also describe the basis of survival analysis, for example, Altman (2003) and Piantadosi (1997).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VPJPUCJK\\clark_et_al_2003_survival_analysis_part_i.pdf},
  isbn = {0007-0920 (Print)0007-0920 (Linking)},
  journal = {British Journal of Cancer},
  keywords = {Kaplan-Meier,Statistical methods,Survival analysis},
  number = {2},
  pmid = {12865907}
}

@article{Claudy1978,
  title = {Multiple Regression and Validity Estimation in One Sample},
  author = {Claudy, John G.},
  year = {1978},
  volume = {2},
  pages = {595--607},
  issn = {0146-6216},
  doi = {10.1177/014662167800200414},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\422FU3XK\\claudy_1978_multiple_regression_and_validity_estimation_in_one_sample.pdf},
  journal = {Applied Psychological Measurement},
  number = {4}
}

@article{Cleves1997,
  title = {Evaluation of Two Competing Methods for Calculating {{Charlson}}'s Comorbidity Index When Analyzing Short-Term Mortality Using Administrative Data.},
  author = {Cleves, M A and Sanchez, N and Draheim, M},
  year = {1997},
  month = aug,
  volume = {50},
  pages = {903--8},
  issn = {0895-4356},
  abstract = {The performance and predictive power of the Deyo-Charlson and the Romano-Charlson comorbidity indices were compared when short-term mortality after hospitalization was the outcome of interest. These indices are commonly used to adjust for the effect of comorbidities when using administrative data in comparative studies. In hospital Medicare clam data for patients admitted to one of six medical categories (back pain, stroke, pneumonia, hip replacement, transurethral radical prostatectomy, or lysis of peritoneal adhesion), were selected for analyses. Logistic regression models were employed to evaluate the relative importance and the explanatory power of these indices for predicting mortality 30, 90, and 180 days after admission. The contribution of each index to mortality was assessed via the likelihood ratio chi-square statistic (G2), and the area under the receiver operator characteristic (ROC) curve was used to assess predictive power. Indices were evaluated using weights suggested by Charlson et al. and using empirically derived weights. Both indices improved the base model equally, although the predictive power of both indices was poor with values of the C statistic ranging from 0.60 to 0.78. Our results suggest limited applicability of these approaches when examining short-term mortality. A slight increase in predictive power was observed when indices were calculated using empirical weights derived from our data.},
  journal = {Journal of clinical epidemiology},
  keywords = {\#nosource},
  number = {8},
  pmid = {9291875}
}

@article{Cnudde2016,
  title = {Linking {{Swedish}} Health Data Registers to Establish a Research Database and a Shared Decision-Making Tool in Hip Replacement},
  author = {Cnudde, Peter and Rolfson, Ola and Nemes, Szilard and K{\"a}rrholm, Johan and Rehnberg, Clas and Rogmark, Cecilia and Timperley, John and Garellick, G{\"o}ran},
  year = {2016},
  volume = {17},
  pages = {414},
  publisher = {{BMC Musculoskeletal Disorders}},
  issn = {1471-2474},
  doi = {10.1186/s12891-016-1262-x},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9V9PNFG3\\cnudde_et_al_2016_linking_swedish_health_data_registers_to_establish_a_research_database_and_a.pdf},
  isbn = {1289101612},
  journal = {BMC Musculoskeletal Disorders},
  keywords = {comorbidities,Comorbidities,database,Database,prom,PROM,revision,Revision,shared decision model,Shared Decision Model,socio-economic,Socio-economic,total hip arthroplasty,Total Hip Arthroplasty},
  number = {1}
}

@article{Cnudde2017,
  title = {Trends in Hip Replacements between 1999 and 2012 in {{Sweden}}},
  author = {Cnudde, Peter and Nemes, Szilard and B{\"u}low, Erik and Timperley, John and Malchau, Henrik and K{\"a}rrholm, Johan and Garellick, G{\"o}ran and Rolfson, Ola},
  year = {2017},
  volume = {36},
  pages = {432--442},
  issn = {1554527X},
  doi = {10.1002/jor.23711},
  abstract = {National Registers document changes in the circumstance, practice, and outcome of surgery with the passage of time. In the context of total hip replacement (THR), registers can help elucidate the relevant factors that affect the clinical outcome. We evaluated the evolution of factors related to patient, surgical procedure, socio-economy, and various outcome parameters after merging databases of the Swedish Hip Arthroplasty Register, Statistics Sweden and the National Board of Health and Welfare. Data on 193,253 THRs (164,113 patients) operated between 1999 and 2012 were merged. We studied the evolution of surgical volume, patient demographics, socio-economic factors, surgical factors, length-of-stay, mortality rate, adverse events, re-operation and revision rates, and Patient Reported Outcome Measures (PROMs). Throughout this time period the majority of patients were operated on with a diagnosis of primary osteoarthritis. Comorbidity indices increased each year observed. The share of all-cemented implants has dropped from 92\% to 68\%. More than 88\% of the bearings were metal-on-polyethylene. Length-of-stay decreased by 50\%. There was a reduction in 30- and 90-day mortality. Re-operation and revision rates at 2 years are decreasing. The post-operative PROMs improved despite the observation of worse pre-operative pain scores getting over time. The demographics of patients receiving a THR, their comorbidities, and their primary diagnosis are changing. Notwithstanding these changes, outcomes like mortality, re-operations, revisions, and PROMs have improved. The practice of hip arthroplasty has evolved, even in a country such as Sweden that is considered to be conservative with regard taking on new surgical practices. (c) 2017 The Authors. Journal of Orthopaedic Research Published by Wiley Periodicals, Inc. on behalf of Orthopaedic Research Society. J Orthop Res.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\X9MIXBJK\\cnudde_et_al_2017_trends_in_hip_replacements_between_1999_and_2012_in_sweden.pdf},
  journal = {Journal of Orthopaedic Research},
  keywords = {and,arthroplasty,at that time 1,coder,developed his,he did so using,in the early 1960s,low friction,register,technology and materials available,the,total hip replacement,trends,when sir john charnley},
  number = {January},
  pmid = {28845900}
}

@article{Cnudde2018,
  title = {Do Patients Live Longer after {{THA}} and Is the Relative Survival Diagnosis-Specific?},
  author = {Cnudde, Peter and Rolfson, Ola and Timperley, A John and Garland, Anne and K{\"a}rrholm, Johan and Garellick, G{\"o}ran and Nemes, Szilard},
  year = {2018},
  volume = {476},
  issn = {0009-921X},
  abstract = {Background Hip replacements are successful in restoring mobility, reducing pain, and improving quality of life. However, the association between THA and the potential for increased life expectancy (as expressed by mortality rate) is less clear, and any such association could well be influenced by diagnosis and patient-related, socioeconomic, and surgical factors, which have not been well studied. Questions/purposes (1) After controlling for birth year and sex, are Swedish patients who underwent THA likely to survive longer than individuals in the general population? (2) After controlling for relevant patient-related, socioeconomic/demographic factors and surgical factors, does relative survival differ across the various diagnoses for which THAs were performed in Sweden? Methods Data from the Swedish Hip Arthroplasty Register, linked to administrative health databases, were used for this study. We identified 131,808 patients who underwent THA between January 1, 1999, and December 31, 2012. Of these, 21,755 had died by the end of followup. Patient- and surgery-specific data in combination with socioeconomic data were available for analysis. We compared patient survival (relative survival) with age- and sex-matched survival data in the entire Swedish population according to Statistics Sweden. We used multivariable modeling proceeded with a Cox proportional hazards model in transformed time. Results Patients undergoing elective THA had a slightly improved survival rate compared with the general population for approximately 10 years after surgery. At 1 year after surgery, the survival in patients undergoing THA was 1\% better than the expected survival (r = 1.01; 95\% confidence interval [CI], 1.01-1.02; p \textexclamdown{} 0.001); at 5 years, this increased to 3\% (r = 1.03; 95\% CI, 1.03-1.03; p \textexclamdown{} 0.001); at 10 years, the difference was 2\% (r = 1.02; 95\% CI, 1.02-1.03; p \textexclamdown{} 0.001); and by 12 years, there was no difference between patients undergoing THA and the general population (r = 1.01; 95\% CI, 0.99-1.02; p = 0.13). Using the diagnosis of primary osteoarthritis as a reference, hip arthroplasties performed for sequelae of childhood hip diseases had a similar survival rate (hazard ratio [HR], 1.02; 95\% CI, 0.88-1.18; p = 0.77). Patients undergoing surgery for osteonecrosis of the femoral head (HR, 1.69; 95\% CI, 1.60-1.79; p \textexclamdown{} 0.001), inflammatory arthritis (HR, 1.49; 95\% CI, 1.38-1.61; p \textexclamdown{} 0.001), and secondary osteoarthritis (HR, 2.46; 95\% CI, 2.03-2.99; p \textexclamdown{} 0.001) all had poorer relative survival. Comorbidities and the Elixhauser comorbidity index had a negative association with relative survival. Level of achieved education (middle level of education: HR, 0.90, 95\% CI, 0.87-0.93, p \textexclamdown{} 0.001; high level: 0.76, 95\% CI, 0.73-0.80, p \textexclamdown{} 0.001) and marital status (single status: HR, 1.33; 95\% CI, 1.28-1.38; p \textexclamdown{} 0.001) were also negatively associated with survival. Conclusions Whereas it has been known that in most patients, THA improves quality of life, this study demonstrates that it also is associated with a slightly increased life expectancy that lasts for approximately 10 years after surgery, especially among patients whose diagnosis was primary osteoarthritis. This adds further proof of a health-economic value for this surgical intervention. The reasons for the increase in relative survival are unknown but are probably multifactorial. Level of Evidence Level III, therapeutic study.},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  keywords = {\#nosource},
  number = {6}
}

@article{Cnudde2018a,
  title = {Risk of Further Surgery on the Same or Opposite Side and Mortality after Primary Total Hip Arthroplasty: {{A}} Multi-State Analysis of 133,654 Patients from the {{Swedish Hip Arthroplasty Register}}},
  author = {Cnudde, Peter H J and Nemes, Szilard and B{\"u}low, Erik and Timperley, A John and Whitehouse, Sarah L and K{\"a}rrholm, Johan and Rolfson, Ola},
  year = {2018},
  volume = {89},
  doi = {10.1080/17453674.2018.1475179},
  abstract = {Most patients undergoing total hip arthroplasty (THA) have an uneventful and relatively pain-free future, whereas some patients will have further health-care encounters related to their hip joints. These contacts may be for revision of the ipsi-lateral hip. The hip might also be re-operated on for reasons not necessitating exchange or extraction of the implant or any of its parts. Some patients will need surgery on the opposite hip and may also undergo re-operation or revision surgery on the second hip. Better knowledge of patients' hip-related timeline (HRT) may improve the understanding and expecta-tions of patients, surgeons, and healthcare providers. Further healthcare contacts are important in the case of bundled pay-ments, tariffs, and payments-by-results (Burwell 2015, Jubelt et al. 2017). The increasing demands and fi nancial pressures on health systems make predictions of further contacts with healthcare providers important. Several studies have described the lifetime risk for revision and long-term mortality, but few have described the different paths (i.e., contralateral THA, revisions, and death) the patient can follow (Gillam et al. 2012, 2013, Abdel et al. 2016, Mara-dit Kremers et al. 2016, Sanders et al. 2017). The increased availability and quality of longitudinal data have stimulated the development of life-history models. Multi-state analysis has been advocated as a natural framework, studying transi-tions between different stages (Commenges 1999) and has been shown to provide a convenient framework for the han-dling of a wide variety of medical conditions, characterized by multiple events where longitudinal data are available (Fare-well and Tom 2014). This framework allows for the combining of several possible outcomes in a single analysis and aids the depiction of the hip-related timeline that patients potentially could follow. This is in contrast with the more classical},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TLXDWEN7\\cnudde_et_al_2018_risk_of_further_surgery_on_the_same_or_opposite_side_and_mortality_after.pdf},
  journal = {Acta Orthopaedica},
  keywords = {coder},
  number = {x}
}

@article{Cnudde2019,
  title = {Association between Patient Survival Following Reoperation after Total Hip Replacement and the Reason for Reoperation: An Analysis of 9,926 Patients in the {{Swedish Hip Arthroplasty Register}}},
  author = {Cnudde, Peter and B{\"u}low, Erik and Nemes, Szilard and Tyson, Yosef and Mohaddes, Maziar and Rolfson, Ola},
  year = {2019},
  month = apr,
  pages = {1--8},
  issn = {1745-3674},
  doi = {10.1080/17453674.2019.1597062},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HAKQQ3TQ\\cnudde_et_al_2019_association_between_patient_survival_following_reoperation_after_total_hip.pdf},
  journal = {Acta Orthopaedica}
}

@article{Cob2014,
  title = {Teknisk Rapport},
  author = {Cob, Connie Benfeldt and Vb, Vibeke Birk},
  year = {2014},
  pages = {339},
  abstract = {Genomf\"orande och metoder Slutlig Fritidsfiske 2015 Alla tre omg\aa ngarna 2 Inledning Statistiska centralbyr\aa n (SCB) genomf\"orde under 2015 \textendash{} 2016 en fritidsfis-keunders\"okning p\aa{} uppdrag av Havs-och vattenmyndigheten. Unders\"ok-ningar av fritidsfiske har tidigare utf\"orts under \aa ren 2008, 2010, 2013 och 2014. F\"orsta insamlingen (jan-april 2015) gjordes med hj\"alp av en kombinerad webb-och pappersenk\"at med en efterf\"oljande bortfallsuppf\"oljning via tele-fon. Andra (maj-aug 2015) och tredje (sept \textendash{} dec 2015) insamlingen skedde genom en kombinerad pappers-och webbenk\"at f\"oljt av en bortfallsuppf\"olj-ning via telefon.},
  isbn = {8790707559},
  keywords = {\#nosource}
}

@book{Cohen2003,
  title = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob and Cohen, Patricia and West, Stephen G and Aiken, Leona S},
  year = {2003},
  isbn = {0-8058-2223-2},
  keywords = {\#nosource}
}

@article{Cohen2012,
  title = {How a Fake Hip Showed up Failings in {{European}} Device Regulation},
  author = {Cohen, Deborah},
  year = {2012},
  volume = {345},
  pages = {1--5},
  issn = {17561833},
  doi = {10.1136/bmj.e7090},
  abstract = {Deborah Cohen investigates how EU authorities would be prepared to allow a fake hip prosthesis with dangerous design flaws onto the market The Changi TMH (total metal hip) does not exist. It is a large diameter metal-on-metal hip prosthesis invented by the BMJ and the Daily Telegraph to test Europe's systems for regulating high risk medical devices. It was modelled on an implant that has been described as one of the biggest disasters in orthopaedic history. In our submission to gain market entry, our fictitious company, Changi, explicitly stated that the device was similar to three controversial implants. Two of these have been recalled by their manufacturers and two are subject to legal action in the United States. And even though the dossier we created said that tests had shown that our hip prosthesis produced potentially toxic levels of metal ions in the body, the implant was passed as having an acceptable design for use in patients across Europe. The European system of regulating medical implants has been heavily criticised after a series of high profile device failures and recalls, exposing large numbers of patients to additional investigations and revision surgery. Both the UK government and the European parliament are currently looking into whether the system is fit for purpose.1 2 Last year a BMJ investigation found that the UK Medicines and Healthcare Products Regulatory Agency (MHRA) was unable to provide even the most basic data on how many high risk devices\textemdash those implanted inside the body\textemdash were currently in use, and refused to say what data had been submitted by manufacturers because this was deemed commercially confidential.3 Under growing scrutiny, what has become clear is that the weakest link in this flawed and opaque system is the almost complete delegation of responsibility from the regulator to an ad hoc \ldots},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HUR6X9ZA\\cohen_2012_how_a_fake_hip_showed_up_failings_in_european_device_regulation.pdf},
  isbn = {0959-8138},
  journal = {BMJ (Online)},
  number = {7880},
  pmid = {23097541}
}

@article{Collins2003,
  title = {Pretesting Survey Instruments: {{An}} Overview of Cognitive Methods},
  author = {Collins, Debbie},
  year = {2003},
  volume = {12},
  pages = {229--238},
  issn = {09629343},
  doi = {10.1023/A:1023254226592},
  abstract = {This article puts forward the case that survey questionnaires, which are a type of measuring instrument, can and should be tested to ensure they meet their purpose. Traditionally survey researchers have been pre-occupied with 'standardising' data collection instruments and procedures such as question wording and have assumed that experience in questionnaire design, coupled with pilot testing of questionnaires, will then ensure valid and reliable results. However, implicit in the notion of standardisation are the assumptions that respondents are able to understand the questions being asked, that questions are understood in the same way by all respondents, and that respondents are willing and able to answer such questions. The development of cognitive question testing methods has provided social researchers with a number of theories and tools to test these assumptions, and to develop better survey instruments and questionnaires. This paper describes some of these theories and tools, and argues that cognitive testing should be a standard part of the development process of any survey instrument.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\732TKERC\\collins_2003_pretesting_survey_instruments.pdf},
  isbn = {09629343},
  journal = {Quality of Life Research},
  keywords = {Cognitive aspects of survey methodology,Cognitive interviews,Data quality},
  number = {3},
  pmid = {12769135}
}

@article{Collins2014,
  title = {External Validation of Multivariable Prediction Models: {{A}} Systematic Review of Methodological Conduct and Reporting},
  author = {Collins, Gary S. and Groot, Joris A. De and Dutton, Susan and Omar, Omar and Shanyinde, Milensu and Tajar, Abdelouahid and Voysey, Merryn and Wharton, Rose and Yu, Ly Mee and Moons, Karel G. and Altman, Douglas G.},
  year = {2014},
  volume = {14},
  pages = {1--11},
  publisher = {{BMC Medical Research Methodology}},
  issn = {14712288},
  doi = {10.1186/1471-2288-14-40},
  abstract = {BACKGROUND: Before considering whether to use a multivariable (diagnostic or prognostic) prediction model, it is essential that its performance be evaluated in data that were not used to develop the model (referred to as external validation). We critically appraised the methodological conduct and reporting of external validation studies of multivariable prediction models.: We conducted a systematic review of articles describing some form of external validation of one or more multivariable prediction models indexed in PubMed core clinical journals published in 2010. Study data were extracted in duplicate on design, sample size, handling of missing data, reference to the original study developing the prediction models and predictive performance measures.: 11,826 articles were identified and 78 were included for full review, which described the evaluation of 120 prediction models. in participant data that were not used to develop the model. Thirty-three articles described both the development of a prediction model and an evaluation of its performance on a separate dataset, and 45 articles described only the evaluation of an existing published prediction model on another dataset. Fifty-seven percent of the prediction models were presented and evaluated as simplified scoring systems. Sixteen percent of articles failed to report the number of outcome events in the validation datasets. Fifty-four percent of studies made no explicit mention of missing data. Sixty-seven percent did not report evaluating model calibration whilst most studies evaluated model discrimination. It was often unclear whether the reported performance measures were for the full regression model or for the simplified models.: The vast majority of studies describing some form of external validation of a multivariable prediction model were poorly reported with key details frequently not presented. The validation studies were characterised by poor design, inappropriate handling and acknowledgement of missing data and one of the most key performance measures of prediction models i.e. calibration often omitted from the publication. It may therefore not be surprising that an overwhelming majority of developed prediction models are not used in practice, when there is a dearth of well-conducted and clearly reported (external validation) studies describing their performance on independent participant data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DIKZ3MJ4\\collins_et_al_2014_external_validation_of_multivariable_prediction_models.pdf},
  isbn = {1471-2288},
  journal = {BMC Medical Research Methodology},
  keywords = {Health Sciences,Medicine,Statistical Theory and Methods,Statistics for Life Sciences,Theory of Medicine/Bioethics},
  number = {1},
  pmid = {24645774}
}

@article{Collins2015,
  title = {Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis ({{TRIPOD}}): {{The TRIPOD Statement}}},
  author = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel G.M. M},
  year = {2015},
  volume = {67},
  pages = {1142--1151},
  publisher = {{The Authors}},
  issn = {18737560},
  doi = {10.1016/j.eururo.2014.11.025},
  abstract = {Context Prediction models are developed to aid health care providers in estimating the probability or risk that a specific disease or condition is present (diagnostic models) or that a specific event will occur in the future (prognostic models), to inform their decision making. However, the overwhelming evidence shows that the quality of reporting of prediction model studies is poor. Only with full and clear reporting of information on all aspects of a prediction model can risk of bias and potential usefulness of prediction models be adequately assessed. Objective The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed a set of recommendations for the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes. Evidence acquisition This article describes how the TRIPOD Statement was developed. An extensive list of items based on a review of the literature was created, which was reduced after a Web-based survey and revised during a 3-day meeting in June 2011 with methodologists, health care professionals, and journal editors. The list was refined during several meetings of the steering group and in e-mail discussions with the wider group of TRIPOD contributors. Evidence synthesis The resulting TRIPOD Statement is a checklist of 22 items, deemed essential for transparent reporting of a prediction model study. The TRIPOD Statement aims to improve the transparency of the reporting of a prediction model study regardless of the study methods used. The TRIPOD Statement is best used in conjunction with the TRIPOD explanation and elaboration document. Conclusions To aid the editorial process and readers of prediction model studies, it is recommended that authors include a completed checklist in their submission (also available at www.tripod-statement.org). Patient summary The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed a set of recommendations for the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZF9IVXLS\\collins_et_al_2015_transparent_reporting_of_a_multivariable_prediction_model_for_individual.pdf},
  isbn = {1539-3704 (Electronic){\r  }0003-4819 (Linking)},
  journal = {European Urology},
  keywords = {Diagnostic,Model development,Model validation,Prediction models,Prognostic,Transparent reporting},
  number = {6},
  pmid = {25561516}
}

@article{Colussi2018,
  title = {{{SOCIAL TIES IN ACADEMIA}}: {{A FRIEND IS A TREASURE}}},
  author = {Colussi, Tommaso},
  year = {2018},
  volume = {100},
  pages = {45--50},
  issn = {1725-2806},
  doi = {10.1162/REST},
  abstract = {This paper employs a unique data set on articles, authors, and editors of the top general interest journals in economics to investigate the role of social connections in the publication process. Ties between editors and authors are identified based on their academic histories. About 43\% of the articles published in these journals are authored by scholars connected to one editor at the time of the publication. Ph.D. students and faculty colleagues of an editor also improve their publication outcomes when this editor is in charge of a journal.},
  isbn = {1000142405274},
  journal = {Review of Economics and Statistics},
  keywords = {\#nosource,Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
  number = {1},
  pmid = {21860536}
}

@inproceedings{Conference2018,
  title = {Use of r in Official Statistics},
  author = {Conference, International},
  year = {2018},
  keywords = {\#nosource}
}

@article{Conner2019,
  title = {Adjusted Restricted Mean Survival Times in Observational Studies},
  author = {Conner, Sarah C. and Sullivan, Lisa M. and Benjamin, Emelia J. and LaValley, Michael P. and Galea, Sandro and Trinquart, Ludovic},
  year = {2019},
  month = may,
  pages = {sim.8206},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0277-6715},
  doi = {10.1002/sim.8206},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YXWM6HSC\\conner_et_al_2019_adjusted_restricted_mean_survival_times_in_observational_studies.pdf},
  journal = {Statistics in Medicine},
  keywords = {inverse probability weighting,observational studies,propensity score,restricted mean survival time,survival analysis,time‐to‐event data}
}

@article{Cook2007,
  title = {Use and Misuse of the Receiver Operating Characteristic Curve in Risk Prediction},
  author = {Cook, Nancy R.},
  year = {2007},
  month = feb,
  volume = {115},
  pages = {928--935},
  issn = {0009-7322},
  doi = {10.1161/CIRCULATIONAHA.106.672402},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4TBVFDXQ\\cook_2007_use_and_misuse_of_the_receiver_operating_characteristic_curve_in_risk_prediction.pdf},
  journal = {Circulation},
  number = {7}
}

@article{Cooke2001,
  title = {Refining the Construct of Psychopath: {{Towards}} a Hierarchical Model.},
  author = {Cooke, David J. and Michie, Christine},
  year = {2001},
  volume = {13},
  pages = {171--188},
  issn = {1040-3590},
  doi = {10.1037//1040-3590.13.2.171},
  abstract = {Psychopathy is characterized by diverse indicators. Clinical accounts have emphasized 3 distinct facets: interpersonal, affective, and behavioral. Research using the Psychopathy Checklist\textemdash Revised (PCL-R), however, has emphasized a 2-factor model. A review of the literature on the PCL-R and related measures of psychopathy, together with confirmatory factor analysis of PCL-R data from North American participants, indicates that the 2-factor model cannot be sustained. A 3-factor hierarchical model was developed in which a coherent superordinate factor, Psychopathy, is underpinned by 3 factors: Arrogant and Deceitful Interpersonal Style, Deficient Affective Experience, and Impulsive and Irresponsible Behavioral Style. The model was cross-validated on North American and Scottish PCL-R data, Psy- chopathy Screening Version data, and data derived from the Diagnostic and Statistical Manual of Mental Disorders (4th ed.; American Psychiatric Association, 1994) antisocial personality disorder field trial.},
  isbn = {1040-35901939-134X},
  journal = {Psychological Assessment},
  keywords = {\#nosource},
  number = {2},
  pmid = {11433793}
}

@article{Coons2009,
  title = {Recommendations on Evidence Needed to Support Measurement Equivalence between Electronic and Paper-Based Patient-Reported Outcome ({{PRO}}) Measures: {{ISPOR ePRO}} Good Research Practices Task Force Report},
  author = {Coons, Stephen Joel and Gwaltney, Chad J. and Hays, Ron D. and Lundy, J. Jason and Sloan, Jeff A. and Revicki, Dennis A. and Lenderking, William R. and Cella, David and Basch, Ethan},
  year = {2009},
  volume = {12},
  pages = {419--429},
  issn = {15244733},
  doi = {10.1111/j.1524-4733.2008.00470.x},
  abstract = {BACKGROUND-reported outcomes (PROs) are the consequences of disease and/or its treatment as reported by the patient. The importance of PRO measures in clinical trials for new drugs, biological agents, and devices was underscored by the release of the US Food and Drug Administration's draft guidance for industry titled "Patient-Reported Outcome Measures: Use in Medical Product Development to Support Labeling Claims." The intent of the guidance was to describe how the FDA will evaluate the appropriateness and adequacy of PRO measures used as effectiveness end points in clinical trials. In response to the expressed need of ISPOR members for further clarification of several aspects of the draft guidance, ISPOR's Health Science Policy Council created three task forces, one of which was charged with addressing the implications of the draft guidance for the collection of PRO data using electronic data capture modes of administration (ePRO). The objective of this report is to present recommendations from ISPOR's ePRO Good Research Practices Task Force regarding the evidence necessary to support the comparability, or measurement equivalence, of ePROs to the paper-based PRO measures from which they were adapted.task force was composed of the leadership team of ISPOR's ePRO Working Group and members of another group (i.e., ePRO Consensus Development Working Group) that had already begun to develop recommendations regarding ePRO good research practices. The resulting task force membership reflected a broad array of backgrounds, perspectives, and expertise that enriched the development of this report. The prior work became the starting point for the Task Force report. A subset of the task force members became the writing team that prepared subsequent iterations of the report that were distributed to the full task force for review and feedback. In addition, review beyond the task force was sought and obtained. Along with a presentation and discussion period at an ISPOR meeting, a draft version of the full report was distributed to roughly 220 members of a reviewer group. The reviewer group comprised individuals who had responded to an emailed invitation to the full membership of ISPOR. This Task Force report reflects the extensive internal and external input received during the 16-month good research practices development process. RESULTS/RECOMMENDATIONS: An ePRO questionnaire that has been adapted from a paper-based questionnaire ought to produce data that are equivalent or superior (e.g., higher reliability) to the data produced from the original paper version. Measurement equivalence is a function of the comparability of the psychometric properties of the data obtained via the original and adapted administration mode. This comparability is driven by the amount of modification to the content and format of the original paper PRO questionnaire required during the migration process. The magnitude of a particular modification is defined with reference to its potential effect on the content, meaning, or interpretation of the measure's items and/or scales. Based on the magnitude of the modification, evidence for measurement equivalence can be generated through combinations of the following: cognitive debriefing/testing, usability testing, equivalence testing, or, if substantial modifications have been made, full psychometric testing. As long as only minor modifications were made to the measure during the migration process, a substantial body of existing evidence suggests that the psychometric properties of the original measure will still hold for the ePRO version. Hence, an evaluation limited to cognitive debriefing and usability testing only may be sufficient. However, where more substantive changes in the migration process has occurred, confirming that the adaptation to the ePRO format did not introduce significant response bias and that the two modes of administration produce essentially equivalent results is necessary. Recommendations regarding the study designs and statistical approaches for assessing measurement equivalence are provided.electronic administration of PRO measures offers many advantages over paper administration. We provide a general framework for decisions regarding the level of evidence needed to support modifications that are made to PRO measures when they are migrated from paper to ePRO devices. The key issues include: 1) the determination of the extent of modification required to administer the PRO on the ePRO device and 2) the selection and implementation of an effective strategy for testing the measurement equivalence of the two modes of administration. We hope that these good research practice recommendations provide a path forward for researchers interested in migrating PRO measures to electronic data collection platforms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NDWHDYU6\\coons_et_al_2009_recommendations_on_evidence_needed_to_support_measurement_equivalence_between.pdf},
  isbn = {1524-4733 (Electronic){\r  }1098-3015 (Linking)},
  journal = {Value in Health},
  keywords = {Effectiveness,Evaluation studies,Health-related quality of life,Patient-reported outcomes},
  number = {4},
  pmid = {19900250}
}

@article{Copay2007,
  title = {Understanding the Minimum Clinically Important Difference: A Review of Concepts and Methods},
  author = {Copay, Anne G. and Subach, Brian R. and Glassman, Steven D. and Polly, David W. and Schuler, Thomas C.},
  year = {2007},
  volume = {7},
  pages = {541--546},
  issn = {15299430},
  doi = {10.1016/j.spinee.2007.01.008},
  abstract = {Background context: The effectiveness of spinal surgery as a treatment option is currently evaluated through the assessment of patient-reported outcomes (PROs). The minimum clinically important difference (MCID) represents the smallest improvement considered worthwhile by a patient. The concept of an MCID is offered as the new standard for determining effectiveness of a given treatment and describing patient satisfaction in reference to that treatment. Purpose: Our goal is to review the various definitions of MCID and the methods available to determine MCID. Study design: The primary means of determining the MCID for a specific treatment are divided into anchor-based and distribution-based methods. Each method is further subdivided and examined in detail. Methods: The overall limitations of the MCID concept are first identified. The basic assumptions, statistical biases, and shortcomings of each method are examined in detail. Results: Each method of determining the MCID has specific shortcomings. Three general limitations in the accurate determination of an MCID have been identified: the multiplicity of MCID determinations, the loss of the patient's perspective, and the relationship between pretreatment baseline and posttreatment change scores. Conclusions: An ideal means of determining the MCID for a given intervention is yet to be determined. It is possible to develop a useful method provided that the assumptions and methodology are initially declared. Our efforts toward the establishment of a MCID will rely on the establishment of specific external criteria based on the symptoms of the patient and treatment intervention being evaluated. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZWL53MHG\\copay_et_al_2007_understanding_the_minimum_clinically_important_difference.pdf},
  journal = {Spine Journal},
  keywords = {Disability,Functional assessment,Metrics,Minimum clinically important difference,Outcomes measures},
  number = {5}
}

@article{Corraini2017,
  title = {Effect Modification, Interaction and Mediation: {{An}} Overview of Theoretical Insights for Clinical Investigators},
  author = {Corraini, Priscila and Olsen, Morten and Pedersen, Lars and Dekkers, Olaf M. and Vandenbroucke, Jan P.},
  year = {2017},
  volume = {9},
  pages = {331--338},
  issn = {11791349},
  doi = {10.2147/CLEP.S129728},
  abstract = {We revisited the three interrelated epidemiological concepts of effect modification, interaction and mediation for clinical investigators and examined their applicability when using research databases. The standard methods that are available to assess interaction, effect modification and mediation are explained and exemplified. For each concept, we first give a simple "best-case" example from a randomized controlled trial, followed by a structurally similar example from an observational study using research databases. Our explanation of the examples is based on recent theoretical developments and insights in the context of large health care databases. Terminology is sometimes ambiguous for what constitutes effect modification and interaction. The strong assumptions underlying the assessment of interaction, and particularly mediation, require clinicians and epidemiologists to take extra care when conducting observational studies in the context of health care databases. These strong assumptions may limit the applicability of interaction and mediation assessments, at least until the biases and limitations of these assessments when using large research databases are clarified.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HPDWAH3E\\corraini_et_al_2017_effect_modification,_interaction_and_mediation.pdf},
  isbn = {1179-1349},
  journal = {Clinical Epidemiology},
  keywords = {Effect modifiers,Epidemiology,Health care administrative claims,Methods,Stratified analyses},
  pmid = {28652815}
}

@article{Corrao2017,
  title = {Developing and Validating a Novel Multisource Comorbidity Score from Administrative Data: A Large Population-Based Cohort Study from {{Italy}}},
  author = {Corrao, Giovanni and Rea, Federico and Martino, Mirko Di and Palma, Rossana De and Scondotto, Salvatore and Fusco, Danilo and Lallo, Adele and Belotti, Laura Maria Beatrice and Ferrante, Mauro and Addario, Sebastiano Pollina and Merlino, Luca and Mancia, Giuseppe and Carle, Flavia},
  year = {2017},
  month = dec,
  volume = {7},
  pages = {e019503},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2017-019503},
  abstract = {OBJECTIVE To develop and validate a novel comorbidity score (multisource comorbidity score (MCS)) predictive of mortality, hospital admissions and healthcare costs using multiple source information from the administrative Italian National Health System (NHS) databases. METHODS An index of 34 variables (measured from inpatient diagnoses and outpatient drug prescriptions within 2 years before baseline) independently predicting 1-year mortality in a sample of 500 000 individuals aged 50 years or older randomly selected from the NHS beneficiaries of the Italian region of Lombardy (training set) was developed. The corresponding weights were assigned from the regression coefficients of a Weibull survival model. MCS performance was evaluated by using an internal (ie, another sample of 500 000 NHS beneficiaries from Lombardy) and three external (each consisting of 500 000 NHS beneficiaries from Emilia-Romagna, Lazio and Sicily) validation sets. Discriminant power and net reclassification improvement were used to compare MCS performance with that of other comorbidity scores. MCS ability to predict secondary health outcomes (ie, hospital admissions and costs) was also investigated. RESULTS Primary and secondary outcomes progressively increased with increasing MCS value. MCS improved the net 1-year mortality reclassification from 27\% (with respect to the Chronic Disease Score) to 69\% (with respect to the Elixhauser Index). MCS discrimination performance was similar in the four regions of Italy we tested, the area under the receiver operating characteristic curves (95\% CI) being 0.78 (0.77 to 0.79) in Lombardy, 0.78 (0.77 to 0.79) in Emilia-Romagna, 0.77 (0.76 to 0.78) in Lazio and 0.78 (0.77 to 0.79) in Sicily. CONCLUSION MCS seems better than conventional scores for predicting health outcomes, at least in the general population from Italy. This may offer an improved tool for risk adjustment, policy planning and identifying patients in need of a focused treatment approach in the everyday medical practice.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HIFISRUW\\corrao_et_al_2017_developing_and_validating_a_novel_multisource_comorbidity_score_from.pdf},
  journal = {BMJ Open},
  number = {12},
  pmid = {29282274}
}

@book{Correlation2016,
  title = {A Review of Correlation and Regression},
  author = {Correlation, a Review O F},
  year = {2016},
  isbn = {978-0-7619-2303-9},
  keywords = {\#nosource}
}

@article{cortesConfidenceIntervalsArea2004,
  title = {Confidence Intervals for the Area under the Roc Curve},
  author = {Cortes, M Mohri C.},
  year = {2004},
  volume = {17},
  pages = {305--312},
  issn = {0262195348},
  abstract = {Inmany applications, good ranking is a highly desirable performance for a classifier. The criterion commonly used to measure the ranking quality of a classification algorithm is the area under the ROC curve (AUC). To report it properly, it is crucial to determine an interval of confidence for its value. This paper provides confidence intervals for the AUC based on a statistical and combinatorial analysis using only simple parameters such as the error rate and the number of positive and negative examples. The analysis is distribution-independent, it makes no assumption about the distribution of the scores of negative or positive examples. The results are of practical use and can be viewed as the equivalent for AUC of the standard confidence intervals given in the case of the error rate. They are comparedwith previous approaches in several standard classification tasks demonstrating the benefits of our analysis. 1},
  isbn = {978-0-262-19534-8},
  journal = {Proceedings Advances in Neural Information Processing Systems (NIPS)},
  keywords = {\#nosource}
}

@book{Cortez2014,
  title = {Modern Optimization with r},
  author = {Cortez, Paulo},
  year = {2014},
  issn = {2197-5736},
  doi = {10.1007/978-3-319-08263-9},
  abstract = {The goal of this book is to gather in a single document the most relevant concepts related to modern optimization methods, showing how such concepts and methods can be addressed using the open source, multi-platform R tool. Modern optimization methods, also known as metaheuristics, are particularly useful for solving complex problems for which no specialized optimization algorithm has been developed. These methods often yield high quality solutions with a more reasonable use of computational resources (e.g. memory and processing effort). Examples of popular modern methods discussed in this book are: simulated annealing; tabu search; genetic algorithms; differential evolution; and particle swarm optimization. This book is suitable for undergraduate and graduate students in Computer Science, Information Technology, and related areas, as well as data analysts interested in exploring modern optimization methods using R.},
  isbn = {978-3-319-08262-2},
  keywords = {\#nosource},
  pmid = {18221464}
}

@article{Cotton2006,
  title = {Reflecting on the Think-Aloud Method for Evaluating e-Learning},
  author = {Cotton, Deborah and Gresty, Karen},
  year = {2006},
  volume = {37},
  pages = {45--54},
  issn = {00071013},
  doi = {10.1111/j.1467-8535.2005.00521.x},
  abstract = {E-learning is increasingly being used in higher education settings, yet research examining how students use e-resources is frequently limited. Some previous studies have used the think-aloud method (an approach with origins in cognitive psychology) as an alternative to the more usual questionnaire or focus groups, but there is little discussion in the educational literature about the advantages and disadvantages of this approach. In this paper, we discuss our experience of using the think-aloud method in a recent study, and we reflect on its potential contribution as a research method. A number of concerns about the method arose during our study, including the level of guidance given to participants, observer influence, and the complexity of data analysis. We conclude, however, that the richness of the data collected outweighs these constraints, and that the think-aloud method has the potential to enhance research in this field.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZZDI6BG5\\cotton_gresty_2006_reflecting_on_the_think-aloud_method_for_evaluating_e-learning.pdf},
  isbn = {0007-1013},
  journal = {British Journal of Educational Technology},
  number = {1},
  pmid = {19344079}
}

@article{Couchoud2017,
  title = {Restricted Mean Survival Time over 15 Years for Patients Starting Renal Replacement Therapy},
  author = {Couchoud, C{\'e}cile and Dantony, Emmanuelle and Elsensohn, Mad-H{\'e}l{\'e}nie and Villar, Emmanuel and Vigneau, C{\'e}cile and Moranne, Olivier and Rabilloud, Muriel and Ecochard, Ren{\'e}},
  year = {2017},
  month = jan,
  volume = {32},
  pages = {gfw386},
  publisher = {{Narnia}},
  issn = {0931-0509},
  doi = {10.1093/ndt/gfw386},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ITQLU9TW\\couchoud_et_al_2017_restricted_mean_survival_time_over_15_years_for_patients_starting_renal.pdf},
  journal = {Nephrology Dialysis Transplantation},
  keywords = {epidemiology,gender,life expectancy,patient prognosis},
  number = {suppl{$_{2}$}}
}

@article{Courvoisier2011,
  title = {Performance of Logistic Regression Modeling: Beyond the Number of Events per Variable, the Role of Data Structure},
  author = {Courvoisier, Delphine S. and Combescure, Christophe and Agoritsas, Thomas and {Gayet-Ageron}, Ang{\`e}le and Perneger, Thomas V.},
  year = {2011},
  month = sep,
  volume = {64},
  pages = {993--1000},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/J.JCLINEPI.2010.11.012},
  abstract = {OBJECTIVE Logistic regression is commonly used in health research, and it is important to be sure that the parameter estimates can be trusted. A common problem occurs when the outcome has few events; in such a case, parameter estimates may be biased or unreliable. This study examined the relation between correctness of estimation and several data characteristics: number of events per variable (EPV), number of predictors, percentage of predictors that are highly correlated, percentage of predictors that were non-null, size of regression coefficients, and size of correlations. STUDY DESIGN Simulation studies. RESULTS In many situations, logistic regression modeling may pose substantial problems even if the number of EPV exceeds 10. Moreover, the number of EPV is not the only element that impacts on the correctness of parameter estimation. High regression coefficients and high correlations between the predictors may cause large problems in the estimation process. Finally, power is generally very low, even at 20 EPV. CONCLUSION There is no single rule based on EPV that would guarantee an accurate estimation of logistic regression parameters. Instead, the number of predictors, probable size of the regression coefficients based on previous literature, and correlations among the predictors must be taken into account as guidelines to determine the necessary sample size.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7IG8EABP\\courvoisier_et_al_2011_performance_of_logistic_regression_modeling.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {9}
}

@article{Cowden1952,
  title = {The Multiple-Partial Correlation Coefficient},
  author = {Cowden, Dudley J.},
  year = {1952},
  volume = {47},
  pages = {442--456},
  issn = {1537274X},
  doi = {10.1080/01621459.1952.10501183},
  abstract = {Abstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)},
  isbn = {01621459},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {259}
}

@article{Cox1972,
  title = {Models and Life-Tables Regression},
  author = {Cox, D. R.},
  year = {1972},
  volume = {34},
  pages = {187--220},
  issn = {00359246},
  doi = {10.1007/978-1-4612-4380-9_37},
  isbn = {00359246},
  journal = {Journal of the Royal Statistical Society, Series B.},
  keywords = {\#nosource,accelerated life tests,age-specific failure rate,asymptotic theory,censored data,conditional inference,hazard function,life table,limit estimate,medical applications,product,regression,reliability,theory,two-sample rank tests},
  number = {2},
  pmid = {2985181}
}

@article{Cox1972,
  title = {Regression Models and Life-Tables},
  author = {Cox, David R},
  year = {1972},
  volume = {34},
  pages = {187--220},
  keywords = {\#nosource},
  number = {2}
}

@article{Cox2016,
  title = {Some Pioneers of Modern Statistical Theory: A Personal Reflection},
  author = {Cox, D. R.},
  year = {2016},
  volume = {103},
  pages = {747--759},
  issn = {0006-3444},
  doi = {10.1093/biomet/asw052},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S82AIINF\\cox_2016_some_pioneers_of_modern_statistical_theory.pdf},
  journal = {Biometrika},
  number = {4}
}

@phdthesis{Crane2010,
  title = {Time to Event Analysis of Standard Ecotoxicity Data},
  author = {Crane, Mark and Grosso, Albania},
  year = {2010},
  doi = {10.1201/9781420032284.ch2},
  keywords = {\#nosource}
}

@article{Crocker1972,
  title = {Some Interpretations of the Multiple Correlation Coefficient},
  author = {Crocker, Douglas C.},
  year = {1972},
  month = apr,
  volume = {26},
  pages = {31--33},
  publisher = {{Taylor \& Francis}},
  issn = {15372731},
  doi = {10.1080/00031305.1972.10477345},
  isbn = {00031305},
  journal = {American Statistician},
  keywords = {\#nosource},
  number = {2}
}

@article{Cross2014,
  title = {The Global Burden of Hip and Knee Osteoarthritis: Estimates from the {{Global Burden}} of {{Disease}} 2010 Study},
  author = {Cross, Marita and Smith, Emma and Hoy, Damian and Nolte, Sandra and Ackerman, Ilana and Fransen, Marlene and Bridgett, Lisa and Williams, Sean and Guillemin, Francis and Hill, L Catherine and Laslett, L Laura and Jones, Graeme and Cicuttini, Flavia and Osborne, Richard and Vos, Theo and Buchbinder, Rachelle and Woolf, Anthony and March, Lyn},
  year = {2014},
  volume = {73},
  pages = {1323--1330},
  doi = {10.1136/annrheumdis-2013-204763},
  abstract = {Objective To estimate the global burden of hip and knee osteoarthritis (OA) as part of the Global Burden of Disease 2010 study and to explore how the burden of hip and knee OA compares with other conditions. Methods Systematic reviews were conducted to source age-specific and sex-specific epidemiological data for hip and knee OA prevalence, incidence and mortality risk. The prevalence and incidence of symptomatic, radiographic and self-reported hip or knee OA were included. Three levels of severity were defined to derive disability weights (DWs) and severity distribution (proportion with mild, moderate and severe OA). The prevalence by country and region was multiplied by the severity distribution and the appropriate disability weight to calculate years of life lived with disability (YLDs). As there are no deaths directly attributed to OA, YLDs equate disability-adjusted life years (DALYs). Results Globally, of the 291 conditions, hip and knee OA was ranked as the 11th highest contributor to global disability and 38th highest in DALYs. The global age-standardised prevalence of knee OA was 3.8\% (95\% uncertainty interval (UI) 3.6\% to 4.1\%) and hip OA was 0.85\% (95\% UI 0.74\% to 1.02\%), with no discernible change from 1990 to 2010. Prevalence was higher in females than males. YLDs for hip and knee OA increased from 10.5 million in 1990 (0.42\% of total DALYs) to 17.1 million in 2010 (0.69\% of total DALYs). Conclusions Hip and knee OA is one of the leading causes of global disability. Methodological issues within this study make it highly likely that the real burden of OA has been underestimated. With the aging and increasing obesity of the world's population, health professions need to prepare for a large increase in the demand for health services to treat hip and knee OA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\C87XZHFY\\cross_et_al_2014_the_global_burden_of_hip_and_knee_osteoarthritis.pdf},
  journal = {Annals of The Rheumatic Diseases}
}

@article{Croux2003,
  title = {Estimators of the Multiple Correlation Coefficient: {{Local}} Robustness and Confidence Intervals},
  author = {Croux, Cristophe and Dehon, Catherine},
  year = {2003},
  month = jul,
  volume = {44},
  pages = {315--334},
  issn = {09325026},
  doi = {10.1007/s00362-003-0158-7},
  abstract = {Many robust regression estimators are defined by minimizing a measure of spread of the residuals. An accompanying R{$^2$}-measure, or multiple correlation coefficient, is then easily obtained. In this paper, local robustness properties of these robust R{$^2$}-coefficients are investigated. It is also shown how confidence intervals for the population multiple correlation coefficient can be constructed in the case of multivariate normality.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V2IKQDUX\\croux_dehon_2003_estimators_of_the_multiple_correlation_coefficient.pdf},
  journal = {Statistical Papers},
  keywords = {influence function,Influence function,multiple correlation coefficient,Multiple correlation coefficient,R² measure,R2-measure,regression analysis,Regression analysis,robustness,Robustness},
  number = {3}
}

@article{Culliford2015,
  title = {Future Projections of Total Hip and Knee Arthroplasty in the {{UK}}: {{Results}} from the {{UK Clinical Practice Research Datalink}}},
  author = {Culliford, D. and Maskell, J. and Judge, A. and Cooper, C. and {Prieto-Alhambra}, D. and Arden, N. K.},
  year = {2015},
  volume = {23},
  pages = {594--600},
  publisher = {{Elsevier Ltd}},
  issn = {15229653},
  doi = {10.1016/j.joca.2014.12.022},
  abstract = {Objective: To estimate the future rate of primary total hip (THR) or knee (TKR) replacement in the UK to 2035 allowing for changes in population demographics and obesity. Design: Using age/gender/body mass index (BMI)-specific incidence rates from a population-based cohort study of 50,000 THR and 45,609 TKR patients from the UK Clinical Practice Research Datalink (CPRD) between 1991 and 2010, we projected future numbers of THR and TKR using two models: a static, estimated rate from 2010 applied to population growth forecasts to 2035, and a log-linear rate extrapolation over the same period. Both scenarios used population forecast data from the UK Office for National Statistics (ONS). Results: Assuming rates of THR and TKR for 2010, and given projected population changes in age, gender and BMI, the number of THRs and TKRs performed in the UK in 2035 is estimated to be, respectively: 95,877 and 118,666. By comparison, an exponential extrapolation of historical rates using a log-linear model produces much higher estimates of THR and TKR counts in 2035 at 439,097 and 1,219,362 respectively. Projected counts were higher for women than men. Assuming a changing (rather than fixed) future BMI distribution increases TKRs by 2035 but not THRs. Conclusions: Using historical rates and population forecasts we have projected the number of THR/TKR operations in the UK up to 2035. This study will inform policymakers requiring estimates of future demand for surgery. Incorporating future forecasts for BMI into projections of joint replacement may be more relevant for TKR rather than THR.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2NGW84F6\\culliford_et_al_2015_future_projections_of_total_hip_and_knee_arthroplasty_in_the_uk.pdf},
  isbn = {1522-9653 (Electronic){\r  }1063-4584 (Linking)},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Arthroplasty,Hip,Knee,Osteoarthritis,Projection},
  number = {4},
  pmid = {25579802}
}

@article{Daabiss2011,
  title = {American {{Society}} of {{Anaesthesiologists}} Physical Status Classification.},
  author = {Daabiss, Mohamed},
  year = {2011},
  month = mar,
  volume = {55},
  pages = {111--5},
  publisher = {{Wolters Kluwer \textendash{} Medknow Publications}},
  issn = {0976-2817},
  doi = {10.4103/0019-5049.79879},
  abstract = {Although the American Society of Anaesthesiologists' (ASA) classification of Physical Health is a widely used grading system for preoperative health of the surgical patients, multiple variations were observed between individual anaesthetist's assessments when describing common clinical problems. This article reviews the current knowledge and evaluation regarding ASA Classification of Physical Health as well as trials for possible modification.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ULKMMGMP\\daabiss_2011_american_society_of_anaesthesiologists_physical_status_classification.pdf},
  journal = {Indian journal of anaesthesia},
  keywords = {Anaesthesia,ASA,physical status classification,preoperative assessment},
  number = {2},
  pmid = {21712864}
}

@article{Dahl2007,
  title = {Identification of Dementia in Epidemiological Research: A Study on the Usefulness of Various Data Sources.},
  author = {Dahl, Anna and Berg, Stig and Nilsson, Sven E},
  year = {2007},
  month = oct,
  volume = {19},
  pages = {381--9},
  issn = {1594-0667},
  abstract = {BACKGROUND AND AIMS Prevalence and incidence ratios of dementia in epidemiological studies vary according to the data source used. Medical records, cognitive tests, and registry information are sources frequently used to differentiate dementia from normal aging. The aim of the present study was to compare the identification of dementia from these different sources with that from consensus diagnosis. METHODS 498 elderly people (age range 70-81 at baseline) enrolled in a Swedish population-based longitudinal twin study (Gender) were evaluated on physical and mental health and interviewed for their socio-demographic background three times during an eight-year period. Reviews of medical records and the Swedish Discharge Registry (DR) were conducted. The 10th percentile was used to differentiate between dementia and non-dementia in all cognitive tests. Scores of 24 or below on the Mini-Mental State Examination (MMSE) (range 1-30) indicated dementia. A consensus conference diagnosed dementia on the basis of total information. The consensus diagnosis was used as the gold standard. RESULTS MMSE scores (sensitivity 64\%, specificity 96\%, kappa 0.65) and the review of medical records (sensitivity 57\%, specificity 99\%, kappa 0.65) were good sources for dementia identification. The precision of medical records increased when recordings of cognitive impairment were included (sensitivity 83\%, specificity 98\%, kappa 0.84). The discharge registry had low sensitivity (26\%) and kappa coefficient (0.31). CONCLUSIONS The present study shows that both review of medical records and MMSE scores are good although not perfect identifiers of dementia. The discharge registry is an uncertain source of dementia identification.},
  journal = {Aging clinical and experimental research},
  keywords = {\#nosource},
  number = {5},
  pmid = {18007116}
}

@article{Dahlqwist2016,
  title = {Model-Based Estimation of the Attributable Fraction for Cross-Sectional, Case\textendash Control and Cohort Studies Using the {{R}} Package {{AF}}},
  author = {Dahlqwist, Elisabeth and Zetterqvist, Johan and Pawitan, Yudi and Sj{\"o}lander, Arvid},
  year = {2016},
  volume = {31},
  pages = {1--8},
  publisher = {{Springer Netherlands}},
  issn = {15737284},
  doi = {10.1007/s10654-016-0137-7},
  abstract = {The attributable fraction (or attributable risk) is a widely used measure that quantifies the public health impact of an exposure on an outcome. Even though the theory for AF estimation is well developed, there has been a lack of up-to-date software implementations. The aim of this article is to present a new R package for AF estimation with binary exposures. The package AF allows for confounder-adjusted estimation of the AF for the three major study designs: cross-sectional, (possibly matched) case-control and cohort. The article is divided into theoretical sections and applied sections. In the theoretical sections we describe how the confounder-adjusted AF is estimated for each specific study design. These sections serve as a brief but self-consistent tutorial in AF estimation. In the applied sections we use real data examples to illustrate how the AF package is used. All datasets in these examples are publicly available and included in the AF package, so readers can easily replicate all analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3HWMNVNQ\\dahlqwist_et_al_2016_model-based_estimation_of_the_attributable_fraction_for_cross-sectional,.pdf},
  journal = {European Journal of Epidemiology},
  keywords = {Attributable fraction,Attributable risk,Confounder-adjusted,Public health,R package,Regression model,Statistical software},
  number = {6},
  pmid = {26992709}
}

@book{Dai2004,
  title = {Advances in Knowledge Discovery and Data Mining : 8th {{Pacific}}-{{Asia}} Conference, {{PAKDD}} 2004, {{Sydney}}, {{Australia}}, {{May}} 26-28, 2004 : Proceedings},
  author = {Dai, Honghua. and Srikant, Ramakrishnan. and Zhang, Chengqi},
  year = {2004},
  publisher = {{Springer}},
  abstract = {This book constitutes the refereed proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data mining, PAKDD 2004, held in Sydney, Australia in May 2004. The 50 revised full papers and 31 revised short papers presented were carefully reviewed and selected from a total of 238 submissions. The papers are organized in topical sections on classification; clustering; association rules; novel algorithms; event mining, anomaly detection, and intrusion detection; ensemble learning; Bayesian network and graph mining; text mining; multimedia mining; text mining and Web mining; statistical methods, sequential data mining, and time series mining; and biomedical data mining. Invited Speeches \textendash{} Session 1A: Classification (I) \textendash{} Session 1B: Clustering (I) \textendash{} Session 1C: Association Rules (I) \textendash{} Session 2A: Novel Algorithms (I) \textendash{} Session 2B: Association (II) \textendash{} Session 2C: Classification (II) \textendash{} Session 3A: Event Mining, Anomaly Detection, and Intrusion Detection \textendash{} Session 3B: Ensemble Learning \textendash{} Session 3C: Bayesian Network and Graph Mining \textendash{} Session 3D: Text Mining (I) \textendash{} Session 4A: Clustering (II) \textendash{} Session 4B: Association (III) \textendash{} Session 4C: Novel Algorithms (II) \textendash{} Session 4D: Multimedia Mining \textendash{} Session 5A: Text Mining and Web Mining (II) \textendash{} Session 5B: Statistical Methods, Sequential Data Mining, and Time Series Mining \textendash{} Session 5C: Novel Algorithms (III) \textendash{} Session 5D: Biomedical Mining.},
  isbn = {3-540-22064-X},
  keywords = {\#nosource}
}

@article{Dale2012,
  title = {Increasing Risk of Prosthetic Joint Infection after Total Hip Arthroplasty: 2,778 Revisions Due to Infection after 432,168 Primary {{THAs}} in the {{Nordic Arthroplasty Register Association}} ({{NARA}})},
  shorttitle = {Increasing Risk of Prosthetic Joint Infection after Total Hip Arthroplasty},
  author = {Dale, H\aa vard and Fenstad, Anne M and Hallan, Geir and Havelin, Leif I and Furnes, Ove and Overgaard, S\o ren and Pedersen, Alma B and K{\"a}rrholm, Johan and Garellick, G{\"o}ran and Pulkkinen, Pekka and Eskelinen, Antti and M{\"a}kel{\"a}, Keijo and Enges\ae ter, Lars B},
  year = {2012},
  month = oct,
  volume = {83},
  pages = {449--458},
  issn = {1745-3674, 1745-3682},
  doi = {10.3109/17453674.2012.733918},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QGB6SYRU\\Dale et al_2012_Increasing risk of prosthetic joint infection after total hip arthroplasty.pdf},
  journal = {Acta Orthopaedica},
  language = {en},
  number = {5}
}

@article{Danielsen2015,
  title = {Translation of Questionnaires Measuring Health Related Quality of Life Is Not Standardized: {{A}} Literature Based Research Study},
  author = {Danielsen, Anne Kjaergaard and Pommergaard, Hans-Christian and Burcharth, Jakob and Angenete, Eva and Rosenberg, Jacob},
  year = {2015},
  volume = {10},
  pages = {e0127050},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0127050},
  abstract = {INTRODUCTION: There is growing awareness of the need to explore patient reported outcomes in clinical trials. In the Scandinavian Surgical Outcomes Research Group we are conducting several clinical trials in cooperation between Danish and Swedish surgical researchers, and we use questionnaires aimed at patients from both countries. In relation to this and similar international cooperation, the validity and reliability of translated questionnaires are central aspects.OBJECTIVES: The purpose of this study was to explore which methodological measures were used in studies reporting translation of questionnaires. Furthermore, we wanted to make some methodological suggestions for clinical researchers who are faced with having to translate a questionnaire.AND METHODS: We designed a research study based on a survey of the literature and extracted data from published studies reporting the methodological process when translating questionnaires on health related quality of life for different diseases.: We retrieved 187 studies and out of theses we included 52 studies. The psychometric properties of the translated versions were validated using different tests. The focus was on internal validity (96\%), reliability (67\%) criterion validity (81\%), and construct validity (62\%). For internal validity Cronbach's alpha was used in 94\% of the studies.: This study shows that there seems to be a consensus regarding the translation process (especially for internal validity) although most researchers did not use a translation guide. Moreover, we recommended that clinical researchers should consider three steps covering the process of translation, the qualitative validation as well as the quantitative validation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ITUDUPAR\\danielsen_et_al_2015_translation_of_questionnaires_measuring_health_related_quality_of_life_is_not.pdf},
  journal = {Plos One},
  number = {5},
  pmid = {25965447}
}

@book{DasGupta2006,
  title = {Asymptotic Theory of Statistics and Probability},
  author = {DasGupta, Anirban},
  year = {2006},
  volume = {102},
  issn = {01621459},
  doi = {10.1016/j.peva.2007.06.006},
  abstract = {Review From the reviews: .,."There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006 "The reader sees not only how measure theory is used to develop probability theory, but also how probability theory is used in applications. a The discourse is delivered in a theorem proof format and thus is better suited for classroom a . The authors prose is generally well thought out a . will make an attractive choice for a two-semester course on measure and probability, or as a second course for students with a semester of measure or probability theory under their belt." (Peter C. Kiessler, Journal of the American Statistical Association, Vol. 102 (479), 2007) "The book is a well written self-contained textbook on measure and probability theory. It consists of 18 chapters. Every chapter contains many well chosen examples and ends with several problems related to the earlier developed theory (some with hints). a At the very end of the book there is an appendix collecting necessary facts from set theory, calculus and metric spaces. The authors suggest a few possibilities on how to use their book." (Kazimierz Musial, Zentralblatt MATH, Vol. 1125 (2), 2008) "The title of the book consists of the names of its two basic parts. The booka (TM)s third part is comprised of some special topics from probability theory. a The authors suggest using the book intwo-semester graduate programs in statistics or a one-semester seminar on special topics. The material of the book is standard a is clear, comprehensive and a  without being intimidatinga (TM)." (Rimas NorvaiAa, Mathematical Reviews, Issue 2007 f) Product Description This is a graduate level textbook on measure theory and probability theory. The book can be used as a text for a two semester sequence of courses in measure theory and probability theory, with an option to include supplemental material on stochastic processes and special topics. It is intended primarily for first year Ph.D. students in mathematics and statistics although mathematically advanced students from engineering and economics would also find the book useful. Prerequisites are kept to the minimal level of an understanding of basic real analysis concepts such as limits, continuity, differentiability, Riemann integration, and convergence of sequences and series. A review of this material is included in the appendix. The book starts with an informal introduction that provides some heuristics into the abstract concepts of measure and integration theory, which are then rigorously developed. The first part of the book can be used for a standard real analysis course for both mathematics and statistics Ph.D. students as it provides full coverage of topics such as the construction of Lebesgue-Stieltjes measures on real line and Euclidean spaces, the basic convergence theorems, L p spaces, signed measures, Radon-Nikodym theorem, Lebesgue's decomposition theorem and the fundamental theorem of Lebesgue integration on R, product spaces and product measures, and Fubini-Tonelli theorems. It also provides an elementary introduction to Banach and Hilbert spaces, convolutions, Fourier series and Fourier and Plancherel transforms. Thus part I would be particularly useful for students in a typical Statistics Ph.D. program if a separate course on real analysis is not a standard requirement. Part II (chapters 6-13) provides full coverage of standard graduate level probability theory. It starts with Kolmogorov's probability model and Kolmogorov's existence theorem. It then treats thoroughly the laws of large numbers including renewal theory and ergodic theorems with applications and then weak convergence of probability distributions, characteristic functions, the Levy-Cramer continuity theorem and the central limit theorem as well as stable laws. It ends with conditional expectations and conditional probability, and an introduction to the theory of discrete time martingales. Part III (chapters 14-18) provides a modest coverage of discrete time Markov chains with countable and general state spaces, MCMC, continuous time discrete space jump Markov processes, Brownian motion, mixing sequences, bootstrap methods, and branching processes. It could be used for a topics/seminar course or as an introduction to stochastic processes. From the reviews: "...There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JZZNE48F\\dasgupta_2006_asymptotic_theory_of_statistics_and_probability.pdf},
  isbn = {978-0-387-78188-4},
  pmid = {10911016}
}

@book{Data2005,
  title = {Survival Analysis Using s},
  author = {Data, Time-to-event},
  year = {2005},
  isbn = {1-58488-408-8},
  keywords = {\#nosource}
}

@article{Data2005,
  title = {Coding Algorithms for Defining Comorbidities In},
  author = {Data, Icd-Administrative},
  year = {2005},
  volume = {43},
  journal = {Medical care},
  keywords = {\#nosource,1130,1139,43,administrative data,comorbidity,department of community health,from the,icd-10,icd-9,med care 2005,outcome,risk adjustment,sciences,university of cal-},
  number = {11}
}

@article{Davies1998,
  title = {Information in Practice {{Using}} Epidemiological Data to Guide Clinical Practice : Combined Oral Contraceptives},
  author = {Davies, Huw Talfryn Oakley and Crombie, Iain Kinloch and Tavakoli, Manouche},
  year = {1998},
  month = mar,
  volume = {316},
  pages = {989--991},
  publisher = {{BMJ Publishing Group}},
  issn = {0022-0671},
  doi = {10.1080/00220671003636752},
  abstract = {Odds ratios are a common measure of the size of an effect and may be reported in case-control studies, cohort studies, or clinical trials. Increasingly, they are also used to report the findings from systematic reviews and meta-analyses. Odds ratios are hard to comprehend directly and are usually interpreted as being equivalent to the relative risk. Unfortunately, there is a recognised problem that odds ratios do not approximate well to the relative risk when the initial risk (that is, the prevalence of the outcome of interest) is high.1,2 Thus there is a danger that if odds ratios are interpreted as though they were relative risks then they may mislead. The advice given in many texts is unusually coy on the matter. For example: ``The odds ratio is approximately the same as the relative risk if the outcome of interest is rare. For common events, however, they can be quite different.''3 How close is ``approximately the same,'' how uncommon does an event have to be to qualify as ``rare,'' and how different is ``quite different''?},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9NSNXDF7\\davies_et_al_1998_information_in_practice_using_epidemiological_data_to_guide_clinical_practice.pdf},
  isbn = {0022-0671},
  journal = {British Medical Journal},
  number = {7136},
  pmid = {9550961}
}

@article{Davies1998,
  title = {When Can Odds Ratios Mislead?},
  author = {Davies, H. T. O. and Crombie, I. K. and Tavakoli, M.},
  year = {1998},
  month = mar,
  volume = {316},
  pages = {989--991},
  doi = {10.1136/bmj.316.7136.989},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PFH6H57G\\davies_et_al_1998_when_can_odds_ratios_mislead.pdf},
  journal = {BMJ: British Medical Journal},
  number = {7136}
}

@book{Davino2014,
  title = {Quantile Regression: {{Theory}} and Applications},
  author = {Davino, Cristina and Furno, Marilena and Vistocco, Domenico},
  year = {2014},
  isbn = {978-1-119-97528-1},
  keywords = {\#nosource}
}

@book{Davison2003,
  title = {Bootstrap Methods and Their Application},
  author = {Davison, A. C. (Anthony Christopher) and Hinkley, D. V.},
  year = {2003},
  abstract = {Reprinted with corrections.},
  isbn = {978-0-521-57471-6},
  keywords = {\#nosource}
}

@article{Debray2017,
  title = {A Guide to Systematic Review and Meta-Analysis of Prediction Model Performance},
  author = {Debray, Thomas P A and Damen, Johanna A A G and Snell, Kym I E and Ensor, Joie and Hooft, Lotty and Reitsma, Johannes B and Riley, Richard D and Moons, Karel G M},
  year = {2017},
  month = jan,
  pages = {i6460},
  issn = {1756-1833},
  doi = {10.1136/bmj.i6460},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7GKJ3IH7\\Debray m. fl. - 2017 - A guide to systematic review and meta-analysis of .pdf},
  journal = {BMJ},
  keywords = {acta review},
  language = {en}
}

@article{Debray2018,
  title = {A Framework for Meta-Analysis of Prediction Model Studies with Binary and Time-to-Event Outcomes:},
  shorttitle = {A Framework for Meta-Analysis of Prediction Model Studies with Binary and Time-to-Event Outcomes},
  author = {Debray, Thomas PA and Damen, Johanna AAG and Riley, Richard D. and Snell, Kym and Reitsma, Johannes B. and Hooft, Lotty and Collins, Gary S. and Moons, Karel GM},
  year = {2018},
  month = jul,
  publisher = {{SAGE PublicationsSage UK: London, England}},
  doi = {10.1177/0962280218785504},
  abstract = {It is widely recommended that any developed\textemdash diagnostic or prognostic\textemdash prediction model is externally validated in terms of its predictive performance measured by...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\99A2JS6G\\Debray m. fl. - 2018 - A framework for meta-analysis of prediction model .pdf;C\:\\Users\\erik_\\Zotero\\storage\\8IVSSP7N\\0962280218785504.html},
  journal = {Statistical Methods in Medical Research},
  keywords = {acta review},
  language = {en}
}

@article{Degenhardt2019,
  title = {Evaluation of Variable Selection Methods for Random Forests and Omics Data Sets},
  author = {Degenhardt, Frauke and Seifert, Stephan and Szymczak, Silke},
  year = {2019},
  month = mar,
  volume = {20},
  pages = {492--503},
  publisher = {{Narnia}},
  issn = {1477-4054},
  doi = {10.1093/bib/bbx124},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RK7VPLK9\\degenhardt_et_al_2019_evaluation_of_variable_selection_methods_for_random_forests_and_omics_data_sets.pdf},
  journal = {Briefings in Bioinformatics},
  number = {2}
}

@article{Deheuvels1993,
  title = {Some Results on the Influence Ofextremes on the Bootstrap},
  author = {Deheuvels, Paul and Mason, David M. and Shorack, Galen R.},
  year = {1993},
  volume = {29},
  pages = {83--103},
  journal = {Probabilit\'es et Statistiques},
  keywords = {\#nosource},
  number = {1}
}

@article{Deleuran2015,
  title = {Cirrhosis Patients Have Increased Risk of Complications after Hip or Knee Arthroplasty: {{A Danish}} Population-Based Cohort Study},
  shorttitle = {Cirrhosis Patients Have Increased Risk of Complications after Hip or Knee Arthroplasty},
  author = {Deleuran, Thomas and Vilstrup, Hendrik and Overgaard, S\o ren and Jepsen, Peter},
  year = {2015},
  month = jan,
  volume = {86},
  pages = {108--113},
  issn = {1745-3674, 1745-3682},
  doi = {10.3109/17453674.2014.961397},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HSJZGW56\\Deleuran et al_2015_Cirrhosis patients have increased risk of complications after hip or knee.pdf},
  journal = {Acta Orthopaedica},
  language = {en},
  number = {1}
}

@article{delgado-rodriguezBias2004,
  title = {Bias.},
  author = {{Delgado-Rodr{\'i}guez}, Miguel and Llorca, Javier},
  year = {2004},
  volume = {58},
  pages = {635--641},
  issn = {0143005X},
  doi = {10.1136/jech.2003.008466},
  abstract = {The concept of bias is the lack of internal validity or incorrect assessment of the association between an exposure and an effect in the target population in which the statistic estimated has an expectation that does not equal the true value. Biases can be classified by the research stage in which they occur or by the direction of change in a estimate. The most important biases are those produced in the definition and selection of the study population, data collection, and the association between different determinants of an effect in the population. A definition of the most common biases occurring in these stages is given.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LHFW3IA6\\delgado-rodríguez_llorca_2004_bias.pdf},
  isbn = {0143-005X (Print)0143-005X (Linking)},
  journal = {Journal of epidemiology and community health},
  number = {8},
  pmid = {15252064}
}

@article{Delong1988,
  title = {Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves : {{A}} Nonparametric Approach Author ( s ): {{Elizabeth}} r . {{DeLong}} , David m . {{DeLong}} and Daniel l . {{Clarke}}-Pearson Published by : {{International}} Biometric Society Stable},
  author = {Delong, Elizabeth R and Carolina, North},
  year = {1988},
  volume = {44},
  pages = {837--845},
  journal = {Biometrics},
  keywords = {\#nosource},
  number = {3}
}

@article{Delong2016,
  title = {Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves : {{A}} Nonparametric Approach Published by : {{International}} Biometric Society Stable {{URL}} : {{http://www.jstor.org/stable/2531595}} {{REFERENCES}} Linked References Are Available},
  author = {Delong, Elizabeth R and Delong, David M and {Clarke-pearson}, Daniel L and Carolina, North},
  year = {2016},
  volume = {44},
  pages = {837--845},
  keywords = {\#nosource},
  number = {3}
}

@book{Deming1993,
  title = {The New Economics},
  author = {Deming, W Edwards},
  year = {1993},
  keywords = {\#nosource}
}

@article{Deyo1992,
  title = {Adapting a Clinical Comorbidity Index for Use with {{ICD}}-9-{{CM}} Administrative Databases},
  author = {Deyo, Richard A. and Cherkin, Daniel C. and Ciol, Marcia A.},
  year = {1992},
  month = jun,
  volume = {45},
  pages = {613--619},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(92)90133-8},
  abstract = {Administrative databases are increasingly used for studying outcomes of medical care. Valid inferences from such data require the ability to account for disease severity and comorbid conditions. We adapted a clinical comorbidity index, designed for use with medical records, for research relying on International Classification of Diseases (ICD-9-CM) diagnosis and procedure codes. The association of this adapted index with health outcomes and resource use was then examined with a sample of Medicare beneficiaries who underwent lumbar spine surgery in 1985 (n = 27,111). The index was associated in the expected direction with postoperative complications, mortality, blood transfusion, discharge to nursing home, length of hospital stay,and hospital charges. These associations were observed whether the index incorporated data from multiple hospitalizations over a year's time, or just from the index surgical admission. They also persisted after controlling for patient age. We conclude that the adapted comorbidity index will be useful in studies of disease outcome and resource use employing administrative databases.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8XXFU9C9\\deyo_et_al_1992_adapting_a_clinical_comorbidity_index_for_use_with_icd-9-cm_administrative.pdf},
  isbn = {ISSN  0895-4356},
  journal = {Journal of Clinical Epidemiology},
  keywords = {ComorbidityAdministrative dataLumbar spine},
  number = {6},
  pmid = {1607900}
}

@article{Dhar2014,
  title = {Big Data and Predictive Analytics in Health Care},
  author = {Dhar, Vasant},
  year = {2014},
  volume = {2},
  pages = {113--116},
  issn = {2167-6461},
  doi = {10.1089/big.2014.1525},
  abstract = {Abstract Predictive analytics show great promise in health care but face some serious hurdles for widespread adoption. I discuss the state of the art of predictive health-care analytics using the clinical arena as an example and discuss how the outputs of predictive systems could be made actionable through differentiated processes that encourage prevention. Such systems have the potential to minimize health risk at the population and individual levels through more personalized health-care delivery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3SDFUKE6\\dhar_2014_big_data_and_predictive_analytics_in_health_care.pdf},
  isbn = {15209202},
  journal = {Big Data},
  number = {3},
  pmid = {1508572639}
}

@article{DHoore1993,
  title = {Risk Adjustment in Outcome Assessment: The {{Charlson}} Comorbidity Index},
  author = {D'Hoore, William and Sicotte, C and Tilquin, C},
  year = {1993},
  volume = {32},
  pages = {382--387},
  publisher = {{Schattauer GmbH}},
  issn = {0026-1270},
  journal = {Methods of information in medicine},
  keywords = {\#nosource},
  number = {05}
}

@article{DHoore1996,
  title = {Practical Considerations on the Use of the Charlson Comorbidity Index with Administrative Data Bases},
  author = {D'Hoore, William and Bouckaert, Andr{\'e} and Tilquin, Charles},
  year = {1996},
  month = dec,
  volume = {49},
  pages = {1429--1433},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(96)00271-5},
  abstract = {To develop a measure of the burden of comorbid disease from the MED-ECHO data base (Qu\'ebec), the so-called Charlson index was adapted to International Classification of Disease (ICD-9) codes. The resulting comorbidity index was applied to the study of inpatient death in 33,940 patients with ischemic heart disease. Multiple logistic regression was used to relate inpatient death to its predictors, including gender, principal diagnosis, age, and the comorbidity index. Various transformations of the comorbidity score were performed, and their effect on the predictive accuracy was assessed. The comorbidity index was constantly and strongly associated with death. From a statistical viewpoint, the best results were obtained when the index was transformed into four dummy independent variables (the area under the receiver-operating curve is then 0.87). In a validation analysis performed on 1990\textendash 1991 MED-ECHO data (36,012 admissions with ischemic heart disease), the comorbidity index has the same statistical properties. We conclude that the Charlson index may be an efficient approach to risk adjustment from administrative data bases, although it should be tested on other conditions.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KK2MBE9K\\d'hoore_et_al_1996_practical_considerations_on_the_use_of_the_charlson_comorbidity_index_with.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {12}
}

@article{Dickman2004,
  title = {Regression Models for Relative Survival},
  author = {Dickman, Paul W. and Sloggett, Andy and Hills, Michael and Hakulinen, Timo},
  year = {2004},
  volume = {23},
  pages = {51--64},
  issn = {02776715},
  doi = {10.1002/sim.1597},
  abstract = {Four approaches to estimating a regression model for relative survival using the method of maximum likelihood are described and compared. The underlying model is an additive hazards model where the total hazard is written as the sum of the known baseline hazard and the excess hazard associated with a diagnosis of cancer. The excess hazards are assumed to be constant within pre-specified bands of follow-up. The likelihood can be maximized directly or in the framework of generalized linear models. Minor differences exist due to, for example, the way the data are presented (individual, aggregated or grouped), and in some assumptions (e.g. distributional assumptions). The four approaches are applied to two real data sets and produce very similar estimates even when the assumption of proportional excess hazards is violated. The choice of approach to use in practice can, therefore, be guided by ease of use and availability of software. We recommend using a generalized linear model with a Poisson error structure based on collapsed data using exact survival times. The model can be estimated in any software package that estimates GLMs with user-defined link functions (including SAS, Stata, S-plus, and R) and utilizes the theory of generalized linear models for assessing goodness-of-fit and studying regression diagnostics.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\REBKDP6U\\dickman_et_al_2004_regression_models_for_relative_survival.pdf},
  isbn = {0277-6715 (Print){\r  }0277-6715 (Linking)},
  journal = {Statistics in Medicine},
  keywords = {Cancer,Excess mortality,Net survival,Registry,Regression,Relative survival},
  number = {1},
  pmid = {14695639}
}

@article{Dickman2013,
  title = {Estimating and Modelling Relative Survival},
  author = {Dickman, Paul W and Coviello, Enzo and Hills, Michael},
  year = {2013},
  pages = {1--23},
  issn = {02776715},
  doi = {10.1002/sim.1597},
  abstract = {Relative survival, the survival analogue of excess mortality, is the method of choice for estimating patient survival using data collected by population-based cancer registries. The relative survival ratio is typically estimated from life tables as the ratio of the observed survival of the patients (where all deaths are considered events) to the expected survival of a comparable group from the general population. This article describes the command strs for life table estimatation of relative survival. Three methods of estimating expected survival are available and estimates can be made using a cohort, period, or hybrid approach. A life table version of the Pohar Perme estimator of net survival is also available. Two methods for age standardisation are available. Probabilities of death due to cancer and due to other causes can be estimated using the method of Cronin and Feuer. Excess mortality can be modelled using a range of approaches including full likelihood (using the ml command) and Poisson regression (using the glm command with a user-specified link function).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IVZ9W5PR\\dickman_et_al_2013_estimating_and_modelling_relative_survival.pdf},
  isbn = {0277-6715 (Print){\r  }0277-6715 (Linking)},
  journal = {Stata Journal},
  keywords = {cancer survival,excess mortality,life table,period analysis,poisson,regression,relative survival,st0001,survival analysis},
  number = {ii},
  pmid = {14695639}
}

@article{Diedenhofen2015,
  title = {Cocor: A Comprehensive Solution for the Statistical Comparison of Correlations.},
  author = {Diedenhofen, Birk and Musch, Jochen},
  year = {2015},
  month = jan,
  volume = {10},
  pages = {e0121945},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0121945},
  abstract = {A valid comparison of the magnitude of two correlations requires researchers to directly contrast the correlations using an appropriate statistical test. In many popular statistics packages, however, tests for the significance of the difference between correlations are missing. To close this gap, we introduce cocor, a free software package for the R programming language. The cocor package covers a broad range of tests including the comparisons of independent and dependent correlations with either overlapping or nonoverlapping variables. The package also includes an implementation of Zou's confidence interval for all of these comparisons. The platform independent cocor package enhances the R statistical computing environment and is available for scripting. Two different graphical user interfaces-a plugin for RKWard and a web interface-make cocor a convenient and user-friendly tool.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7EZVNWDH\\diedenhofen_musch_2015_cocor.pdf},
  journal = {PloS one},
  number = {3},
  pmid = {25835001}
}

@article{Dieppe2011,
  title = {Who Should Have Knee Joint Replacement Surgery for Osteoarthritis?},
  author = {Dieppe, Paul and Lim, Keith and Lohmander, Stefan},
  year = {2011},
  volume = {14},
  pages = {175--180},
  issn = {17561841},
  doi = {10.1111/j.1756-185X.2011.01611.x},
  abstract = {Knee joint replacement is an effective and cost-effective intervention for severe symptomatic osteoarthritis of the knee joint. However, utilisation rates vary hugely, there are no indications, it is difficult to know when (in the course of arthritis) it is best to operate, and some 10-20\% of people who have this surgery are unhappy with the outcome, and have persistent pain. In this article we briefly discuss the variations in utilization of knee joint replacement, and then outline four different approaches to the selection and prioritisation of patients for this procedure. Consensus criteria, including appropriateness criteria are available, but if produced by professionals alone, they may conflict with the views of patients and the public. Databases and cohort studies can be used to attempt relating outcomes to baseline characteristics, but at present we can only account for a small percentage of the variance with this technique. Finally, we propose use of the 'capacity to benefit framework' to attempt providing guidance to both patients and healthcare professionals.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BWR7ZAKY\\dieppe_et_al_2011_who_should_have_knee_joint_replacement_surgery_for_osteoarthritis.pdf},
  isbn = {17561841},
  journal = {International Journal of Rheumatic Diseases},
  keywords = {Indications,Joint replacement,Knee,Osteoarthritis,Variations},
  number = {2},
  pmid = {21518317}
}

@article{Dignam2008,
  title = {Choice and Interpretation of Statistical Tests Used When Competing Risks Are Present},
  author = {Dignam, James J. and Kocherginsky, Maria N.},
  year = {2008},
  volume = {26},
  pages = {4027--4034},
  issn = {0732183X},
  doi = {10.1200/JCO.2007.12.9866},
  abstract = {In clinical cancer research, competing risks are frequently encountered. For example, individuals undergoing treatment for surgically resectable disease may experience recurrence near the removed tumor, metastatic recurrence at other sites, occurrence of second primary cancer, or death resulting from noncancer causes before any of these events. Two quantities, the cause-specific hazard function and the cumulative incidence function, are commonly used to summarize outcomes by event type. Tests for event-specific differences between treatment groups may thus be based on comparison of (a) cause-specific hazards via a log-rank or related test, or (b) the cumulative incidence functions via one of several available tests. Inferential results for tests based on these different metrics can differ considerably for the same cause-specific end point. Depending on the questions of principal interest, one or both metrics may be appropriate to consider. We present simulation study results and discuss examples from cancer clinical trials to illustrate these points and provide guidance for analysis when competing risks are present. \textcopyright{} 2008 by American Society of Clinical Oncology.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HF8NEDTZ\\dignam_kocherginsky_2008_choice_and_interpretation_of_statistical_tests_used_when_competing_risks_are.pdf},
  journal = {Journal of Clinical Oncology},
  number = {24}
}

@article{dishoeckDisplayingRandomVariation2011,
  title = {Displaying Random Variation in Comparing Hospital Performance},
  author = {Dishoeck, A. M. Van and Looman, C. W N and Lier, E. C M Van Der Wilden-van and Mackenbach, J. P. and Steyerberg, E. W.},
  year = {2011},
  volume = {20},
  pages = {651--657},
  issn = {20445415},
  doi = {10.1136/bmjqs.2009.035881},
  abstract = {The role of transparency in quality of care is becoming ever more important. Various indicators are used to assess hospital performance. Judging hospitals using rank order takes no account of disturbing factors such as random variation and case-mix differences. The purpose of this article is to compare displays for the influence of random variation on the apparent differences in the quality of care between the Dutch hospitals.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HSHGLE8E\\dishoeck_et_al_2011_displaying_random_variation_in_comparing_hospital_performance.pdf},
  isbn = {2044-5423 (Electronic){\r  }2044-5415 (Linking)},
  journal = {BMJ Quality and Safety},
  number = {8},
  pmid = {21228432}
}

@article{Djernes2006,
  title = {Prevalence and Predictors of Depression in Populations of Elderly: {{A}} Review},
  author = {Djernes, J. K.},
  year = {2006},
  volume = {113},
  pages = {372--387},
  issn = {0001690X},
  doi = {10.1111/j.1600-0447.2006.00770.x},
  abstract = {OBJECTIVE: To offer an update on prevalence and predictors of old age depression in populations of elderly Caucasians.: The databases MEDLINE and Psychinfo were searched and relevant literature from 1993 onwards was reviewed.: The prevalence of major depression ranges from 0.9\% to 9.4\% in private households, from 14\% to 42\% in institutional living, and from 1\% to 16\% among elderly living in private households or in institutions; and clinically relevant depressive symptom 'cases' in similar settings vary between 7.2\% and 49\%. The main predictors of depressive disorders and depressive symptom cases are: female gender, somatic illness, cognitive impairment, functional impairment, lack or loss of close social contacts, and a history of depression.: Depression is frequent in populations of elderly. Methodological differences between the studies hinder consistent conclusions about geographical and cross-cultural variations in prevalence and predictors of depression. Improved comparability will provide a basis for consistent conclusions.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZIF4Y7AE\\djernes_2006_prevalence_and_predictors_of_depression_in_populations_of_elderly.pdf},
  isbn = {0001-690X},
  journal = {Acta Psychiatrica Scandinavica},
  keywords = {Aged,Community,Depression,Epidemiology,Predictors,Prevalence,Residential facilities},
  number = {5},
  pmid = {16603029}
}

@book{Dobrow2013,
  title = {Probability with Applications and r},
  author = {Dobrow, Robert P.},
  year = {2013},
  volume = {53},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \AA{} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GTDJHL3E\\dobrow_2013_probability_with_applications_and_r.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {icle},
  pmid = {25246403}
}

@book{Dobson2002,
  title = {An Introduction to Generalized Linear Models},
  author = {Dobson, Annette J},
  year = {2002},
  issn = {0040-1706},
  doi = {10.1198/tech.2002.s91},
  abstract = {Generalized linear models provide a unified theoretical and conceptual framework for many of the most commonly used statistical methods. In the ten years since publication of the first edition of this bestselling text, great strides have been made in the development of new methods and in software for generalized linear models and other closely related models.Thoroughly revised and updated, An Introduction to Generalized Linear Models, Second Edition continues to initiate intermediate students of statistics, and the many other disciplines that use statistics, in the practical use of these models and methods. The new edition incorporates many of the important developments of the last decade, including survival analysis, nominal and ordinal logistic regression, generalized estimating equations, and multi-level models. It also includes modern methods for checking model adequacy and examples from an even wider range of application.Statistics can appear to the uninitiated as a collection of unrelated tools. An Introduction to Generalized Linear Models, Second Edition illustrates how these apparently disparate methods are examples or special cases of a conceptually simple structure based on the exponential family of distribution, maximum likelihood estimation, and the principles of statistical modelling.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6Y4Y6CC4\\dobson_2002_an_introduction_to_generalized_linear_models.pdf},
  isbn = {1-58488-165-8},
  keywords = {generalized linear models,statistics}
}

@article{Dolan1997,
  title = {Modeling Valuations for {{EuroQoal}} Health States},
  author = {Dolan, Paul},
  year = {1997},
  volume = {35},
  pages = {1095--1108},
  issn = {0025-7079},
  abstract = {Objectives. It has become increasingly common for preference-based measures of health-related quality of life to be used in the evaluation of different health-care interventions. For one such measure, The EuroQol, designed to be used for these purposes, it was necessary to derive a single index value for each of the 243 health states it generates. The problem was that it was virtually impossible to generate direct valuations for all of these states, and thus it was necessary to find a procedure that allows the valuations of all EuroQol states to be interpolated from direct valuations on a subset of these. Methods. In a recent study, direct valuations were elicited for 42 EuroQol health states (using the time trade-off method) from a representative sample of the UK population. This article reports on the methodology that was adopted to build up a "tariff" of EuroQol values from this data. Results. A parsimonious model that fits the data well was defined as one in which valuations were explained in terms of the level of severity associated with each dimension, an intercept associated with any move away from full health, and a term that picked up whether any dimension in the state was at its most severe level. Conclusions. The model presented in this article appears to predict the values of the states for which there are direct observations and, thus, can be used to interpolate values for the states for which no direct observations exist.},
  journal = {Medical Care},
  keywords = {\#nosource,EuroQol,health status measurement,time trade-off},
  number = {11}
}

@book{doncasterAnalysisVarianceCovariance2007,
  title = {Analysis of Variance and Covariance: {{How}} to Choose and Construct Models for the Life Sciences},
  author = {Doncaster, C. Patrick and Davey, Andrew J. H.},
  year = {2007},
  isbn = {978-0-521-68447-7},
  keywords = {\#nosource}
}

@article{Donoghoe2015,
  title = {Flexible Regression Models for Rate Differences, Risk Differences and Relative Risks},
  author = {Donoghoe, Mark W. and Marschner, Ian C.},
  year = {2015},
  month = jan,
  volume = {11},
  pages = {91--108},
  issn = {15574679},
  doi = {10.1515/ijb-2014-0044},
  abstract = {Generalized additive models (GAMs) based on the binomial and Poisson distributions can be used to provide flexible semi-parametric modelling of binary and count outcomes. When used with the canonical link function, these GAMs provide semi-parametrically adjusted odds ratios and rate ratios. For adjustment of other effect measures, including rate differences, risk differences and relative risks, non-canonical link functions must be used together with a constrained parameter space. However, the algorithms used to fit these models typically rely on a form of the iteratively reweighted least squares algorithm, which can be numerically unstable when a constrained non-canonical model is used. We describe an application of a combinatorial EM algorithm to fit identity link Poisson, identity link binomial and log link binomial GAMs in order to estimate semi-parametrically adjusted rate differences, risk differences and relative risks. Using smooth regression functions based on B-splines, the method provides stable convergence to the maximum likelihood estimates, and it ensures that the estimates always remain within the parameter space. It is also straightforward to apply a monotonicity constraint to the smooth regression functions. We illustrate the method using data from a clinical trial in heart attack patients.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WRYZJAMH\\donoghoe_marschner_2015_flexible_regression_models_for_rate_differences,_risk_differences_and_relative.pdf},
  journal = {International Journal of Biostatistics},
  keywords = {B-splines,generalized additive models,risk models,semi-parametric regression},
  number = {1},
  pmid = {25781711}
}

@book{Driscoll2009,
  title = {Learning Matlab},
  author = {Driscoll, Tobin A.},
  year = {2009},
  publisher = {{SIAM}},
  isbn = {978-0-89871-683-2},
  keywords = {\#nosource}
}

@article{Duchateau2007,
  title = {The Frailty Model},
  author = {Duchateau, Luc and Janssen, Paul},
  year = {2007},
  keywords = {\#nosource}
}

@article{Duivenvoorden2013,
  title = {Anxiety and Depressive Symptoms before and after Total Hip and Knee Arthroplasty: A Prospective Multicentre Study.},
  author = {Duivenvoorden, T and Vissers, M M and Verhaar, J A N and Busschbach, J J V and Gosens, T and Bloem, R M and {Bierma-Zeinstra}, S M A and Reijman, M},
  year = {2013},
  volume = {21},
  pages = {1834--40},
  publisher = {{Elsevier Ltd}},
  issn = {1522-9653},
  doi = {10.1016/j.joca.2013.08.022},
  abstract = {BACKGROUND: A subset of patients with total hip arthroplasty (THA) or total knee arthroplasty (TKA) has suboptimal postoperative results in terms of Patient Reported Outcomes (PROs), and psychological factors could contribute to these suboptimal results. OBJECTIVES: To examine the prevalence of anxiety and depressive symptoms in patients undergoing primary THA or TKA preoperatively and postoperatively, and the relationship between preoperative anxiety and depressive symptoms on PROs of THA and TKA. DESIGN: In this prospective study patients were measured preoperatively, and 3 and 12 months postoperatively. Patients filled in the Hospital Anxiety and Depression Scale, Knee injury and Osteoarthritis Outcome Score (KOOS) or Hip disability and Osteoarthritis Outcome Score (HOOS) and a satisfaction questionnaire. RESULTS: Data were obtained from 149 hip and 133 knee patients. The prevalence of anxiety symptoms decreased significantly from 27.9\% to 10.8\% 12 months postoperatively in hip patients, and from 20.3\% to 14.8\% in knee patients. Depressive symptoms decreased significantly from 33.6\% to 12.1\% 12 months postoperatively in hip patients, and from 22.7\% to 11.7\% in knee patients. In hip and knee patients, preoperative depressive symptoms predicted smaller changes in different HOOS or KOOS subscales and patients were less satisfied 12 months postoperatively. CONCLUSIONS: Preoperatively, the prevalence of anxiety and depressive symptoms was high. At 3 and 12 months postoperatively, the prevalence of anxiety and depressive symptoms was decreased in both hip and knee patients. However, patients with preoperative anxiety and depressive symptoms had worse PROs 3 and 12 months after THA and TKA and were less satisfied than patients without anxiety or depressive symptoms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\398VVSTP\\duivenvoorden_et_al_2013_anxiety_and_depressive_symptoms_before_and_after_total_hip_and_knee_arthroplasty.pdf},
  isbn = {1063-4584},
  journal = {Osteoarthritis and cartilage / OARS, Osteoarthritis Research Society},
  keywords = {80 and over,Aged,Anxiety,Anxiety: epidemiology,Anxiety: psychology,Arthroplasty,Depression,Depression: epidemiology,Depression: psychology,Female,Hip,Hip: psychology,Hip: surgery,Humans,Knee,Knee: psychology,Knee: surgery,Longitudinal Studies,Male,Middle Aged,Osteoarthritis,Patient Satisfaction,Prevalence,Prospective Studies,Replacement,Surveys and Questionnaires,Treatment Outcome},
  number = {12},
  pmid = {24012622}
}

@article{dunn+WellseparatedClustersOptimal1974,
  title = {Well-Separated Clusters and Optimal Fuzzy Partitions},
  author = {Dunn\textdagger, J. C.},
  year = {1974},
  month = jan,
  volume = {4},
  pages = {95--104},
  publisher = {{Taylor \& Francis Group}},
  issn = {0022-0280},
  doi = {10.1080/01969727408546059},
  abstract = {Abstract Two separation indices are considered for partitions P = \{X1, \ldots, Xk\} of a finite data set X in a general inner product space. Both indices increase as the pairwise distances between the subsets Xi become large compared to the diameters of Xi Maximally separated partitions p' are defined and it is shown that as the indices of p' increase without bound, the characteristic functions of Xi' in P' are approximated more and more closely by the membership functions in fuzzy partitions which minimize certain fuzzy extensions of the k-means squared error criterion function.},
  journal = {Journal of Cybernetics},
  keywords = {\#nosource},
  number = {1}
}

@article{Dupont1998,
  title = {Power and Sample Size Calculations for Studies Involving Linear Regression.},
  author = {Dupont, W D and Plummer, W D},
  year = {1998},
  volume = {19},
  pages = {589--601},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(98)00037-3},
  abstract = {This article presents methods for sample size and power calculations for studies involving linear regression. These approaches are applicable to clinical trials designed to detect a regression slope of a given magnitude or to studies that test whether the slopes or intercepts of two independent regression lines differ by a given amount. The investigator may either specify the values of the independent (x) variable(s) of the regression line(s) or determine them observationally when the study is performed. In the latter case, the investigator must estimate the standard deviation(s) of the independent variable(s). This study gives examples using this method for both experimental and observational study designs. Cohen's method of power calculations for multiple linear regression models is also discussed and contrasted with the methods of this study. We have posted a computer program to perform these and other sample size calculations on the Internet (see http://www.mc.vanderbilt.edu/prevmed/psintro+ ++.htm). This program can determine the sample size needed to detect a specified alternative hypothesis with the required power, the power with which a specific alternative hypothesis can be detected with a given sample size, or the specific alternative hypotheses that can be detected with a given power and sample size. Context-specific help messages available on request make the use of this software largely self-explanatory.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BXS3MY8G\\dupont_plummer_1998_power_and_sample_size_calculations_for_studies_involving_linear_regression.pdf},
  isbn = {0197-2456},
  journal = {Controlled clinical trials},
  keywords = {linear models,power calculations,regression analysis,sample size calculations,statistics},
  number = {6},
  pmid = {9875838}
}

@article{Edelstein2015,
  title = {Can the American College of Surgeons Risk Calculator Predict 30-{{Day}} Complications after Knee and Hip Arthroplasty?},
  author = {Edelstein, Adam I. and Kwasny, Mary J. and Suleiman, Linda I. and Khakhkhar, Rishi H. and Moore, Michael A. and Beal, Matthew D. and Manning, David W.},
  year = {2015},
  month = sep,
  volume = {30},
  pages = {5--10},
  publisher = {{Churchill Livingstone Inc.}},
  issn = {15328406},
  doi = {10.1016/j.arth.2015.01.057},
  abstract = {Accurate risk stratification of patients undergoing total hip (THA) and knee (TKA) arthroplasty is essential in the highly scrutinized world of pay-for-performance, value-driven healthcare. We assessed the American College of Surgeons National Surgical Quality Improvement Program (ACS-NSQIP) surgical risk calculator's ability to predict 30-day complications using 1066 publicly-reported Medicare patients undergoing primary THA or TKA. Risk estimates were significantly associated with complications in the categories of any complication (= .005), cardiac complication (\textexclamdown{} .001), pneumonia (\textexclamdown{} .001) and discharge to skilled nursing facility (\textexclamdown{} .001). However, predictability of complication occurrence was poor for all complications assessed. To facilitate the equitable provision and reimbursement of patient care, further research is needed to develop accurate risk stratification tools in TKA and THA surgery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CDMWJA3I\\edelstein_et_al_2015_can_the_american_college_of_surgeons_risk_calculator_predict_30-day.pdf},
  journal = {Journal of Arthroplasty},
  keywords = {Complications,Hip arthroplasty,Knee arthroplasty,Risk calculator},
  number = {9},
  pmid = {26165953}
}

@book{Editors2009,
  title = {Use r !},
  author = {Editors, Series and Gentleman, Robert and Hornik, Kurt and Parmigiani, Giovanni G},
  year = {2009},
  issn = {9780387938363},
  doi = {10.1007/978-0-387-78171-6},
  isbn = {978-0-387-93836-3},
  keywords = {\#nosource},
  pmid = {22057480}
}

@article{Efron1997,
  title = {Improvements on Cross-Validation: {{The}} .632 plus Bootstrap Method},
  author = {Efron, B. and Tibshirani, R.},
  year = {1997},
  volume = {92},
  pages = {548},
  issn = {0162-1459},
  doi = {10.1080/01621459.1997.10474007},
  abstract = {A study investigates the error rate of a rule for predicting future responses constructed from a training set of data. Results are nonparametric and apply to any possible prediction rule.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LHUB86QI\\efron_tibshirani_1997_improvements_on_cross-validation.pdf},
  isbn = {0162-1459},
  journal = {Journal of the American Statistical Association},
  keywords = {classification,Classification,cross-validation bootstrap,Cross-validation bootstrap,prediction rule,Prediction rule},
  number = {438},
  pmid = {370}
}

@article{Eiben2005,
  title = {Obesity in 70-Year-Old {{Swedes}}: Secular Changes over 30 Years.},
  author = {Eiben, G and Dey, D K and Rothenberg, E and Steen, B and Bj{\"o}rkelund, C and Bengtsson, C and Lissner, L},
  year = {2005},
  volume = {29},
  pages = {810--7},
  issn = {0307-0565},
  doi = {10.1038/sj.ijo.0802940},
  abstract = {OBJECTIVE: Secular increases in obesity have been widely reported in middle-aged adults, but less is known about such trends among the elderly. The primary purpose of this paper is to document the most recent wave of the obesity epidemic in population-based samples of 70-y-old men and women from G\"oteborg. Additionally, we will investigate the influences of physical activity, smoking and education on these secular trends.AND METHODS: Five population-based samples of 3702 70-y-olds (1669 men and 2033 women) in G\"oteborg, Sweden, born between 1901 and 1930, were examined in the Gerontological and Geriatric Population Studies (H70) between 1971 and 2000. Cohort differences in anthropometric measures were the main outcomes studied. Physical activity, smoking habits and education were assessed by comparable methods in all cohorts. Subsamples of the women in the latest two cohorts (birth years 1922 and 1930) were also part of the Prospective Population Study of Women in G\"oteborg. In these women, it was possible to examine body mass index (BMI) and waist-to-hip circumference ratio (WHR) longitudinally since 1968.AND CONCLUSIONS: Significant upward trends were found for height, weight, BMI, waist circumference (WC), WHR, prevalence of overweight (BMI\textquestiondown{} or =25 kg/m(2)) and obesity (BMI\textquestiondown{} or =30 kg/m(2)) across cohorts in both sexes. In 2000, 20\% of the 70-y-old men born in 1930 were obese, and the largest increment (almost doubling) had occurred between the early 1980s and the early 1990s. In 70-y-old women the prevalence of obesity was 24\% in 2000, a 50\% increase compared to the cohort born 8 y earlier. BMI increased over time in all physical activity, smoking and education groups, with the exception of never-smoking men. Although 70-y-old women in 2000 were heavier than cohorts examined 8 y previously, data from the women studied longitudinally revealed that these differences were already present in earlier adulthood. In conclusion, the elderly population is very much part of the obesity epidemic, although secular trends in BMI were detected slightly earlier in men than in women. The health implications of these secular trends should be focused on in future gerontological research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SL2QTGJD\\eiben_et_al_2005_obesity_in_70-year-old_swedes.pdf},
  isbn = {0307-0565},
  journal = {International journal of obesity (2005)},
  keywords = {Aged,Anthropometry,Body Mass Index,Cohort Studies,Educational Status,Exercise,Female,Humans,Male,Obesity,Obesity: epidemiology,Sweden,Sweden: epidemiology},
  number = {7},
  pmid = {15917864}
}

@article{Ekman2019,
  title = {Early Postoperative Mortality Similar between Cemented and Uncemented Hip Arthroplasty: A Register Study Based on {{Finnish}} National Data},
  author = {Ekman, Elina and Palom{\"a}ki, Antton and Laaksonen, Inari and Peltola, Mikko and H{\"a}kkinen, Unto and M{\"a}kel{\"a}, Keijo},
  year = {2019},
  volume = {90},
  pages = {6--10},
  issn = {17453682},
  doi = {10.1080/17453674.2018.1558500},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\L6BXZCST\\ekman_et_al_2019_early_postoperative_mortality_similar_between_cemented_and_uncemented_hip.pdf},
  journal = {Acta Orthopaedica},
  number = {1}
}

@article{Elixhauser1998,
  title = {Comorbidity Measures for Use with Administrative Data},
  author = {Elixhauser, Anne and Steiner, Claudia and Harris, D Robert and Coffey, Rosanna M},
  year = {1998},
  volume = {36},
  pages = {8--27},
  journal = {Medical care},
  keywords = {\#nosource,coder},
  number = {1}
}

@article{Elm2007,
  title = {Strengthening the Reporting of Observational Studies in Epidemiology ({{STROBE}}) [Abstract]},
  author = {Elm, E and Pocock, S and Vandenbroucke, J and Altman, D and Egger, M},
  year = {2007},
  volume = {18},
  pages = {805--835},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e3181577511},
  abstract = {Background: Incomplete and inadequate reporting of research in the medical literature is a widely recognised problem which hampers the critical appraisal and appropriate interpretation of research findings and complicates the practice of evidence-based health care. Reporting guidelines that are adopted by leading medical journals can improve the quality of reporting, as demonstrated by the CONSORT statement for randomised controlled trials. The interest in systematic reviews of observational studies has increased in recent years. Better reporting of such studies may facilitate the conduct of valid systematic reviews of non-randomised evidence in the future. Objectives: To strengthen the reporting of observational studies in epidemiology. To develop a checklist of items considered essential for the reporting of observational research (STROBE statement). Methods: A group of epidemiologists, methodologists, medical statisticians and editors from several European countries and the USA met for a workshop in Bristol in September 2004. The aim was to develop recommendations for the reporting of observational studies, including cohort, case-control, and cross-sectional studies. The resulting draft checklist was posted on the initiative's website (www.strobe-statement.org) in spring 2005 and further input has since been collected from the community at large. Results: The STROBE statement comprises a checklist of 22 items that are recommended for the reporting of observational studies. The checklist is structured in five sections. Fourteen items are generic and three items are specific for each of the three designs cohort, case-control, and cross-sectional study. Five items have a generic and a specific part. The latest full version of the checklist will be presented at the Colloquium. Conclusions: Dissemination and adoption of reporting recommendations have a potential to improve current reporting practice also of observational studies. The STROBE statement should be seen as the result of an ongoing process. Future revisions of the statement and extensions to cover additional study designs are planned. The Cochrane community is heartily invited to contribute to this process. OTHER PUBLICATIONS OF THIS RESEARCH: Vandenbroucke JP; Von Elm E; Altman DG; Gotzsche PC; Mulrow CD; Pocock SJ; Poole C; Schlesselman JJ; Egger M. [Strengthening the reporting of observational studies in epidemiology (STROBE): explanation and elaboration]. Gaceta Sanitaria 2009;23(2):158. von Elm E, Altman DG, Egger M, Pocock SJ, Gotzsche PC, Vandenbroucke JP. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. Journal of Clinical Epidemiology 2008;61(4):344-9. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. [The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies]. Revista Espanola de Salud Publica 2008; 82(3):251-9. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. [The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): guidelines for reporting observational studies]. Gaceta Sanitaria 2008;22(2):144-50. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. [The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting of observational studies] Der Internist 2008;49(6):688-93. Vandenbroucke JP; von Elm E; Altman DG; Gotzsche PC; Mulrow CD; Pocock SJ; Poole C; Schlesselman JJ; Egger M. Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): explanation and elaboration. Annals of Internal Medicine 2007;147(8):W163-94. Vandenbroucke JP, von Elm E, Altman DG, Gotzsche PC, Mulrow CD, Pocock SJ, Poole C, Schlesselman JJ, Egger M. Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): explanation and elaboration. PLoS Medicine 2007;4(10):e297. Vandenbroucke JP; von Elm E; Altman DG; Gotzsche PC; M lrow CD; Pocock SJ; Poole C; Schlesselman JJ; Egger M. Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): explanation and elaboration. Epidemiology 2007;18(6):805-35. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. Annals of Internal Medicine 2007;147(8):573-7. von Elm E, Altman DG, Egger M, Pocock SJ, Gotzsche PC, Vandenbroucke JP. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. Lancet 2007;370(9596):1453-7. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. PLoS Medicine 2007;4(10):e296. von Elm E; Altman DG; Egger M; Pocock SJ; Gotzsche PC; Vandenbroucke JP. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. Epidemiology 2007;18(6):800-4.},
  journal = {Epidemiology},
  keywords = {\#nosource,CMR: Evaluation methodology - non-randomised studi},
  number = {6}
}

@article{Emilsson2015,
  title = {Review of 103 Swedish Healthcare Quality Registries},
  author = {Emilsson, L. and Lindahl, B. and K{\"o}ster, M. and Lambe, M. and Ludvigsson, J. F.},
  year = {2015},
  month = jan,
  volume = {277},
  pages = {94--136},
  issn = {09546820},
  doi = {10.1111/joim.12303},
  abstract = {BACKGROUND AND OBJECTIVES: In the past two decades, an increasing number of nationwide, Swedish Healthcare Quality Registries (QRs) focusing on specific disorders have been initiated, mostly by physicians. Here, we describe the purpose, organization, variables, coverage and completeness of 103 Swedish QRs. METHODS: From March to September 2013, we examined the 2012 applications of 103 QRs to the Swedish Association of Local Authorities and Regions (SALAR) and also studied the annual reports from the same QRs. After initial data abstraction, the coordinator of each QR was contacted at least twice between June and October 2013 and asked to confirm the accuracy of the data retrieved from the applications and reports. RESULTS: About 60\% of the QRs covered {$\geq$}80\% of their target population (completeness). Data recorded in Swedish QRs include aspects of disease management (diagnosis, clinical characteristics, treatment and lead times). In addition, some QRs retrieve data on self-reported quality of life (EQ5D, SF-36 and disease-specific measures), lifestyle (smoking) and general health status (World Health Organization performance status, body mass index and blood pressure). CONCLUSION: Detailed clinical data available in Swedish QRs complement information from government-administered registries and provide an important source not only for assessment and development of quality of care but also for research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YB5S7B36\\emilsson_et_al_2015_review_of_103_swedish_healthcare_quality_registries.pdf},
  isbn = {1365-2796 (Electronic){\r  }0954-6820 (Linking)},
  journal = {Journal of Internal Medicine},
  keywords = {Adult,Child,Life quality,Morbidity,Register,Registry},
  number = {1},
  pmid = {25174800}
}

@article{Eneqvist2017,
  title = {Lumbar Surgery Prior to Total Hip Arthroplasty Is Associated with Worse Patient-Reported Outcomes},
  author = {Eneqvist, T. and Nemes, S. and Brisby, H. and Fritzell, P. and Garellick, G. and Rolfson, O.},
  year = {2017},
  volume = {99-B},
  pages = {759--765},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.99B6.BJJ-2016-0577.R2},
  journal = {Bone \& Joint Journal},
  keywords = {\#nosource},
  number = {6}
}

@article{Eneqvist2018,
  title = {Can Patient-Reported Outcomes Predict Re-Operations after Total Hip Replacement?},
  author = {Eneqvist, Ted and Nemes, Szil{\'a}rd and B{\"u}low, Erik and Mohaddes, Maziar and Rolfson, Ola},
  year = {2018},
  month = jan,
  pages = {1--7},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {0341-2695},
  doi = {10.1007/s00264-017-3711-z},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KTYIL788\\eneqvist_et_al_2018_can_patient-reported_outcomes_predict_re-operations_after_total_hip_replacement.pdf},
  journal = {International Orthopaedics},
  keywords = {patient-reported outcome measurements,Patient-reported outcome measurements,prediction,Prediction,re-operation,Re-operation,total hip replacement,Total hip replacement},
  number = {C}
}

@article{Eneqvist2018a,
  title = {Patients with a Previous Total Hip Replacement Experience Less Reduction of Back Pain Following Lumbar Back Surgery},
  author = {Eneqvist, Ted and B{\"u}low, E. and Nemes, S. and Brisby, Helena and Garellick, G. and Fritzell, P. and Rolfson, O.},
  year = {2018},
  pages = {1--7},
  issn = {1554527X},
  doi = {10.1002/jor.24018},
  abstract = {\textcopyright{} 2018 Orthopaedic Research Society. The coexistence of degenerative disorders from the hip joint and the lumbar spine, known as "the hip-spine syndrome," is a common encounter in clinical practice. These degenerative conditions may cause similar symptoms which often entail diagnostic challenges in determining the origin of pain. Lumbar back surgery (LBS) with fusion and/or decompression, and total hip replacement (THR) are both often successful interventions. However, the knowledge is limited about the post-operative patient-reported outcome (PRO) following LBS in the presence of a prior THR. The aims of this study were to compare 1-year post-operative patient-reported outcome measures (PROMs) following lumbar back surgery (LBS) in patients with and without a prior total hip replacement (THR). Data from Swespine and the Swedish Hip Arthroplasty Register were linked in order to identify the study group of patients with THR prior to LBS. The study group (n=220) and a matched control group (n=220) with isolated LBS was defined by using a step-wise selection process. Linear- and logistic regression analyses adjusted for age, sex and pre-operative PROMs demonstrated that THR prior to LBS was associated with worse back-pain (VAS) at 1-year follow-up (B=5.3, 95\%CI: 0.3;10.3). However, previous THR did not influence the EQ-5D index (B=0.01, 95\%CI: -0.05;0.06), EQ VAS (B=-3.0, 95\%CI: -6.9;1.0), leg pain (B=1.5, 95\%CI: -4.0;7.0), Oswestry Disability Index (B=2.6, 95\%CI: -0.5;5.6) or satisfaction (OR=1.1, 97.5\%CI 0.7;1.6). This knowledge is important to communicate prior to LBS in order to set proper expectations on surgical outcomes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZI2Z4MA8\\eneqvist_et_al_2018_patients_with_a_previous_total_hip_replacement_experience_less_reduction_of.pdf},
  journal = {Journal of Orthopaedic Research},
  keywords = {Hip-spine syndrome,Lumbar spine surgery,Patient-reported outcome measurement,Register,Total hip replacement},
  pmid = {29663509}
}

@techreport{Engel1965,
  title = {Klassifikation Av Sjukdomar Del 1},
  author = {Engel, Arthur and Soop, Erik},
  year = {1965},
  institution = {{Kungliga Medecinalstyrelse}},
  keywords = {\#nosource}
}

@article{engerMarkovprocesser2006,
  title = {Markovprocesser},
  author = {Enger, Jan and Grandell, Jan},
  year = {2006},
  keywords = {\#nosource}
}

@article{Ensrud2007,
  title = {Frailty and Risk of Falls, Fracture, and Mortality in Older Women: The Study of Osteoporotic Fractures.},
  author = {Ensrud, Kristine E and Ewing, Susan K and Taylor, Brent C and Fink, Howard A and Stone, Katie L and Cauley, Jane A and Tracy, J Kathleen and Hochberg, Marc C and Rodondi, Nicolas and Cawthon, Peggy M and Group, for the Study of Osteoporotic Fractures Research Study of Osteoporotic Fractures Research},
  year = {2007},
  volume = {62},
  pages = {744--51},
  issn = {1079-5006},
  doi = {10.1111/j.1532-5415.2005.53405.x},
  abstract = {BACKGROUND A standard phenotype of frailty was associated with an increased risk of adverse outcomes including mortality in a recent study of older adults. However, the predictive validity of this phenotype for fracture outcomes and across risk subgroups is uncertain. METHODS To determine whether a standard frailty phenotype was independently associated with risk of adverse health outcomes in older women and to evaluate the consistency of associations across risk subgroups defined by age and body mass index (BMI), we ascertained frailty status in a cohort of 6724 women\textquestiondown or=69 years and followed them prospectively for incident falls, fractures, and mortality. Frailty was defined by the presence of three or more of the following criteria: unintentional weight loss, weakness, self-reported poor energy, slow walking speed, and low physical activity. Incident recurrent falls were defined as at least two falls during the subsequent year. Incident fractures (confirmed with x-ray reports), including hip fractures, and deaths were ascertained during an average of 9 years of follow-up. RESULTS After controlling for multiple confounders such as age, health status, medical conditions, functional status, depressive symptoms, cognitive function, and bone mineral density, frail women were subsequently at increased risk of recurrent falls (multivariate odds ratio=1.38, 95\% confidence interval [CI], 1.02-1.88), hip fracture (multivariate hazards ratio [MHR]=1.40, 95\% CI, 1.03-1.90), any nonspine fracture (MHR=1.25, 95\% CI, 1.05-1.49), and death (MHR=1.82, 95\% CI, 1.56-2.13). The associations between frailty and these outcomes persisted among women\textquestiondown or=80 years. In addition, associations between frailty and an increased risk of falls, fracture, and mortality were consistently observed across categories of BMI, including BMI\textquestiondown or=30 kg/m2. CONCLUSION Frailty is an independent predictor of adverse health outcomes in older women, including very elderly women and older obese women.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IATU4HZP\\ensrud_et_al_2007_frailty_and_risk_of_falls,_fracture,_and_mortality_in_older_women.pdf},
  isbn = {1079-5006},
  journal = {The journals of gerontology. Series A, Biological sciences and medical sciences},
  number = {7},
  pmid = {17634322}
}

@book{epidemiologyEpidemiology1990,
  title = {Epidemiology.},
  author = {Epidemiology, International Society for Environmental},
  year = {1990},
  publisher = {{Blackwell Scientific Publications}},
  issn = {1044-3983},
  abstract = {Published: Baltimore, MD : Williams \& Wilkins and Epidemiology Resources Inc., \textexclamdown Jan. 1992-Nov. 1993\textquestiondown; Lippincott, Williams \& Wilkins and and Epidemiology Resources Inc., \textexclamdown Jan. 1999\textquestiondown -Nov.1999; Lippincott, Williams \& Wilkins, Jan. 2000-},
  keywords = {\#nosource}
}

@book{Erikssons1991,
  title = {Konstitutionell R\"att {{I}} - Statsskick , Fri- Och R\"attigheter Samt Offentliga Akt\"orer},
  author = {Erikssons, Magnus and Rf, Av and Ro, L and Rf, F and Sverige, Sedan},
  year = {1991},
  keywords = {\#nosource}
}

@techreport{ernkransEtikprovningAvForskning2019,
  title = {Etikpr\"ovning Av Forskning \textendash{} Tydligare Regler Och Sk\"arpta Straff},
  author = {Ernkrans, Matilda and Lenberg, Eva},
  year = {2019},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MT6VWASH\\ernkrans_lenberg_2019_etikprövning_av_forskning_–_tydligare_regler_och_skärpta_straff.pdf}
}

@book{EuroQol2014,
  ids = {Szende2014},
  title = {Self-Reported Population Health: {{An InternationalPerspective}} Based on {{EQ}}-{{5D}}},
  author = {EuroQol, Group and J., Janssen B Szende A Cabase\textasciiacute s},
  year = {2014},
  issn = {10983015},
  doi = {10.1007/978-94-007-7596-1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ISNDXJ7T\\euroqol_j._2014_self-reported_population_health.pdf},
  isbn = {978-94-007-7595-4}
}

@article{Evans2016,
  title = {Time, Space and Form: {{Necessary}} for Causation in Health, Disease and Intervention?},
  author = {Evans, David W. and Lucas, Nicholas and Kerry, Roger},
  year = {2016},
  volume = {19},
  pages = {207--213},
  issn = {15728633},
  doi = {10.1007/s11019-015-9662-5},
  abstract = {Sir Austin Bradford Hill's 'aspects of causation' represent some of the most influential thoughts on the subject of proximate causation in health and disease. Hill compiled a list of features that, when present and known, indicate an increasing likelihood that exposure to a factor causes-or contributes to the causation of-a disease. The items of Hill's list were not labelled 'criteria', as this would have inferred every item being necessary for causation. Hence, criteria that are necessary for causation in health, disease and intervention processes, whether known, knowable, or not, remain undetermined and deserve exploration. To move beyond this position, this paper aims to explore factors that are necessary in the constitution of causative relationships between health, disease processes, and intervention. To this end, disease is viewed as a causative pathway through the often overlapping stages of aetiology, pathology and patho-physiology. Intervention is viewed as a second, independent causative pathway, capable of causing changes in health for benefit or harm. For the natural course of a disease pathway to change, we argue that intervention must not only occupy the same time and space, but must also share a common form; the point at which the two pathways converge and interact. This improved conceptualisation may be used to facilitate the interpretation of clinical observations and inform future research, particularly enabling predictions of the mechanistic relationship between health, disease and intervention.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EVV89HUR\\evans_et_al_2016_time,_space_and_form.pdf},
  journal = {Medicine, Health Care and Philosophy},
  keywords = {Bradford Hill,Causation,Disease,Evidence-based medicine,Health,Intervention,Mechanism,Treatment},
  number = {2},
  pmid = {26351062}
}

@article{Everhart2013,
  title = {Medical {{Comorbidities Are Independent Preoperative Risk Factors}} for {{Surgical Infection After Total Joint Arthroplasty}}},
  author = {Everhart, Joshua S. and Altneu, Eric and Calhoun, Jason H.},
  year = {2013},
  month = oct,
  volume = {471},
  pages = {3112--3119},
  issn = {0009-921X, 1528-1132},
  doi = {10.1007/s11999-013-2923-9},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\778PKHDX\\Everhart et al_2013_Medical Comorbidities Are Independent Preoperative Risk Factors for Surgical.pdf},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  language = {en},
  number = {10}
}

@book{Everitt2006,
  title = {The Cambridge Dictionary of Statistics},
  author = {Everitt, B E},
  year = {2006},
  isbn = {978-0-521-86039-0},
  keywords = {\#nosource}
}

@book{Everitt2011,
  title = {An Introduction to Applied Multivariate Analysis with {{R}}},
  author = {Everitt, B and Hothorn, Torsten},
  year = {2011},
  issn = {9780387938363},
  doi = {10.1007/978-1-4419-9650-3},
  abstract = {"The majority of data sets collected by researchers in all disciplines are multivariate, meaning that several measurements, observations, or recordings are taken on each of the units in the data set. These units might be human subjects, archaeological artifacts, countries, or a vast variety of other things. In a few cases, it may be sensible to isolate each variable and study it separately, but in most instances all the variables need to be examined simultaneously in order to fully grasp the structure and key features of the data. For this purpose, one or another method of multivariate analysis might be helpful, and it is with such methods that this book is largely concerned. Multivariate analysis includes methods both for describing and exploring such data and for making formal inferences about them. The aim of all the techniques is, in general sense, to display or extract the signal in the data in the presence of noise and to find out what the data show us in the midst of their apparent chaos. An Introduction to Applied Multivariate Analysis with R explores the correct application of these methods so as to extract as much information as possible from the data at hand, particularly as some type of graphical representation, via the R software. Throughout the book, the authors give many examples of R code used to apply the multivariate techniques to multivariate data."\textendash Publisher's description.},
  isbn = {978-1-4419-9649-7},
  keywords = {\#nosource},
  pmid = {22057480}
}

@article{Ezekiel1929,
  title = {The Application of the Theory of Error to Multiple and Curvilinear Correlation},
  author = {{Ezekiel} and {Mordecai}},
  year = {1929},
  volume = {24},
  pages = {99--104},
  isbn = {0521773628},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {165}
}

@article{Faber2016,
  title = {Meta-Analyses Including Non-Randomized Studies of Therapeutic Interventions: A Methodological Review},
  shorttitle = {Meta-Analyses Including Non-Randomized Studies of Therapeutic Interventions},
  author = {Faber, Timor and Ravaud, Philippe and Riveros, Carolina and Perrodeau, Elodie and Dechartres, Agnes},
  year = {2016},
  month = dec,
  volume = {16},
  pages = {35},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0136-0},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FAXQWYLS\\Faber m. fl. - 2016 - Meta-analyses including non-randomized studies of .pdf},
  journal = {BMC Medical Research Methodology},
  keywords = {acta review},
  language = {en},
  number = {1}
}

@article{Falcaro2015,
  title = {Estimating Excess Hazard Ratios and Net Survival When Covariate Data Are Missing Strategies for Multiple Imputation},
  author = {Falcaro, Milena and Nur, Ula and Rachet, Bernard and Carpenter, James R.},
  year = {2015},
  volume = {26},
  pages = {421--428},
  issn = {15315487},
  doi = {10.1097/eDe.0000000000000283},
  abstract = {BACKGROUND: Net survival is the survival probability we would observe if the disease under study were the only cause of death. When estimated from routinely collected population-based cancer registry data, this indicator is a key metric for cancer control. Unfortunately, such data typically contain a non-negligible proportion of missing values on important prognostic factors (eg, tumor stage). METHODS: We carried out an empirical study to compare the performance of complete records analysis and several multiple imputation strategies when net survival is estimated via a flexible parametric proportional hazards model that includes stage, a partially observed categorical covariate. Starting from fully observed cancer registry data, we induced missingness on stage under three scenarios. For each of these scenarios, we simulated 100 incomplete datasets and evaluated the performance of the different strategies. RESULTS: Ordinal logistic models are not suitable for the imputation of tumor stage. Complete records analysis may lead to grossly misleading estimates of net survival, even when the missing data mechanism is conditionally independent of survival time given the covariates and the bias on the excess hazard ratios estimates is negligible. CONCLUSIONS: As key covariates are unlikely missing completely at random, studies estimating net survival should not use complete records. When the missingness can be inferred from available data, appropriate multiple imputation should be performed. In the context of flexible parametric proportional hazards models with a partially observed stage covariate, a multinomial logistic imputation model for stage should be used and should include the Nelson-Aalen cumulative hazard estimate and the event indicator.},
  isbn = {0000000000000},
  journal = {Epidemiology},
  keywords = {\#nosource},
  number = {3},
  pmid = {25774607}
}

@book{Fallis2012,
  title = {Parallel r},
  author = {Fallis, A.G},
  year = {2012},
  volume = {53},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \AA{} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\C6BHXABZ\\fallis_2012_parallel_r.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {icle},
  pmid = {25246403}
}

@article{Faraway1992,
  title = {On the Cost of Data Analysis},
  author = {Faraway, Julian J},
  year = {1992},
  volume = {1},
  pages = {213--229},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. A regression analysis usually consists of several stages, such as variable selec-tion, transformation and residual diagnosis. Inference is often made from the selected model without regard to the model selection methods that preceeded it. This can result in overoptimistic and biased inferences. We first characterize data-analytic actions as functions acting on regression models. We investigate the extent of the problem and test bootstrap, jackknife, and sample-splitting methods for ameliorating it. We also demon-strate an interactive LISP-STAT system for assessing the cost of the data analysis while it is taking place.},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {\#nosource,Bootstrap,Data splitting,Jackknife,Model selection,Regression analysis},
  number = {3}
}

@book{Faraway2004,
  ids = {Faraway2009},
  title = {Linear Models with r},
  author = {Faraway, Julian J.},
  year = {2004},
  issn = {1584881704},
  abstract = {The book focuses on the practice of regression and analysis of variance. It clearly demonstrates the different methods available and in which situations each one applies. It covers all of the standard topics, from the basics of estimation to missing data, factorial designs, and block designs, but it also includes discussion of topics, such as model uncertainty, rarely addressed in books of this type. The presentation incorporates an abundance of examples that clarify both the use of each technique and the conclusions one can draw from the results.},
  isbn = {1-58488-425-8},
  keywords = {\#nosource}
}

@article{Faraway2006,
  title = {Extending the Linear Model with {{R}}: Generalized Linear, Mixed Effects and Nonparametric Regression Models},
  author = {Faraway, Julian J},
  year = {2006},
  pages = {1--28},
  issn = {00319155},
  doi = {10.1111/j.1541-0420.2006.00596_12.x},
  abstract = {Linear models are central to the practice of statistics. They are part of the core knowledge expected of any applied statistician. Linear models are the foundation of a broad range of statistical methodologies; this book is a survey of techniques that grow from a linear model. Our starting point is the regression model with response y and predictors x1,...xp. The model takes the form: y={$\beta$}0+{$\beta$}1x1+...+{$\beta$}pxp+{$\epsilon$} where {$\epsilon$} is normally distributed. This book presents three extensions to this framework. The first generalizes the y part; the second, the {$\epsilon$} part; and the third, the x part of the linear model. Generalized Linear Models: The standard linear model cannot handle nonnormal responses, y, such as counts or proportions. This motivates the development of generalized linear models that can represent categorical, binary and other response types. Mixed Effect Models: Some data has a grouped, nested or hierarchical structure. Repeated measures, longitudinal and multilevel data consist of several observations taken on the same individual or group. This induces a correlation structure in the error, {$\epsilon$}. Mixed effect models allow the modeling of such data. Nonparametric Regression Models: In the linear model, the predictors, x, are combined in a linear way to model the effect on the response. Sometimes this linearity is insufficient to capture the structure of the data and more flexibility is required. Methods such as additive models, trees and neural networks allow a more flexible regression modeling of the response that combine the predictors in a nonparametric manner. This book aims to provide the reader with a well-stocked toolbox of statistical methodologies. A practicing statistician needs to be aware of and familiar with the basic use of a broad range of ideas and techniques. This book will be a success if the reader is able to recognize and get started on a wide range of problems. However, the breadth comes at the expense of some depth. Fortunately, there are book-length treatments of topics discussed in every chapter of this book, so the reader will know where to go next if needed. R is a free software environment for statistical computing and graphics. It runs on a wide variety of platforms including the Windows, Linux and Macintosh operating systems. Although there are several excellent statistical packages, only R is both free and possesses the power to perform the analyses demonstrated in this book. While it is possible in principle to learn statistical methods from purely theoretical expositions, I believe most readers learn best from the demonstrated interplay of theory and practice. The data analysis of real examples is woven into this book and all the R commands necessary to reproduce the analyses are provided.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NUHLVUZK\\faraway_2006_extending_the_linear_model_with_r.pdf},
  isbn = {0-203-49228-5},
  journal = {Chapman \& Hall/CRC Texts in Statistical Science Series},
  pmid = {60435631}
}

@article{Fawcett2006,
  title = {An Introduction to {{ROC}} Analysis},
  author = {Fawcett, Tom},
  year = {2006},
  month = jun,
  volume = {27},
  pages = {861--874},
  publisher = {{North-Holland}},
  issn = {0167-8655},
  doi = {10.1016/J.PATREC.2005.10.010},
  abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BICRXMU4\\fawcett_2006_an_introduction_to_roc_analysis.pdf},
  journal = {Pattern Recognition Letters},
  number = {8}
}

@article{Fay2013,
  title = {Pointwise Confidence Intervals for a Survival Distribution with Small Samples or Heavy Censoring},
  author = {Fay, Michael P. and Brittain, Erica H. and Proschan, Michael A.},
  year = {2013},
  volume = {14},
  pages = {723--736},
  issn = {14654644},
  doi = {10.1093/biostatistics/kxt016},
  abstract = {We propose a beta product confidence procedure (BPCP) that is a non-parametric confidence procedure for the survival curve at a fixed time for right-censored data assuming independent censoring. In such situations, the Kaplan-Meier estimator is typically used with an asymptotic confidence interval (CI) that can have coverage problems when the number of observed failures is not large, and/or when testing the latter parts of the curve where there are few remaining subjects at risk. The BPCP guarantees central coverage (i.e. ensures that both one-sided error rates are no more than half of the total nominal rate) when there is no censoring (in which case it reduces to the Clopper-Pearson interval) or when there is progressive type II censoring (i.e. when censoring only occurs immediately after failures on fixed proportions of the remaining individuals). For general independent censoring, simulations show that the BPCP maintains central coverage in many situations where competing methods can have very substantial error rate inflation for the lower limit. The BPCP gives asymptotically correct coverage and is asymptotically equivalent to the CI on the Kaplan-Meier estimator using Greenwood's variance. The BPCP may be inverted to create confidence procedures for a quantile of the underlying survival distribution. Because the BPCP is easy to implement, offers protection in settings when other methods fail, and essentially matches other methods when they succeed, it should be the method of choice.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IN8FC3G9\\fay_et_al_2013_pointwise_confidence_intervals_for_a_survival_distribution_with_small_samples.pdf},
  journal = {Biostatistics},
  keywords = {Clopper-Pearson confidence interval,Exact confidence interval,Kaplan-Meier estimator,Median survival,Non-parametric methods,Survival analysis},
  number = {4},
  pmid = {23632624}
}

@book{Fayers2013,
  title = {Quality of Life: The Assessment, Analysis and Interpretation of Patient-Reported Outcomes},
  author = {Fayers, Peter M. and Machin, David},
  year = {2013},
  abstract = {Third edition. The assessment of patient-reported outcomes and health-related quality of life continue to be rapidly evolving areas of research and this new edition reflects the development within the field from an emerging subject to one that is an essential part of the assessment of clinical trials and other clinical studies. The analysis and interpretation of quality of life relies on a variety of psychometric and statistical methods which are explained in this book in a non-technical way. The result is a practical guide that covers a wide range of methods and emphasizes the use of simple techniques using numerous examples, with extensive chapters covering detailed qualitative methods, the impact of guidelines, the analysis of ordinal data and bootstrap methods. The material in this third edition reflects current teaching methods and content widened to address continuing developments in item response theory, computer adaptive testing, and analyses with missing data, Bayesian methods, systematic reviews and meta-analysis. This book is aimed at everyone involved in quality of life research and is applicable to medical and non-medical, statistical and non-statistical readers. It is of particular relevance for clinical and biomedical researchers within both the pharmaceutical industry and clinical practice. \textendash Book Jacket. Principles of measurement scales \textendash{} Developing a questionnaire \textendash{} Scores and measurement : validity, reliability, sensibility \textendash{} Multi-item scales \textendash{} Factor analysis and structural equation modelling \textendash{} Item response theory and differential item functioning \textendash{} Item banks, item linking, and computer-adaptive tests \textendash{} Choosing and scoring questionnaires \textendash{} Clinical trials \textendash{} Samples sizes \textendash{} Cross-sectional analysis \textendash{} Exploring longitudinal data \textendash{} Modelling longitudinal data \textendash{} Missing data \textendash{} Practical and reporting issues \textendash{} Death and quality-adjusted survival \textendash{} Clinical interpretation \textendash{} Biased reporting and response shift \textendash{} Meta-analysis.},
  isbn = {978-1-4443-3795-2},
  keywords = {\#nosource}
}

@article{Fedak2015,
  title = {Applying the {{Bradford Hill}} Criteria in the 21st Century: {{How}} Data Integration Has Changed Causal Inference in Molecular Epidemiology},
  author = {Fedak, Kristen M. and Bernal, Autumn and Capshaw, Zachary A. and Gross, Sherilyn},
  year = {2015},
  volume = {12},
  issn = {17427622},
  doi = {10.1186/s12982-015-0037-4},
  abstract = {In 1965, Sir Austin Bradford Hill published nine "viewpoints" to help determine if observed epidemiologic associations are causal. Since then, the "Bradford Hill Criteria" have become the most frequently cited framework for causal inference in epidemiologic studies. However, when Hill published his causal guidelines-just 12 years after the double-helix model for DNA was first suggested and 25 years before the Human Genome Project began-disease causation was understood on a more elementary level than it is today. Advancements in genetics, molecular biology, toxicology, exposure science, and statistics have increased our analytical capabilities for exploring potential cause-and-effect relationships, and have resulted in a greater understanding of the complexity behind human disease onset and progression. These additional tools for causal inference necessitate a re-evaluation of how each Bradford Hill criterion should be interpreted when considering a variety of data types beyond classic epidemiology studies. Herein, we explore the implications of data integration on the interpretation and application of the criteria. Using examples of recently discovered exposure-response associations in human disease, we discuss novel ways by which researchers can apply and interpret the Bradford Hill criteria when considering data gathered using modern molecular techniques, such as epigenetics, biomarkers, mechanistic toxicology, and genotoxicology.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2M4RFCMT\\fedak_et_al_2015_applying_the_bradford_hill_criteria_in_the_21st_century.pdf},
  isbn = {1298201500},
  journal = {Emerging Themes in Epidemiology},
  keywords = {Bradford Hill,Causal inference,Causation,Data integration,Molecular epidemiology},
  number = {1},
  pmid = {26425136}
}

@article{Feinstein1970,
  title = {The Pre-Therapeutic Classification of Co-Morbidity in Chronic Disease},
  author = {Feinstein, Alvan R},
  year = {1970},
  volume = {23},
  pages = {455--468},
  issn = {0021-9681},
  doi = {10.1016/0021-9681(70)90054-8},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\622NDFTY\\feinstein_1970_the_pre-therapeutic_classification_of_co-morbidity_in_chronic_disease.pdf},
  journal = {Journal of Chronic Diseases},
  number = {7}
}

@article{Ferro2003,
  title = {Journal of the \{\vphantom\}{{R}}\vphantom\{\}oyal \{\vphantom\}{{S}}\vphantom\{\}tatistical \{\vphantom\}{{S}}\vphantom\{\}ociety: \{\vphantom\}{{S}}\vphantom\{\}eries \{\vphantom\}{{B}}\vphantom\{\} (\{\vphantom\}{{S}}\vphantom\{\}tatistical \{\vphantom\}{{M}}\vphantom\{\}ethodology)},
  author = {Ferro, Christopher A T and Segers, Johan},
  year = {2003},
  volume = {65},
  pages = {545--556},
  journal = {Journal of the Royal Statistical Society},
  keywords = {\#nosource},
  number = {2}
}

@article{Field1987,
  title = {Relations between the Statistics of Natural Images and the Response Properties of Cortical Cells},
  author = {Field, David J.},
  year = {1987},
  month = dec,
  volume = {4},
  pages = {2379},
  issn = {1084-7529},
  doi = {10.1364/JOSAA.4.002379},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DFQBIK77\\field_1987_relations_between_the_statistics_of_natural_images_and_the_response_properties.pdf},
  journal = {Journal of the Optical Society of America A},
  number = {12}
}

@article{Finazzi2011,
  title = {Calibration Belt for Quality-of-Care Assessment Based on Dichotomous Outcomes},
  author = {Finazzi, Stefano and Poole, Daniele and Luciani, Davide and Cogo, Paola E. and Bertolini, Guido},
  year = {2011},
  volume = {6},
  issn = {19326203},
  doi = {10.1371/journal.pone.0016110},
  abstract = {Prognostic models applied in medicine must be validated on independent samples, before their use can be recommended. The assessment of calibration, i.e., the model's ability to provide reliable predictions, is crucial in external validation studies. Besides having several shortcomings, statistical techniques such as the computation of the standardized mortality ratio (SMR) and its confidence intervals, the Hosmer-Lemeshow statistics, and the Cox calibration test, are all non-informative with respect to calibration across risk classes. Accordingly, calibration plots reporting expected versus observed outcomes across risk subsets have been used for many years. Erroneously, the points in the plot (frequently representing deciles of risk) have been connected with lines, generating false calibration curves. Here we propose a methodology to create a confidence band for the calibration curve based on a function that relates expected to observed probabilities across classes of risk. The calibration belt allows the ranges of risk to be spotted where there is a significant deviation from the ideal calibration, and the direction of the deviation to be indicated. This method thus offers a more analytical view in the assessment of quality of care, compared to other approaches. \textcopyright{} 2011 Finazzi et al.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J93W6YWL\\finazzi_et_al_2011_calibration_belt_for_quality-of-care_assessment_based_on_dichotomous_outcomes.pdf},
  journal = {PLoS ONE},
  number = {2}
}

@article{Fine1999,
  title = {A Proportional Hazards Model for the Subdistribution of a Competing Risk},
  author = {Fine, Jason P and Gray, Robert J},
  year = {1999},
  month = jun,
  volume = {94},
  pages = {496--509},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1999.10474144},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7H2M2ER4\\fine_gray_1999_a_proportional_hazards_model_for_the_subdistribution_of_a_competing_risk.pdf},
  journal = {Journal of the American Statistical Association},
  number = {446}
}

@article{Fiorentino2011,
  title = {Modelling to Estimate Future Trends in Cancer Prevalence},
  author = {Fiorentino, Francesca and Maddams, Jacob and M\o ller, Henrik and Utley, Martin},
  year = {2011},
  volume = {14},
  pages = {262--266},
  issn = {13869620},
  doi = {10.1007/s10729-011-9149-8},
  abstract = {Recent estimates suggest that there are 2 million people in the UK living with or beyond a diagnosis of cancer and there is increasing attention being given to assessing the health and social care needs of this growing population. A simple analytical model has been constructed to estimate future trends in cancer prevalence, using existing prevalence estimates and trends in cancer incidence and survival. Separate estimates are generated for the contribution to future prevalence due to the current prevalent population and that due to future diagnoses. For the current prevalent population, we adopt a conditional survival model incorporating time since diagnosis in addition to age, tumour type and other factors. We discuss the analytical framework that has been constructed and its intended use in providing information that is useful to those planning health and social care services.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KZBHAIIZ\\fiorentino_et_al_2011_modelling_to_estimate_future_trends_in_cancer_prevalence.pdf},
  journal = {Health Care Management Science},
  keywords = {Cancer prevalence,Forecasting,Incidence,Population health,Survival},
  number = {3},
  pmid = {21344202}
}

@article{FIRTH1993,
  title = {Bias Reduction of Maximum Likelihood Estimates},
  author = {FIRTH, DAVID},
  year = {1993},
  month = mar,
  volume = {80},
  pages = {27--38},
  publisher = {{Narnia}},
  issn = {0006-3444},
  doi = {10.1093/biomet/80.1.27},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SUV3BBBT\\firth_1993_bias_reduction_of_maximum_likelihood_estimates.pdf},
  journal = {Biometrika},
  number = {1}
}

@article{Fisher1915,
  title = {Frequency Distribution of the Values of the Correlation Coefficient in Samples from an Indefinitely Large Population},
  author = {Fisher, R. A.},
  year = {1915},
  volume = {10},
  pages = {507},
  issn = {00063444},
  doi = {10.2307/2331838},
  abstract = {508 Distribution of the Correlation Coeffeients of Samples In the second of these two papers the more difficult problem of the frequency distribution of the correlation coefficient is attempted. For samples of 2 the frequency},
  isbn = {0006-3444},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {4},
  pmid = {25246403}
}

@generic{Fisher1921,
  title = {On the Probable Error of a Coefficient of Correlation Deduced from a Small Samlpe},
  author = {Fisher, R A},
  year = {1921},
  volume = {1},
  pages = {205--235},
  abstract = {This is the second of three papers dealing with the sampling errors of correlation coefficients covering the cases (i) "The frequency distribution of the values of the correlation coeffricient in samples from an indefinitely large population", Biometrika, 1915.},
  journal = {Metron},
  keywords = {\#nosource},
  number = {1-32}
}

@article{Fisher1924,
  title = {The Distribution of the Partial Correlation Coefficient.},
  author = {Fisher, R.A. A.},
  year = {1924},
  volume = {3},
  pages = {329--332},
  abstract = {Reproduced with permission of Metron 35 THE DISTRIBUTION OF THE PARTIAL CORRELATION COEFFICIENT .1. The theoretical . distribution In ascertaining the exact distribution iu random samples to which the correlation coefficient between two normally distributed vari\^ates is ...},
  journal = {Metron},
  keywords = {\#nosource},
  number = {3-4}
}

@article{Fisher1928,
  title = {The General Sampling Distribution of the Multiple Correlation Coefficient},
  author = {Fisher, R A},
  year = {1928},
  month = dec,
  volume = {121},
  pages = {654--673},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\88BEHHQZ\\fisher_1928_the_general_sampling_distribution_of_the_multiple_correlation_coefficient.pdf},
  journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  number = {788}
}

@article{Fisher1999,
  title = {Time-Dependent Covariates in the Cox Proportional-Hazards Regression Model},
  author = {Fisher, Lloyd D. and Lin, D. Y.},
  year = {1999},
  volume = {20},
  pages = {145--157},
  issn = {0163-7525},
  doi = {10.1146/annurev.publhealth.20.1.145},
  abstract = {The Cox proportional-hazards regression model has achieved widespread use in the analysis of time-to-event data with censoring and covariates. The covariates may change their values over time. This article discusses the use of such time-dependent covariates, which offer additional opportunities but must be used with caution. The interrelationships between the outcome and variable over time can lead to bias unless the relationships are well understood. The form of a time-dependent covariate is much more complex than in Cox models with fixed (non-time-dependent) covariates. It involves constructing a function of time. Further, the model does not have some of the properties of the fixed-covariate model; it cannot usually be used to predict the survival (time-to-event) curve over time. The estimated probability of an event over time is not related to the hazard function in the usual fashion. An appendix summarizes the mathematics of time-dependent covariates.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6ABWDIYT\\fisher_lin_1999_time-dependent_covariates_in_the_cox_proportional-hazards_regression_model.pdf},
  isbn = {0163-7525 (Print){\r  }0163-7525},
  journal = {Annual Review of Public Health},
  keywords = {censored data,longitudinal analysis,model checking,survival analysis},
  number = {1},
  pmid = {10352854}
}

@article{Fishman2003,
  title = {Risk Adjustment Using Automated Ambulatory Pharmacy Data: The {{RxRisk}} Model.},
  author = {Fishman, Paul A and Goodman, Michael J and Hornbrook, Mark C and Meenan, Richard T and Bachman, Donald J and Rosetti, Maureen C O'Keeffe},
  year = {2003},
  month = jan,
  volume = {41},
  pages = {84--99},
  issn = {0025-7079},
  doi = {10.1097/01.MLR.0000039830.19812.29},
  abstract = {OBJECTIVES Develop and estimate the RxRisk model, a risk assessment instrument that uses automated ambulatory pharmacy data to identify chronic conditions and predict future health care cost. The RxRisk model's performance in predicting cost is compared with a demographic-only model, the Ambulatory Clinical Groups (ACG), and Hierarchical Coexisting Conditions (HCC) ICD-9-CM diagnosis-based risk assessment instruments. Each model's power to forecast health care resource use is assessed. DATA SOURCES Health services utilization and cost data for approximately 1.5 million individuals enrolled in five mixed-model Health Maintenance Organizations (HMOs) from different regions in the United States. STUDY DESIGN Retrospective cohort study using automated managed care data. SUBJECTS All persons enrolled during 1995 and 1996 in Group Health Cooperative of Puget Sound, HealthPartners of Minnesota and the Colorado, Ohio and Northeast Regions of Kaiser-Permanente. MEASURES RxRisk, an algorithm that classifies prescription drug fills into chronic disease classes for adults and children. RESULTS HCCs produce the most accurate forecasts of total costs than either RxRisk or ACGs but RxRisk performs similarly to ACGs. Using the R(2) criteria HCCs explain 15.4\% of the prospective variance in cost, whereas RxRisk explains 8.7\% and ACGs explain 10.2\%. However, for key segments of the cost distribution the differences in forecasting power among HCCs, RxRisk, and ACGs are less obvious, with all three models generating similar predictions for the middle 60\% of the cost distribution. CONCLUSIONS HCCs produce more accurate forecasts of total cost, but the pharmacy-based RxRisk is an alternative risk assessment instrument to several diagnostic based models and depending on the nature of the application may be a more appropriate option for medical risk analysis.},
  journal = {Medical care},
  keywords = {\#nosource},
  number = {1},
  pmid = {12544546}
}

@article{Fithian2014,
  title = {{{LOCAL CASE}}-{{CONTROL SAMPLING}}: {{EFFICIENT SUBSAMPLING IN IMBALANCED DATA SETS}}.},
  author = {Fithian, William and Hastie, Trevor},
  year = {2014},
  month = oct,
  volume = {42},
  pages = {1693--1724},
  publisher = {{NIH Public Access}},
  doi = {10.1214/14-AOS1220},
  abstract = {For classification problems with significant class imbalance, subsampling can reduce computational costs at the price of inflated variance in estimating model parameters. We propose a method for subsampling efficiently for logistic regression by adjusting the class balance locally in feature space via an accept-reject scheme. Our method generalizes standard case-control sampling, using a pilot estimate to preferentially select examples whose responses are conditionally rare given their features. The biased subsampling is corrected by a post-hoc analytic adjustment to the parameters. The method is simple and requires one parallelizable scan over the full data set. Standard case-control sampling is inconsistent under model misspecification for the population risk-minimizing coefficients \texttheta *. By contrast, our estimator is consistent for \texttheta * provided that the pilot estimate is. Moreover, under correct specification and with a consistent, independent pilot estimate, our estimator has exactly twice the asymptotic variance of the full-sample MLE-even if the selected subsample comprises a miniscule fraction of the full data set, as happens when the original data are severely imbalanced. The factor of two improves to [Formula: see text] if we multiply the baseline acceptance probabilities by c \textquestiondown{} 1 (and weight points with acceptance probability greater than 1), taking roughly [Formula: see text] times as many data points into the subsample. Experiments on simulated and real data show that our method can substantially outperform standard case-control subsampling.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LWR7BLAB\\fithian_hastie_2014_local_case-control_sampling.pdf},
  journal = {Annals of statistics},
  number = {5},
  pmid = {25492979}
}

@article{Flather2011,
  title = {Cluster-Randomized Trial to Evaluate the Effects of a Quality Improvement Program on Management of Non-{{ST}}-Elevation Acute Coronary Syndromes: {{The European Quality Improvement Programme}} for {{Acute Coronary Syndromes}} ({{EQUIP}}-{{ACS}})},
  author = {Flather, Marcus D. and Babalis, Daphne and Booth, Jean and Bardaji, Alfredo and MacHecourt, Jacques and Opolski, Grzegorz and Ottani, Filippo and Bueno, H{\'e}ctor and Banya, Winston and Brady, Anthony R. and Bojestig, Mats and Lindahl, Bertil},
  year = {2011},
  volume = {162},
  pages = {700-707.e1},
  publisher = {{Mosby, Inc.}},
  issn = {00028703},
  doi = {10.1016/j.ahj.2011.07.027},
  abstract = {Background: Registries have shown that quality of care for acute coronary syndromes (ACS) often falls below the standards recommended in professional guidelines. Quality improvement (QI) is a strategy to improve standards of clinical care for patients, but the efficacy of QI for ACS has not been tested in randomized trials. Methods: We undertook a prospective, cluster-randomized, multicenter, multinational study to evaluate the efficacy of a QI program for ACS. Participating centers collected data on consecutive admissions for non-ST-elevation ACS for 4 months before the QI intervention and 3 months after. Thirty-eight hospitals in France, Italy, Poland, Spain, and the United Kingdom were randomized to receive the QI program or not, 19 in each group. We measured 8 in-hospital quality indicators (risk stratification, coronary angiography, anticoagulation, {$\beta$}-blockers, statins, angiotensin-converting enzyme inhibitors, and clopidogrel loading and maintenance) before and after the intervention and compared composite changes between the QI and non-QI groups. Results: A total of 2604 patients were enrolled. The absolute overall change in use of quality indicators in the QI group was 8.5\% compared with 0.8\% in the non-QI group (odds ratio for achieving a quality indicator in QI versus non-QI 1.66, 95\% CI 1.43-1.94; P \textexclamdown.001). The main changes were observed in the use of risk stratification and clopidogrel loading dose. Conclusions: The QI strategy resulted in a significant improvement in the quality indicators measured. This type of QI intervention can lead to useful changes in health care practice for ACS in a wide range of settings. \textcopyright{} 2011 Mosby, Inc. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9MQL2MUT\\flather_et_al_2011_cluster-randomized_trial_to_evaluate_the_effects_of_a_quality_improvement.pdf},
  isbn = {1097-6744 (Electronic) 0002-8703 (Linking)},
  journal = {American Heart Journal},
  number = {4},
  pmid = {21982663}
}

@article{Folkh2016,
  title = {Nationella Folkh\"alsoenk\"aten \textendash{} H\"alsa P\aa{} Lika Villkor?},
  author = {Folkh, Solna},
  year = {2016},
  pages = {18--21},
  keywords = {\#nosource}
}

@article{Fong2014,
  title = {Psychometric Properties of the Copenhagen Burnout Inventory - Chinese Version},
  author = {Fong, Ted C.T. and Ho, Rainbow T.H. and Ng, S. M.},
  year = {2014},
  month = may,
  volume = {148},
  pages = {255--266},
  publisher = {{Taylor \& Francis Group}},
  issn = {19401019},
  doi = {10.1080/00223980.2013.781498},
  abstract = {The Copenhagen Burnout Inventory is a measurement scale that assesses the degree of burnout in the personal, work, and client domains. The aim of this study was to examine the psychometric properties of the inventory's Chinese version (CBI-C) in a sample of 312 human service workers in Hong Kong with follow-up assessment for 245 participants. The results of confirmatory factor analyses show the revised three-factor model to have an adequate fit in the baseline and cross-validation samples. The CBI-C demonstrates good degrees of internal consistency, test-retest reliability, and concurrent validity, and appears to be a valid and reliable measurement tool of burnout in the Chinese context. \textcopyright{} 2014 Copyright Taylor \& Francis Group, LLC.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PG78NSCC\\fong_et_al_2014_psychometric_properties_of_the_copenhagen_burnout_inventory_-_chinese_version.pdf},
  journal = {Journal of Psychology: Interdisciplinary and Applied},
  keywords = {Chinese,confirmatory factor analysis,Copenhagen Burnout Inventory,psychometrics},
  number = {3}
}

@article{Forni2016,
  title = {Mortality after Hip Fracture in the Elderly: {{The}} Role of a Multidisciplinary Approach and Time to Surgery in a Retrospective Observational Study on 23,973 Patients},
  author = {Forni, Silvia and Pieralli, Francesca and Sergi, Alessandro and Lorini, Chiara and Bonaccorsi, Guglielmo and Vannucci, Andrea},
  year = {2016},
  volume = {66},
  pages = {13--17},
  publisher = {{Elsevier Ireland Ltd}},
  issn = {18726976},
  doi = {10.1016/j.archger.2016.04.014},
  abstract = {Background: Since most hip fractures occur in fragile patients, an important step forward in the treatment may be a co-managed, multidisciplinary treatment approach with orthopaedic surgeons and geriatricians. This multidisciplinary care model (MCM) is implemented in some Tuscan hospitals, while in hospitals with the usual care model (UCM) medical consultation is required only as deemed necessary by the admitting surgeon. The primary aim of this study was to assess the effect of the MCM on 30-day mortality, compared with the UCM. Methods: A retrospective study was conducted on patients with main diagnosis of hip fracture, as reported in the hospital admission discharge reports, aged 65 years and older, who underwent surgery in Tuscan hospitals from 2010 to 2013. A multilevel logistic regression model was performed to assess the effect of the MCM vs the UCM. The Charlson Comorbidity Index (CCI) was used as a proxy for case mix complexity. Results: 23,973 patients were included: 23\% men and 77\% women; the mean age was 83.5 years. The multilevel analysis showed that mortality was significantly higher in the UCM, after adjusting for gender, age, comorbidity and timing of surgery (OR = 1.32; 95\% CI 1.09-1.59; p = 0.004). Surgical delay was not significantly associated with higher mortality rates. Conclusions: A co-managed approach to hip fracture, with orthopaedic surgeons and geriatricians, offers a multidisciplinary pathway for the elderly and leads to a reduction in mortality after hip fracture surgery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TRJD2874\\forni_et_al_2016_mortality_after_hip_fracture_in_the_elderly.pdf},
  journal = {Archives of Gerontology and Geriatrics},
  keywords = {Elderly,Hip fracture,Hospital care,Orthogeriatric management,Patient outcomes,Time to surgery},
  number = {124},
  pmid = {27174126}
}

@article{Fortin2017,
  title = {Optimal Look Back Period and Summary Method for {{Elixhauser}} Comorbidity Measures in a {{US}} Population-Based Electronic Health Record Database},
  author = {Fortin, Yannick and Crispo, James A G and Cohen, Deborah and Mcnair, Douglas S and Mattison, Donald R and Krewski, Daniel},
  year = {2017},
  pages = {1--13},
  journal = {Open access medical statistics},
  keywords = {\#nosource,comorbidity,electronic health records,icd-9,mortality,risk adjustment,statisti-}
}

@generic{Foster2006,
  title = {Honest Confidence Intervals for the Error Variance in Stepwise Regression},
  author = {Foster, Dean P. and Stine, Robert A.},
  year = {2006},
  month = jan,
  volume = {31},
  pages = {89--102},
  publisher = {{IOS Press}},
  issn = {0747-9662},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YPL8FIY9\\foster_stine_2006_honest_confidence_intervals_for_the_error_variance_in_stepwise_regression.pdf},
  journal = {Journal of Economic and Social Measurement},
  number = {1,2}
}

@article{Franklin2017,
  title = {Comparing the Performance of Propensity Score Methods in Healthcare Database Studies with Rare Outcomes},
  author = {Franklin, Jessica M. and Eddings, Wesley and Austin, Peter C. and Stuart, Elizabeth A. and Schneeweiss, Sebastian},
  year = {2017},
  issn = {10970258},
  doi = {10.1002/sim.7250},
  abstract = {Nonrandomized studies of treatments from electronic healthcare databases are critical for producing the evidence necessary to making informed treatment decisions, but often rely on comparing rates of events observed in a small number of patients. In addition, studies constructed from electronic healthcare databases, for example, administrative claims data, often adjust for many, possibly hundreds, of potential confounders. Despite the importance of maximizing efficiency when there are many confounders and few observed outcome events, there has been relatively little research on the relative performance of different propensity score methods in this context. In this paper, we compare a wide variety of propensity-based estimators of the marginal relative risk. In contrast to prior research that has focused on specific statistical methods in isolation of other analytic choices, we instead consider a method to be defined by the complete multistep process from propensity score modeling to final treatment effect estimation. Propensity score model estimation methods considered include ordinary logistic regression, Bayesian logistic regression, lasso, and boosted regression trees. Methods for utilizing the propensity score include pair matching, full matching, decile strata, fine strata, regression adjustment using one or two nonlinear splines, inverse propensity weighting, and matching weights. We evaluate methods via a 'plasmode' simulation study, which creates simulated datasets on the basis of a real cohort study of two treatments constructed from administrative claims data. Our results suggest that regression adjustment and matching weights, regardless of the propensity score model estimation method, provide lower bias and mean squared error in the context of rare binary outcomes. Copyright \textcopyright{} 2017 John Wiley \& Sons, Ltd.},
  journal = {Statistics in Medicine},
  keywords = {\#nosource,epidemiology,healthcare databases,propensity score,risk ratio,simulation},
  pmid = {28208229}
}

@article{frerotWhatEpidemiologyChanging2018,
  title = {What Is Epidemiology? {{Changing}} Definitions of Epidemiology 1978-2017},
  author = {Fr{\'e}rot, Mathilde and Lefebvre, Annick and Aho, Simon and Callier, Patrick and Astruc, Karine and Gl{\'e}l{\'e}, Ludwig Serge Aho},
  year = {2018},
  volume = {13},
  pages = {e0208442},
  doi = {10.1371/JOURNAL.PONE.0208442},
  abstract = {Context Epidemiology is a discipline which has evolved with the changes taking place in society and the emergence of new diseases and new discipline related to epidemiology. With these evolutions, it is important to understand epidemiology and to analyse the evolution of content of definitions of epidemiology. Objectives The main objective of this paper was to identify new definitions of epidemiology available since 1978. Secondary objectives were to analyse the content of these definitions, to compare them with those used by Lilienfeld and to determine whether changes have taken place over the last forty years. Methods A review of grey literature and published literature was conducted to find the definitions of epidemiology written between 1978 and 2017. Results 102 definitions of epidemiology were retained. They helped to highlight 20 terms and concepts related to epidemiology. Most of them were already used in the definitions used by Lilienfeld. Five terms were present in more than 50\% of definitions from the period 1978 to 2017: ``population'', ``study'', ``disease'', ``health'' and ``distribution''. Several developments have occurred: strengthening of the terms ``control'' and ``health'' already used, the concept of ``disease'' was less frequently encountered whereas the concepts ``infectious diseases'', ``mass phenomenon'' are no longer used in definitions from 1978 to 2017. Conclusion This evolution of content of definition of epidemiology is absent from books on epidemiology. A thematic analysis of definitions of epidemiology could be conducted in order to improve our understanding of changes observed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5SK5C8GP\\frérot_et_al_2018_what_is_epidemiology.pdf},
  journal = {PLOS ONE},
  number = {12}
}

@article{Fridolin2018,
  title = {Lagr\aa dsremiss Behandling Av Personuppgifter F\"or Forsknings\"andam\aa l},
  author = {Fridolin, Gustav},
  year = {2018},
  pages = {1--326},
  keywords = {\#nosource}
}

@article{Friederichs2010,
  title = {Statistical Downscaling of Extreme Precipitation Events Using Extreme Value Theory},
  author = {Friederichs, Petra},
  year = {2010},
  month = jun,
  volume = {13},
  pages = {109--132},
  publisher = {{Springer US}},
  doi = {10.1007/s10687-010-0107-5},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3CAW3KW6\\friederichs_2010_statistical_downscaling_of_extreme_precipitation_events_using_extreme_value.pdf},
  journal = {Extremes},
  number = {2}
}

@article{Friedman2010,
  title = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  year = {2010},
  month = feb,
  volume = {33},
  pages = {1--22},
  issn = {1548-7660},
  doi = {10.18637/jss.v033.i01},
  abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include {$\mathscr{l}$} 1 (the lasso), {$\mathscr{l}$} 2 (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RSU839HF\\friedman_et_al_2010_regularization_paths_for_generalized_linear_models_via_coordinate_descent.pdf},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{frobertThrombusAspirationSTsegment2013,
  title = {Thrombus Aspiration during {{ST}}-Segment Elevation Myocardial Infarction},
  author = {Fr{\"o}bert, Ole and Lagerqvist, Bo and Olivecrona, G{\"o}ran K. and Omerovic, Elmir and Gudnason, Thorarinn and Maeng, Michael and Aasa, Mikael and Anger\aa s, Oskar and Calais, Fredrik and Danielewicz, Mikael and Erlinge, David and Hellsten, Lars and Jensen, Ulf and Johansson, Agneta C. and K\aa regren, Amra and Nilsson, Johan and Robertson, Lotta and Sandhall, Lennart and Sj{\"o}gren, Iwar and {\"O}stlund, Ollie and Harnek, Jan and James, Stefan K.},
  year = {2013},
  volume = {369},
  pages = {1587--1597},
  issn = {15334406},
  doi = {10.1056/NEJMoa1308789},
  abstract = {BACKGROUND: The clinical effect of routine intracoronary thrombus aspiration before primary percutaneous coronary intervention (PCI) in patients with ST-segment elevation myocardial infarction (STEMI) is uncertain. We aimed to evaluate whether thrombus aspiration reduces mortality. METHODS: We conducted a multicenter, prospective, randomized, controlled, open-label clinical trial, with enrollment of patients from the national comprehensive Swedish Coronary Angiography and Angioplasty Registry (SCAAR) and end points evaluated through national registries. A total of 7244 patients with STEMI undergoing PCI were randomly assigned to manual thrombus aspiration followed by PCI or to PCI only. The primary end point was all-cause mortality at 30 days. RESULTS: No patients were lost to follow-up. Death from any cause occurred in 2.8\% of the patients in the thrombus-aspiration group (103 of 3621), as compared with 3.0\% in the PCI-only group (110 of 3623) (hazard ratio, 0.94; 95\% confidence interval [CI], 0.72 to 1.22; P = 0.63). The rates of hospitalization for recurrent myocardial infarction at 30 days were 0.5\% and 0.9\% in the two groups, respectively (hazard ratio, 0.61; 95\% CI, 0.34 to 1.07; P = 0.09), and the rates of stent thrombosis were 0.2\% and 0.5\%, respectively (hazard ratio, 0.47; 95\% CI, 0.20 to 1.02; P = 0.06). There were no significant differences between the groups with respect to the rate of stroke or neurologic complications at the time of discharge (P = 0.87). The results were consistent across all major prespecified subgroups, including subgroups defined according to thrombus burden and coronary flow before PCI. CONCLUSIONS: Routine thrombus aspiration before PCI as compared with PCI alone did not reduce 30-day mortality among patients with STEMI. Copyright \textcopyright{} 2013 Massachusetts Medical Society.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HYB5BDM9\\fröbert_et_al_2013_thrombus_aspiration_during_st-segment_elevation_myocardial_infarction.pdf},
  journal = {New England Journal of Medicine},
  number = {17}
}

@article{Frosch1999,
  title = {Shared Decision Making in Clinical Medicine: {{Past}} Research and Future Directions},
  author = {Frosch, Dominick L and Kaplan, Robert M},
  year = {1999},
  volume = {17},
  pages = {285--294},
  abstract = {Content: Shared medical decision making is a process by which patients and providers consider outcome probabilities and patient preferences and reach a health care decision based on mutual agreement. Shared decision making is best used for problems involving medical uncertainty. During the process the provider-patient dyad considers treatment options and consequences and explores the fit of expected benefits and consequences of treatment with patient preferences for various outcomes. This paper reviews the literature on shared medical decision making. Several questions are considered. Although several studies suggest that patients do not want to be involved in decision making, these studies typically fail to separate decisions about technical aspects of treatment from preferences for outcomes. There is considerable evidence that patients want to be consulted about the impact of treatment. Studies on the acceptability of shared decision making for physicians have produced inconsistent results. Shared decision making is more acceptable to younger and better-educated patients. It remains unclear whether shared decision making requires expensive video presentations or whether the same results can be obtained with simpler methods, such as the decision board. We conclude that shared medical decision making is an important development in health care. More research is necessary to identify the effects of shared decision making on patient satisfaction and health outcomes. Further, more research is necessary in order to evaluate the most effective methods for engaging patients in decisions about their own health care. Medical Subject Headings (MeSH): decision making, outcome assessment, research, patient satisfaction, probability, decision aid (Am J Prev Med 1999;17(4):285\textendash 294) \textcopyright{} 1999 American Journal of Preventive Medicine O ver the last decades, there has been an increas-ing emphasis on patient participation in med-ical decision making. An alternative to the paternalistic model in which the physician makes all treatment decisions is " shared decision making. " Shared decision making must not be confused with obtaining informed consent from a patient. While ethical guidelines mandate informed consent, espe-cially when a recommendation involves a potentially harmful intervention, shared decision making goes several steps further. Beyond presenting the patient with facts about a procedure, shared decision making is a process by which doctor and patient consider avail-able information about the medical problem in ques-tion, including treatment options and consequences, and then consider how these fit with the patient's preferences for health states and outcomes. After con-sidering the options, a treatment decision is made based on mutual agreement. 1 Several conditions must be met for shared decision making to occur. First, the atmosphere must be conducive to active patient partic-ipation. The attending physician must make patients feel that their contributions are valued. Patients in turn need to be frank about their preferences and goals for treatment. The physician then helps the patient deter-mine how these goals and preferences fit with the available treatment options and a shared decision is reached.},
  journal = {American Journal of Preventive Medicine},
  keywords = {\#nosource},
  number = {4}
}

@article{Fu2005,
  title = {Estimating Misclassification Error with Small Samples via Bootstrap Cross-Validation},
  author = {Fu, Wenjiang J. and Carroll, Raymond J. and Wang, Suojin},
  year = {2005},
  volume = {21},
  pages = {1979--1986},
  issn = {13674803},
  doi = {10.1093/bioinformatics/bti294},
  abstract = {MOTIVATION: Estimation of misclassification error has received increasing attention in clinical diagnosis and bioinformatics studies, especially in small sample studies with microarray data. Current error estimation methods are not satisfactory because they either have large variability (such as leave-one-out cross-validation) or large bias (such as resubstitution and leave-one-out bootstrap). While small sample size remains one of the key features of costly clinical investigations or of microarray studies that have limited resources in funding, time and tissue materials, accurate and easy-to-implement error estimation methods for small samples are desirable and will be beneficial.: A bootstrap cross-validation method is studied. It achieves accurate error estimation through a simple procedure with bootstrap resampling and only costs computer CPU time. Simulation studies and applications to microarray data demonstrate that it performs consistently better than its competitors. This method possesses several attractive properties: (1) it is implemented through a simple procedure; (2) it performs well for small samples with sample size, as small as 16; (3) it is not restricted to any particular classification rules and thus applies to many parametric or non-parametric methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SQILHPUJ\\fu_et_al_2005_estimating_misclassification_error_with_small_samples_via_bootstrap.pdf},
  isbn = {1367-4803 (Print){\r  }1367-4803 (Linking)},
  journal = {Bioinformatics},
  number = {9},
  pmid = {15691862}
}

@article{Galar2012,
  title = {A Review on Ensembles for the Class Imbalance Problem: {{Bagging}}-, Boosting-, and Hybrid-Based Approaches},
  author = {Galar, M. and Fernandez, A. and Barrenechea, E. and Bustince, H. and Herrera, F.},
  year = {2012},
  month = jul,
  volume = {42},
  pages = {463--484},
  publisher = {{IEEE Press}},
  doi = {10.1109/TSMCC.2011.2161285},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  keywords = {\#nosource},
  number = {4}
}

@article{Galloway2016,
  title = {Help, My Rating Looks Bad! {{Coding}} Comorbidities in Arthroplasty},
  author = {Galloway, Joseph D. and Voss, Frank R.},
  year = {2016},
  volume = {2},
  pages = {133--136},
  publisher = {{Elsevier Inc}},
  issn = {23523441},
  doi = {10.1016/j.artd.2016.03.003},
  abstract = {In medicine today, there is a trend toward increasing transparency. Higher quality and better value are being sought, and one of the methods being used is publicly reported health care outcomes. However, there is a problem that comes from our loss of anonymity. Physicians who are being individually watched have to choose between doing what is best for the patient and doing what would look good when it is publicly reported. Often this might mean choosing not to treat a particularly sick patient who is unlikely to have a good outcome. Adjusting outcomes to account for risk factors should be a way to prevent this effect, but these methods need to be studied more. The current performance measures being released are based on administrative claims data, and to date, much of that information is not properly risk adjusted. To ensure that the increasing transparency reveals an accurate picture, it is critical that the complexity of care provided by surgeons be carefully documented. Therefore, we propose accurate coding of patients' comorbidities during hospitalization for total knee arthroplasty and total hip arthroplasty, and we have included a chart detailing our recommendations of the specific diagnostic codes that are most important.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VZ43F377\\galloway_voss_2016_help,_my_rating_looks_bad.pdf},
  journal = {Arthroplasty Today},
  keywords = {ICD 10,Outcomes,ProPublica,Public profile,Scorecard},
  number = {3}
}

@article{Gao2012,
  title = {Which Is the Best Alternative for Displaced Femoral Neck Fractures in the Elderly?: {{A}} Meta-Analysis},
  author = {Gao, Hongwei and Liu, Zhonghao and Xing, Deguo and Gong, Mingzhi},
  year = {2012},
  volume = {470},
  pages = {1782--1791},
  issn = {0009921X},
  doi = {10.1007/s11999-012-2250-6},
  abstract = {BACKGROUND: Treatment of displaced femoral neck fractures includes internal fixation and arthroplasty. However, whether arthroplasty or internal fixation is the primary treatment for displaced femoral neck fractures in elderly patients remains a subject for debate. The literature contains conflicting evidence regarding rates of mortality, revision surgery, major postoperative complications, and function in elderly patients with displaced femoral neck fractures treated either by internal fixation or arthroplasty (either hemiarthroplasty or THA). QUESTIONS/PURPOSE: We determined mortality, revision surgery rates, major surgical complications (which include infection, nonunion or early redisplacement, avascular necrosis, dislocation, loosening of the prosthesis, acetabular erosion, fracture below or around the implant, and other severe general complications such as deep vein thrombosis and pulmonary embolism), and function in patients treated with either internal fixation or arthroplasty for displaced femoral neck fractures in the elderly. METHODS: We searched PubMed, Embase, and the Cochrane Library for randomized controlled trials (RCTs) comparing internal fixation and arthroplasty. We identified 20 RCTs with 4508 patients meeting all the criteria for eligibility. We performed a meta-analysis of the major complications, reoperations, function, pain, and mortality. RESULTS: Compared with internal fixation, arthroplasty reduced the risk of the major complications (95\% CI, 0.21-0.54 for 1 year; 95\% CI, 0.16-0.31 for 5 years) and the incidence of reoperation 1 to 5 years after surgery (95\% CI, 0.15-0.34 for 1 year; 95\% CI, 0.08-0.24 for 5 years), and provided better pain relief (95\% CI, 0.34-0.72). Function was superior (RR = 0.59; 95\% CI, 0.44-0.79) for patients treated with arthroplasty than for patients treated by internal fixation. However, mortality 1 to 3 years after surgery was similar (95\% CI, 0.96-1.23, p = 0.20 for 1 year; 95\% CI, 0.91-1.17, p = 0.63 for 3 years). CONCLUSIONS: Arthroplasty can reduce the risk of major complications and the incidence of reoperation compared with internal fixation, and provide better pain relief and function, but it does not reduce mortality. LEVEL OF EVIDENCE: Level II, prognostic study. See the Guidelines for Authors for a complete description of levels of evidence.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZIB6535X\\gao_et_al_2012_which_is_the_best_alternative_for_displaced_femoral_neck_fractures_in_the.pdf},
  isbn = {1528-1132; 0009-921X},
  journal = {Clinical Orthopaedics and Related Research},
  number = {6},
  pmid = {22278852}
}

@article{Garcia2010,
  title = {Variable Selection in the Cox Regression Model with Covariates Missing at Random.},
  author = {Garcia, Ramon I and Ibrahim, Joseph G and Zhu, Hongtu},
  year = {2010},
  month = mar,
  volume = {66},
  pages = {97--104},
  publisher = {{NIH Public Access}},
  doi = {10.1111/j.1541-0420.2009.01274.x},
  abstract = {We consider variable selection in the Cox regression model (Cox, 1975, Biometrika 362, 269-276) with covariates missing at random. We investigate the smoothly clipped absolute deviation penalty and adaptive least absolute shrinkage and selection operator (LASSO) penalty, and propose a unified model selection and estimation procedure. A computationally attractive algorithm is developed, which simultaneously optimizes the penalized likelihood function and penalty parameters. We also optimize a model selection criterion, called the IC(Q) statistic (Ibrahim, Zhu, and Tang, 2008, Journal of the American Statistical Association 103, 1648-1658), to estimate the penalty parameters and show that it consistently selects all important covariates. Simulations are performed to evaluate the finite sample performance of the penalty estimates. Also, two lung cancer data sets are analyzed to demonstrate the proposed methodology.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\THB4UYFD\\garcia_et_al_2010_variable_selection_in_the_cox_regression_model_with_covariates_missing_at_random.pdf},
  journal = {Biometrics},
  number = {1},
  pmid = {19459831}
}

@techreport{Garellick2014,
  title = {Svenska H\"oftprotesregistret: {{\AA rsrapport}} 2014},
  author = {Garellick, G{\"o}ran and K{\"a}rrholm, Johan and Lindahl, Hans and Malchau, Henrik and Rogmark, Cecilia and Rolfson, Ola},
  year = {2014},
  doi = {10.18158/SJhEVmKcb},
  city = {Gothenburg, Sweden},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BSFC8KYI\\garellick_et_al_2014_svenska_höftprotesregistret.pdf}
}

@article{Garland2017,
  title = {Risk of Early Mortality after Cemented Compared with Cementless Total Hip Arthroplasty},
  author = {Garland, A. and Gordon, M. and Garellick, G. and K{\"a}rrholm, J. and Sk{\"o}ldenberg, O. and Hailer, N. P.},
  year = {2017},
  month = jan,
  volume = {99-B},
  pages = {37--43},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.99B1.BJJ-2016-0304.R1},
  abstract = {AimsIt has been suggested that cemented fixation of total hip arthroplasty (THA) is associated with an increased peri-operative mortality compared with cementless THA. Our aim was to investigate th...},
  journal = {The Bone \& Joint Journal},
  keywords = {\#nosource,Mortality,Osteoarthritis,Post-operative,Total hip arthroplasty,Total hip replacement},
  number = {1}
}

@article{Gasparini2018,
  title = {Comorbidity: {{An}} r Package for Computing Comorbidity Scores Software \textbullet{} Review \textbullet{} Repository \textbullet{} Archive},
  author = {Gasparini, Alessandro},
  year = {2018},
  doi = {10.21105/joss.00648},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CG2Y4CGI\\gasparini_2018_comorbidity.pdf},
  keywords = {coder}
}

@article{Gaujoux2010,
  title = {A Flexible {{R}} Package for Nonnegative Matrix Factorization},
  author = {Gaujoux, Renaud and Seoighe, Cathal},
  year = {2010},
  month = dec,
  volume = {11},
  pages = {367},
  publisher = {{BioMed Central}},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-11-367},
  abstract = {Nonnegative Matrix Factorization (NMF) is an unsupervised learning technique that has been applied successfully in several fields, including signal processing, face recognition and text mining. Recent applications of NMF in bioinformatics have demonstrated its ability to extract meaningful information from high-dimensional data such as gene expression microarrays. Developments in NMF theory and applications have resulted in a variety of algorithms and methods. However, most NMF implementations have been on commercial platforms, while those that are freely available typically require programming skills. This limits their use by the wider research community. Our objective is to provide the bioinformatics community with an open-source, easy-to-use and unified interface to standard NMF algorithms, as well as with a simple framework to help implement and test new NMF methods. For that purpose, we have developed a package for the R/BioConductor platform. The package ports public code to R, and is structured to enable users to easily modify and/or add algorithms. It includes a number of published NMF algorithms and initialization methods and facilitates the combination of these to produce new NMF strategies. Commonly used benchmark data and visualization methods are provided to help in the comparison and interpretation of the results. The NMF package helps realize the potential of Nonnegative Matrix Factorization, especially in bioinformatics, providing easy access to methods that have already yielded new insights in many applications. Documentation, source code and sample data are available from CRAN.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A3GCRJ8V\\gaujoux_seoighe_2010_a_flexible_r_package_for_nonnegative_matrix_factorization.pdf},
  journal = {BMC Bioinformatics},
  keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
  number = {1}
}

@article{Gayen1951,
  title = {The Frequency Distribution of the Product-Moment Correlation Coefficient in Random Samples of Any Size Drawn from Non-Normal Universes},
  author = {Gayen, A. K.},
  year = {1951},
  volume = {38},
  pages = {219--247},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {1/2}
}

@book{Gehring2010,
  title = {Undergraduate Texts in Mathematics},
  author = {Gehring, F W and Halmos, P R and Deprima, C and Herstein, I and Kiefer, J and Leveque, W},
  year = {2010},
  volume = {51},
  issn = {0172-6056},
  doi = {10.1007/978-0-387-92712-1},
  abstract = {Undergraduate students often struggle to learn mathematics because introductory classes are taught in large lectures that do not engage students in active problem-solving. These students do not connect mathematics to their lives and feel that learning mathematics is a solitary undertaking. We now use Tablet PCs in a networked classroom to address these challenges. Students in classes that use the Tablet PCs can view and annotate the instructor's Powerpoint slides in real time and also participate in interactive problem-solving. Students save their own annotated slides for subsequent review. They also have immediate access to the synchronized screen capture and audio recording of the class since the instructor posts this file to the course management website. These technological interventions allow students to focus on classroom activities rather than on note-taking. To date, students have taken three introductory undergraduate mathematics courses (College Algebra and Trigonometry, Calculus I, and Calculus II) using Tablet PCs. Student attendance and retention were better in the cohort of students who participated in the Tablet PC courses than in comparable non-Tablet PC courses taught by the same instructor. The evaluation of the instructor was unchanged.},
  isbn = {3-540-90163-9},
  keywords = {\#nosource},
  pmid = {25246403}
}

@article{Gellerstedt2011,
  title = {Hur M\aa nga M\aa ste Man Fr\aa ga ? {{Har}} Jag Chans P\aa{} Dig ?},
  author = {Gellerstedt, Martin},
  year = {2011},
  keywords = {\#nosource}
}

@article{Gelman2009,
  title = {Splitting a Predictor at the Upper Quarter or Third and the Lower Quarter or Third},
  author = {Gelman, Andrew and Park, David K.},
  year = {2009},
  volume = {63},
  pages = {1--8},
  issn = {15372731},
  doi = {10.1198/tast.2009.0001},
  abstract = {A linear regression of y on x can be approximated by a simple difference: the average values of y corresponding to the highest quarter or third of x, minus the average values of y corresponding to the lowest quarter or third of x. A simple theoretical analysis, similar to analyses that have been done in psychometrics, shows this comparison to perform reasonably well, with 80\%\textendash 90\% efficiency compared to the regression if the predictor is uniformly or normally distributed. By discretizing x into three categories, we claw back about half the efficiency lost by the commonly used strategy of dichotomizing the predictor. We illustrate with the example that motivated our research: an analysis of income and voting which we had originally performed for a scholarly journal but then wanted to communicate to a general audience.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B7PRMSQN\\gelman_park_2009_splitting_a_predictor_at_the_upper_quarter_or_third_and_the_lower_quarter_or.pdf},
  isbn = {0003-1305},
  journal = {American Statistician},
  keywords = {Discretizing,Linear regression,Statistical communication,Trichotomizing},
  number = {1}
}

@article{Gelman2017,
  title = {Beyond Subjective and Objective in Statistics},
  author = {Gelman, Andrew and Hennig, Christian},
  year = {2017},
  month = oct,
  volume = {180},
  pages = {967--1033},
  publisher = {{Wiley/Blackwell (10.1111)}},
  issn = {1467985X},
  doi = {10.1111/rssa.12276},
  abstract = {We argue that the words "objectivity" and "subjectivity" in statistics discourse are used in a mostly unhelpful way, and we propose to replace each of them with broader collections of attributes, with objectivity replaced by transparency, consensus, impartiality, and correspondence to observable reality, and subjectivity replaced by awareness of multiple perspectives and context dependence. The advantage of these reformulations is that the replacement terms do not oppose each other. Instead of debating over whether a given statistical method is subjective or objective (or normatively debating the relative merits of subjectivity and objectivity in statistical practice), we can recognize desirable attributes such as transparency and acknowledgment of multiple perspectives as complementary goals. We demonstrate the implications of our proposal with recent applied examples from pharmacology, election polling, and socioeconomic stratification.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BSNUPECD\\gelman_hennig_2017_beyond_subjective_and_objective_in_statistics.pdf},
  isbn = {0022-0957 (Print)0022-0957 (Linking)},
  journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
  keywords = {Bayesian,Frequentist,Good practice,Philosophy of statistics,Virtues},
  number = {4},
  pmid = {10340204}
}

@article{Gelman2017,
  title = {Some Natural Solutions to the P-Value Communication Problem\textemdash{} and Why They Won't Work *},
  author = {Gelman, Andrew and Carlin, John},
  year = {2017},
  abstract = {It is well known that even experienced scientists routinely misinterpret p-values in all sorts of ways, including confusion of statistical and practical significance, treating non-rejection as acceptance of the null hypothesis, and interpreting the p-value as some sort of replication probability or as the posterior probability that the null hypothesis is true. A common conceptual error is that researchers take the rejection of a straw-man null as evidence in favor of their preferred alternative (Gelman, 2014). A standard mode of operation goes like this: p \textexclamdown{} 0.05 is taken as strong evidence against the null hypothesis, p \textquestiondown{} 0.15 is taken as evidence in favor of the null, and p near 0.10 is taken either as weak evidence for an effect or as evidence of a weak effect. Unfortunately, none of those inferences is generally appropriate: a low p-value is not necessarily strong evidence against the null (see, for example, Morris, 1987, and Gelman and Carlin 2014), a high p-value does not necessarily favor the null (the strength and even the direction of the evidence depends on the alternative hypotheses), and p-values are in general not measures of the size of any underlying effect. But these errors persist, reflecting (a) inherent difficulties in the mathematics and logic of p-values, and (b) the desire of researchers to draw strong conclusions from their data. Continued evidence of these and other misconceptions and their dire consequences for science (the " replication crisis " in psychology, biology, and other applied fields), especially in light of new understanding of how common it is that abundant " researcher degrees of freedom " (Simmons, Nelson, and Simonsohn, 2011) and " gardens of forking paths " (Gelman and Loken, 2014) allow researchers to routinely obtain statistically significant and publishable results from noise, motivated the American Statistical Association to release a Statement on Statistical Significance and p-values in an attempt to highlight the magnitude and importance of problems with current standard practice (Wasserstein and Lazar, 2016). At this point it would be natural for statisticians to think that this is a problem of education and communication. If we could just add a few more paragraphs to the relevant sections of our textbooks, and persuade applied practitioners to consult more with statisticians, then all would be well, or so goes this logic. In their new paper, McShane and Gal present survey data showing that even authors of published articles in a top statistics journal are often confused about the meaning of p-values, especially by treating 0.05, or the range 0.05\textendash 0.15, as the location of a threshold. The underlying problem seems to be deterministic thinking. To put it another way, applied researchers and also statisticians are in the habit of demanding more certainty than their data can legitimately supply. The problem is not just that 0.05 is an arbitrary convention; rather, even a seemingly wide range of p-values such as 0.01\textendash 0.10 cannot serve to classify evidence in the desired way (Gelman and Stern, 2006).},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource}
}

@article{Gerdhem2004,
  title = {Just One Look, and Fractures and Death Can Be Predicted in Elderly Ambulatory Women},
  author = {Gerdhem, Paul and Ringsberg, Karin and \AA kesson, Kristina and Obrant, Karl J.},
  year = {2004},
  volume = {50},
  pages = {309--314},
  issn = {0304324X},
  doi = {10.1159/000079129},
  abstract = {BACKGROUND: The chronological age is clearly the strongest risk factor for fractures or death. Age as a concept can be described exactly as chronological age. Age in relative terms can be described as biological age.: We postulated that, even without taking into account known or unknown comorbidity, an immediate and totally subjective evaluation of an individual's biological age is predictive of forthcoming fractures and death.: At baseline the biological age was estimated in 1,004 randomly recruited ambulatory 75-year-old women. All women were of the same ethnic background. Two independent observers estimated the biological age within 15 s of first sight of each woman. Based on this estimation of the biological age, the women were divided into tertiles. The women were then followed prospectively for a mean of 4.6 (range 3.0-6.5) years. All retrospective fractures and prospective fractures and deaths were registered.: When the tertile of the biologically oldest women was compared with all other women, their odds ratio for sustaining any type of prospective fracture was 1.71 (95\% confidence interval 1.22-2.39), for hip fractures 2.69 (1.42-5.11), for clinical vertebral fractures 2.83 (1.57-5.11), and for multiple fractures 3.17 (1.64-6.10). Also, when retrospectively sustained fractures were included, the predictive ability for biological age remained. The death rate amongst the tertile of biologically oldest women was increased when compared with the rest of the women (odds ratio 4.33, CI 3.62-5.17).: In ambulatory elderly women, without specific consideration of comorbidity, a subjective estimate of the biological age is predictive of future fractures and death. Subjective estimation of the biological age, in relation to the chronological age, is a valuable indicator of health, conveying additional information that merits its use in clinical practice.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3W7PSL6L\\gerdhem_et_al_2004_just_one_look,_and_fractures_and_death_can_be_predicted_in_elderly_ambulatory.pdf},
  isbn = {0304-324X (Print){\r  }0304-324X (Linking)},
  journal = {Gerontology},
  keywords = {Death prediction,Elderly ambulatory women,Fracture prediction,fractures/death},
  number = {5},
  pmid = {15331860}
}

@article{Gerdin2016,
  title = {Validation of a Novel Prediction Model for Early Mortality in Adult Trauma Patients in Three Public University Hospitals in Urban {{India}}.},
  author = {Gerdin, Martin and Roy, Nobhojit and Khajanchi, Monty and Kumar, Vineet and {Fell{\"a}nder-Tsai}, Li and Petzold, Max and Tomson, G{\"o}ran and {von Schreeb}, Johan and (TITCO), Towards Improved Trauma Care Outcomes in India},
  year = {2016},
  month = feb,
  volume = {16},
  pages = {15},
  issn = {1471-227X},
  doi = {10.1186/s12873-016-0079-0},
  abstract = {BACKGROUND Trauma is one of the top threats to population health globally. Several prediction models have been developed to supplement clinical judgment in trauma care. Whereas most models have been developed in high-income countries the majority of trauma deaths occur in low- and middle-income countries. Almost 20 \% of all global trauma deaths occur in India alone. The aim of this study was to validate a basic clinical prediction model for use in urban Indian university hospitals, and to compare it with existing models for use in early trauma care. METHODS We conducted a prospective cohort study in three hospitals across urban India. The model we aimed to validate included systolic blood pressure and Glasgow coma scale. We compared this model with three additional models, which all have been designed for use in bedside trauma care, and two single variable models based on systolic blood pressure and Glasgow coma scale respectively. The outcome was early mortality, defined as death within 24 h from the time when vital signs were first measured. We compared the models in terms of discrimination, calibration, and potential clinical consequences using decision curve analysis. Multiple imputation was used to handle missing data. Performance measures are reported using their median and inter-quartile range (IQR) across imputed datasets. RESULTS We analysed 4440 patients, out of which 1629 were used as an updating sample and 2811 as a validation sample. We found no evidence that the basic model that included only systolic blood pressure and Glasgow coma scale had worse discrimination or potential clinical consequences compared to the other models. A model that also included heart had better calibration. For the model with systolic blood pressure and Glasgow coma scale the discrimination in terms of area under the receiver operating characteristics curve was 0.846 (IQR 0.841-0.849). Calibration measured by estimating a calibration slope was 1.183 (IQR 1.168-1.202). Decision curve analysis revealed that using this model could potentially result in 45 fewer unnecessary surveys per 100 patients. CONCLUSIONS A basic clinical prediction model with only two parameters may prove to be a feasible alternative to more complex models in contexts such as the Indian public university hospitals studied here. We present a colour-coded chart to further simplify the decision making in early trauma care.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UG42SEKK\\gerdin_et_al_2016_validation_of_a_novel_prediction_model_for_early_mortality_in_adult_trauma.pdf},
  journal = {BMC emergency medicine},
  pmid = {26905408}
}

@article{Ghali1996,
  title = {Searching for an Improved Clinical Comorbidity Index for Use with {{ICD}}-9-{{CM}} Administrative Data},
  author = {Ghali, William A. and Hall, Ruth E. and Rosen, Amy K. and Ash, Arlene S. and Moskowitz, Mark A.},
  year = {1996},
  month = mar,
  volume = {49},
  pages = {273--278},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(95)00564-1},
  abstract = {We studied approaches to comorbidity risk adjustment by comparing two ICD-9-CM adaptations (Deyo, Dartmouth-Manitoba) of the Charlson comorbidity index applied to Massachusetts coronary artery bypass surgery data. We also developed a new comorbidity index by assigning study-specific weights to the original Charlson comorbidity variables. The 2 ICD-9-CM coding adaptations assigned identical Charlson comorbidity scores to 90\% of cases, and specific comorbidities were largely found in the same cases ({$\kappa$} values of 0.72\textendash 1.0 for 15 of 16 comorbidities). Meanwhile, the study-specific comorbidity index identified a 10\% subset of patients with 15\% mortality, whereas the 5\% highest-risk patients according to the Charlson index had only 8\% mortality (p = 0.01). A model using the new index to predict mortality had better validated performance than a model based on the original Charlson index (c = 0.74 vs. 0.70). Thus, in our population, the ICD-9-CM adaptation used to create the Charlson score mattered little, but using study-specific weights with the Charlson variables substantially improved the power of these data to predict mortality.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WHM6GKJF\\ghali_et_al_1996_searching_for_an_improved_clinical_comorbidity_index_for_use_with_icd-9-cm.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {3}
}

@book{Ghatak2017,
  title = {Machine Learning with r},
  author = {Ghatak, Abhijit},
  year = {2017},
  issn = {1098-6596},
  doi = {10.1007/978-981-10-6808-9},
  abstract = {applicability for this approach.},
  isbn = {978-981-10-6808-9},
  keywords = {\#nosource},
  pmid = {25246403}
}

@article{Gilbert2017,
  title = {On the Use of Summary Comorbidity Measures for Prognosis and Survival Treatment Effect Estimation},
  author = {Gilbert, Elizabeth A and Krafty, Robert T and Bleicher, Richard J and Egleston, Brian L},
  year = {2017},
  volume = {17},
  pages = {237--255},
  issn = {1572-9400},
  doi = {10.1007/s10742-017-0171-2},
  abstract = {Prognostic scores have been proposed as outcome based confounder adjustment scores akin to propensity scores. However, prognostic scores have not been widely used in the substantive literature. Instead, comorbidity scores, which are limited versions of prognostic scores, have been used extensively by clinical and health services researchers. A comorbidity is an existing disease an individual has in addition to a primary condition of interest, such as cancer. Comorbidity scores are used to reduce the dimension of a vector of comorbidity variables into a single scalar variable. Such scores are often added to regression models with other non-comorbidity variables such as age and sex, both for analyzing prognosis and for confounder adjustment when analyzing treatment effects. Despite their widespread use, the properties of and conditions under which comorbidity scores are valid dimension reduction tools in statistical models is largely unknown. In this article, we show that under relatively standard assumptions, comorbidity scores can have equal prognostic and confounder-adjustment abilities as the individual comorbidity variables, but that biases can occur if there are additional effects, such as interactions, of covariates beyond that captured by the comorbidity score. Simulations were performed to illustrate empirical properties and a data example using breast cancer data from the SEER Medicare Database demonstrates the application of these results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XYHC5YT7\\gilbert_et_al_2017_on_the_use_of_summary_comorbidity_measures_for_prognosis_and_survival_treatment.pdf},
  journal = {Health Services and Outcomes Research Methodology},
  keywords = {felmetod},
  number = {3}
}

@article{Gillam2010,
  title = {Competing Risks Survival Analysis Applied to Datafrom the Australian Orthopaedic {{AssociationNational}} Joint Replacement Registry},
  author = {Gillam, Marianne H and Ryan, Philip and Graves, Stephen E and Miller, Lisa N and {de Steiger}, Richard N and Salter, Amy and Ryan, Philip and Graves, Stephen E},
  year = {2010},
  volume = {81},
  pages = {548--555},
  issn = {1745-3674},
  abstract = {BACKGROUND AND PURPOSE: The Kaplan-Meier (KM) method is often used in the analysis of arthroplasty registry data to estimate the probability of revision after a primary procedure. In the presence of a competing risk such as death, KM is known to overestimate the probability of revision. We investigated the degree to which the risk of revision is overestimated in registry data. PATIENTS AND METHODS: We compared KM estimates of risk of revision with the cumulative incidence function (CIF), which takes account of death as a competing risk. We considered revision by (1) prosthesis type in subjects aged 75-84 years with fractured neck of femur (FNOF), (2) cement use in monoblock prostheses for FNOF, and (3) age group in patients undergoing total hip arthroplasty (THA) for osteoarthritis (OA). RESULTS: In 5,802 subjects aged 75-84 years with a monoblock prosthesis for FNOF, the estimated risk of revision at 5 years was 6.3\% by KM and 4.3\% by CIF, a relative difference (RD) of 46\%. In 9,821 subjects of all ages receiving an Austin Moore (non-cemented) prosthesis for FNOF, the RD at 5 years was 52\% and for 3,116 subjects with a Thompson (cemented) prosthesis, the RD was 79\%. In 44,365 subjects with a THA for OA who were less than 70 years old, the RD was just 1.4\%; for 47,430 subjects \textquestiondown{} 70 years of age, the RD was 4.6\% at 5 years. INTERPRETATION: The Kaplan-Meier method substantially overestimated the risk of revision compared to estimates using competing risk methods when the risk of death was high. The bias increased with time as the incidence of the competing risk of death increased. Registries should adopt methods of analysis appropriate to the nature of their data.},
  journal = {Acta Orthopaedica},
  keywords = {\#nosource},
  number = {5}
}

@article{Gillam2012,
  title = {Multi-State Models and Arthroplasty Histories after Unilateral Total Hip Arthroplasties},
  author = {Gillam, Marianne H. and Ryan, Philip and Salter, Amy and Graves, Stephen E.},
  year = {2012},
  volume = {83},
  pages = {220--226},
  issn = {17453674},
  doi = {10.3109/17453674.2012.684140},
  abstract = {BACKGROUND AND PURPOSE: An increasing number of patients have several joint replacement procedures during their lifetime. We investigated the use and suitability of multi-state model techniques in providing a more comprehensive analysis and description of complex arthroplasty histories held in arthroplasty registries than are allowed for with traditional survival methods.AND METHODS: We obtained data from the Australian Orthopaedic Association National Joint Replacement Registry on patients (n = 84,759) who had undergone a total hip arthroplasty for osteoarthritis in the period 2002-2008. We set up a multi-state model where patients were followed from their first recorded arthroplasty to several possible states: revision of first arthroplasty, either a hip or knee as second arthroplasty, revision of the second arthroplasty, and death. The Summary Notation for Arthroplasty Histories (SNAH) was developed in order to help to manage and analyze this type of data.: At the end of the study period, 12\% of the 84,759 patients had received a second hip, 3 times as many as had received a knee. The estimated probabilities of having received a second arthroplasty decreased with age. Males had a lower transition rate for receiving a second arthroplasty, but a higher mortality rate.: Multi-state models in combination with SNAH codes are well suited to the management and analysis of arthroplasty registry data on patients who experience multiple joint procedures over time. We found differences in the progression of joint replacement procedures after the initial total hip arthroplasty regarding type of joint, age, and sex.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6SYU7II7\\gillam_et_al_2012_multi-state_models_and_arthroplasty_histories_after_unilateral_total_hip.pdf},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {22553904}
}

@article{Gillam2013,
  title = {The Progression of End-Stage Osteoarthritis: {{Analysis}} of Data from the {{Australian}} and {{Norwegian}} Joint Replacement Registries Using a Multi-State Model},
  author = {Gillam, M. H. and Lie, S. A. and Salter, A. and Furnes, O. and Graves, S. E. and Havelin, L. I. and Ryan, P.},
  year = {2013},
  volume = {21},
  pages = {405--412},
  publisher = {{Elsevier Ltd}},
  issn = {10634584},
  doi = {10.1016/j.joca.2012.12.008},
  abstract = {Objective: The incidence of joint replacements is considered an indicator of symptomatic end-stage osteoarthritis (OA). We analysed data from two national joint replacement registries in order to investigate whether evidence of a pattern of progression of end-stage hip and knee OA could be found in data from large unselected populations. Design: We obtained data on 78,634 hip and 122,096 knee arthroplasties from the Australian Orthopaedic Association National Joint Replacement Registry and 19,786 hip and 12,082 knee arthroplasties from the Norwegian Arthroplasty Register. A multi-state model was developed where individuals were followed from their first recorded hip or knee arthroplasty for OA to receiving subsequent hip and/or knee arthroplasties. We used this model to estimate relative hazard rates and probabilities for each registry separately. Results: The hazard rates of receiving subsequent arthroplasties in non-cognate joints were higher on the contralateral side than on the ipsilateral side to the index arthroplasty, especially if the index was a hip arthroplasty. After 5 years, the estimated probabilities of having received a knee contralateral to the index hip were more than 1.7 times the probabilities of having received a knee ipsilateral to the index hip. Conclusion: The results indicate that there is an association between the side of the first hip arthroplasty and side of subsequent knee arthroplasties. Further studies are needed to investigate whether increased risk of receiving an arthroplasty in the contralateral knee is related to having a hip arthroplasty and/or preoperative factors such as pain and altered gait associated with hip OA. ?? 2013.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7IPRZYUE\\gillam_et_al_2013_the_progression_of_end-stage_osteoarthritis.pdf},
  isbn = {6188223407},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Arthroplasty,End-stage osteoarthritis,Hip,Knee,Multi-state model},
  number = {3},
  pmid = {23274101}
}

@article{Gilson2010,
  title = {Risk Factors for Total Joint Arthroplasty Infection in Patients Receiving Tumor Necrosis Factor {$\alpha$}-Blockers: A Case-Control Study},
  shorttitle = {Risk Factors for Total Joint Arthroplasty Infection in Patients Receiving Tumor Necrosis Factor {$\alpha$}-Blockers},
  author = {Gilson, M{\'e}lanie and Gossec, Laure and Mariette, Xavier and Gherissi, Dalenda and Guyot, Marie-H{\'e}l{\`e}ne and Berthelot, Jean-Marie and Wendling, Daniel and Michelet, Christian and Dellamonica, Pierre and Tubach, Florence and Dougados, Maxime and Salmon, Dominique},
  year = {2010},
  volume = {12},
  pages = {R145},
  issn = {1478-6354},
  doi = {10.1186/ar3087},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NR4PW3I2\\Gilson et al_2010_Risk factors for total joint arthroplasty infection in patients receiving tumor.pdf},
  journal = {Arthritis Research \& Therapy},
  language = {en},
  number = {4}
}

@article{Gjerstorff2011,
  title = {The Danish Cancer Registry},
  author = {Gjerstorff, Marianne Lundkj\ae r},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {42--45},
  issn = {14034948},
  doi = {10.1177/1403494810393562},
  abstract = {Introduction: The Danish Cancer Registry was founded in 1942. Content: The Cancer Registry contains data on the incidence of cancer in the Danish population since 1943. Validity and coverage: Validity of the Cancer Registry is secured by the application of manual quality control routines in the daily production of the Cancer Registry, the application of the automated cancer logic, and the use of multiple notifications from different data sources, which also secures a high degree of completeness. Conclusion: In 2008 the Cancer Registry finished a process of modernisation where reporting became electronic through integration with the patient administrative systems and manual coding was partly replaced by an automatic coding logic. \textcopyright{} 2011 the Nordic Societies of Public Health.},
  journal = {Scandinavian Journal of Public Health},
  keywords = {\#nosource,Automated cancer logic,cancer coding,cancer registration,Danish Cancer Registry,modernisation},
  number = {7}
}

@article{Gjertsen2014,
  title = {Hemiarthroplasties after Hip Fractures in {{Norway}} and {{Sweden}}: {{A}} Collaboration between the {{Norwegian}} and {{Swedish}} National Registries},
  author = {Gjertsen, Jan Erik and Fenstad, Anne Marie and Leonardsson, Olof and Enges\ae ter, Lars Birger and K{\"a}rrholm, Johan and Furnes, Ove and Garellick, G{\"o}ran and Rogmark, Cecilia},
  year = {2014},
  volume = {24},
  pages = {223--230},
  issn = {11207000},
  doi = {10.5301/hipint.5000105},
  abstract = {National registration of hemiarthroplasties after hip fractures has been established in both Norway and Sweden. We aimed to investigate differences in demographics, choice of implant selection, surgical approaches, and reoperations between the Norwegian Hip Fracture Register (NHFR) and the Swedish Hip Arthroplasty Register (SHAR). As part of the Nordic Arthroplasty Register Association (NARA) project a common hemiarthroplasty dataset has been established. 36,989 primary hemiarthroplasties (HAs) for acute hip fractures reported to NHFR (n = 12,761) and SHAR (n = 24,228) for the period 2005-2010 were included. Cemented prostheses were used in 78\% of the operations in Norway and in 95\% of the patients in Sweden. In Norway HAs almost exclusively had bipolar design (98\%), whereas in Sweden HAs with unipolar design were used in 42\% of the cases. Monoblock (non-modular) prostheses were uncommon, but still more frequently used in Sweden than in Norway (6.9\% and 2.1\% respectively). The lateral approach was more common in Norway (83\%) than in Sweden (52\%), where the posterior approach was used in 42\% of the cases. The five-year survival of all HAs was 95.5\% (95\% CI: 94.8-96.2) in Norway and 94.8\% (95\% CI: 94.4-95.3) in Sweden. We concluded that surprisingly large differences between the two countries in demographics, implant design, and surgical technique had been revealed. This common dataset enables further investigations of the impact of these differences on revision rates and mortality.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GW3DKSS6\\gjertsen_et_al_2014_hemiarthroplasties_after_hip_fractures_in_norway_and_sweden.pdf},
  isbn = {1724-6067 (Electronic){\r  }1120-7000 (Linking)},
  journal = {HIP International},
  keywords = {Hemiarthroplasty,Hip fractures,Registries,Reoperation},
  number = {3},
  pmid = {24500828}
}

@article{Glassou2017,
  title = {Is Decreasing Mortality in Total Hip and Knee Arthroplasty Patients Dependent on Patients' Comorbidity?},
  author = {Glassou, Eva N and Pedersen, Alma B and Hansen, Torben B},
  year = {2017},
  month = may,
  volume = {88},
  pages = {288--293},
  publisher = {{Taylor \& Francis}},
  issn = {1745-3674},
  doi = {10.1080/17453674.2017.1279496},
  abstract = {Background and purpose \textemdash{} Mortality after primary total hip and knee arthroplasty (THA and TKA) has declined, and the proportion of THA and TKA patients with comorbid conditions has increased. We th...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KLKDVPKY\\glassou_et_al_2017_is_decreasing_mortality_in_total_hip_and_knee_arthroplasty_patients_dependent.pdf},
  journal = {Acta Orthopaedica},
  number = {3}
}

@article{Glassou2018,
  title = {Is Gain in Health-Related Quality of Life after a Total Hip Arthroplasty Depended on the Comorbidity Burden?},
  author = {Glassou, Eva N. and Pedersen, Alma B. and Aalund, Peter K. and Mosegaard, Sebastian B. and Hansen, Torben B.},
  year = {2018},
  pages = {1--6},
  issn = {17453682},
  doi = {10.1080/17453674.2018.1457885},
  abstract = {Background and purpose \textemdash{} Using patient-reported health-related quality of life (HRQoL), approximately 10\% of patients report some degree of dissatisfaction after a total hip arthroplasty (THA). The preoperative comorbidity burden may play a role in predicting which patients may have limited benefit from a THA. Therefore, we examined whether gain in HRQoL measured with the EuroQol-5D (EQ-5D) at 3 and 12 months of follow-up depended on the comorbidity burden in THA patientsPatients and methods \textemdash{} 1,582 THA patients treated at the Regional Hospital West Jutland from 2008 to 2013 were included. The comorbidity burden was collected from an administrative database and assessed with the Charlson Comorbidity Index (CCI). The CCI was divided into 3 levels: no comorbidity burden, low, and high comorbidity burden. HRQoL was measured using the EQ-5D preoperatively and at 3 and 12 months' follow-up. Association between low and high comorbidity burden compared with no comorbidity burden and gain in HRQoL was analyzed wi...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\G39NV5RE\\glassou_et_al_2018_is_gain_in_health-related_quality_of_life_after_a_total_hip_arthroplasty.pdf},
  journal = {Acta Orthopaedica},
  number = {May},
  pmid = {29621916}
}

@article{Gonzalez-Zabaleta2016,
  title = {Comorbidity as a Predictor of Mortality and Mobility after Hip Fracture},
  author = {{Gonz{\'a}lez-Zabaleta}, Jorge and {Pita-Fernandez}, Salvador and {Seoane-Pillado}, Teresa and {L{\'o}pez-Calvi{\~n}o}, Beatriz and {Gonzalez-Zabaleta}, Jose Luis},
  year = {2016},
  volume = {16},
  pages = {561--569},
  issn = {14470594},
  doi = {10.1111/ggi.12510},
  abstract = {AIM: To determine mortality and mobility rates after hip fracture.: A prospective study (n = 199 patients) was carried out in the Health Care Center of A Coru\~na (Spain) during the period between January 2009 and December 2011. A descriptive study, and Cox and logistic regression analysis were carried out. Informed consent and ethical review board approval were obtained (code 2010/120 CEIC Galicia).: The patients' mean age was 82.5 {$\pm$} 8.4 years and 76\% were female. The average Charlson Comorbidity Index score was 6.1 {$\pm$} 2.1. Creatinine clearance \textexclamdown 60 mL/min/1.73 m(2) was 44\%. The probability of survival 6 months after hip fracture was 89.2\% and the survival rate at 12 months was 81.4\%. Cox regression analysis showed that the indicator that most influenced mortality rate was comorbidity (HR = 1.133; P = 0.020) and age approaching borderline statistical significance (HR = 1.034; P = 0.064). The Parker Mobility Score decreased significantly (P \textexclamdown{} 0.001) after hip fracture. Before fracture, 19\% of the patients were able to get about the house, 26\% were able to get out of the house and 55\% were able to go shopping. After hip fracture (90 days), the percentages changed to 56.2\%, 19.1\% and 24.7\%, respectively (P \textexclamdown{} 0.001). After taking into account age, sex, type of fracture, surgical delay, previous fracture and comorbidity, the only indicator capable of predicting incapacity to walk was comorbidity.: Comorbidity is the best predictor of mortality and mobility after hip fracture. Geriatr Gerontol Int 2015; \ding{108}\ding{108}: \ding{108}\ding{108}-\ding{108}\ding{108}.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7UQKUUDL\\gonzález-zabaleta_et_al_2016_comorbidity_as_a_predictor_of_mortality_and_mobility_after_hip_fracture.pdf},
  journal = {Geriatrics and Gerontology International},
  keywords = {Hip fractures,Hip replacement,Mobility,Mortality,Recovery of function},
  number = {5},
  pmid = {25981487}
}

@article{gonzalezCorrelationCoefficientAttacks2006,
  title = {The Correlation Coefficient Attacks Again},
  author = {Gonz{\'a}lez, A. Gustavo and Herrador, M. {\'A}ngeles and Asuero, Agust{\'i}n G. and Sayago, Ana},
  year = {2006},
  volume = {11},
  pages = {256--258},
  issn = {09491775},
  doi = {10.1007/s00769-006-0153-5},
  abstract = {The use of the correlation coefficient for testing the linearity of calibration curves is performed according to the ANOVA checking of the lack-of-fit. The procedure is illustrated from a case study.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\56ZC7Q3Q\\gonzález_et_al_2006_the_correlation_coefficient_attacks_again.pdf},
  isbn = {0949-1775},
  journal = {Accreditation and Quality Assurance},
  keywords = {Coefficient of determination,Correlation coefficient,Lack-of-fit,Linearity},
  number = {5}
}

@article{Gordon2013,
  title = {The Influence of Comorbidity Scores on Re-Operations Following Primary Total Hip Replacement: Comparison and Validation of Three Comorbidity Measures.},
  author = {Gordon, M and Stark, A and Sk{\"o}ldenberg, O G and K{\"a}rrholm, J and Garellick, G},
  year = {2013},
  month = sep,
  volume = {95-B},
  pages = {1184--91},
  publisher = {{British Editorial Society of Bone and Joint Surgery}},
  issn = {2049-4408},
  doi = {10.1302/0301-620X.95B9.31006},
  abstract = {While an increasing amount of arthroplasty articles report comorbidity measures, none have been validated for outcomes. In this study, we compared commonly used International Classification of Diseases-based comorbidity measures with re-operation rates after total hip replacement (THR). Scores used included the Charlson, the Royal College of Surgeons Charlson, and the Elixhauser comorbidity score. We identified a nationwide cohort of 134 423 THRs from the Swedish Hip Arthroplasty Register. Re-operations were registered post-operatively for up to 12 years. The hazard ratio was estimated by Cox's proportional hazards regression, and we used C-statistics to assess each measure's ability to predict re-operation. Confounding variables were age, gender, type of implant fixation, hospital category, hospital implant volume and year of surgery. In the first two years only the Elixhauser score showed any significant relationship with increased risk of re-operation, with increased scores for both one to two and three or more comorbidities. However, the predictive C-statistic in this period for the Elixhauser score was poor (0.52). None of the measures proved to be of any value between two and 12 years. They might be of value in large cohort or registry studies, but not for the individual patient.},
  journal = {The bone \& joint journal},
  keywords = {\#nosource,Charlson index,Comorbidity,Elixhausers index,RCS Charlson index,Total hip arthroplasty},
  number = {9},
  pmid = {23997129}
}

@article{Gordon2014,
  title = {Age- and Health-Related Quality of Life after Total Hip Replacement},
  author = {Gordon, Max and Greene, Meridith and Frumento, Paolo and Rolfson, Ola and Garellick, G{\"o}ran and Stark, Andr{\'e}},
  year = {2014},
  volume = {85},
  pages = {244--249},
  issn = {17453682},
  doi = {10.3109/17453674.2014.916492},
  abstract = {BACKGROUND: While age is a common confounder, its impact on health-related quality of life (HRQoL) after total hip replacement is uncertain. This could be due to improper statistical modeling of age in previous studies, such as treating age as a linear variable or by using age categories. We hypothesized that there is a non-linear association between age and HRQoL.: We selected a nationwide cohort from the Swedish Hip Arthroplasty Register of patients operated with total hip replacements due to primary osteoarthritis between 2008 and 2010. For estimating HRQoL, we used the generic health outcome questionnaire EQ-5D of the EuroQol group that consits or 2 parts: the EQ-5D index and the EQ VAS estimates. Using linear regression, we modeled the EQ-5D index and the EQ VAS against age 1 year after surgery. Instead of using a straight line for age, we applied a method called restricted cubic splines that allows the line to bend in a controlled manner. Confounding was controlled by adjusting for preoperative HRQoL, sex, previous contralateral hip surgery, pain, and Charnley classification.: Complete data on 27,245 patients were available for analysis. Both the EQ-5D index and EQ VAS showed a non-linear relationship with age. They were fairly unaffected by age until the patients were in their late sixties, after which age had a negative effect.: There is a non-linear relationship between age and HRQoL, with improvement decreasing in the elderly.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2GN7XY8P\\gordon_et_al_2014_age-_and_health-related_quality_of_life_after_total_hip_replacement.pdf},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {24786908}
}

@article{Gorsuch2010,
  title = {Correlation Coefficients: {{Mean}} Bias and Confidence Interval Distortions},
  author = {Gorsuch, Rl and Lehmann, Cs},
  year = {2010},
  volume = {1},
  pages = {52--65},
  issn = {2159-7855},
  abstract = {Non-zero correlation coefficients have non-normal distributions, affecting both means and standard deviations. Previous research suggests that z transformation may effectively correct mean bias for N's less than 30. In this study, simulations with small (20 and 30) and large (50 and 100) N's found that mean bias adjustments for larger N's are seldom needed. However, z transformations improved confidence intervals even for N = 100. The improvement was not in the estimated standard errors so much as in the asymmetrical CI's estimates based upon the z transformation. The resulting observed probabilities were generally accurate to within 1 point in the first non-zero digit. These issues are an order of magnitude less important for accuracy than design issues influencing the accuracy of the results, such as reliability, restriction of range, and N. Keywords: Confidence intervals; Correlation coefficient; Fisher's z transformation; Monte Carlo study; Mean bias in correlation coefficients},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4HB6YCWG\\gorsuch_lehmann_2010_correlation_coefficients.pdf},
  journal = {Journal of Methods and Measurement in the Social Sciences},
  keywords = {because the distribution of,coefficients,confidence intervals,correlation coefficient,estimate the population correlation,fisher,is known to slightly,mean bias in correlation,monte carlo,r,r is,s z transformation,study,the observed correlation coefficient,under,ρ},
  number = {2}
}

@article{Graafland2012,
  title = {Systematic Review of Serious Games for Medical Education and Surgical Skills Training},
  author = {Graafland, M. and Schraagen, J. M. and Schijven, M. P.},
  year = {2012},
  month = oct,
  volume = {99},
  pages = {1322--1330},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {00071323},
  doi = {10.1002/bjs.8819},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\48UBSPM9\\graafland_et_al_2012_systematic_review_of_serious_games_for_medical_education_and_surgical_skills.pdf},
  journal = {British Journal of Surgery},
  number = {10}
}

@article{Graafland2015,
  title = {Training Situational Awareness to Reduce Surgical Errors in the Operating Room},
  author = {Graafland, M. and Schraagen, J. M. C. and Boermeester, M. A. and Bemelman, W. A. and Schijven, M. P.},
  year = {2015},
  month = jan,
  volume = {102},
  pages = {16--23},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {00071323},
  doi = {10.1002/bjs.9643},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\P5XHX9IE\\graafland_et_al_2015_training_situational_awareness_to_reduce_surgical_errors_in_the_operating_room.pdf},
  journal = {British Journal of Surgery},
  number = {1}
}

@article{Graber1976,
  title = {Notes and Comments.},
  author = {Graber, T. M.},
  year = {1976},
  volume = {21},
  pages = {712--713},
  issn = {00118486},
  journal = {Dental abstracts; a selection of world dental literature},
  keywords = {\#nosource},
  number = {12}
}

@article{Grady2011,
  title = {Why Is a Good Clinical Prediction Rule so Hard to Find?},
  author = {Grady, D and SA, Berkowitz},
  year = {2011},
  month = oct,
  volume = {171},
  pages = {1701--1702},
  issn = {0003-9926},
  abstract = {Clinical prediction rules (CPRs) (also called clinical decision rules, prediction models, and risk scores) are tools designed to assist clinical decision making. Clinical prediction rules generally provide an estimate of the risk of disease, disease outcome, or the benefit of a diagnostic or therapeutic action.1,2 For example, the well-known Framingham Risk Score3 uses age, sex, total cholesterol level, high-density lipoprotein cholesterol level, smoking status, blood pressure, and use of hypertension medication to estimate the risk of myocardial infarction or coronary death during the next 10 years. Because CPRs are designed to guide clinical care, it is important that they be accurate and reliable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RHFC5RR9\\grady_sa_2011_why_is_a_good_clinical_prediction_rule_so_hard_to_find.pdf},
  journal = {Archives of Internal Medicine},
  number = {19}
}

@article{Grambsch1994,
  title = {Proportional Hazards Tests and Diagnostics Based on Weighted Residuals},
  author = {Grambsch, PATRICIA M. and Therneau, TERRY M. and Thernearu, Terry M. and Thernau, Terry M},
  year = {1994},
  month = sep,
  volume = {81},
  pages = {515--526},
  publisher = {{Oxford University Press}},
  issn = {0006-3444},
  doi = {10.1093/biomet/81.3.515},
  abstract = {SUMMARYNonproportional hazards can often be expressed by extending the Cox model to include time varying coefficients; e.g., for a single covariate, the hazard function for subject i is modelled as exp \{{$\beta$}(t)Zi(t)\}. A common example is a treatment effect that decreases with time. We show that the function {$\beta$}i(t) can be directly visualized by smoothing an appropriate residual plot. Also, many tests of proportional hazards, including those of Cox (1972), Gill \&amp; Schumacher (1987), Harrell (1986), Lin (1991), Moreau, O'Quigley \&amp; Mesbah (1985), Nagelkerke, Oosting \&amp; Hart (1984), O'Quigley \&amp; Pessione (1989), Schoenfeld (1980) and Wei (1984) are related to time-weighted score tests of the proportional hazards hypothesis, and can be visualized as a weighted least-squares line fitted to the residual plot.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4XSH8DGT\\grambsch_et_al_1994_proportional_hazards_tests_and_diagnostics_based_on_weighted_residuals.pdf},
  journal = {Biometrika},
  number = {3}
}

@article{Gran2009,
  title = {Growth Rates in Epidemic Models: Application to a Model for {{HIV}}/{{AIDS}} Progression},
  author = {Gran, J.M. and Wasmuth, L. and Amundsen, E.J. and Lindqvist, B.H. and Aalen, O.O.},
  year = {2009},
  volume = {28},
  pages = {221--239},
  issn = {02776715},
  doi = {10.1002/sim},
  abstract = {Although sample size calculations have become an important element in the design of research projects, such methods for studies involving current status data are scarce. Here, we propose a method for calculating power and sample size for studies using current status data. This method is based on a Weibull survival model for a two-group comparison. The Weibull model allows the investigator to specify a group difference in terms of a hazards ratio or a failure time ratio. We consider exponential, Weibull and uniformly distributed censoring distributions. We base our power calculations on a parametric approach with the Wald test because it is easy for medical investigators to conceptualize and specify the required input variables. As expected, studies with current status data have substantially less power than studies with the usual right-censored failure time data. Our simulation results demonstrate the merits of these proposed power calculations.},
  isbn = {2007090091480},
  journal = {Statistics in medicine},
  keywords = {\#nosource,ces-d,conditional maximum likelihood,fixed effects,generalized linear mixed model,hausman test,linear mixed model,random effects,robust,variance},
  number = {July 2006},
  pmid = {19455509}
}

@article{Grauer2015,
  title = {Editorial: {{Large}} Database {{Studies}}???{{What}} They Can Do, What They Cannot Do, and Which Ones We Will Publish},
  author = {Grauer, Jonathan N. and Leopold, Seth S.},
  year = {2015},
  volume = {473},
  pages = {1537--1539},
  issn = {15281132},
  doi = {10.1007/s11999-015-4223-z},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QGSECJH4\\grauer_leopold_2015_editorial.pdf},
  journal = {Clinical Orthopaedics and Related Research},
  number = {5},
  pmid = {25724835}
}

@techreport{Graunt1661,
  title = {Natural and Political Observations Mentioned in a Following Index, and Made upon the Bills of Mortality},
  author = {Graunt, John},
  year = {1661},
  city = {London},
  keywords = {\#nosource}
}

@book{Graunt1960,
  title = {The World of Mathematics},
  author = {Graunt, John},
  editor = {Newman, James Roy},
  year = {1960},
  city = {London},
  keywords = {\#nosource}
}

@techreport{Grecchi2016,
  title = {Aneurismal Bone Cyst: {{A}} Conservative Surgical Technique. {{A}} Case Report Treated with a Small Access Osteotomy {{Implantology View}} Project {{Anatomy View}} Project},
  author = {Grecchi, Emma and Borgonovo, Andrea and Re, Dino},
  year = {2016},
  abstract = {The user has requested enhancement of the downloaded file.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RSFNMC7N\\grecchi_et_al_2016_aneurismal_bone_cyst.pdf}
}

@article{Greco1992,
  title = {The Probability Integral of the Sample Correlation Coefficient},
  author = {Greco, Luigi},
  year = {1992},
  month = aug,
  volume = {1},
  pages = {289--294},
  issn = {1121-9130},
  doi = {10.1007/BF02589036},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7TXD8MBK\\greco_1992_the_probability_integral_of_the_sample_correlation_coefficient.pdf},
  journal = {Journal of the Italian Statistical Society},
  keywords = {correlation coefficient,normal bi-variate popula-,probability distributions},
  number = {2}
}

@article{Greco1992,
  title = {{{THE PROBABILITY INTEGRAL OF THE SAMPLE CORRELATION COEFFICIENT Ik}}-},
  author = {Greco, Luigi},
  year = {1992},
  volume = {2},
  pages = {289--294},
  journal = {J. ltaL Statist. Soc.},
  keywords = {\#nosource,correlation coefficient,normal bi-variate popula-,probability distributions}
}

@article{Greene2015,
  title = {Standard Comorbidity Measures Do Not Predict Patient-Reported Outcomes 1 Year after Total Hip Arthroplasty},
  author = {Greene, Meridith E. and Rolfson, Ola and Gordon, Max and Garellick, G{\"o}ran and Nemes, Szilard},
  year = {2015},
  month = nov,
  volume = {473},
  pages = {3370--3379},
  publisher = {{Springer US}},
  issn = {15281132},
  doi = {10.1007/s11999-015-4195-z},
  abstract = {Background: Comorbidities influence surgical outcomes and therefore need to be included in risk adjustment when predicting patient-reported outcomes. However, there is no consensus on how best to use the available data about comorbidities in registry-based predictive models.; Questions/purposes: The purposes of this study were (1) to determine whether the International Classification of Diseases, 10(th) Revision (ICD-10)-based comorbidity measures (Elixhauser, Charlson, and Royal College of Surgeons Charlson) offer added value in explaining patients' health-related quality of life (HRQoL), pain, and satisfaction after total hip arthroplasty (THA) when preoperative HRQoL, pain, and Charnley classification were known; and (2) to determine the ideal timeframe for recording the different diagnoses that serves as the basis for comorbidity measure calculations.; Methods: There were 22,263 patients who had undergone THA with complete pre- and postoperative patient-reported outcome measures (PROMs) included in the Swedish Hip Arthroplasty Register between 2002 and 2007. The three comorbidity indices were calculated with ICD-10 codes identified in the Swedish National Patient Register from 1, 2, and 5 years before the patient underwent THA. The impact of the comorbidity indices on the PROM scores (EQ-5D index, EQ visual analog scale [VAS], pain VAS, and satisfaction VAS) was modeled with linear regression where the 1-year patient postoperative outcome score was the dependent variable and independent variables included patient preoperative Charnley classification, preoperative HRQoL and pain, and comorbidity indices. The partial R(2) value indicated how much each variable uniquely contributed to the predictive capacity of the model.; Results: The ICD-10-based comorbidity measures added little predictive value to the models for each of the outcomes of interest (EQ-5D index, EQ VAS, pain VAS, and satisfaction VAS). Charnley classification and the preoperative scores were the strongest predictors of both measures of postoperative HRQoL, of postoperative pain, and postoperative satisfaction with outcomes from surgery. Of all the predictors considered, only the Charnley classification was associated with all outcomes, irrespective of the timeframe considered. For each of the outcomes considered, there was a gradual increase in the models' predictive power with the length of the timeframe considered for calculating the comorbidity measures.; Conclusions: For predicting outcomes 1 year after THA, we found that there was no added value in ICD-10-based comorbidity measures if patient Charnley classification and preoperative HRQoL and pain measures were known.; Level Of Evidence: Level III, therapeutic study.;},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LPH4JZ5F\\greene_et_al_2015_standard_comorbidity_measures_do_not_predict_patient-reported_outcomes_1_year.pdf},
  isbn = {0009-921X},
  journal = {Clinical Orthopaedics and Related Research},
  number = {11},
  pmid = {25700999}
}

@article{Greenhill2011,
  title = {The Separation Plot: {{A}} New Visual Method for Evaluating the Fit of Binary Models},
  author = {Greenhill, Brian and Ward, Michael D. and Sacks, Audrey},
  year = {2011},
  month = oct,
  volume = {55},
  pages = {991--1002},
  publisher = {{John Wiley \& Sons, Ltd (10.1111)}},
  issn = {00925853},
  doi = {10.1111/j.1540-5907.2011.00525.x},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F3HW9IK9\\greenhill_et_al_2011_the_separation_plot.pdf},
  journal = {American Journal of Political Science},
  number = {4}
}

@article{Greenland2016,
  title = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power: A Guide to Misinterpretations},
  author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
  year = {2016},
  volume = {31},
  pages = {337--350},
  publisher = {{Springer Netherlands}},
  issn = {15737284},
  doi = {10.1007/s10654-016-0149-3},
  abstract = {Misinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so-and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3K5BQZP7\\greenland_et_al_2016_statistical_tests,_p_values,_confidence_intervals,_and_power.pdf},
  isbn = {1573-7284 (Electronic){\r  }0393-2990 (Linking)},
  journal = {European Journal of Epidemiology},
  keywords = {Confidence intervals,Hypothesis testing,Null testing,P value,Power,Significance tests,Statistical testing},
  number = {4},
  pmid = {27209009}
}

@generic{grojerDoktorandspegelnEnkatOm2016,
  title = {Doktorandspegeln En Enk\"at Om Doktorandernas Studiesituation},
  author = {Gr{\"o}jer, Anette},
  year = {2016},
  keywords = {\#nosource}
}

@article{Guo1995,
  title = {Collapsibility of {{Logistic Regression Coefficients}}},
  author = {Guo, Jianhua and Geng, Zhi},
  year = {1995},
  volume = {57},
  pages = {263--267},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  abstract = {In this paper we discuss collapsibility of logistic regression coefficients over a background variable and present necessary and sufficient conditions for collapsibility.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WVE44H73\\Guo och Geng - 1995 - Collapsibility of Logistic Regression Coefficients.pdf},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  number = {1}
}

@article{Guo2015,
  title = {Improved Variable Selection Algorithm Using a {{LASSO}}-{{Type}} Penalty, with an Application to Assessing Hepatitis b Infection Relevant Factors in Community Residents},
  author = {Guo, Pi and Zeng, Fangfang and Hu, Xiaomin and Zhang, Dingmei and Zhu, Shuming and Deng, Yu and Hao, Yuantao},
  editor = {{Emmert-Streib}, Frank},
  year = {2015},
  month = jul,
  volume = {10},
  pages = {e0134151},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0134151},
  abstract = {Objectives In epidemiological studies, it is important to identify independent associations between collective exposures and a health outcome. The current stepwise selection technique ignores stochastic errors and suffers from a lack of stability. The alternative LASSO-penalized regression model can be applied to detect significant predictors from a pool of candidate variables. However, this technique is prone to false positives and tends to create excessive biases. It remains challenging to develop robust variable selection methods and enhance predictability. Material and methods Two improved algorithms denoted the two-stage hybrid and bootstrap ranking procedures, both using a LASSO-type penalty, were developed for epidemiological association analysis. The performance of the proposed procedures and other methods including conventional LASSO, Bolasso, stepwise and stability selection models were evaluated using intensive simulation. In addition, methods were compared by using an empirical analysis based on large-scale survey data of hepatitis B infection-relevant factors among Guangdong residents. Results The proposed procedures produced comparable or less biased selection results when compared to conventional variable selection models. In total, the two newly proposed procedures were stable with respect to various scenarios of simulation, demonstrating a higher power and a lower false positive rate during variable selection than the compared methods. In empirical analysis, the proposed procedures yielding a sparse set of hepatitis B infection-relevant factors gave the best predictive performance and showed that the procedures were able to select a more stringent set of factors. The individual history of hepatitis B vaccination, family and individual history of hepatitis B infection were associated with hepatitis B infection in the studied residents according to the proposed procedures. Conclusions The newly proposed procedures improve the identification of significant variables and enable us to derive a new insight into epidemiological association analysis.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZYC9NTS8\\guo_et_al_2015_improved_variable_selection_algorithm_using_a_lasso-type_penalty,_with_an.pdf},
  journal = {PLOS ONE},
  number = {7}
}

@article{Guo2019,
  title = {A {{Sparse Corruption Non}}-{{Negative Matrix Factorization}} Method and Application in Face Image Processing \& Recognition},
  author = {Guo, Zhibo and Zhang, Ying},
  year = {2019},
  volume = {136},
  pages = {429--437},
  publisher = {{Elsevier Ltd}},
  issn = {02632241},
  doi = {10.1016/j.measurement.2018.12.087},
  abstract = {Non-negative Matrix Factorization (NMF) has attracted widely attentions in the areas of data analysis, image processing \& measurement and noise separation. NMF can obtain the non-negative low-dimensional representation of the data and low-rank matrix is of great importance to classification and recognition. Classic NMF assumes that noise is subject to Gaussian noise or Poisson noise, while it is inapplicable to some other noise. In addition, corrupted data in the test set cannot be restored by NMF. Many scholars have studied NMF and proposed a variety of improved algorithms so far, such as Robust Non-Negative Matrix Factorization (RNMF), which is designed to deal with sparse corruption. Our paper presents Sparse Corruption Non-Negative Matrix Factorization (SCNMF). SCNMF separates a sparse noise matrix out of the corrupted input matrix, and the rest of the input matrix is represented as the product of two low-dimensional matrices. The product of two low-dimensional matrices approximates the non-corrupted input matrix. The base matrix calculated by the proposed method is tolerant to noise. It can reconstruct new data well regardless of whether the new data is corrupted and non-corrupted. Experiments on specific face databases verifies the validity of SCNMF. Reconstructed faces by the proposed method are clearer and more recognizable and the recognition rate is three percentage points higher by comparison.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TRSNMVE8\\guo_zhang_2019_a_sparse_corruption_non-negative_matrix_factorization_method_and_application_in.pdf},
  journal = {Measurement: Journal of the International Measurement Confederation},
  keywords = {Dimensionality reduction,Face recognition,Image processing,L 1 -norm,Matrix factorization}
}

@article{Gutacker2015,
  title = {Comparing the Performance of the {{Charlson}}/{{Deyo}} and {{Elixhauser}} Comorbidity Measures across Five {{European}} Countries and Three Conditions},
  author = {Gutacker, Nils and Bloor, Karen and Cookson, Richard},
  year = {2015},
  volume = {25},
  pages = {15--20},
  issn = {1464360X},
  doi = {10.1093/eurpub/cku221},
  abstract = {BACKGROUND: The Charlson and Elixhauser comorbidity measures are commonly used methods to account for patient comorbidities in hospital-level comparisons of clinical quality using administrative data. Both have been validated in North America, but there is less evidence of their performance in Europe and in pooled cross-country data, which are features of the European Collaboration for Healthcare Optimization (ECHO) project. This study compares the performance of the Charlson/Deyo and Elixhauser comorbidity measures in predicting in-hospital mortality using data from five European countries in three inpatient groups. METHODS: Administrative data is used from five countries in 2008-2009 for three indicators commonly used in hospital quality comparisons: mortality rates following acute myocardial infarction, coronary artery bypass graft surgery and stroke. Logistic regression models are constructed to predict mortality controlling for age, gender and the relevant comorbidity measure. Model discrimination is evaluated using c-statistics. Model calibration is evaluated using calibration slopes. Overall goodness-of-fit is evaluated using Nagelkerke's R(2) and the Akaike information criterion. All models are validated internally by using bootstrapping and externally by using the 2009 model parameters to predict mortality in 2008. RESULTS: The Elixhauser measure has better overall predictive ability in terms of discrimination and goodness-of-fit than the Charlson/Deyo measure or the age-sex only model. There is no clear difference in model calibration. These findings are robust to the choice of country, to pooling all five countries and to internal and external validation. CONCLUSIONS: The Elixhauser list contains more comorbidities, which may enable it to achieve better discrimination than the Charlson measure. Both measures achieve similar calibration, so for the purpose of ECHO we judged the Elixhauser measure to be preferable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\W92U3ZMA\\gutacker_et_al_2015_comparing_the_performance_of_the_charlson-deyo_and_elixhauser_comorbidity.pdf},
  journal = {European journal of public health},
  pmid = {25690125}
}

@book{hadzibajramovicAspectsValidityStress2015,
  title = {Aspects of Validity in Stress Research: {{Measurement}} Properties and the Application of Self- Reported Stress Questionnaires},
  author = {Had{\v z}ibajramovi{\'c}, Emina},
  year = {2015},
  abstract = {Aim: To increase knowledge about validity evaluation and interpretability of a multi-item self-report questionnaire used in occupational health and stress research, and to investigate longitudinal associations between the psychosocial work environment and symptoms of burnout. Method: The data come from a four-wave cohort study of public health care workers from the Region V\"astra G\"otaland. Rasch analysis was used for evaluation of measurement properties. A criterion based approach (CBA) was developed, and along with the median proposed for global scores in the Stress- Energy Questionnaire (SEQ). The CBA was applied for the SEQ-Leisure Time (SEQ-LT) and for the measurements of demands, decision authority, effort and reward. Longitudinal associations were analysed using mixed-effects regression models with random intercept. Results: Good psychometric properties were found for the SEQ and SEQ-LT. The CBA was recommended for the SEQ. The CBA was applied to the SEQ and SEQ-LT, demands, decision authority, effort and reward. Investigated workplace factors were associated with increased symptoms of burnout. Conclusion: The SEQ and SEQ-LT provide valid and useful tools for assessing work-related and non-work-related affective stress responses respectively. Rasch analysis is proposed for the evaluation of measurement properties. Increased awareness of the construction of global scores is needed. The CBA can be used for identification of the risk groups for adverse health effects, as defined by the theoretical foundations of the questionnaires, provided good measurement properties defined by the Rasch model. Longitudinal associations were found between demands, decision authority, effort and reward) and the symptoms of burnout.},
  isbn = {978-91-628-9587-7},
  keywords = {\#nosource,Affective stress response,Global scores,Rasch analysis,Validity},
  number = {October}
}

@article{Hafdahl2009,
  title = {Meta-Analysis of Correlations Revisited: Attempted Replication and Extension of {{Field}}'s (2001) Simulation Studies.},
  author = {Hafdahl, Adam R and a Williams, Michelle},
  year = {2009},
  volume = {14},
  pages = {24--42},
  issn = {1082-989X},
  doi = {10.1037/a0014697},
  abstract = {In 2 Monte Carlo studies of fixed- and random-effects meta-analysis for correlations, A. P. Field (2001) ostensibly evaluated Hedges-Olkin-Vevea Fisher-z and Schmidt-Hunter Pearson-r estimators and tests in 120 conditions. Some authors have cited those results as evidence not to meta-analyze Fisher-z correlations, especially with heterogeneous correlation parameters. The present attempt to replicate Field's simulations included comparisons with analytic values as well as results for efficiency and confidence-interval coverage. Field's results under homogeneity were mostly replicable, but those under heterogeneity were not: The latter exhibited up to over .17 more bias than ours and, for tests of the mean correlation and homogeneity, respectively, nonnull rejection rates up to .60 lower and .65 higher. Changes to Field's observations and conclusions are recommended, and practical guidance is offered regarding simulation evidence and choices among methods. Most cautions about poor performance of Fisher-z methods are largely unfounded, especially with a more appropriate z-to-r transformation. The Appendix gives a computer program for obtaining Pearson-r moments from a normal Fisher-z distribution, which is used to demonstrate distortion due to direct z-to-r transformation of a mean Fisher-z correlation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Q8QAP4BE\\hafdahl_williams_2009_meta-analysis_of_correlations_revisited.pdf},
  isbn = {1082-989X1939-1463},
  journal = {Psychological methods},
  keywords = {10,1037,a0014697,decades,doi,during the past 3,dx,fisher,http,meta-analysis,meta-analysis has become a,monte carlo simulation,org,random effects,s z transformation,supp,supplemental materials,validity generalization},
  number = {1},
  pmid = {19271846}
}

@book{haggstromSannolikhetsteorinsGrunder1999,
  title = {Sannolikhetsteorins Grunder},
  author = {H{\"a}ggstr{\"o}m, Olle and Lindvall, Torgny},
  year = {1999},
  keywords = {\#nosource}
}

@article{Hagquist2009,
  title = {Using the {{Rasch}} Model in Nursing Research: {{An}} Introduction and Illustrative Example},
  author = {Hagquist, Curt and Bruce, Malin and Gustavsson, J. Petter},
  year = {2009},
  volume = {46},
  pages = {380--393},
  issn = {00207489},
  doi = {10.1016/j.ijnurstu.2008.10.007},
  abstract = {Objective: The purpose was to introduce the Rasch model by showing an application in nursing research. Methods: The Rasch model was used to examine the psychometric properties of the nursing self-efficacy (NSE) scale. Data were collected among nursing students in Sweden. Two sets of items were analysed more thoroughly: an original set of nine items with eleven response categories and a revised set of seven items with seven response categories. Invariance of the item functioning and the categorisation of the items were analysed. Targeting was examined by comparisons of the items and persons locations. Differential Item Functioning across sample groups such as gender was examined using analysis of variance. The final set of seven items was also analysed more closely with respect to possible multidimensionality and response dependence. Results: The Rasch analysis of the original set of nine items showed high reliability measured by a person separation index, but it also indicated severe problems with the targeting, the categorisation of the items as well as lack of invariance. Although the revised set comprising seven items with seven categories performed better than the original item set some items showed misfit according to formal test statistics. Graphical examination showed, however, that the items operated in the right direction. The formal test of local independence of the items indicated minor signs of multidimensionality, alternatively response dependence. Conclusions: The Rasch model is useful for rigorous examination and development of measurement instruments in nursing research. The Rasch model facilitates disclosure of lack of invariance and other measurement problems that may not be easily detected by traditional analyses. Hence, the NSE-scale would probably have performed much better if the developmental work had been guided by Rasch analyses. In future work on the scale, priority should be given to improving the targeting and the categorisation of the items. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MS7FIHKB\\hagquist_et_al_2009_using_the_rasch_model_in_nursing_research.pdf},
  isbn = {0020-7489},
  journal = {International Journal of Nursing Studies},
  keywords = {Nursing self-efficacy,Nursing student,Rasch analysis},
  number = {3},
  pmid = {19059593}
}

@article{Halfon2002,
  title = {Measuring Potentially Avoidable Hospital Readmissions},
  author = {Halfon, Patricia and Eggli, Yves and {van Melle}, Guy and Chevalier, Julia and Wasserfallen, Jean-Blaise and Burnand, Bernard},
  year = {2002},
  volume = {55},
  pages = {573--587},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(01)00521-2},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VVASRZEQ\\halfon_et_al_2002_measuring_potentially_avoidable_hospital_readmissions.pdf},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Avoidable,Hospital quality,Hospitalization,Readmission,Risk factors},
  number = {6}
}

@article{Halkidi2001,
  title = {On Clustering Validation Techniques},
  author = {Halkidi, Maria and Batistakis, Yannis and Vazirgiannis, Michalis},
  year = {2001},
  volume = {17},
  pages = {107--145},
  publisher = {{Kluwer Academic Publishers}},
  issn = {09259902},
  doi = {10.1023/A:1012801612483},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\U942D4IC\\halkidi_et_al_2001_on_clustering_validation_techniques.pdf},
  journal = {Journal of Intelligent Information Systems},
  number = {2/3}
}

@article{Halkidi2002,
  title = {Cluster Validity Methods Part 1},
  author = {Halkidi, Maria and Batistakis, Yannis and Vazirgiannis, Michalis},
  year = {2002},
  month = jun,
  volume = {31},
  pages = {40},
  publisher = {{ACM}},
  issn = {01635808},
  doi = {10.1145/565117.565124},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KI7XTRTG\\halkidi_et_al_2002_cluster_validity_methods_part_1.pdf},
  journal = {ACM SIGMOD Record},
  number = {2}
}

@article{Halkidi2002,
  title = {Clustering Validity Checking Methods: {{Part II}}},
  author = {Halkidi, Maria and Batistakis, Yannis and Vazirgiannis, Michalis},
  year = {2002},
  month = sep,
  volume = {31},
  pages = {19},
  publisher = {{ACM}},
  issn = {01635808},
  doi = {10.1145/601858.601862},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2LU4IGMR\\halkidi_et_al_2002_clustering_validity_checking_methods.pdf},
  journal = {ACM SIGMOD Record},
  keywords = {clustering validation,pattern discovery,unsupervised learning},
  number = {3}
}

@book{Hallin2002,
  title = {Jakten P\aa{} Den Goda Styrningen \textendash\textendash{} {{En}} Kunskaps\"oversikt Kring Styrning Och Organisation Inom H\"also- Och Sjukv\aa rden},
  author = {Hallin, Bo and Siverbo, Sven},
  year = {2002},
  isbn = {91-974223-2-0},
  keywords = {\#nosource},
  number = {3}
}

@article{Hallin2018,
  title = {Readmission and Mortality in Patients Treated by Interprofessional Student Teams at a Training Ward Compared with Patients Receiving Usual Care: {{A}} Retrospective Cohort Study},
  author = {Hallin, Karin and Gordon, Max and Sk{\"o}ldenberg, Olof and Henriksson, Peter and Kiessling, Anna},
  year = {2018},
  issn = {20446055},
  doi = {10.1136/bmjopen-2018-022251},
  abstract = {OBJECTIVE: This study aimed to compare the rate of patient readmissions and mortality between care provided at an orthopaedic interprofessional training ward (IPTW) and usual care. DESIGN: Retrospective cohort study. SETTING: Orthopaedic wards at a level II trauma centre at a Swedish university teaching hospital between 2006 and 2011. PARTICIPANTS: Two cohorts were identified: (1) a control cohort that had not received care at the IPTW, and (2) patients who had been treated for at least 1 day at the IPTW. MAIN OUTCOME MEASURES: Readmission at 90 days and 1-year mortality. RESULTS: We included 4652 controls and 1109 in the IPTW group. The mean age was 63 years, and 58\% were women. The groups did not differ in any of the outcomes: the readmission rate in the control and IPTW groups was 13.5\% and 14.0\%, respectively, while mortality was 5.2\% and 5.3\%, respectively. This lack of difference remained after adjusting for confounders. CONCLUSION: Interprofessional undergraduate training in patient-based settings can be performed in a level II trauma hospital with satisfactory patient safety.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PRHGCA3H\\hallin_et_al_2018_readmission_and_mortality_in_patients_treated_by_interprofessional_student.pdf},
  journal = {BMJ Open},
  keywords = {epidemiology,interprofessional training,mortality,readmission},
  pmid = {30341125}
}

@book{Halmstad2016,
  title = {\AA rsrapport},
  author = {Halmstad, Movement and Stockholm, Orthocenter},
  year = {2016},
  isbn = {978-91-88017-11-6},
  keywords = {\#nosource}
}

@article{Hanley1982,
  title = {The Meaning and Use of the Area under a Receiver Operating Characteristic ({{ROC}}) Curve},
  author = {Hanley, A.J. and McNeil, J.B.},
  year = {1982},
  volume = {143},
  pages = {29--36},
  issn = {0033-8419},
  doi = {10.1148/radiology.143.1.7063747},
  abstract = {A representation and interpretation of the area under a receiver operating characteristic (ROC) curve obtained by the "rating" method, or by mathematical predictions based on patient characteristics, is presented. It is shown that in such a setting the area represents the probability that a randomly chosen diseased subject is (correctly) rated or ranked with greater suspicion than a randomly chosen non-diseased subject. Moreover, this probability of a correct ranking is the same quantity that is estimated by the already well-studied nonparametric Wilcoxon statistic. These two relationships are exploited to (a) provide rapid closed-form expressions for the approximate magnitude of the sampling variability, i.e., standard error that one uses to accompany the area under a smoothed ROC curve, (b) guide in determining the size of the sample required to provide a sufficiently reliable estimate of this area, and (c) determine how large sample sizes should be to ensure that one can statistically detect differences in the accuracy of diagnostic techniques.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\N7M7KQXM\\hanley_mcneil_1982_the_meaning_and_use_of_the_area_under_a_receiver_operating_characteristic_(roc).pdf},
  isbn = {0033-8419 (Print) 0033-8419 (Linking)},
  journal = {Radiology},
  pmid = {7063747}
}

@article{Hanley2003,
  title = {Statistical Analysis of Correlated Data Using Generalized Estimating Equations: {{An}} Orientation},
  author = {Hanley, James A. and Negassa, Abdissa and deB Edwardes, Michael D and Forrester, Janet E.},
  year = {2003},
  volume = {157},
  pages = {364--375},
  issn = {00029262},
  doi = {10.1093/aje/kwf215},
  abstract = {The method of generalized estimating equations (GEE) is often used to analyze longitudinal and other correlated response data, particularly if responses are binary. However, few descriptions of the method are accessible to epidemiologists. In this paper, the authors use small worked examples and one real data set, involving both binary and quantitative response data, to help end-users appreciate the essence of the method. The examples are simple enough to see the behind-the-scenes calculations and the essential role of weighted observations, and they allow nonstatisticians to imagine the calculations involved when the GEE method is applied to more complex multivariate data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JGHRALND\\hanley_et_al_2003_statistical_analysis_of_correlated_data_using_generalized_estimating_equations.pdf},
  isbn = {0002-9262; 0002-9262},
  journal = {American Journal of Epidemiology},
  keywords = {Correlation,Epidemiologic methods,Generalized estimating equation,Longitudinal studies,Odds ratio,Statistics},
  number = {4},
  pmid = {12578807}
}

@article{Hansson2015,
  title = {Complications and Patient-Reported Outcome after Hip Fracture. {{A}} Consecutive Annual Cohort Study of 664 Patients},
  author = {Hansson, Susanne and Rolfson, Ola and \AA kesson, Kristina and Nemes, Szilard and Leonardsson, Olof and Rogmark, Cecilia},
  year = {2015},
  volume = {46},
  pages = {2206--2211},
  issn = {18790267},
  doi = {10.1016/j.injury.2015.07.024},
  abstract = {Introduction The aim of every patient with hip fracture is to regain previous function but we know little about the outcome, especially patient-reported outcome. We wanted to investigate what factors influence the result one year after hip fracture, including fast-track for hip fracture patients, as well as investigating the patients' satisfaction with their rehabilitation and to what degree they regained their pre-fracture function. Methods All patients (\textquestiondown 20 years, non-pathological fracture, residents in the catchment area, n = 664) having surgery for hip fracture at our hospital during 2011 were included in a retrospective cohort study. From medical records, information was gathered about pre-fracture condition as well as fracture type, surgical details, length of stay and whether the patient entered the hospital through the fast-track system. Medical records were scrutinised for general complications up to six months and for local complications up to one year after surgery. A postal questionnaire was sent one year after surgery inquiring about health status, pain and satisfaction along with multiple-choice questions regarding mobility and rehabilitation. Variables were analysed with linear regression or the proportional odds model. Results The most common general complications were new falls, pneumonia and new fractures. Deep infection was the most frequent local complication. The only significant effect of the fast-track system was shorter time to surgery (78 vs. 62\% had surgery within 24 h, p \textexclamdown{} 0.001). A total of 29\% reported to have regained their previous mobility and 30\% considered the rehabilitation to be adequate. Mean value for pain VAS was 24 (SD 22) and for satisfaction 28 (SD 25). Absence of general and local complications correlated to satisfaction and hip pain. General complications correlated to loss of function. Higher age correlated to inadequate rehabilitation. Conclusion General complications seem to be the major risk factor, being the only factor affecting functional outcome and together with local complications affecting pain and satisfaction. To avoid general complications, co-operation between orthopaedic surgeons and internists may be crucial in the aftercare of hip fracture patients. A majority did not receive adequate rehabilitation and efforts need to be made to improve the rehabilitation process.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9ESVWLZG\\hansson_et_al_2015_complications_and_patient-reported_outcome_after_hip_fracture.pdf},
  isbn = {1879-0267 (Electronic) 0020-1383 (Linking)},
  journal = {Injury},
  keywords = {Complications,Fast-track,Function,Hip fracture,Patient-reported outcome},
  number = {11},
  pmid = {26298023}
}

@article{Hansson2017,
  title = {Reduced Risk of Reoperation after Treatment of Femoral Neck Fractures with Total Hip Arthroplasty: {{A}} Matched Pair Analysis},
  author = {Hansson, Susanne and Nemes, Szilard and K{\"a}rrholm, Johan and Rogmark, Cecilia},
  year = {2017},
  month = sep,
  volume = {88},
  pages = {500--504},
  publisher = {{Taylor \& Francis}},
  issn = {17453682},
  doi = {10.1080/17453674.2017.1348095},
  abstract = {Background and purpose \textemdash{} Femoral neck fractures (FNFs) are commonly treated with some kind of arthroplasty, but evidence on whether to use hemiarthroplasty (HA) or total hip arthro-plasty (THA) is lacking. HA reduces the risk of dislocation, but may lead to acetabular erosion. THA implies longer surgery and increased bleeding. THA may result in better function and health-related quality of life, but evidence is contradictory. We compared HA and THA and in terms of revision, reoperation and death. Patients and methods \textemdash{} Data were extracted from the Swedish Hip Arthroplasty Register for 11,253 patients with acute FNF receiving cemented HA or THA during 2008\textendash 2012. 2,902 patients with THA were matched by propensity score matching with as many patients with HA based on age, sex, BMI, and ASA classifi -cation. We used competing risks survival regression with reopera-tion or death and revision or death as endpoints. Results \textemdash{} THA patients had signifi cantly reduced risk of revi-sion (absolute risk reduction 0.51; 95\% CI 0.39\textendash 0.67) and reoper-ation (0.58; 0.46\textendash 0.74). THA was associated with an almost 50\% reduced mortality (risk ratio as competing risk for reoperation 0.51; 0.46\textendash 0.57). Interpretation \textemdash{} In our national register study of femoral neck fractures, THA had a lower risk than HA for further surgical pro-cedures related to the hip. The reasons for lower mortality after THA are not known. Despite matching, there might be a selec-tion of more healthy patients for this procedure, and other factors unknown to us, with or without relation to the choice of implant.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PKKTWEB9\\hansson_et_al_2017_reduced_risk_of_reoperation_after_treatment_of_femoral_neck_fractures_with.pdf},
  journal = {Acta Orthopaedica},
  number = {5},
  pmid = {28691547}
}

@article{Hansson2020,
  title = {More Hip Complications after Total Hip Arthroplasty than after Hemi\-arthroplasty as Hip Fracture Treatment: Analysis of 5,815 Matched Pairs in the {{Swedish Hip Arthroplasty Register}}},
  shorttitle = {More Hip Complications after Total Hip Arthroplasty than after Hemi\-arthroplasty as Hip Fracture Treatment},
  author = {Hansson, Susanne and B{\"u}low, Erik and Garland, Anne and K{\"a}rrholm, Johan and Rogmark, Cecilia},
  year = {2020},
  month = mar,
  volume = {91},
  pages = {133--138},
  issn = {1745-3674, 1745-3682},
  doi = {10.1080/17453674.2019.1690339},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EB2MNECR\\Hansson m. fl. - 2020 - More hip complications after total hip arthroplast.pdf},
  journal = {Acta Orthopaedica},
  keywords = {coder},
  language = {en},
  number = {2}
}

@article{Hardt2012,
  title = {Auxiliary Variables in Multiple Imputation in Regression with Missing {{X}}: {{A}} Warning against Including Too Many in Small Sample Research},
  author = {Hardt, Jochen and Herke, Max and Leonhart, Rainer},
  year = {2012},
  volume = {12},
  pages = {1--13},
  issn = {14712288},
  doi = {10.1186/1471-2288-12-184},
  abstract = {BACKGROUND: Multiple imputation is becoming increasingly popular. Theoretical considerations as well as simulation studies have shown that the inclusion of auxiliary variables is generally of benefit.: A simulation study of a linear regression with a response Y and two predictors X1 and X2 was performed on data with n = 50, 100 and 200 using complete cases or multiple imputation with 0, 10, 20, 40 and 80 auxiliary variables. Mechanisms of missingness were either 100\% MCAR or 50\% MAR + 50\% MCAR. Auxiliary variables had low (r=.10) vs. moderate correlations (r=.50) with X's and Y.: The inclusion of auxiliary variables can improve a multiple imputation model. However, inclusion of too many variables leads to downward bias of regression coefficients and decreases precision. When the correlations are low, inclusion of auxiliary variables is not useful.: More research on auxiliary variables in multiple imputation should be performed. A preliminary rule of thumb could be that the ratio of variables to cases with complete data should not go below 1 : 3.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\897CKAXP\\hardt_et_al_2012_auxiliary_variables_in_multiple_imputation_in_regression_with_missing_x.pdf},
  isbn = {1471-2288 (Electronic)1471-2288 (Linking)},
  journal = {BMC Medical Research Methodology},
  keywords = {Auxiliary variables,Multiple imputation,Simulation study,Small and medium size samples},
  pmid = {23216665}
}

@article{Hardy2014,
  title = {Hardy{\textsubscript{gh}}{$_{-}$}{\textsubscript{am}}athematician\textsubscript{s}{\textsubscript{a}}pology{$_{-}$}{\textsubscript{c}}ambridge},
  author = {Hardy, G H},
  year = {2014},
  keywords = {\#nosource}
}

@article{Hare1990,
  title = {The Revised Psychopathy Checklist: {{Reliability}} and Factor Structure},
  author = {Hare, Robert D. and Harpur, Timothy J. and Hakstian, A. R. and Forth, Adelle E. and Hart, Stephen D. and Newman, Joseph P.},
  year = {1990},
  volume = {2},
  pages = {338--341},
  issn = {10403590},
  doi = {10.1037/1040-3590.2.3.338},
  abstract = {The revised Psychopathy Checklist (PCL) is a 20-item scale scored from interview and file information. Analyses of data from 5 prison samples (N = 925) and 3 forensic psychiatric samples (N = 356) indicate that the revised PCL resembles its 22-item predecessor in all important respects. It has excellent psychometric properties, and it measures 2 correlated factors that were cross-validated both within and between samples. Correlations between the original PCL and the revised version approached unity for both the factors and the full scale. We conclude that the revised PCL measures the same construct as the original and that the PCL is a reliable and valid instrument for the assessment of psychopathy in male forensic populations.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KLB7G9VI\\hare_et_al_1990_the_revised_psychopathy_checklist.pdf},
  isbn = {1939-134X 1040-3590},
  journal = {Psychological Assessment},
  number = {3}
}

@article{Harrell1996,
  title = {Regression Coefficients and Scoring Rules},
  author = {Harrell, Frank},
  year = {1996},
  volume = {49},
  pages = {819},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(95)00068-2},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4STSJBKK\\harrell_1996_regression_coefficients_and_scoring_rules.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {7}
}

@article{Harrell1996,
  title = {Multivariable Prognostic Models: Issues in Developing Models, Evaluating Assumptions and Adequacy, and Measuring and Reducing Errors},
  author = {Harrell, Frank E. and Lee, Kerry L. and Mark, Daniel B.},
  year = {1996},
  month = feb,
  volume = {15},
  pages = {361--387},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A9BPYXJU\\harrell_et_al_1996_multivariable_prognostic_models.pdf},
  journal = {Statistics in Medicine},
  number = {4}
}

@article{Harrell1996,
  title = {Statistics in Medicine, Vol. 15,361-387 (1996)},
  author = {Harrell, Frank E and Lee, Kerry L and Mark, Daniel B},
  year = {1996},
  volume = {15},
  pages = {361--387},
  journal = {Statistics},
  keywords = {\#nosource}
}

@book{Harrell2015,
  title = {Regression Modeling Strategies : With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis},
  author = {Harrell, Frank E.},
  year = {2015},
  edition = {Second},
  publisher = {{Springer}},
  abstract = {Second edition. This highly anticipated second edition features new chapters and sections, 225 new references, and comprehensive R software. In keeping with the previous edition, this book is about the art and science of data analysis and predictive modeling, which entails choosing and using multiple tools. Instead of presenting isolated techniques, this text emphasizes problem solving strategies that address the many issues arising when developing multivariable models using real data and not standard textbook examples. It includes imputation methods for dealing with missing data effectively, methods for fitting nonlinear relationships and for making the estimation of transformations a formal part of the modeling process, methods for dealing with "too many variables to analyze and not enough observations," and powerful model validation techniques based on the bootstrap.\textcircledP{$\mathscr{l}$} The reader will gain a keen understanding of predictive accuracy, and the harm of categorizing continuous predictors or outcomes.\textcircledP{$\mathscr{l}$} This text realistically deals with model uncertainty, and its effects on inference, to achieve "safe data mining." It also presents many graphical methods for communicating complex regression models to non-statisticians. Regression Modeling Strategies presents full-scale case studies of non-trivial datasets instead of over-simplified illustrations of each method. These case studies use freely available R functions that make the multiple imputation, model building, validation, and interpretation tasks described in the book relatively easy to do. Most of the methods in this text apply to all regression models, but special emphasis is given to multiple regression using generalized least squares for longitudinal data, the binary logistic model, models for ordinal responses, parametric survival regression models, and the Cox semiparametric survival model.\textcircledP{$\mathscr{l}$} A new emphasis is given to the robust analysis of continuous dependent variables using ordinal regression. As in the first edition, this text is intended for Masters' or Ph. D. level graduate students who have had a general introductory probability and statistics course and who are well versed in ordinary multiple regression and intermediate algebra. The book will also serve as a reference for data analysts and statistical methodologists, as it contains an up-to-date survey and bibliography of modern statistical modeling techniques. Examples used in the text mostly come from biomedical research, but the methods are applicable anywhere predictive models ("analytics") are useful, including economics, epidemiology, sociology, psychology, engineering, and marketing. Introduction \textendash{} General Aspects of Fitting Regression Models \textendash{} Missing Data \textendash{} Multivariable Modeling Strategies \textendash{} Describing, Resampling, Validating and Simplifying the Model \textendash{} R Software \textendash{} Modeling Longitudinal Responses using Generalized Least Squares \textendash{} Case Study in Data Reduction \textendash{} Overview of Maximum Likelihood Estimation \textendash{} Binary Logistic Regression \textendash{} Binary Logistic Regression Case Study 1 \textendash{} Logistic Model Case Study 2: Survival of Titanic Passengers \textendash{} Ordinal Logistic Regression \textendash{} Case Study in Ordinal Regression, Data Reduction and Penalization.- Regression Models for Continuous Y and Case Study in Ordinal Regression \textendash{} Transform-Both-Sides Regression \textendash{} Introduction to Survival Analysis \textendash{} Parametric Survival Models \textendash{} Case Study in Parametric Survival Modeling and Model Approximation \textendash{} Cox Proportional Hazards Regression Model \textendash{} Case Study in Cox Regression \textendash{} Appendix.},
  isbn = {3-319-19424-0},
  keywords = {\#nosource}
}

@article{Harris2018,
  title = {American Joint Replacement Registry Risk Calculator Does Not Predict 90-Day Mortality in Veterans Undergoing Total Joint Replacement},
  author = {Harris, Alex H. S. and Kuo, Alfred C. and Bozic, Kevin J. and Lau, Edmund and Bowe, Thomas and Gupta, Shalini and Giori, Nicholas J.},
  year = {2018},
  volume = {476},
  pages = {1869--1875},
  issn = {0009-921X},
  doi = {10.1097/CORR.0000000000000377},
  abstract = {Water-cooled heat sinks are investigated both experimentally andas model systems to simulate the energy and mass transportdevices used for cooling of optoelectronic microsystems. The designthe micro-channel heat sinks results in a decrease of their thermaland of the pressure drop of the coolant allowing an increasedload of an optoelectronic microsystem such as diode laser.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\U9VWMRL5\\harris_et_al_2018_american_joint_replacement_registry_risk_calculator_does_not_predict_90-day.pdf},
  journal = {Clinical Orthopaedics and Related Research},
  number = {9}
}

@article{Harris2018a,
  title = {Prediction Models for 30-{{Day}} Mortality and Complications after Total Knee and Hip Arthroplasties for Veteran Health Administration Patients with Osteoarthritis},
  author = {Harris, Alex HS. and Kuo, Alfred C. and Bowe, Thomas and Gupta, Shalini and Nordin, David and Giori, Nicholas J.},
  year = {2018},
  month = may,
  volume = {33},
  pages = {1539--1545},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2017.12.003},
  abstract = {BACKGROUND Statistical models to preoperatively predict patients' risk of death and major complications after total joint arthroplasty (TJA) could improve the quality of preoperative management and informed consent. Although risk models for TJA exist, they have limitations including poor transparency and/or unknown or poor performance. Thus, it is currently impossible to know how well currently available models predict short-term complications after TJA, or if newly developed models are more accurate. We sought to develop and conduct cross-validation of predictive risk models, and report details and performance metrics as benchmarks. METHODS Over 90 preoperative variables were used as candidate predictors of death and major complications within 30 days for Veterans Health Administration patients with osteoarthritis who underwent TJA. Data were split into 3 samples\textemdash for selection of model tuning parameters, model development, and cross-validation. C-indexes (discrimination) and calibration plots were produced. RESULTS A total of 70,569 patients diagnosed with osteoarthritis who received primary TJA were included. C-statistics and bootstrapped confidence intervals for the cross-validation of the boosted regression models were highest for cardiac complications (0.75; 0.71-0.79) and 30-day mortality (0.73; 0.66-0.79) and lowest for deep vein thrombosis (0.59; 0.55-0.64) and return to the operating room (0.60; 0.57-0.63). CONCLUSIONS Moderately accurate predictive models of 30-day mortality and cardiac complications after TJA in Veterans Health Administration patients were developed and internally cross-validated. By reporting model coefficients and performance metrics, other model developers can test these models on new samples and have a procedure and indication-specific benchmark to surpass.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JMM286UP\\harris_et_al_2018_prediction_models_for_30-day_mortality_and_complications_after_total_knee_and.pdf},
  journal = {The Journal of Arthroplasty},
  number = {5}
}

@article{Harris2019,
  title = {Can Machine Learning Methods Produce Accurate and Easy-to-Use Prediction Models of 30-Day Complications and Mortality after Knee or Hip Arthroplasty?},
  author = {Harris, Alex H. S. and Kuo, Alfred C. and Weng, Yingjie and Trickey, Amber W. and Bowe, Thomas and Giori, Nicholas J.},
  year = {2019},
  month = feb,
  volume = {477},
  pages = {452--460},
  issn = {0009-921X},
  doi = {10.1097/CORR.0000000000000601},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5XF5CY3E\\Harris m. fl. - 2019 - Can machine learning methods produce accurate and .pdf},
  journal = {Clinical Orthopaedics and Related Research},
  keywords = {\#nosource},
  number = {2}
}

@article{Hastie2009,
  ids = {Mining2009},
  title = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  volume = {1},
  pages = {337--387},
  issn = {03436993},
  doi = {10.1007/b94608},
  abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
  isbn = {9780387848570},
  journal = {Elements},
  keywords = {\#nosource},
  pmid = {15512507}
}

@article{Hauck1977,
  title = {Wald's Test as Applied to Hypotheses in Logit Analysis},
  author = {Hauck, Walter W. and Donner, Allan},
  year = {1977},
  month = dec,
  volume = {72},
  pages = {851},
  issn = {01621459},
  doi = {10.2307/2286473},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {360}
}

@article{Havelin2011,
  title = {A Scandinavian Experience of Register Collaboration: The Nordic Arthroplasty Register Association ({{NARA}}).},
  author = {Havelin, Leif I. and Robertsson, Otto and Fenstad, Anne M. and Overgaard, S\o ren and Garellick, G{\"o}ran and Furnes, Ove},
  year = {2011},
  volume = {93 Suppl 3},
  pages = {13--19},
  issn = {15351386},
  doi = {10.2106/JBJS.K.00951},
  abstract = {Background: The Nordic (Scandinavian) countries have had working arthroplasty registers for several years. However,},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\787B5PFL\\havelin_et_al_2011_a_scandinavian_experience_of_register_collaboration.pdf},
  isbn = {1535-1386},
  journal = {The Journal of bone and joint surgery. American volume},
  keywords = {JBJS-A,The Journal of Bone and Joint Surgery},
  number = {E},
  pmid = {22262418}
}

@article{Hawker2013,
  title = {Which Patients Are Most Likely to Benefit from Total Joint Arthroplasty?},
  author = {Hawker, Gillian A. and Badley, Elizabeth M. and Borkhoff, Cornelia M. and Croxford, Ruth and Davis, Aileen M. and Dunn, Sheila and Gignac, Monique A. and Jaglal, Susan B. and Kreder, Hans J. and Sale, Joanna E M},
  year = {2013},
  volume = {65},
  pages = {1243--1252},
  issn = {00043591},
  doi = {10.1002/art.37901},
  abstract = {OBJECTIVE: To evaluate patient predictors of good outcome following total joint arthroplasty (TJA). METHODS: A population cohort with hip/knee arthritis (osteoarthritis [OA] or inflammatory arthritis) ages {$\geq$}55 years was recruited between 1996 and 1998 (baseline) and assessed annually for demographics, troublesome joints, health status, and overall hip/knee arthritis severity using the Western Ontario and McMaster Universities OA Index (WOMAC). Survey data were linked with administrative databases to identify primary TJAs. Good outcome was defined as an improvement in WOMAC summary score greater than or equal to the minimal important difference (MID; 0.5 SD of the mean change). Logistic regression and Akaike's information criterion were used to determine the optimal number of predictors and the best model of that size. Log Poisson regression was used to determine the relative risk (RR) for a good outcome. RESULTS: Primary TJA was performed in 202 patients (mean age 71.0 years; 79.7\% female; 82.7\% with \textquestiondown 1 troublesome hip/knee; 65.8\% knee replacements). Mean improvement in WOMAC summary score was 10.2 points (SD 18.05; MID 9 points). Of these patients, 53.5\% experienced a good outcome. Four predictors were optimal. The best 4-variable model included pre-TJA WOMAC, comorbidity, number of troublesome hips/knees, and arthritis type (C statistic 0.80). The probability of a good outcome was greater with worse (higher) pre-TJA WOMAC summary scores (adjusted RR 1.32 per 10-point increase; P \textexclamdown{} 0.0001), fewer troublesome hips/knees (adjusted RR 0.82 per joint; P = 0.002), OA (adjusted RR for rheumatoid arthritis versus OA 0.33; P = 0.009), and fewer comorbidities (adjusted RR per condition 0.88; P = 0.01). CONCLUSION: In an OA cohort with a high prevalence of multiple troublesome joints and comorbidity, only half achieved a good TJA outcome, defined as improved pain and disability. A more comprehensive assessment of the benefits and risks of TJA is warranted.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7FIINU7A\\hawker_et_al_2013_which_patients_are_most_likely_to_benefit_from_total_joint_arthroplasty.pdf},
  isbn = {1529-0131 (Electronic){\r  }0004-3591 (Linking)},
  journal = {Arthritis and Rheumatism},
  number = {5},
  pmid = {23459843}
}

@article{Hawkins1989,
  title = {Using {{U}} Statistics to Derive the Asymptotic Distribution of {{Fisher}}'s {{Z}} Statistic},
  author = {Hawkins, D L},
  year = {1989},
  volume = {43},
  pages = {235--237},
  issn = {00031305},
  doi = {10.2307/2685369},
  abstract = {Hogg, RV, and Craig, AT (1978), Introduction to Mathematical Sta- tistics (4th ed.), New York: Macmillan. Pitman, EG (1939), "A Note on Normal CorTelation," Biomnetrika, 31, 9-12. Snedecor, GW, and Cochran, WG (1980), Statistical Methods (7th ed.), Ames: Iowa State},
  journal = {American Statistician},
  keywords = {\#nosource},
  number = {4}
}

@article{Hayden2006,
  title = {Evaluation of the {{Quality}} of {{Prognosis Studies}} in {{Systematic Reviews}}},
  author = {Hayden, Jill A. and C{\^o}t{\'e}, Pierre and Bombardier, Claire},
  year = {2006},
  month = mar,
  volume = {144},
  pages = {427},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-144-6-200603210-00010},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CHR9WDGP\\Hayden et al. - 2006 - Evaluation of the Quality of Prognosis Studies in .pdf},
  journal = {Annals of Internal Medicine},
  keywords = {acta review},
  language = {en},
  number = {6}
}

@article{Hayden2013,
  title = {Assessing {{Bias}} in {{Studies}} of {{Prognostic Factors}}},
  author = {Hayden, Jill A. and {van der Windt}, Danielle A. and Cartwright, Jennifer L. and C{\^o}t{\'e}, Pierre and Bombardier, Claire},
  year = {2013},
  month = feb,
  volume = {158},
  pages = {280},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-158-4-201302190-00009},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QSSCLD6I\\Hayden et al_2013_Assessing Bias in Studies of Prognostic Factors.pdf},
  journal = {Annals of Internal Medicine},
  language = {en},
  number = {4}
}

@article{Haylock2006,
  title = {Downscaling Heavy Precipitation over the {{United Kingdom}}: {{A}} Comparison of Dynamical and Statistical Methods and Their Future Scenarios},
  author = {Haylock, Malcolm R. and Cawley, Gavin C. and Harpham, Colin and Wilby, Rob L. and Goodess, Clare M.},
  year = {2006},
  volume = {26},
  pages = {1397--1415},
  issn = {08998418},
  doi = {10.1002/joc.1318},
  abstract = {Six statistical and two dynamical downscaling models were compared with regard to their ability to downscale seven seasonal indices of heavy precipitation for two station networks in northwest and southeast England. The skill among the eight downscaling models was high for those indices and seasons that had greater spatial coherence. Generally, winter showed the highest downscaling skill and summer the lowest. The rainfall indices that were indicative of rainfall occurrence were better modelled than those indicative of intensity. Models based on non-linear artificial neural networks were found to be the best at modelling the inter-annual variability of the indices; however, their strong negative biases implied a tendency to underestimate extremes. A novel approach used in one of the neural network models to output the rainfall probability and the gamma distribution scale and shape parameters for each day meant that resampling methods could be used to circumvent the underestimation of extremes. Six of the models were applied to the Hadley Centre global circulation model HadAM3P forced by emissions according to two SRES scenarios. This revealed that the inter-model differences between the future changes in the downscaled precipitation indices were at least as large as the differences between the emission scenarios for a single model. This implies caution when interpreting the output from a single model or a single type of model (e.g. regional climate models) and the advantage of including as many different types of downscaling models, global models and emission scenarios as possible when developing climate-change projections at the local scale.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PB3WMA4P\\haylock_et_al_2006_downscaling_heavy_precipitation_over_the_united_kingdom.pdf},
  isbn = {08998418 (ISSN)},
  journal = {International Journal of Climatology},
  keywords = {Climate-change scenarios,Downscaling,Extremes,Precipitation,United Kingdom},
  number = {10}
}

@article{Haynes1995,
  title = {An Assessment of the Consistency of {{ASA}} Physical Status Classification Allocation.},
  author = {Haynes, S R and Lawler, P G},
  year = {1995},
  month = mar,
  volume = {50},
  pages = {195--9},
  issn = {0003-2409},
  abstract = {The American Society of Anesthesiologists' (ASA) Physical Status Classification was tested for consistency of use by anaesthetists. A postal questionnaire was sent to 113 anaesthetists of varying experience working in the Northern Region of England. They were asked to allot ASA grades to 10 hypothetical patients. Ninety-seven (85.8\%) responded to two mailings. In no case was there complete agreement on ASA grade, and in only one case were responses restricted to two of the five possible grades. In one case there was a significant difference in answers between anaesthetists with the FRCA (or equivalent) qualification, and those without. So much variation was observed between individual anaesthetist's assessments when describing common clinical problems that the ASA grade alone cannot be considered to satisfactorily describe the physical status of a patient.},
  journal = {Anaesthesia},
  keywords = {\#nosource},
  number = {3},
  pmid = {7717481}
}

@article{Heagerty2000,
  title = {Time-Dependent {{ROC}} Curves for Censored Survival Data and a Diagnostic Marker},
  author = {Heagerty, Patrick J and Lumley, Thomas and Pepe, Margaret S},
  year = {2000},
  month = may,
  volume = {56},
  pages = {337--344},
  publisher = {{Wiley/Blackwell (10.1111)}},
  issn = {0006-341X},
  doi = {10.1111/j.0006-341X.2000.00337.x},
  abstract = {Summary. ROC curves are a popular method for displaying sensitivity and specificity of a continuous marker, X, for a binary disease variable, D. However, many disease outcomes are time dependent, D(t, and ROC curves that vary as a function of time may be mire appropriate. A common examples of a time-dependent variable is vital status, where D(t) = 1 if a patient has died prior to time t and zero otherwise. We propose summarizing the discrimination potential of a marker X, measured at baseline (t= 0), by calculating ROC Curves for cumulative disease or death incidence by time t, which we denote as ROC(t). A typical complexity with survival data is that observations may be censored. Two ROC curve estimators are proposed that can accommodate censored data. A simple estimator is based on using the Kaplan-Meier estimated for each possible subset X \textquestiondown{} c. However, this estimator does not guarantee the necessary condition that sensitivity and specificity are monotone in X. An alternative estimator that does guarantee monotonicity is based on a nearest neighbor estimator for the bivariate distribution function of (X, T), where T represents survival time (Akritas, M. J., 1994, Annals of Statistics22, 1299?1327). We present an example where ROC(t) is used to compare a standard and a modified flow cytometry measurement for predicting survival after detection of breast cancer and an example where the ROC(t) curve displays the impact of modifying eligibility criteria for sample size and power in HIV prevention trials.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZJW8GVLK\\heagerty_et_al_2000_time-dependent_roc_curves_for_censored_survival_data_and_a_diagnostic_marker.pdf},
  journal = {Biometrics},
  keywords = {Accuracy,Discrimination,Kaplan-Meier estimator,Kernel smoothing,Sensitivity,Specificity},
  number = {2}
}

@article{Heagerty2000a,
  title = {Marginalized Multilevel Models and Likelihood Inference},
  author = {Heagerty, Patrick J and Zeger, Scott L},
  year = {2000},
  volume = {15},
  pages = {1--26},
  journal = {Statistical Science},
  keywords = {\#nosource,and phrases,generalized linear model,latent variable,logis-,random effects model,tic regression},
  number = {1}
}

@article{Heagerty2005,
  title = {Survival Model Predictive Accuracy and {{ROC}} Curves.},
  author = {Heagerty, Patrick J and Zheng, Yingye},
  year = {2005},
  month = mar,
  volume = {61},
  pages = {92--105},
  issn = {0006-341X},
  doi = {10.1111/j.0006-341X.2005.030814.x},
  abstract = {The predictive accuracy of a survival model can be summarized using extensions of the proportion of variation explained by the model, or R2, commonly used for continuous response models, or using extensions of sensitivity and specificity, which are commonly used for binary response models. In this article we propose new time-dependent accuracy summaries based on time-specific versions of sensitivity and specificity calculated over risk sets. We connect the accuracy summaries to a previously proposed global concordance measure, which is a variant of Kendall's tau. In addition, we show how standard Cox regression output can be used to obtain estimates of time-dependent sensitivity and specificity, and time-dependent receiver operating characteristic (ROC) curves. Semiparametric estimation methods appropriate for both proportional and nonproportional hazards data are introduced, evaluated in simulations, and illustrated using two familiar survival data sets.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZM9IBNHK\\heagerty_zheng_2005_survival_model_predictive_accuracy_and_roc_curves.pdf},
  journal = {Biometrics},
  keywords = {Biliary,Biliary: drug therapy,Biliary: mortality,Biometry,Humans,Liver Cirrhosis,Lung Neoplasms,Lung Neoplasms: mortality,Lung Neoplasms: therapy,Models,Penicillamine,Penicillamine: therapeutic use,Predictive Value of Tests,Proportional Hazards Models,Randomized Controlled Trials as Topic,Randomized Controlled Trials as Topic: methods,Randomized Controlled Trials as Topic: statistics,Risk,ROC Curve,Sensitivity and Specificity,Statistical,Survival Analysis,Time Factors},
  number = {1},
  pmid = {15737082}
}

@article{Helland1987,
  title = {On the Interpretation and Use of {{R2}} in Regression Analysis},
  author = {Helland, Inge S},
  year = {1987},
  volume = {43},
  pages = {61--69},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006341X, 15410420},
  doi = {10.2307/2531949},
  abstract = {The coefficient of determination (or squared multiple correlation coefficient) R2 is a common output from computer regression packages. We argue first that this statistic can be interpreted as an estimator of a population parameter only when the regressors are random. In such a model the variation of R2 is discussed, and a simple approximate confidence interval for the population coefficient of determination is proposed. Its use is illustrated on data from computerized tomography investigation of pigs.},
  journal = {Biometrics},
  keywords = {\#nosource},
  number = {1}
}

@article{helweg-larsenDanishRegisterCauses2011,
  title = {The {{Danish}} Register of Causes of Death},
  author = {{Helweg-Larsen}, Karin},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {26--29},
  issn = {14034948},
  doi = {10.1177/1403494811399958},
  abstract = {Introduction: Cause-specific mortality statistics is a valuable source for the identification of risk factors for poor public health. Content: Since 1875, the National Board of Health has maintained the register covering all deaths among citizens dying in Denmark, and since 1970 has computerised individual records. Validity and coverage: Classification of cause(s) of deaths is done in accordance to WHO's rules, since 1994 by ICD-10 codes. A change in coding practices and a low autopsy rate might influence the continuity and validity in cause-specific mortality. Conclusion: The longstanding national registration of causes of death is essential for much research. The quality of the register on causes of death relies mainly upon the correctness of the physicians' notification and the coding in the National Board of Health. \textcopyright{} 2011 the Nordic Societies of Public Health.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZIFLNHUE\\helweg-larsen_2011_the_danish_register_of_causes_of_death.pdf},
  journal = {Scandinavian Journal of Public Health},
  keywords = {Cause of death,coding,content,Denmark,register,validity},
  number = {7},
  pmid = {21775346}
}

@article{Hendler2014,
  title = {Data Integration for Heterogenous Datasets},
  author = {Hendler, James},
  year = {2014},
  volume = {2},
  pages = {205--215},
  issn = {2167-6461},
  doi = {10.1089/big.2014.0068},
  abstract = {More and more, the needs of data analysts are requiring the use of data outside the control of their own organizations. The increasing amount of data available on the Web, the new technologies for linking data across datasets, and the increasing need to integrate structured and unstructured data are all driving this trend. In this article, we provide a technical overview of the emerging "broad data" area, in which the variety of heterogeneous data being used, rather than the scale of the data being analyzed, is the limiting factor in data analysis efforts. The article explores some of the emerging themes in data discovery, data integration, linked data, and the combination of structured and unstructured data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CCSQ34NQ\\hendler_2014_data_integration_for_heterogenous_datasets.pdf},
  isbn = {2167-6461 (Print)2167-6461},
  journal = {Big Data},
  number = {4},
  pmid = {25553272}
}

@article{Herbert2017,
  title = {Data Resource Profile: {{Hospital}} Episode Statistics Admitted Patient Care ({{HES APC}})},
  author = {Herbert, Annie and Wijlaars, Linda and Zylbersztejn, Ania and Cromwell, David and Hardelid, Pia},
  year = {2017},
  month = aug,
  volume = {46},
  pages = {1093-1093i},
  issn = {0300-5771},
  doi = {10.1093/ije/dyx015},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XPM3PHWE\\herbert_et_al_2017_data_resource_profile.pdf},
  journal = {International Journal of Epidemiology},
  number = {4}
}

@article{Herberts2014,
  title = {Registrens Historia: {{Svenska}} Registren Blev Internationell F\"orebild},
  author = {Herberts, Peter},
  year = {2014},
  volume = {2},
  pages = {12--14},
  journal = {Ortopediskt Magasin},
  keywords = {\#nosource}
}

@article{Herdman2011,
  title = {Development and Preliminary Testing of the New Five-Level Version of {{EQ}}-{{5D}} ({{EQ}}-{{5D}}-{{5L}})},
  author = {Herdman, M. and Gudex, C. and Lloyd, A. and Janssen, MF. and Kind, P. and Parkin, D. and Bonsel, G. and Badia, X.},
  year = {2011},
  month = dec,
  volume = {20},
  pages = {1727--1736},
  publisher = {{Springer Netherlands}},
  issn = {0962-9343},
  doi = {10.1007/s11136-011-9903-x},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7CCLZI2V\\herdman_et_al_2011_development_and_preliminary_testing_of_the_new_five-level_version_of_eq-5d.pdf},
  journal = {Quality of Life Research},
  number = {10}
}

@book{hermerenGodForskningssed2011,
  title = {God Forskningssed},
  author = {Hermer{\'e}n, G{\"o}ran},
  year = {2011},
  issn = {21583226},
  doi = {10.1063/1.4944399},
  abstract = {Research ethics is not static, neither as a discipline nor as a practice. Whenscientific landscape changes, sometimes the debate about researchshifts as well. New principles may be added, and old ones may need to be reinterpreted or applied differently.considerations in research are largely a matter of finding a reasonable balance between various interests that are all legitimate. One such interest is our quest for knowledge. Individual privacy interests as well as protection against various forms of harm or risk of harm are other legitimate interests. But sometimes new knowledge can only be gained if research subjects and participants are exposed to a certain degree of risk. The harm and risks involved may vary considerably depending on the disciplinary domain.different kinds of research call for different types of considerations.-benefit assessments can be performed in several ways, and ethicalsystems \textendash{} whose purpose it is to promote the quest for knowledgeto look after the interests of participants \textendash{} are not identical acrossfields. Ethical regulations of research are comprehensive, and what is applicable may vary. However, the purpose of this book is to discuss the overarching issues of research ethics that can emerge during the research process.book addresses relevant legislation and ethical requirements and recommendations against the background of questions that may arise in research work. Generally speaking, these questions may involve diverse approaches, responsibilities, conflicts of interest, methods, reliability, etc.specifically, it is vital to know that some research requires permission.holds for research targeting humans and research involving animal experiments, but for some other types of research as well. When the material collected and analyzed is sensitive in terms of the privacy of individuals, ethical issues are often related to differing interests of researchers, participating, other researchers, to what the researcher may promise, who owns the research material, etc.current changes in the conditions for and organization of research, in Sweden and abroad, raise new challenges for research ethics. For instance, against this backdrop, considerations of research ethics arise in connection with questions of responsibility in multicenter studies and major international projects. Clear assignments of responsibility are important, and the coordinating research director at the national or international level is responsible for anticipating potential problems that might be encountered in the course of the research work and for taking measures to avert or prevent them.publication of research findings is a precondition for these findingsbe useful, either for immediate application or as a piece of the puzzlethe ongoing quest for knowledge. Who is entitled to stand as author is, not only in terms of career opportunities but also in regard toof responsibility. The roles of peer reviewer, executive editor, andraise their own special ethical questions. This is also true of the's role as a thesis supervisor, a teacher, and an expert.problem of research ethics that often attracts attention, also in the, concerns academic fraud and misconduct. This can be a matter ofresults, plagiarism, and doctoring data, but also of libel, sabotage, misrepresentation of one's own qualifications in connection with applications for grants or positions, etc. When fraud is suspected, it is imperativeit be dealt with fairly, under the rule of law, and that there be a clearuniform system of sanctions.is thus a multitude of laws, directives, guidelines, and ethicalfor research and for professions that researchers should know about and observe in order to perform their work in both a legal and an ethically well-considered manner.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Y5LT7DQA\\hermerén_2011_god_forskningssed.pdf},
  isbn = {978-91-7307-189-5}
}

@book{hernanCausalInference2019,
  title = {Causal Inference},
  author = {Hern{\'a}n, MA and Robins, JM},
  year = {2019},
  edition = {beta},
  publisher = {{Chapman \& Hall/CRC}},
  keywords = {\#nosource}
}

@article{hernanHazardsHazardRatios2010,
  title = {The Hazards of Hazard Ratios},
  author = {Hern{\'a}n, Miguel A.},
  year = {2010},
  volume = {21},
  pages = {13--15},
  issn = {10443983},
  doi = {10.1097/EDE.0b013e3181c1ea43},
  abstract = {Editors' note: This series addresses topics that affect epidemiologists across a range of specialties. Commentaries start as invited talks at symposia organized by the Editors. This paper was presented at the 2009 Society for Epidemiologic Research Annual Meeting in Anaheim, CA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4CC8GRSQ\\hernán_2010_the_hazards_of_hazard_ratios.pdf},
  isbn = {1531-5487; 1531-5487},
  journal = {Epidemiology},
  number = {1},
  pmid = {20010207}
}

@article{hernanStructuralApproachSelection2004,
  title = {A Structural Approach to Selection Bias},
  author = {Hern{\'a}n, Miguel A. and {Hernandez-Diaz}, S and Robins, James M. and {Hern{\'a}ndez-D{\'i}az}, Sonia and Robins, James M.},
  year = {2004},
  volume = {15},
  pages = {615--625},
  issn = {10443983},
  doi = {00001648-200409000-00020 [pii]},
  abstract = {The term "selection bias" encompasses various biases in epidemiology. We describe examples of selection bias in case-control studies (eg, inappropriate selection of controls) and cohort studies (eg, informative censoring). We argue that the causal structure underlying the bias in each example is essentially the same: conditioning on a common effect of 2 variables, one of which is either exposure or a cause of exposure and the other is either the outcome or a cause of the outcome. This structure is shared by other biases (eg, adjustment for variables affected by prior exposure). A structural classification of bias distinguishes between biases resulting from conditioning on common effects ("selection bias") and those resulting from the existence of common causes of exposure and outcome ("confounding"). This classification also leads to a unified approach to adjust for selection bias.},
  isbn = {1044-3983 (Print){\r  }1044-3983 (Linking)},
  journal = {Epidemiology},
  keywords = {\#nosource,Case-Control Studies,Disease/etiology,Environmental Exposure/adverse effects,Epidemiologic Methods,Epidemiologic Research Design,Evaluation Studies as Topic,Humans,Longitudinal Studies,Models,Research,Research Subjects,Risk Factors,Selection Bias,Theoretical},
  number = {5},
  pmid = {15308962}
}

@article{Heskes1997,
  title = {Practical Conndence and Prediction Intervals},
  author = {Heskes, Tom},
  year = {1997},
  volume = {9},
  pages = {176--182},
  doi = {10.1.1.56.3753},
  abstract = {We propose a new method to compute prediction intervals. Especially for small data sets the width of a prediction interval does not only de-pend on the variance of the target distribution, but also on the accuracy of our estimator of the mean of the target, i.e., on the width of the con-dence interval. The conndence interval follows from the variation in an ensemble of neural networks, each of them trained and stopped on bootstrap replicates of the original data set. A second improvement is the use of the residuals on validation patterns instead of on training patterns for estimation of the variance of the target distribution. As illustrated on a synthetic example, our method is better than existing methods with regard to extrapolation and interpolation in data regimes with a limited amount of data, and yields prediction intervals which actual conndence levels are closer to the desired conndence levels.},
  journal = {Advances in neural information processing systems},
  keywords = {\#nosource}
}

@article{Hess1999,
  title = {Hazard Function Estimators: A Simulation Study},
  author = {Hess, Kenneth R and Serachitopol, Dan M and Brown, Barry W},
  year = {1999},
  month = oct,
  volume = {18},
  pages = {3075--3088},
  publisher = {{Wiley-Blackwell}},
  issn = {0277-6715},
  doi = {10.1002/(SICI)1097-0258(19991130)18:22<3075::AID-SIM244>3.0.CO;2-6},
  abstract = {Abstract Kernel-based methods for the smooth, non-parametric estimation of the hazard function have received considerable attention in the statistical literature. Although the mathematical properties of the kernel-based hazard estimators have been carefully studied, their statistical properties have not. We reviewed various kernel-based methods for hazard function estimation from right-censored data and compared the statistical properties of these estimators through computer simulations. Our simulations covered seven distributions, three levels of random censoring, four types of bandwidth functions, two sample sizes and three types of boundary correction. We conducted a total of 504 simulation experiments with 500 independent samples each. Our results confirmed the advantages of two recent innovations in kernel estimation ? boundary correction and locally optimal bandwidths. The median relative improvement (decrease) in mean square error over fixed-bandwidth estimators without boundary correction was 3 per cent for fixed-bandwidth estimators with left boundary correction, 52 per cent locally optimal bandwidths without boundary correction, and 66 per cent for locally optimal bandwidths with left boundary correction. The locally optimal bandwidth estimators with left boundary correction also outperformed three previously published and publicly available algorithms, with median relative improvements in mean square error of 31 per cent, 77 per cent and 80 per cent. Copyright ? 1999 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8L4AWMV3\\hess_et_al_1999_hazard_function_estimators.pdf},
  journal = {Statistics in Medicine},
  number = {22}
}

@article{Hesterberg2014,
  title = {What Teachers Should Know about the Bootstrap: {{Resampling}} in the Undergraduate Statistics Curriculum},
  author = {Hesterberg, Tim C.},
  year = {2014},
  volume = {69},
  pages = {371--386},
  issn = {15372731},
  doi = {10.1080/00031305.2015.1089789},
  abstract = {I have three goals in this article: (1) To show the enormous potential of bootstrapping and permutation tests to help students understand statistical concepts including sampling distributions, standard errors, bias, confidence intervals, null distributions, and P-values. (2) To dig deeper, understand why these methods work and when they don't, things to watch out for, and how to deal with these issues when teaching. (3) To change statistical practice\textemdash by comparing these methods to common t tests and intervals, we see how inaccurate the latter are; we confirm this with asymptotics. n \textquestiondown = 30 isn't enough\textemdash think n \textquestiondown = 5000. Resampling provides diagnostics, and more accurate alternatives. Sadly, the common bootstrap percentile interval badly under-covers in small samples; there are better alternatives. The tone is informal, with a few stories and jokes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3UVY52TS\\hesterberg_2014_what_teachers_should_know_about_the_bootstrap.pdf},
  journal = {arXiv preprint},
  keywords = {Bias,bootstrap,Confidence intervals,permutation test,randomization test,Sampling distribution,Standard error,Statistical concepts,teaching,Teaching},
  number = {June 2016},
  pmid = {27019512}
}

@article{Hidalgo2013,
  title = {Multivariate or Multivariable Regression?},
  author = {Hidalgo, Bertha and Goodman, Melody},
  year = {2013},
  volume = {103},
  pages = {39--40},
  issn = {00900036},
  doi = {10.2105/AJPH.2012.300897},
  abstract = {The terms multivariate and multivariable are often used interchangeably in the public health literature. However, these terms actually represent 2 very distinct types of analyses. We define the 2 types of analysis and assess the prevalence of use of the statistical term multivariate in a 1-year span of articles published in the American Journal of Public Health. Our goal is to make a clear distinction and to identify the nuances that make these types of analyses so distinct from one another.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XCZTI2WH\\hidalgo_goodman_2013_multivariate_or_multivariable_regression.pdf},
  isbn = {9781581107142},
  journal = {American Journal of Public Health},
  number = {1},
  pmid = {23153131}
}

@article{Higuera2011,
  title = {2010 {{Mid}}-{{America Orthopaedic Association Physician}} in {{Training Award}}: {{Predictors}} of {{Early Adverse Outcomes}} after {{Knee}} and {{Hip Arthroplasty}} in {{Geriatric Patients}}},
  shorttitle = {2010 {{Mid}}-{{America Orthopaedic Association Physician}} in {{Training Award}}},
  author = {Higuera, Carlos A. and Elsharkawy, Karim and Klika, Alison K. and Brocone, Matthew and Barsoum, Wael K.},
  year = {2011},
  month = may,
  volume = {469},
  pages = {1391--1400},
  issn = {0009-921X, 1528-1132},
  doi = {10.1007/s11999-011-1804-3},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GDZGSVZA\\Higuera et al_2011_2010 Mid-America Orthopaedic Association Physician in Training Award.pdf},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  language = {en},
  number = {5}
}

@article{Hills2001,
  title = {Stratification and Statistical Modelling in Epidemiology},
  author = {Hills, Michael and Clayton, David},
  year = {2001},
  volume = {7},
  keywords = {\#nosource}
}

@article{Hindmarsh2014,
  title = {Effect of Comorbidity on Relative Survival Following Hospitalisation for Fall-Related Hip Fracture in Older People},
  author = {Hindmarsh, Diane and Loh, Ming and Finch, Caroline F. and Hayen, Andrew and Close, Jacqueline Ct},
  year = {2014},
  volume = {33},
  pages = {E1-E7},
  issn = {17416612},
  doi = {10.1111/j.1741-6612.2012.00638.x},
  abstract = {AIM: To assess the effect of comorbidity on relative survival after hip fracture.: Relative survival analysis was undertaken in 16 838 fall-related hip fracture hospitalisations in New South Wales, Australia. Comorbidity was measured on the basis of additional diagnosis codes on the same hospital separation as the hip fracture using the Charlson Comorbidity Index (CCI). Interval-specific relative survival and relative excess risk of death were calculated.: Comorbidity was more frequently documented in men than women across the age groups. Survival decreased with increasing age and increasing comorbidity, but the relative impact of comorbidity was greater in the younger-old age group (65-74 years). The excess mortality in men was not accounted for by age or comorbidities.: This study demonstrates an association between increasing comorbidity and death particularly in the first 3 months post hip fracture. It also highlights a relative excess risk of death in men after hip fracture after adjusting for age and comorbidity.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MCDGINZS\\hindmarsh_et_al_2014_effect_of_comorbidity_on_relative_survival_following_hospitalisation_for.pdf},
  journal = {Australasian Journal on Ageing},
  keywords = {Aged,Comorbidity,Fall,Hip fracture,Mortality},
  number = {3},
  pmid = {24521513}
}

@article{Ho2007,
  title = {Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference},
  author = {Ho, Daniel E. and Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
  year = {2007},
  volume = {15},
  pages = {199--236},
  issn = {10471987},
  doi = {10.1093/pan/mpl013},
  abstract = {Although published works rarely include causal estimates from morea few model specifications, authors usually choose the presentedfrom numerous trial runs readers never see. Given the oftenvariation in estimates across choices of control variables,forms, and other modeling assumptions, how can researchersthat the few estimates presented are accurate or representative?do readers know that publications are not merely demonstrationsit is possible to find a specification that fits the author'shypothesis? And how do we evaluate or even define statisticallike unbiasedness or mean squared error when no uniqueor estimator even exists? Matching methods, which offer theof causal inference with fewer assumptions, constitute oneway forward, but crucial results in this fast-growing methodologicalare often grossly misinterpreted. We explain how to avoidmisinterpretations and propose a unified approach that makespossible for researchers to preprocess data with matching (suchwith the easy-to-use software we offer) and then to apply theparametric techniques they would have used anyway. This procedureparametric models produce more accurate and considerably less-dependent causal inferences.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DVNA9BNF\\ho_et_al_2007_matching_as_nonparametric_preprocessing_for_reducing_model_dependence_in.pdf},
  isbn = {1047198714764989},
  journal = {Political Analysis},
  number = {3},
  pmid = {194669130}
}

@article{Ho2011,
  title = {{{MatchIt}} : {{Nonparametric}} Preprocessing for Parametric Causal Inference},
  author = {Ho, Daniel E. and Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
  year = {2011},
  volume = {42},
  issn = {1548-7660},
  doi = {10.18637/jss.v042.i08},
  abstract = {MatchIt implements the suggestions of Ho, Imai, King, and Stuart (2007) for improv- ing parametric statistical models by preprocessing data with nonparametric matching methods. MatchIt implements a wide range of sophisticated matching methods, making it possible to greatly reduce the dependence of causal inferences on hard-to-justify, but commonly made, statistical modeling assumptions. The software also easily fits into ex- isting research practices since, after preprocessing data with MatchIt, researchers can use whatever parametric model they would have used without MatchIt, but produce infer- ences with substantially more robustness and less sensitivity to modeling assumptions. MatchIt is an R program, and also works seamlessly with Zelig.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JQM6PFE2\\ho_et_al_2011_matchit.pdf},
  isbn = {1548-7660},
  journal = {Journal of Statistical Software},
  number = {8}
}

@article{Hodges2019,
  title = {Statistical Methods Research Done as Science Rather than Mathematics},
  author = {Hodges, James S.},
  year = {2019},
  pages = {1--25},
  abstract = {This paper is about how we study statistical methods. As an example, it uses the random regressions model, in which the intercept and slope of cluster-specific regression lines are modeled as a bivariate random effect. Maximizing this model's restricted likelihood often gives a boundary value for the random effect correlation or variances. We argue that this is a problem; that it is a problem because our discipline has little understanding of how contemporary models and methods map data to inferential summaries; that we lack such understanding, even for models as simple as this, because of a near-exclusive reliance on mathematics as a means of understanding; and that math alone is no longer sufficient. We then argue that as a discipline, we can and should break open our black-box methods by mimicking the five steps that molecular biologists commonly use to break open Nature's black boxes: design a simple model system, formulate hypotheses using that system, test them in experiments on that system, iterate as needed to reformulate and test hypotheses, and finally test the results in an "in vivo" system. We demonstrate this by identifying conditions under which the random-regressions restricted likelihood is likely to be maximized at a boundary value. Resistance to this approach seems to arise from a view that it lacks the certainty or intellectual heft of mathematics, perhaps because simulation experiments in our literature rarely do more than measure a new method's operating characteristics in a small range of situations. We argue that such work can make useful contributions including, as in molecular biology, the findings themselves and sometimes the designs used in the five steps; that these contributions have as much practical value as mathematical results; and that therefore they merit publication as much as the mathematical results our discipline esteems so highly.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\23INDRPH\\hodges_2019_statistical_methods_research_done_as_science_rather_than_mathematics.pdf}
}

@article{Hoenig2001,
  title = {The Abuse of Power: {{The}} Pervasive Fallacy of Power Calculations for Data Analysis},
  author = {Hoenig, John M. and Heisey, Dennis M.},
  year = {2001},
  volume = {55},
  pages = {19--24},
  issn = {00031305},
  doi = {10.1198/000313001300339897},
  abstract = {It is well known that statistical power calculations can be valuable in planning an experiment. There is also a large lit- erature advocating that power calculations be made when- ever one performs a statistical test of a hypothesis and one obtains a statistically nonsignificant result. Advocates of such post-experiment power calculations claim the calcu- lations should be used to aid in the interpretation of the experimental results. This approach, which appears in vari- ous forms, is fundamentally flawed. We document that the problem is extensive and present arguments to demonstrate the flaw in the logic.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TGKKSFF9\\hoenig_heisey_2001_the_abuse_of_power.pdf},
  isbn = {0003-1305},
  journal = {American Statistician},
  keywords = {Bioequivalence testing,Burden of proof,Observed power,Retrospective power analysis,Statistical power,Type II error},
  number = {1},
  pmid = {11310512}
}

@article{Hoeting1999,
  title = {Bayesian Model Averaging: A Tutorial},
  author = {a Hoeting, Jennifer and Madigan, David and Raftery, Adrian E and Volinsky, C T},
  year = {1999},
  volume = {14},
  pages = {382--417},
  issn = {08834237},
  doi = {10.2307/2676803},
  abstract = {Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. Bayesian model averaging (BMA) provides a coherent mechanism for accounting for this model uncertainty. Several methods for implementing BMA have recently emerged. We discuss these methods and present a number of examples. In these examples, BMA provides improved out-of- sample predictive performance. We also provide a catalogue of currently available BMA software.},
  journal = {Statistical Science},
  keywords = {\#nosource,Bayesian graphical models,Bayesian model averaging,learning,Markov chain Monte Carlo.,model uncertainty},
  number = {4}
}

@article{Hoffman2001,
  title = {Within-Cluster Resampling},
  author = {Hoffman, E. B. and Sen, P. K. and Weinberg, C. R.},
  year = {2001},
  volume = {88},
  pages = {1121--1134},
  issn = {0006-3444},
  doi = {10.1093/biomet/88.4.1121},
  abstract = {Hoffman et al. [1] proposed an elegant resampling method for analyzing clustered binary data. The focus of their paper was to perform association tests on clustered binary data using within-cluster-resampling (WCR) method. Follmann et al. [2] extended Hoffman et al.'s procedure more generally with applicability to angular data, combining of p-values, testing of vectors of parameters, and Bayesian inference. Follmann et al. [2] termed their procedure multiple outputation because all "excess" data within each cluster is thrown out multiple times. Herein, we refer to this procedure as WCR-MO. For any statistical test to be useful for a particular design, it must be robust, have adequate power, and be easy to implement and flexible. WCR-MO can be easily extended to continuous data and is a computationally intensive but simple and highly flexible method. Considering family as a cluster, one can apply WCR to familial data in genetic studies. Using simulations, we evaluated WCR-MO's robustness for analysis of a continuous trait in terms of type I error rates in genetic research. WCR-MO performed well at the 5\% {$\alpha$}-level. However, it provided inflated type I error rates for {$\alpha$}-levels less than 5\% implying the procedure is liberal and may not be ready for application to genetic studies where {$\alpha$} levels used are typically much less than 0.05.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HQ27AN33\\hoffman_et_al_2001_within-cluster_resampling.pdf},
  journal = {Biometrika},
  number = {4}
}

@article{Hofstede2016,
  title = {Preoperative Predictors for Outcomes after Total Hip Replacement in Patients with Osteoarthritis: A Systematic Review.},
  author = {Hofstede, Stefanie N and Gademan, Maaike G J and Vlieland, Thea P M Vliet and Nelissen, Rob G H H and {de Mheen}, Perla J Marang-van},
  year = {2016},
  volume = {17},
  pages = {212},
  issn = {1471-2474},
  doi = {10.1186/s12891-016-1070-3},
  abstract = {BACKGROUND This systematic review examines which patient related factors influence functional and clinical outcomes after total hip arthroplasty (THA) in patients with hip osteoarthritis (OA). METHODS We performed a systematic review according to the PRISMA guidelines. We searched databases and trial registries for prospective studies including OA patients who underwent primary THA. Studies with preoperative measurements on predictors, with at least 1 year follow-up were included. Risk of bias and confounding was assessed for two domains: follow-up rate and looking at independent effects. RESULTS Thirty-five studies were included (138,039 patients). Only nine studies (29 \%) had low risk of bias for all domains thus suggesting an overall low quality of evidence. Studies were heterogeneous in the predictors tested and in the observed directions of the associations. Overall, preoperative function (13 studies (37 \%), 2 with low risk of bias) and radiological OA (6 studies (17 \%), 1 with low risk of bias) were predictors with the most consistent findings. Worse preoperative function and more severe radiological OA were associated with larger postoperative improvement. However, these patients never reached the level of postoperative functioning as patients with better preoperative function or less severe radiological OA. For age, gender, comorbidity, pain and quality of life the results of studies were conflicting. For BMI, some studies (n = 5, 2 with low risk of bias) found worse outcomes for patients with higher BMI. However, substantial improvement was still achieved regardless of their BMI. CONCLUSION There is not enough evidence to draw succinct conclusions on preoperative predictors for postoperative outcome in THA, as results of studies are conflicting and the methodological quality is low. Results suggest to focus on preoperative function and radiological osteoarthritis to decide when THA will be most effective. The present mapping of current evidence on the relationship between patient related factors and outcomes provides better information compared to individual studies and may help to set patient expectations before surgery. In addition, these findings may contribute to discussions on how to achieve the best possible postoperative outcome for specific patient groups. TRIAL REGISTRATION This systematic review was registered in Prospero, registration number RD42014009977 .},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KSQ5T8ME\\hofstede_et_al_2016_preoperative_predictors_for_outcomes_after_total_hip_replacement_in_patients.pdf},
  journal = {BMC musculoskeletal disorders},
  keywords = {Hip arthroplasty,Osteoarthritis,Outcome,Predictors,Review},
  pmid = {27184266}
}

@article{Hogben1968,
  title = {The Distribution of the Sample Correlation Coefficient with One Variable Fixed},
  author = {Hogben, David},
  year = {1968},
  volume = {72B},
  pages = {33},
  issn = {0098-8979},
  doi = {10.6028/jres.072B.007},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6WLGJUF6\\hogben_1968_the_distribution_of_the_sample_correlation_coefficient_with_one_variable_fixed.pdf},
  journal = {Journal of Research of the National Bureau of Standards, Section B: Mathematical Sciences},
  keywords = {anal ysis of variance,calibrali on,co rrelation coeffi cie,degrees of free dom,di s-,e,fix ed vari abl,nonce ntral beta variabl,noncentrality,nt,q variate,tribution},
  number = {1}
}

@techreport{Hojer1951,
  title = {Statistisk Klassifikation Av Sjukdomar, Skador Och D\"odsorsaker},
  author = {H{\"o}jer, J Axe{\"o} and Soop, Erik and Hultgren, G{\"o}sta},
  year = {1951},
  institution = {{Kungliga Medicinalstyrelsen}},
  city = {Stockholm},
  keywords = {\#nosource}
}

@article{Holcombe2019,
  title = {Farewell Authors, Hello Contributors},
  author = {Holcombe, Alex},
  year = {2019},
  month = jul,
  volume = {571},
  pages = {147--147},
  doi = {10.1038/d41586-019-02084-8},
  journal = {Nature},
  keywords = {\#nosource},
  number = {7764}
}

@article{Holvik2010,
  title = {Predictors of Mortality in Older Hip Fracture Inpatients Admitted to an Orthogeriatric Unit in Oslo, Norway},
  author = {Holvik, K. and Ranhoff, A. H. and Martinsen, M. I. and Solheim, L. F.},
  year = {2010},
  volume = {22},
  pages = {1114--1131},
  issn = {0898-2643},
  doi = {10.1177/0898264310378040},
  abstract = {To identify to which degree patient-related factors (age, gender, place of residence, general health condition, comorbidity) and hospital-related factors (waiting time for surgery, type of surgery, in-hospital complications, length of stay) may predict 1-year mortality in elderly hip fracture patients in an orthogeriatric unit, to optimize treatment and care.},
  isbn = {1552-6887},
  journal = {Journal of Aging and Health},
  keywords = {\#nosource},
  number = {8},
  pmid = {20881106}
}

@techreport{Hommel2016,
  title = {Riksh\"oft: {{\AA rsrapport}} 2015},
  author = {Hommel, Anu and Hedstr{\"o}m, Margareta and Thorngren, Karl-G{\"o}ran and Nordstr{\"o}m, Peter and Zid{\'e}n, Lena and Berggren, Peter and Cederholm, Tommy and Hedstr{\"o}m, Gunilla Gosman and R{\"o}den, Margareta Berglund and J{\"o}nsson, Lena},
  year = {2016},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\I9JNYDTZ\\hommel_et_al_2016_rikshöft.pdf}
}

@article{Hooper2009,
  title = {Bilateral Total Joint Arthroplasty: {{The}} Early Results from the New Zealand National Joint Registry},
  author = {Hooper, Gary J. and Hooper, Nikki M. and Rothwell, Alastair G. and Hobbs, Toni},
  year = {2009},
  month = dec,
  volume = {24},
  pages = {1174--1177},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2008.09.022},
  abstract = {This study evaluated the mortality rate, major complications, and early outcomes of single anesthetic bilateral total hip and knee arthroplasty compared with unilateral and staged procedures. A total of 37 828 total hip and knee arthroplasties were evaluated with 6-month Oxford 12 scores. Major complications and mortality rates were recorded. Analysis of variance tables were used for statistical analysis. The single anesthetic bilateral group were significantly younger (P \textexclamdown{} .001), with their age-adjusted postoperative Oxford 12 scores significantly better (P \textexclamdown{} .001) than the other 2 groups. The surgeons involved, in general, performed more than 25 total knee and hip arthroplasties per year. There was 1 death within the first 6 months occurring in the staged bilateral group and was unrelated to the surgery. The complication rate as reported by patients was low in all groups, and there was no significant difference. The results show that, in selected patients, single anesthetic bilateral total knee or hip arthroplasty is a safe, low-risk procedure with very good patient-generated outcome scores at 6 months when performed by an experienced surgeon.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DHNBJE37\\hooper_et_al_2009_bilateral_total_joint_arthroplasty.pdf},
  journal = {The Journal of Arthroplasty},
  number = {8}
}

@article{Horiguchi2018,
  title = {A Flexible and Coherent Test/Estimation Procedure Based on Restricted Mean Survival Times for Censored Time-to-Event Data in Randomized Clinical Trials},
  author = {Horiguchi, Miki and Cronin, Angel M. and Takeuchi, Masahiro and Uno, Hajime},
  year = {2018},
  month = jul,
  volume = {37},
  pages = {2307--2320},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/sim.7661},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\H4IL9FA8\\horiguchi_et_al_2018_a_flexible_and_coherent_test-estimation_procedure_based_on_restricted_mean.pdf},
  journal = {Statistics in Medicine},
  keywords = {logrank test,perturbation resampling method,proportional hazards,robust tests,test/estimation coherency},
  number = {15}
}

@generic{Hornik2012,
  title = {The Comprehensive r Archive Network},
  author = {Hornik, Kurt},
  year = {2012},
  volume = {4},
  pages = {394--398},
  issn = {19395108},
  doi = {10.1002/wics.1212},
  abstract = {The Comprehensive R Archive Network (CRAN) is a network of sites acting as the primary web service distributing R sources and binaries, extension packages, and documentation. We discuss this functionality in more detail, with particular emphasis on the CRAN package repository, and its underlying design and operation principles. WIREs Comput Stat 2012 doi: 10.1002/wics.1212 For further resources related to this article, please visit the WIREs website},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9LJQ6NFF\\hornik_2012_the_comprehensive_r_archive_network.pdf},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  keywords = {Collaborative software development,Knowledge domain,R,R package repositories,R sources and binaries,Software quality,Statistical computing},
  number = {4}
}

@article{hossjerCoefficientDeterminationMixed2008,
  title = {On the Coefficient of Determination for Mixed Regression Models},
  author = {H{\"o}ssjer, Ola},
  year = {2008},
  volume = {138},
  pages = {3022--3038},
  issn = {03783758},
  doi = {10.1016/j.jspi.2007.11.010},
  abstract = {For mixed regression models, we define a variance decomposition including three terms, explained individual variance, unexplained individual variance and noise variance. In contrast to traditional variance decomposition, it is thus the unexplained, not the explained, variance that is split. It gives rise to a coefficient of individual determination (CID) defined as the estimated fraction of explained individual variance. We argue that in many applications CID is a valuable complement to R2, since it excludes noise variance (which can never be explained) and thus has one as a natural upper bound. A general theory for coefficients determination is presented, including various choices of regression models, weight functions and parameter estimates. In particular we focus on models where CID is computable, such as univariate mixed Poisson and logistic regression models, as well as multivariate mixed linear regression models. Large sample properties and confidence intervals are derived and finally, the theory is exemplified using Poisson regression on a Swedish motor traffic insurance data set. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZWWDTUNA\\hössjer_2008_on_the_coefficient_of_determination_for_mixed_regression_models.pdf},
  isbn = {0378-3758},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Coefficient of determination,Explained variance,Individual variance,Mixed regression models,Noise variance,Variance decomposition},
  number = {10}
}

@article{Hotelling1953,
  title = {New Light on the Correlation Coefficient and Its Transforms Author(s): {{Harold}} Hotelling},
  author = {Hotelling, Harold},
  year = {1953},
  volume = {15},
  pages = {296-193-232},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
  keywords = {\#nosource},
  number = {2}
}

@article{Hothorn2006,
  title = {Interface Foundation of America Unbiased Recursive Partitioning: {{A}} Conditional Inference Framework Unbiased Recursive Partitioning: {{A}} Conditional Inference Framework},
  author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
  year = {2006},
  volume = {15},
  pages = {651--674},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. Recursive binary partitioning is a popular tool for regression analysis. Two fun damental problems of exhaustive search procedures usually applied to fit such models have been known for a long time: overfitting and a selection bias towards covariates with many possible splits or missing values. While pruning procedures are able to solve the overfitting problem, the variable selection bias still seriously affects the interpretabil ity of tree-structured regression models. For some special cases unbiased procedures have been suggested, however lacking a common theoretical foundation. We propose a unified framework for recursive partitioning which embeds tree-structured regression models into a well defined theory of conditional inference procedures. Stopping criteria based on multiple test procedures are implemented and it is shown that the predictive performance of the resulting trees is as good as the performance of established exhaus tive search procedures. It turns out that the partitions and therefore the models induced by both approaches are structurally different, confirming the need for an unbiased vari able selection. Moreover, it is shown that the prediction accuracy of trees with early stopping is equivalent to the prediction accuracy of pruned trees with unbiased variable selection. The methodology presented here is applicable to all kinds of regression prob lems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. Data from studies on glau coma classification, node positive breast cancer survival and mammography experience are re-analyzed.},
  journal = {Source: Journal of Computational and Graphical Statistics},
  keywords = {\#nosource},
  number = {3}
}

@article{Hougaard1995,
  title = {Frailty Models for Survival Data},
  author = {Hougaard, Philip},
  year = {1995},
  volume = {1},
  pages = {255--273},
  issn = {13807870},
  doi = {10.1007/BF00985760},
  abstract = {A frailty model is a random effects model for time variables, where the random effect (the frailty) has a multiplicative effect on the hazard. It can be used for univariate (independent) failure times, i.e. to describe the influence of unobserved covariates in a proportional hazards model. More interesting, however, is to consider multivariate (dependent) failure times generated as conditionally independent times given the frailty. This approach can be used both for survival times for individuals, like twins or family members, and for repeated events for the same individual. The standard assumption is to use a gamma distribution for the frailty, but this is a restriction that implies that the dependence is most important for late events. More generally, the distribution can be stable, inverse Gaussian, or follow a power variance function exponential family. Theoretically, large differences are seen between the choices. In practice, using the largest model makes it possible to allow for more general dependence structures, without making the formulas too complicated.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UTG54L68\\hougaard_1995_frailty_models_for_survival_data.pdf},
  isbn = {1380-7870 (Print){\r  }1380-7870 (Linking)},
  journal = {Lifetime Data Analysis},
  number = {3},
  pmid = {9385105}
}

@article{Houwelingen2014,
  title = {Board of the Foundation of the Scandinavian Journal of Statistics Dynamic Prediction by Landmarking in Event History Analysis},
  author = {Houwelingen, Hans C V A N},
  year = {2014},
  volume = {34},
  pages = {70--85},
  keywords = {\#nosource,dependent covariates,landmark analysis,landmarking,pseudo-partial likelihood,survival analysis,tim,time-varying effects},
  number = {1}
}

@article{Howald2007,
  title = {Invasive Rodent Eradication on Islands},
  author = {Howald, Gregg and Donlan, C. Josh and Galv{\'a}n, Juan Pablo and Russell, James C. and Parkes, John and Samaniego, Araceli and Wang, Yiwei and Veitch, Dick and Genovesi, Piero and Pascal, Michel and Saunders, Alan and Tershy, Bernie},
  year = {2007},
  volume = {21},
  pages = {1258--1268},
  issn = {08888892},
  doi = {10.1111/j.1523-1739.2007.00755.x},
  abstract = {Invasive mammals are the greatest threat to island biodiversity and invasive rodents are likely responsible for the greatest number of extinctions and ecosystem changes. Techniques for eradicating rodents from islands were developed over 2 decades ago. Since that time there has been a significant development and application of this conservation tool. We reviewed the literature on invasive rodent eradications to assess its current state and identify actions to make it more effective. Worldwide, 332 successful rodent eradications have been undertaken; we identified 35 failed eradications and 20 campaigns of unknown result. Invasive rodents have been eradicated from 284 islands (47,628 ha). With the exception of two small islands, rodenticides were used in all eradication campaigns. Brodifacoum was used in 71\% of campaigns and 91\% of the total area treated. The most frequent rodenticide distribution methods (from most to least) are bait stations, hand broadcasting, and aerial broadcasting. Nevertheless, campaigns using aerial broadcast made up 76\% of the total area treated. Mortality of native vertebrates due to nontarget poisoning has been documented, but affected species quickly recover to pre-eradication population levels or higher. A variety of methods have been developed to mitigate nontarget impacts, and applied research can further aid in minimizing impacts. Land managers should routinely remove invasive rodents from islands \textexclamdown 100 ha that lack vertebrates susceptible to nontarget poisoning. For larger islands and those that require nontarget mitigation, expert consultation and greater planning effort are needed. With the exception of house mice (Mus musculus), island size may no longer be the limiting factor for rodent eradications; rather, social acceptance and funding may be the main challenges. To be successful, large-scale rodent campaigns should be integrated with programs to improve the livelihoods of residents, island biosecurity, and reinvasion response programs.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MG9KI6L4\\howald_et_al_2007_invasive_rodent_eradication_on_islands.pdf},
  isbn = {1523-1739 (Electronic)0888-8892 (Linking)},
  journal = {Conservation Biology},
  keywords = {Eradication,Invasive species,Island conservation,Mus musculus,Rattus exulans,Rattus norvegicus,Rattus rattus},
  number = {5},
  pmid = {17883491}
}

@article{Hoyer1959,
  title = {Centre Interfacultaire d'{{Anthropologie}} et de Linguistique Africaines de l'{{Universit\'e}} Officielle Du Congo Belge et Du Ruanda-Urundi},
  author = {Hoyer, Patrik O},
  year = {1959},
  volume = {29},
  pages = {85--86},
  issn = {17500184},
  doi = {10.1017/S0001972000059520},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J9UITTXR\\hoyer_1959_centre_interfacultaire_d'anthropologie_et_de_linguistique_africaines_de.pdf},
  journal = {Africa},
  keywords = {data-adaptive representations,non-negative matrix factorization,sparseness},
  number = {1}
}

@article{Hu2012,
  title = {Preoperative Predictors for Mortality Following Hip Fracture Surgery: {{A}} Systematic Review and Meta-Analysis},
  author = {Hu, Fangke and Jiang, Chengying and Shen, Jing and Tang, Peifu and Wang, Yan},
  year = {2012},
  volume = {43},
  pages = {676--685},
  publisher = {{Elsevier Ltd}},
  issn = {00201383},
  doi = {10.1016/j.injury.2011.05.017},
  abstract = {Background: Hip fractures are always associated with a high postoperative mortality, the preoperative predictors for mortality have neither been well identified or summarised. This systematic review and meta-analysis was performed to identify the preoperative non-interventional predictors for mortality in hip fracture patients, especially focused on 1 year mortality. Methods: Non-interventional studies were searched in Pubmed, Embase, Cochrane central database (all to February 26th, 2011). Only prospective studies and retrospective studies with prospective collected data were included. Qualities of included studies were assessed by a standardised scale previous reported for observational studies. The effects of individual studies were combined with the study quality score using a previous reported model of best-evidence synthesis. The hazard ratios of strong evidence predictors were combined only by high quality studies. Results: 75 included studies with 94 publications involving 64,316 patients were included and the available observations was a heterogeneous group. The overall inpatient or 1 month mortality was 13.3\%, 3-6 months was 15.8\%, 1 year 24.5\% and 2 years 34.5\%. There were strong evidence for 12 predictors, including advanced age, male gender, nursing home or facility residence, poor preoperative walking capacity, poor activities of daily living, higher ASA grading, poor mental state, multiple comorbidities, dementia or cognitive impairment, diabetes, cancer and cardiac disease. We also identified 7 moderate evidence and 12 limited evidence mortality predictors, and only the race was identified as the conflicting evidence predictor. Conclusion: Whilst there is no conclusive evidence of the preoperative predictors for mortality following hip fractures, special attention should be paid to the above 12 strong evidence predictors. Future researches were still needed to evaluate the effects of these predictors. ?? 2011 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7X9AK2N6\\hu_et_al_2012_preoperative_predictors_for_mortality_following_hip_fracture_surgery.pdf},
  isbn = {0108821986},
  journal = {Injury},
  keywords = {Hip fracture,Meta-analysis,Mortality,Multivariate analysis,Predictor,Systematic review},
  number = {6},
  pmid = {21683355}
}

@article{Huang2018,
  title = {Comparison of the Restricted Mean Survival Time with the Hazard Ratio in Superiority Trials with a Time-to-Event End Point},
  author = {Huang, Bo and Kuan, Pei Fen},
  year = {2018},
  volume = {17},
  pages = {202--213},
  issn = {15391612},
  doi = {10.1002/pst.1846},
  abstract = {With the emergence of novel therapies exhibiting distinct mechanisms of action compared to traditional treatments, departure from the proportional hazard (PH) assumption in clinical trials with a time-to-event end point is increasingly common. In these situations, the hazard ratio may not be a valid statistical measurement of treatment effect, and the log-rank test may no longer be the most powerful statistical test. The restricted mean survival time (RMST) is an alternative robust and clinically interpretable summary measure that does not rely on the PH assumption. We conduct extensive simulations to evaluate the performance and operating characteristics of the RMST-based inference and against the hazard ratio-based inference, under various scenarios and design parameter setups. The log-rank test is generally a powerful test when there is evident separation favoring 1 treatment arm at most of the time points across the Kaplan-Meier survival curves, but the performance of the RMST test is similar. Under non-PH scenarios where late separation of survival curves is observed, the RMST-based test has better performance than the log-rank test when the truncation time is reasonably close to the tail of the observed curves. Furthermore, when flat survival tail (or low event rate) in the experimental arm is expected, selecting the minimum of the maximum observed event time as the truncation timepoint for the RMST is not recommended. In addition, we recommend the inclusion of analysis based on the RMST curve over the truncation time in clinical settings where there is suspicion of substantial departure from the PH assumption.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\55RGHFXD\\huang_kuan_2018_comparison_of_the_restricted_mean_survival_time_with_the_hazard_ratio_in.pdf},
  journal = {Pharmaceutical Statistics},
  keywords = {log-rank test,proportional hazard,restricted mean survival time,time to event},
  number = {3},
  pmid = {29282880}
}

@article{Huber2019,
  title = {Predicting Patient-Reported Outcomes Following Hip and Knee Replacement Surgery Using Supervised Machine Learning},
  author = {Huber, Manuel and Kurz, Christoph and Leidl, Reiner},
  year = {2019},
  volume = {19},
  doi = {10.1186/s12911-018-0731-6},
  abstract = {Background: Machine-learning classifiers mostly offer good predictive performance and are increasingly used to support shared decision-making in clinical practice. Focusing on performance and practicability, this study evaluates prediction of patient-reported outcomes (PROs) by eight supervised classifiers including a linear model, following hip and knee replacement surgery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\USZR8YWI\\huber_et_al_2019_predicting_patient-reported_outcomes_following_hip_and_knee_replacement_surgery.pdf},
  journal = {BMC Medical Informatics and Decision Making},
  number = {3}
}

@article{Huberty1980,
  title = {Estimation in Multiple Correlation/Prediction},
  author = {Huberty, Carl J. and Mourad, Salah A.},
  year = {1980},
  volume = {40},
  pages = {101--112},
  issn = {15523888},
  doi = {10.1177/001316448004000113},
  journal = {Educational and Psychological Measurement},
  keywords = {\#nosource},
  number = {1}
}

@article{Hunt2013,
  title = {90-Day Mortality after 409 096 Total Hip Replacements for Osteoarthritis, from the {{National Joint Registry}} for {{England}} and {{Wales}}: A Retrospective Analysis},
  author = {Hunt, Linda P and {Ben-Shlomo}, Yoav and Clark, Emma M and Dieppe, Paul and Judge, Andrew and MacGregor, Alex J and Tobias, Jon H and Vernon, Kelly and Blom, Ashley W},
  year = {2013},
  month = sep,
  volume = {382},
  pages = {1097--1104},
  publisher = {{Elsevier}},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(13)61749-3},
  abstract = {BACKGROUND Death within 90 days after total hip replacement is rare but might be avoidable dependent on patient and treatment factors. We assessed whether a secular decrease in death caused by hip replacement has occurred in England and Wales and whether modifiable perioperative factors exist that could reduce deaths. METHODS We took data about hip replacements done in England and Wales between April, 2003, and December, 2011, from the National Joint Registry for England and Wales. Patient identifiers were used to link these data to the national mortality database and the Hospital Episode Statistics database to obtain details of death, sociodemographics, and comorbidity. We assessed mortality within 90 days of operation by Kaplan-Meier analysis and assessed the role of patient and treatment factors by Cox proportional hazards model. FINDINGS 409 096 primary hip replacements were done to treat osteoarthritis. 1743 patients died within 90 days of surgery during 8 years, with a substantial secular decrease in mortality, from 0{$\cdot$}56\% in 2003 to 0{$\cdot$}29\% in 2011, even after adjustment for age, sex, and comorbidity. Several modifiable clinical factors were associated with decreased mortality according to an adjusted model: posterior surgical approach (hazard ratio [HR] 0{$\cdot$}82, 95\% CI 0{$\cdot$}73\textendash 0{$\cdot$}92; p=0{$\cdot$}001), mechanical thromboprophylaxis (0{$\cdot$}85, 0{$\cdot$}74\textendash 0{$\cdot$}99; p=0{$\cdot$}036), chemical thromboprophylaxis with heparin with or without aspirin (0{$\cdot$}79, 0{$\cdot$}66\textendash 0{$\cdot$}93; p=0{$\cdot$}005), and spinal versus general anaesthetic (0{$\cdot$}85, 0{$\cdot$}74\textendash 0{$\cdot$}97; p=0{$\cdot$}019). Type of prosthesis was unrelated to mortality. Being overweight was associated with lower mortality (0{$\cdot$}76, 0{$\cdot$}62\textendash 0{$\cdot$}92; p=0{$\cdot$}006). INTERPRETATION Postoperative mortality after hip joint replacement has fallen substantially. Widespread adoption of four simple clinical management strategies (posterior surgical approach, mechanical and chemical prophylaxis, and spinal anaesthesia) could, if causally related, reduce mortality further. FUNDING National Joint Registry for England and Wales.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8A8DNZEI\\hunt_et_al_2013_90-day_mortality_after_409_096_total_hip_replacements_for_osteoarthritis,_from.pdf},
  journal = {The Lancet},
  number = {9898}
}

@article{Huotari2007,
  title = {Patient Outcomes after Simultaneous Bilateral Total Hip and Knee Joint Replacements},
  author = {Huotari, K. and Lyytik{\"a}inen, O. and Seitsalo, S.},
  year = {2007},
  month = mar,
  volume = {65},
  pages = {219--225},
  publisher = {{W.B. Saunders}},
  issn = {0195-6701},
  doi = {10.1016/J.JHIN.2006.10.018},
  abstract = {Simultaneous arthroplasties are increasingly being performed during one single anaesthetic event. No national nosocomial surveillance systems have yet reported data on this issue. We compared patient populations undergoing bi- and unilateral total hip (THA) and total knee (TKA) arthroplasties in terms of two outcome variables, deep surgical site infections (SSI) and mortality, by analysing surveillance data from the Finnish Hospital Infection Programme (SIRO). A total of 8201 patients underwent 9831 total arthroplasties during 2001\textendash 2004. Of the prosthetic joints, 7.2\% were inserted in a bilateral operation (range by hospital, 0.6\textendash 19.2\%; range by procedure type, 5.2\textendash 9.9\%). Patients who underwent bilateral operations were younger; more often males, and their ASA score was lower than those who underwent unilateral procedures. The rate of deep SSI in bi- and unilateral THAs and in bi- and unilateral TKAs was 0, 0.5, 1.0 and 0.9\%, respectively. Following bilateral operations, four deep SSIs were detected, all from bilateral TKAs, three of which were on the second operative side. In these three cases, single doses of antimicrobial prophylaxis were administered 115, 155 and 218min before incision (median time in unilateral operations: 47min). According to multi-variate analysis, bilateral operations were not an independent risk factor for deep SSIs. Mortality did not differ between bi- and unilateral THAs or TKAs. Our surveillance data indicate that simultaneous bilateral surgery did not increase the risk of deep SSIs or death after THA and TKA. Bilateral operations may, however, require specific guidelines regarding antimicrobial prophylaxis.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HCX4C3J3\\huotari_et_al_2007_patient_outcomes_after_simultaneous_bilateral_total_hip_and_knee_joint.pdf},
  journal = {Journal of Hospital Infection},
  number = {3}
}

@article{Husted2014,
  title = {Traditions and Myths in Hip and Knee Arthroplasty},
  author = {Husted, Henrik and Gromov, Kirill and Malchau, Henrik and Freiberg, Andrew and Gebuhr, Peter and Troelsen, Anders},
  year = {2014},
  volume = {85},
  pages = {548--555},
  issn = {1745-3674},
  doi = {10.3109/17453674.2014.971661},
  abstract = {BACKGROUND AND PURPOSE: Traditions are passed on from experienced surgeons to younger fellows and become "the right way to do it". Traditions associated with arthroplasty surgery may, however, not be evidence-based and may be potentially deleterious to both patients and society, increasing morbidity and mortality, slowing early functional recovery, and increasing cost.: We identified selected traditions and performed a literature search using relevant search criteria (June 2014). We present a narrative review grading the studies according to evidence, and we suggest some lines of future research.: We present traditions and evaluate them against the published evidence. Preoperative removal of hair, urine testing for bacteria, use of plastic adhesive drapes intraoperatively, and prewarming of the operation room should be abandoned-as should use of a tourniquet, a space suit, a urinary catheter, and closure of the knee in extension. The safety and efficacy of tranexamic acid is supported by meta-analyses. Postoperatively, there is no evidence to support postponement of showering or postponement of changing of dressings to after 48 h. There is no evidence to recommend routine dental antibiotic prophylaxis, continuous passive motion (CPM), the use of compression stockings, cooling for pain control or reduction of swelling, flexion of at least 90 degrees as a discharge criterion following TKA, or having restrictions after THA. We present evidence supporting the use of NSAIDs, early mobilization, allowing early travel, and a low hemoglobin trigger for transfusion.: Revision of traditions and myths surrounding hip and knee arthroplasty towards more contemporary evidence-based principles can be expected to improve early functional recovery, thus reducing morbidity, mortality, and costs.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NA93TBA6\\husted_et_al_2014_traditions_and_myths_in_hip_and_knee_arthroplasty.pdf},
  isbn = {1745-3674},
  journal = {Acta Orthopaedica},
  keywords = {Arthroplasty,Attitude of Health Personnel,Evidence-Based Medicine,Hip,Hip: standards,Humans,Knee,Knee: standards,Practice Guidelines as Topic,Replacement},
  number = {6},
  pmid = {25285615}
}

@article{Iezzoni1997,
  title = {Assessing Quality Using Administrative Data.},
  author = {Iezzoni, L I},
  year = {1997},
  month = oct,
  volume = {127},
  pages = {666--74},
  issn = {0003-4819},
  abstract = {Administrative data result from administering health care delivery, enrolling members into health insurance plans, and reimbursing for services. The primary producers of administrative data are the federal government, state governments, and private health care insurers. Although the clinical content of administrative data includes only the demographic characteristics and diagnoses of patients and codes for procedures, these data are often used to evaluate the quality of health care. Administrative data are readily available, are inexpensive to acquire, are computer readable, and typically encompass large populations. They have identified startling practice variations across small geographic areas and-supported research about outcomes of care. Many hospital report cards (which compare patient mortality rates) and physician profiles (which compare resource consumption) are derived from administrative data. However, gaps in clinical information and the billing context compromise the ability to derive valid quality appraisals from administrative data. With some exceptions, administrative data allow limited insight into the quality of processes of care, errors of omission or commission, and the appropriateness of care. In addition, questions about the accuracy and completeness of administrative data abound. Current administrative data are probably most useful as screening tools that highlight areas in which quality should be investigated in greater depth. The growing availability of electronic clinical information will change the nature of administrative data in the future, enhancing opportunities for quality measurement.},
  journal = {Annals of internal medicine},
  keywords = {\#nosource},
  number = {8 Pt 2},
  pmid = {9382378}
}

@article{Ihaka1996,
  title = {R: A Language for Data Analysis and Graphics},
  author = {Ihaka, A and Gentleman, R},
  year = {1996},
  volume = {5},
  pages = {299--314},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {\#nosource,computer language,statistical computing},
  number = {3}
}

@techreport{Ihaka1998,
  title = {R : {{Past}} and Future History},
  author = {Ihaka, Ross},
  year = {1998},
  city = {Auckland},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VWEDN9SU\\ihaka_1998_r.pdf}
}

@article{Ihaka2010,
  title = {R: {{Lessons}} Learned, Directions for the Future},
  author = {Ihaka, Ross and Bates, Douglas and Lumley, Thomas and Murrell, Paul and Lang, Duncan Temple},
  year = {2010},
  pages = {1--5},
  abstract = {2010 JSM Proceedings - Papers presented at Joint Statistical Meetings - Vancouver, British Columbia, July 31 \textendash{} August 5, 2010 and other ASA-sponsored conferences},
  keywords = {\#nosource,statistical computing},
  number = {square v}
}

@article{Inacio2015,
  title = {Using Medications for Prediction of Revision after Total Joint Arthroplasty.},
  author = {Inacio, Maria C S and Pratt, Nicole L and Roughead, Elizabeth E and Graves, Stephen E},
  year = {2015},
  month = dec,
  volume = {30},
  pages = {2061--70},
  issn = {1532-8406},
  doi = {10.1016/j.arth.2015.06.009},
  abstract = {This study evaluated the ability of a pharmacy based co-morbidity measure (RxRisk-V) to predict odds of one and five years revision in total hip arthroplasty (THA) and total knee arthroplasty (TKA) and compared its performance to the more commonly used co-morbidity measures in orthopaedics (Charlson and Elixhauser). 11,848 patients with THAs and 18,972 with TKAs performed between 2001 and 2012 were evaluated. Using a combination of conditions, identified by both the pharmacy and diagnoses based coding algorithms, models with acceptable predictive ability of THA and TKA revision were developed. These findings suggest prescription based co-morbidity measures can positively contribute to case-mix adjustment and outcome prediction in this patient population.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BFNSVMUX\\inacio_et_al_2015_using_medications_for_prediction_of_revision_after_total_joint_arthroplasty.pdf},
  journal = {The Journal of arthroplasty},
  keywords = {co-morbidities,medications,RxRisk-V,total hip arthroplasty,total knee arthroplasty},
  number = {12},
  pmid = {26190569}
}

@article{Inacio2015,
  title = {Comparing Co-Morbidities in Total Joint Arthroplasty Patients Using the {{RxRisk}}-{{V}}, {{Elixhauser}}, and {{Charlson Measures}}: A Cross-Sectional Evaluation},
  author = {Inacio, Maria C. S. and Pratt, Nicole L. and Roughead, Elizabeth E. and Graves, Stephen E.},
  year = {2015},
  month = dec,
  volume = {16},
  pages = {385},
  publisher = {{BioMed Central}},
  issn = {1471-2474},
  doi = {10.1186/s12891-015-0835-4},
  abstract = {Joint arthroplasty patients have a high prevalence of co-morbidities and this impacts their surgical outcomes. There are different ways to ascertain co-morbidities and appropriate measurement is necessary. The purpose of this study was to: (1) describe the prevalence of co-morbidities in a cohort of total hip arthroplasty (THA) and knee arthroplasty (TKA) patients using two diagnoses-based measures (Charlson and Elixhauser) and one prescription-based measure (RxRisk-V); (2) compare the agreement of co-morbidities amongst the measures. A cross-sectional study of Australian veterans undergoing THAs (n = 11,848) and TKAs (n = 18,972) between 2001 and 2012 was conducted. Seventeen co-morbidities were identified using the Charlson, 30 using the Elixhauser, and 42 using the RxRisk-V measure. Agreement between co-morbidities was calculated using Kappa ({$\kappa$}) statistics. Combining measures, 64 conditions were identified, of these 28 were only identified using the RxRisk-V, 11 using the Elixhauser, and 2 using the Charlson. The most prevalent conditions was pain treated with anti-inflammatories (58.7 \% THAs, 55.9 \% TKAs), pain treated with narcotics (55.0 \% THAs, 50.9 \% TKAs), hypertension (56.0 \% THAs and TKAs), and anticoagulation disorders (53.0 \% THAs, 48.6 \% TKAs). Diabetes was the only condition with substantial agreement (all {$\kappa$} \textquestiondown{} 0.6) amongst all measures. When comparing the diagnoses based algorithms, agreement was high for overlapping conditions (all {$\kappa$} \textquestiondown{} 0.71). Different measures identified different co-morbidities, provided different estimates for the same co-morbidity, and had different levels of agreement for common co-morbidities. This highlights the importance of understanding co-morbidity measures and using them appropriately in studies and case-mix adjustments analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V43HF8A2\\inacio_et_al_2015_comparing_co-morbidities_in_total_joint_arthroplasty_patients_using_the.pdf},
  journal = {BMC Musculoskeletal Disorders},
  keywords = {Epidemiology,Internal Medicine,Orthopedics,Rehabilitation,Rheumatology,Sports Medicine},
  number = {1}
}

@article{Inacio2015a,
  title = {Predicting {{Infections After Total Joint Arthroplasty Using}} a {{Prescription Based Comorbidity Measure}}},
  author = {Inacio, Maria C.S. and Pratt, Nicole L. and Roughead, Elizabeth E. and Graves, Stephen E.},
  year = {2015},
  month = oct,
  volume = {30},
  pages = {1692--1698},
  issn = {08835403},
  doi = {10.1016/j.arth.2015.05.004},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {10}
}

@article{Inacio2016,
  title = {Evaluation of Three Co-Morbidity Measures to Predict Mortality in Patients Undergoing Total Joint Arthroplasty.},
  author = {Inacio, M.C.S. C S and Pratt, N.L. L and Roughead, E.E. E and Graves, S.E. E},
  year = {2016},
  month = oct,
  volume = {24},
  pages = {1718--1726},
  publisher = {{W.B. Saunders}},
  issn = {1522-9653},
  doi = {10.1016/j.joca.2016.05.006},
  abstract = {OBJECTIVE To evaluate the 90 days and 1 year mortality predictive ability of the RxRisk-V, Charlson, and Elixhauser co-morbidity measures in total hip arthroplasty (THA) and total knee arthroplasty (TKA) patients. METHOD A retrospective study of 11,848 THAs and 18,972 TKAs (2001-2002) was conducted. Death within 90 days and 1 year of the surgery were the main endpoints. Co-morbidity measures were calculated using either medication or hospitalisation history. Logistic regression models were employed and discrimination and calibration were assessed. Specifically, models with unweighted and weighted measure scores, models with the specific conditions, and a model combining conditions identified by all measures were assessed. RESULTS In THAs, the best performing prediction models included co-morbidities from all three measures (90 days: c = 0.84, P = 0.284, 1 year: c = 0.79, P = 0.158). Individually, the model with Charlson conditions performed best at 90 days mortality (c = 0.80, P = 0.777) and the Charlson and Elixhauser performed similarly at 1 year (both c = 0.77, P \textquestiondown{} 0.05). In TKAs, the best performing prediction model included co-morbidities from all measures (90 days: c = 0.82, P = 0.349, 1 year: c = 0.78, P = 0.873). Individually, the model with Elixhauser conditions performed best with 90 days mortality (c = 0.79, P = 0.435) and all performed similarly at 1 year (c = 0.74-0.75, all P \textquestiondown{} 0.05). CONCLUSIONS A combined model with co-morbidities identified by the Elixhauser, Charlson, and RxRisk-V was the best mortality prediction model. The RxRisk-V did not perform as well as the others. Because of the Elixhauser and Charlson's similar performance we suggest basing the choice of measurement use on factors such as the need of specific conditions and modelling limitations.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PXWFMDTL\\inacio_et_al_2016_evaluation_of_three_co-morbidity_measures_to_predict_mortality_in_patients.pdf},
  journal = {Osteoarthritis and cartilage},
  keywords = {Charlson,Co-morbidity,Elixhauser,Joint arthroplasty,Mortality,RxRisk-V},
  number = {10},
  pmid = {27188683}
}

@article{Ince2012,
  title = {The Case for Open Computer Programs},
  author = {Ince, Darrel C. and Hatton, Leslie and {Graham-Cumming}, John},
  year = {2012},
  month = feb,
  volume = {482},
  pages = {485--488},
  publisher = {{Nature Publishing Group}},
  issn = {0028-0836},
  doi = {10.1038/nature10836},
  abstract = {Scientific reproducibility now very often depends on the computational method being available to duplicate, so here it is argued that all source code should be freely available.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MH3NSCVJ\\ince_et_al_2012_the_case_for_open_computer_programs.pdf},
  journal = {Nature},
  keywords = {Information technology},
  number = {7386}
}

@article{Interpretation2015,
  title = {Journal of the Royal Statistical Society. {{Series}} b (Methodological),},
  author = {Interpretation, The and Author, Statistical Maps and Source, Moran and Statistical, Royal and Stable, Society},
  year = {2015},
  volume = {10},
  pages = {243--251},
  keywords = {\#nosource},
  number = {2}
}

@article{Investigators2019,
  title = {Total Hip Arthroplasty or Hemiarthroplasty for Hip Fracture},
  author = {Investigators, The HEALTH},
  year = {2019},
  month = sep,
  pages = {NEJMoa1906190},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1906190},
  abstract = {Abstract Background Globally, hip fractures are among the top 10 causes of disability in adults. For displaced femoral neck fractures, there remains uncertainty regarding the effect of a total hip ...},
  journal = {New England Journal of Medicine},
  keywords = {\#nosource}
}

@article{Iorio2012,
  title = {Diabetes {{Mellitus}}, {{Hemoglobin A1C}}, and the {{Incidence}} of {{Total Joint Arthroplasty Infection}}},
  author = {Iorio, Richard and Williams, Kelly M. and Marcantonio, Andrew J. and Specht, Lawrence M. and Tilzey, John F. and Healy, William L.},
  year = {2012},
  month = may,
  volume = {27},
  pages = {726-729.e1},
  issn = {08835403},
  doi = {10.1016/j.arth.2011.09.013},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {5}
}

@article{Ireland2015,
  title = {Risk Factor Profiles for Early and Delayed Mortality after Hip Fracture: {{Analyses}} of Linked {{Australian Department}} of {{Veterans}}' {{Affairs}} Databases},
  author = {Ireland, Anthony W. and Kelly, Patrick J. and Cumming, Robert G.},
  year = {2015},
  month = jun,
  volume = {46},
  pages = {1028--1035},
  issn = {00201383},
  doi = {10.1016/j.injury.2015.03.006},
  abstract = {Introduction One-year mortality after hip fracture may exceed 30\% with a very large number of reported risk factors. Determinants of mortality beyond 1 year are rarely described. This study employs multiple data linkages to examine mortality rates, risk factor profiles and age-specific excess mortality at intervals from 30 days to 4 years. Methods Retrospective cohort study of linked administrative datasets describing hospital episodes, residential aged care (RAC) admissions and date of death for 2552 Australian veterans and war widows hospitalised for hip fracture in 2008-09. Associations between time to death and patient age, sex, pre-fracture accommodation, fracture type, treatment options, selected comorbidities and complications were tested in Cox proportional hazards models. Results In a population with mean age of 86.6 years (range 54-100 years), overall death rate was 11\% at 30 days, 34\% at 1 year, 47\% at 2 years and 67\% after 4 years. For males hospitalised from RAC 1-year mortality was 72\%, contrasting with 19\% for females from the community. Risk of death within 1 year was increased by male sex, increasing age, pre-fracture RAC residency, transfer to intensive care and coexistent cancer, cardiac and renal failure, cerebrovascular disease and pressure ulcers. Patients selected for rehabilitation had lower mortality rates. Patterns of determinants for mortality changed over time. Above-expected age-specific mortality was sustained for 4 years except for males 90 years and older. Conclusion Pre-fracture RAC residence was the strongest determinant factor for mortality. Patients selected for rehabilitation had lower mortality rates. The profiles of explanatory variables for death altered with increasing time from the index fracture event.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MS8R3ZJ3\\ireland_et_al_2015_risk_factor_profiles_for_early_and_delayed_mortality_after_hip_fracture.pdf},
  isbn = {0020-1383},
  journal = {Injury},
  number = {6},
  pmid = {25813734}
}

@article{Irwin1949,
  title = {The Standard Error of an Estimate of Expectation of Life, with Special Reference to Expectation of Tumourless Life in Experiments with Mice},
  author = {Irwin, J. O.},
  year = {1949},
  month = jun,
  volume = {47},
  pages = {188--189},
  publisher = {{Cambridge University Press}},
  issn = {0022-1724},
  doi = {10.1017/S0022172400014443},
  abstract = {\textexclamdown p\textquestiondown{} An expectation of life limited to \textexclamdown italic\textquestiondown n\textexclamdown/italic\textquestiondown{} years is properly defined by \textexclamdown/p\textquestiondown},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RDD9GCDG\\irwin_1949_the_standard_error_of_an_estimate_of_expectation_of_life,_with_special.pdf},
  journal = {Journal of Hygiene},
  number = {2}
}

@article{Isaksson2008,
  title = {Cross-Validation and Bootstrapping Are Unreliable in Small Sample Classification},
  author = {Isaksson, A. and Wallman, M. and G??ransson, H. and Gustafsson, M. G.},
  year = {2008},
  issn = {01678655},
  doi = {10.1016/j.patrec.2008.06.018},
  abstract = {The interest in statistical classification for critical applications such as diagnoses of patient samples based on supervised learning is rapidly growing. To gain acceptance in applications where the subsequent decisions have serious consequences, e.g. choice of cancer therapy, any such decision support system must come with a reliable performance estimate. Tailored for small sample problems, cross-validation (CV) and bootstrapping (BTS) have been the most commonly used methods to determine such estimates in virtually all branches of science for the last 20 years. Here, we address the often overlooked fact that the uncertainty in a point estimate obtained with CV and BTS is unknown and quite large for small sample classification problems encountered in biomedical applications and elsewhere. To avoid this fundamental problem of employing CV and BTS, until improved alternatives have been established, we suggest that the final classification performance always should be reported in the form of a Bayesian confidence interval obtained from a simple holdout test or using some other method that yields conservative measures of the uncertainty. ?? 2008 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\22JQGLW3\\isaksson_et_al_2008_cross-validation_and_bootstrapping_are_unreliable_in_small_sample_classification.pdf},
  isbn = {01678655},
  journal = {Pattern Recognition Letters},
  keywords = {Confidence interval,Performance estimation,Supervised classification}
}

@article{Issa2013,
  title = {Total Hip Replacement: {{Mortality}} and Risks},
  author = {Issa, Kimona and Mont, Michael A.},
  year = {2013},
  volume = {382},
  pages = {1074--1076},
  issn = {1474547X},
  doi = {10.1016/S0140-6736(13)61891-7},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WX6EIIWB\\issa_mont_2013_total_hip_replacement.pdf},
  journal = {The Lancet},
  number = {9898},
  pmid = {24075035}
}

@article{Jackson2007,
  title = {Multi-State Modelling with {{R}}: The Msm Package},
  author = {Jackson, Christopher},
  year = {2007},
  pages = {1--53},
  abstract = {The multi-state Markov model is a useful way of describing a process in which an individual moves through a series of states in continuous time. The msm package for R allows a general multi-state model to be fitted to longitudinal data. Data often consist of observations of the process at arbitrary times, so that the exact times when the state changes are unobserved. For example, the progression of chronic diseases is often described by stages of severity, and the state of the patient may only be known at doctor or hospital visits. Features of msm include the ability to model transition rates and hidden Markov output models in terms of covariates, and the ability to model data with a variety of observation schemes, including censored states. Hidden Markov models, in which the true path through states is only observed through some error-prone marker, can also be fitted. The observation is generated, conditionally on the underly- ing states, via some distribution. An example is a screening misclassification model in which states are observed with error. More generally, hidden Markov models can have a continuous response, with some arbitrary distribution, conditionally on the underlying state. This manual introduces the theory behind multi-state Markov and hidden Markov models, and gives a tutorial in the typical use of the msm package, illustrated by some typical applications to modelling chronic diseases.},
  journal = {Cambridge, UK},
  keywords = {\#nosource}
}

@article{Jackson2016,
  title = {Flexsurv: {{A}} Platform for Parametric Survival Modeling in r},
  author = {Jackson, Christopher},
  year = {2016},
  month = may,
  volume = {70},
  pages = {1--33},
  doi = {10.18637/jss.v070.i08},
  abstract = {flexsurv is an R package for fully-parametric modeling of survival data. Any parametric time-to-event distribution may be fitted if the user supplies a probability density or hazard function, and ideally also their cumulative versions. Standard survival distributions are built in, including the three and four-parameter generalized gamma and F distributions. Any parameter of any distribution can be modeled as a linear or log-linear function of covariates. The package also includes the spline model of Royston and Parmar (2002), in which both baseline survival and covariate effects can be arbitrarily flexible parametric functions of time. The main model-fitting function, flexsurvreg, uses the familiar syntax of survreg from the standard survival package (Therneau 2016). Censoring or left-truncation are specified in 'Surv' objects. The models are fitted by maximizing the full log-likelihood, and estimates and confidence intervals for any function of the model parameters can be printed or plotted. flexsurv also provides functions for fitting and predicting from fully-parametric multi-state models, and connects with the mstate package (de Wreede, Fiocco, and Putter 2011). This article explains the methods and design principles of the package, giving several worked examples of its use.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J2JV9ADF\\jackson_2016_flexsurv.pdf},
  journal = {Journal of Statistical Software},
  number = {8}
}

@article{Jacobsen1995,
  title = {Do Reproductive Factors Influence Colorectal Cancer Survival?},
  author = {Jacobsen, Bjarne K. and Vollset, Stein Emil and Kv\aa le, Gunnar},
  year = {1995},
  month = sep,
  volume = {48},
  pages = {1119--1122},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(95)00009-S},
  abstract = {During 29 years follow up of 63,090 Norwegian women, 1347 women had a diagnosed cancer of the colon or rectum. Seven hundred and fifty-five of these women (56\%) subsequently died of colorectal cancer. We investigated possible relationships between reproductive history and cancer survival and found little evidence that reproductive history is of prognostic value for colorectal cancer survival.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RUWCY9FH\\jacobsen_et_al_1995_do_reproductive_factors_influence_colorectal_cancer_survival.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {9}
}

@book{James2013,
  title = {An Introduction to Statistical Learning},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  volume = {103},
  publisher = {{Springer New York}},
  issn = {1431-875X},
  doi = {10.1007/978-1-4614-7138-7},
  city = {New York, NY},
  isbn = {978-1-4614-7137-0},
  keywords = {\#nosource}
}

@article{Jamsen2012,
  title = {Obesity, {{Diabetes}}, and {{Preoperative Hyperglycemia}} as {{Predictors}} of {{Periprosthetic Joint Infection}}: {{A Single}}-{{Center Analysis}} of 7181 {{Primary Hip}} and {{Knee Replacements}} for {{Osteoarthritis}}},
  shorttitle = {Obesity, {{Diabetes}}, and {{Preoperative Hyperglycemia}} as {{Predictors}} of {{Periprosthetic Joint Infection}}},
  author = {J{\"a}msen, Esa and Nevalainen, Pasi and Eskelinen, Antti and Huotari, Kaisa and Kalliovalkama, Jarkko and Moilanen, Teemu},
  year = {2012},
  month = jul,
  volume = {94},
  pages = {e101-1-9},
  issn = {0021-9355},
  doi = {10.2106/JBJS.J.01935},
  journal = {The Journal of Bone and Joint Surgery-American Volume},
  language = {en},
  number = {14}
}

@article{Janitza2018,
  title = {A Computationally Fast Variable Importance Test for Random Forests for High-Dimensional Data},
  author = {Janitza, Silke and Celik, Ender and Boulesteix, Anne-Laure},
  year = {2018},
  month = dec,
  volume = {12},
  pages = {885--915},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {1862-5347},
  doi = {10.1007/s11634-016-0276-4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8JXKNET6\\janitza_et_al_2018_a_computationally_fast_variable_importance_test_for_random_forests_for.pdf},
  journal = {Advances in Data Analysis and Classification},
  number = {4}
}

@article{Jawad2019,
  title = {Multi-State Analysis of Hemi- and Total Hip Arthroplasty for Hip Fractures in the {{Swedish}} Population\textemdash{{Results}} from a {{Swedish}} National Database Study of 38,912 Patients},
  author = {Jawad, Z. and Nemes, S. and B{\"u}low, E. and Rogmark, C. and Cnudde, P.},
  year = {2019},
  month = feb,
  volume = {50},
  pages = {272--277},
  publisher = {{Elsevier}},
  issn = {0020-1383},
  doi = {10.1016/J.INJURY.2018.12.022},
  abstract = {INTRODUCTION Hip fractures are a common problem of the elderly population with significant mortality and morbidity. The choice between total hip arthroplasty (THA) and hemiarthroplasty depends on multiple factors including comorbidity. The Swedish Hip Arthroplasty Register (SHAR) provides a unique opportunity to study mortality and revision rates in this population. Linkage with government databases allow for in-depth research into the factors that influence risk of revision surgery and death in the hip fracture patient. PATIENTS AND METHODS Data was linked between SHAR, Statistics Sweden and the National Board of Health and Welfare. Data was collected on 38,912 patients who received a fracture-related hip arthroplasty between 2005 and 2012. A multistate analysis was performed and three states were identified: primary hip surgery and alive (state 1), revision after primary hip surgery (state 2) and death (state 3). These were marking points in the longitudinal outcome study. RESULTS 38,912 patients who received an arthroplasty for an acute hip fracture were included. By the end of the study period 1309 (3.4\%) of these patients underwent a revision and 17,365 (45.1\%) patients died. Patients with THA had a reduced risk of death from primary operation compared to hemiarthroplasty (HR = 0.49) and a decreased revision risk (HR = 0.69). Female patients had a statistically significant reduced mortality (HR = 0.6) compared to men. There was no statistically significant difference in risk of revision surgery between direct lateral and posterior approach. CONCLUSION We identified an influence of type of surgery, sex, age and Elixhauser Comorbidity Index (ECI) on risk of revision and mortality. Males, greater comorbidity burden and older patients had higher mortality risks. The posterior approach did not have a significant influence on revision risk. Further research could include all patients who had reoperation(s) to further strengthen our findings. Patients who had a THA had lower revision rate and mortality. The latter is likely due to selection.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\W7FNTU36\\jawad_et_al_2019_multi-state_analysis_of_hemi-_and_total_hip_arthroplasty_for_hip_fractures_in.pdf},
  journal = {Injury},
  keywords = {coder},
  number = {2}
}

@article{Jensen2011,
  title = {Danish Education Registers},
  author = {Jensen, Vibeke M. and Rasmussen, Astrid W.},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {91--94},
  issn = {14034948},
  doi = {10.1177/1403494810394715},
  abstract = {Introduction: Collection of systematic information on education is a long-established practice in Denmark. Content: We describe the education registers available through Statistics Denmark. In particular, we describe the most widely used register: the Population Education Register (PER). Validity and coverage: In 2008, 96\% of the Danish population aged 15-69 have non-missing education information in PER. For the immigrant population born in the same cohorts the coverage is 85-90\%, which is a high coverage in an international context. Conclusion: The validity and coverage of the Danish education registers are very high. \textcopyright{} 2011 the Nordic Societies of Public Health.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R75SZP9T\\jensen_rasmussen_2011_danish_education_registers.pdf},
  journal = {Scandinavian Journal of Public Health},
  keywords = {Coverage,education,registers,validity},
  number = {7}
}

@article{Jeong2014,
  title = {Collaborative Research for Academic Knowledge Creation: {{How}} Team Characteristics, Motivation, and Processes Influence Research Impact},
  author = {Jeong, Seongkyoon and Choi, Jae Young},
  year = {2014},
  volume = {42},
  pages = {460--473},
  issn = {0302-3427},
  doi = {10.1093/scipol/scu067},
  abstract = {Contending that collaboration management practices and interpersonal relationships are the main factors in successful collaboration in R\&D, scholars have turned their attention to the relationships between collaborators. Internal factors in research collaboration activities are not yet understood at the team level. They are the so-called black box of collaboration study. The purpose of this paper is to empirically demonstrate how factors relating to team characteristics, motivation, and processes influence research impact. The study works from a multi-theoretical perspective, extending from behavioral science to general management study, and seeks to answer the question: How should we organize and manage a collaborative team to improve its research impact? The empirical results show that, along with previously identified qualitative and quantitative factors, input factors such as: project motivation, transformational leadership, frequent face-to-face communication, more outsourcing, more attentional resource, and more evenly distributed workload improve research impact.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A9JE66F7\\jeong_choi_2014_collaborative_research_for_academic_knowledge_creation.pdf},
  isbn = {0302-3427},
  journal = {Science and Public Policy},
  keywords = {co-authorship analysis,Co-authorship analysis,negative binomial regression,Negative binomial regression,research collaboration,Research collaboration,research management,Research management},
  number = {4}
}

@article{Jevsevar2015,
  title = {Orthopaedic Healthcare Worldwide: {{Using}} Clinical Practice Guidelines in Clinical Decision Making},
  author = {Jevsevar, David S and Bozic, Kevin J},
  year = {2015},
  volume = {473},
  pages = {2762--2764},
  doi = {10.1007/s11999-015-4336-4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EZ4NPKIR\\jevsevar_bozic_2015_orthopaedic_healthcare_worldwide.pdf},
  journal = {Clinical Orthopaedics and Related Research}
}

@article{Jiang2005,
  title = {Development and Initial Validation of a Risk Score for Predicting In-Hospital and 1-{{Year}} Mortality in Patients with Hip Fractures},
  author = {Jiang, Hong X and Majumdar, Sumit R and Dick, Donald A and Moreau, Marc and Raso, James and Otto, David D and Johnston, D William C},
  year = {2005},
  volume = {20},
  pages = {494--500},
  issn = {08840431},
  doi = {10.1359/JBMR.041133},
  abstract = {UNLABELLED Our objectives were to better define the rates and determinants of in-hospital and 1-year mortality after hip fracture. We studied a population-based cohort of 3981 hip fracture patients. Using multivariable regression methods, we identified risk factors for mortality (older age, male sex, long-term care residence, 10 prefracture co-morbidities) and calculated a hip fracture-specific score that could accurately predict or risk-adjust in-hospital and 1-year mortality. Our methods, after further validation, may be useful for comparing outcomes across hospitals or regions. INTRODUCTION Hip fractures in the elderly are common and associated with significant mortality and variations in outcome. The rates and determinants of mortality after hip fracture are not well defined. Our objectives were (1) to define the rate of in-hospital and 1-year mortality in hip fracture patients, (2) to describe co-morbidities at the time of fracture, and (3) to develop and validate a multivariable risk-adjustment model for mortality. MATERIALS AND METHODS We studied a population-based cohort of 3981 hip fracture patients \textquestiondown{} or =60 years of age admitted to hospitals in a large Canadian health region from 1994 to 2000. We collected sociodemographic and prefracture co-morbidity data. Main outcomes were in-hospital and 1-year mortality. We used multivariable regression methods to first derive a risk-adjustment model for mortality in 2187 patients treated at one hospital and then validated it in 1794 patients treated at another hospital. These models were used to calculate a score that could predict or risk-adjust in-hospital and 1-year mortality after hip fracture. RESULTS AND CONCLUSIONS The median age of the cohort was 82 years, 71\% were female, and 26\% had more than four prefracture co-morbidities. In-hospital mortality was 6.3\%; 10.2\% for men and 4.7\% for women (adjusted odds ratio, 1.8; 95\% CI, 1.3-2.4). Mortality at 1 year was 30.8\%; 37.5\% for men and 28.2\% for women (adjusted p \textexclamdown{} 0.001). Older age, male sex, long-term care residence, and 10 different co-morbidities were independently associated with mortality. Risk-adjustment models based on these variables had excellent accuracy for predicting mortality in-hospital (c-statistic = 0.82) and at 1 year (c-statistic = 0.74). We conclude that 1 in 15 elderly patients with hip fracture will die during hospitalization, and almost one-third of those who survive to discharge will die within the year. The determinants of mortality were primarily older age, male sex, and prefracture co-morbidities. Our hip fracture-specific risk-adjustment tool is pragmatic and reliable, and after further validation, may be useful for comparing outcomes across different hospitals or regions.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WJYKQII7\\jiang_et_al_2005_development_and_initial_validation_of_a_risk_score_for_predicting_in-hospital.pdf},
  journal = {Journal of Bone and Mineral Research},
  keywords = {2,20 years,3,co-morbidity,fracture is be-,hip fracture,hospital mortality for a,mortality,next,outcomes,patient with a hip,population-based studies,previous studies have estimated,risk adjustment,steadily increasing and projected,that in-,to double within the},
  number = {3},
  pmid = {15746995}
}

@article{Johansen2014,
  title = {48 * {{USING THE NATIONAL HIP FRACTURE DATABASE}} ({{NHFD}}) {{TO PROFILE THE IMPACT OF HIP FRACTURE ON THE NHS}}},
  author = {Johansen, A. and Neuberger, J. and Boulton, C. and Williams, A. and Plant, F. and Wakeman, R. and Cromwell, D. and Wilson, H. and Moran, C.},
  year = {2014},
  month = oct,
  volume = {43},
  pages = {ii13-ii13},
  issn = {0002-0729},
  doi = {10.1093/ageing/afu126.1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SEDHDEBQ\\johansen_et_al_2014_48_using_the_national_hip_fracture_database_(nhfd)_to_profile_the_impact_of.pdf},
  journal = {Age and Ageing},
  number = {suppl 2}
}

@article{John2019,
  title = {Assessing Causal Treatment Effect Estimation When Using Large Observational Datasets},
  author = {John, E. R. and Abrams, K. R. and Brightling, C. E. and Sheehan, N. A.},
  year = {2019},
  month = nov,
  volume = {19},
  pages = {207},
  publisher = {{BioMed Central Ltd.}},
  doi = {10.1186/s12874-019-0858-x},
  abstract = {Background: Recently, there has been a heightened interest in developing and evaluating different methods for analysing observational data. This has been driven by the increased availability of large data resources such as Electronic Health Record (EHR) data alongside known limitations and changing characteristics of randomised controlled trials (RCTs). A wide range of methods are available for analysing observational data. However, various, sometimes strict, and often unverifiable assumptions must be made in order for the resulting effect estimates to have a causal interpretation. In this paper we will compare some common approaches to estimating treatment effects from observational data in order to highlight the importance of considering, and justifying, the relevant assumptions prior to conducting an observational analysis. Methods: A simulation study was conducted based upon a small cohort of patients with chronic obstructive pulmonary disease. Two-stage least squares instrumental variables, propensity score, and linear regression models were compared under a range of different scenarios including different strengths of instrumental variable and unmeasured confounding. The effects of violating the assumptions of the instrumental variables analysis were also assessed. Sample sizes of up to 200,000 patients were considered. Results: Two-stage least squares instrumental variable methods can yield unbiased treatment effect estimates in the presence of unmeasured confounding provided the sample size is sufficiently large. Adjusting for measured covariates in the analysis reduces the variability in the two-stage least squares estimates. In the simulation study, propensity score methods produced very similar results to linear regression for all scenarios. A weak instrument or strong unmeasured confounding led to an increase in uncertainty in the two-stage least squares instrumental variable effect estimates. A violation of the instrumental variable assumptions led to bias in the two-stage least squares effect estimates. Indeed, these were sometimes even more biased than those from a na\"ive linear regression model. Conclusions: Instrumental variable methods can perform better than na\"ive regression and propensity scores. However, the assumptions need to be carefully considered and justified prior to conducting an analysis or performance may be worse than if the problem of unmeasured confounding had been ignored altogether.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5R5IFCYJ\\john_et_al_2019_assessing_causal_treatment_effect_estimation_when_using_large_observational.pdf},
  journal = {BMC Medical Research Methodology},
  keywords = {Causal effect,Instrumental variable,Observational data,Propensity scores,Unmeasured confounding},
  number = {1}
}

@article{Johnson2006,
  title = {Adapting the {{Rx}}-{{Risk}}-{{V}} for Mortality Prediction in Outpatient Populations.},
  author = {Johnson, Michael L and {El-Serag}, Hashem B and Tran, Tung Thomas and Hartman, Christine and Richardson, Peter and Abraham, Neena S},
  year = {2006},
  month = aug,
  volume = {44},
  pages = {793--7},
  issn = {0025-7079},
  doi = {10.1097/01.mlr.0000218804.41758.ef},
  abstract = {OBJECTIVES We sought to operationalize, test, and validate an outpatient pharmacy-based case-mix adjuster. METHODS Outpatients from the Department of Veterans Affairs (VA) prescribed a nonsteroidal anti-inflammatory drug (NSAID) or cyclooxygenase-2 selective drug during 2002 were identified. We updated and extended the Rx-Risk-V by adding 26 additional disease categories and mapping them to VA drug-class codes; derived empirical weights for each from a logistic model of 1-year mortality; adjusted for age, race and sex; and scored the weights into 1 measure of comorbidity. We compared the weighted score to the Deyo diagnosis-based comorbidity index and validated it in a national cohort of 260,321 outpatients with chronic heart failure (CHF). RESULTS One-year mortality among the 724,270-outpatient NSAID cohort was 1.6\% (n = 11,766). Using a baseline model of age, race, and gender (c-index = 0.716), we found that the Deyo measure improved the prediction of mortality (c-index = 0.765), and the pharmacy comorbidity score further improved the prediction (c-index = 0.782), an increase of 25.8\%. Using both, we found further improvement (c-index = 0.792). Among the CHF cohort, 9.7\% (n = 25,251) died within 1 year. Performance of the baseline model controlling for age, race, and gender (c index = 0.620) improved with addition of the pharmacy comorbidity score (c index = 0.689), compared with the addition of the Deyo measure (c index = 0.651), an increase of 55.1\%. Together, they slightly improved prediction in CHF patients (c index = 0.695). CONCLUSIONS The updated and extended Rx-Risk-V is useful for case-mix adjustment of mortality in an outpatient population.},
  journal = {Medical care},
  keywords = {\#nosource},
  number = {8},
  pmid = {16862043}
}

@article{Johnson2013,
  title = {Using Log-Linear and Logistic Regression for Inferences on Adjusted Estimates of Relative Risk in Randomized Comparative Trials},
  author = {Johnson, William D and Replogle, William H and Han, Hongmei},
  year = {2013},
  pages = {3408--3416},
  keywords = {\#nosource,binomial,generalized linear model,incidence,large sample inference,odds ratio}
}

@inproceedings{Johnson2017,
  title = {Reproducibility in Critical Care: A Mortality Prediction Case Study},
  shorttitle = {Reproducibility in Critical Care},
  booktitle = {Machine {{Learning}} for {{Healthcare Conference}}},
  author = {Johnson, Alistair E. W. and Pollard, Tom J. and Mark, Roger G.},
  year = {2017},
  month = nov,
  pages = {361--376},
  issn = {1938-7228},
  abstract = {Mortality prediction of intensive care unit (ICU) patients facilitates hospital benchmarking and has the opportunity to provide caregivers with useful summaries of patient health at the bedside. Th...},
  chapter = {Machine Learning},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4WCVACH2\\Johnson m. fl. - 2017 - Reproducibility in critical care a mortality pred.pdf;C\:\\Users\\erik_\\Zotero\\storage\\YMGWHXT9\\johnson17a.html},
  language = {en}
}

@article{Johnson2018,
  title = {Use of Alternative Medicine for Cancer and Its Impact on Survival},
  author = {Johnson, Skyler B. and Park, Henry S. and Gross, Cary P. and Yu, James B.},
  year = {2018},
  volume = {110},
  pages = {54--71},
  issn = {0027-8874},
  doi = {10.1093/jnci/djx145},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\K6Y9QJSU\\johnson_et_al_2018_use_of_alternative_medicine_for_cancer_and_its_impact_on_survival.pdf},
  journal = {JNCI: Journal of the National Cancer Institute},
  keywords = {alternative medicine,breast,cancer,cancer therapy,chemotherapy regimen,colorectal cancer,comorbidity,endocrine therapy,hormone replacement therapy,lung,lung cancer,operative,prostate,radiation therapy,socioeconomic factors,surgery specialty,surgical procedures,survival analysis},
  number = {1}
}

@article{Johnston2002,
  title = {Impact of Different Measures of Comorbid Disease on Predicted Mortality of Intensive Care Unit Patients.},
  author = {a Johnston, Joseph and Wagner, Douglas P and Timmons, Stephen and Welsh, Deborah and Tsevat, Joel and Render, Marta L},
  year = {2002},
  volume = {40},
  pages = {929--40},
  issn = {0025-7079},
  doi = {10.1097/01.MLR.0000027367.95427.AA},
  abstract = {BACKGROUND: Valid comparison of patient survival across ICUs requires adjustment for burden of chronic illness. The optimal measure of comorbidity in this setting remains uncertain.: To examine the impact of different measures of comorbid disease on predicted mortality for ICU patients.: Retrospective cohort study.: Seventeen thousand eight hundred ninety-three veterans from 17 geographically diverse VA Medical Centers and 43 ICUs were studied, admitted between February 1, 1996 and July 31, 1997.: ICD-9-CM codes reflecting comorbid disease from hospital stays before and including the index hospitalization from local VA computer databases were extracted, and three measures of comorbid disease were then compared: (1) an APACHE-weighted comorbidity score using comorbid diseases used in APACHE, (2) a count of conditions described by Elixhauser, and (3) Elixhauser comorbid diseases weighted independently. Univariate analyses and multivariate logistic regression models were used to determine the contribution of each measure to in-hospital mortality predictions.: Models using independently weighted Elixhauser comorbidities discriminated better than models using an APACHE-weighted score or a count of Elixhauser comorbidities. Twenty-three and 14 of the Elixhauser conditions were significant univariate and multivariable predictors of in-hospital mortality, respectively. In a multivariable model including all available predictors, comorbidity accounted for less (8.4\%) of the model's uniquely attributable chi statistic than laboratory values (67.7\%) and diagnosis (17.7\%), but more than age (4.0\%) and admission source (2.1\%). Excluding codes from prior hospitalizations did not adversely affect model performance.: Independently weighted comorbid conditions identified through computerized discharge abstracts can contribute significantly to ICU risk adjustment models.},
  isbn = {0000027367},
  journal = {Medical care},
  keywords = {\#nosource,APACHE,Chronic Disease,Chronic Disease: classification,Chronic Disease: epidemiology,Cohort Studies,Comorbidity,Female,Hospital Mortality,Hospitals,Humans,Intensive Care Units,Intensive Care Units: statistics \& numerical data,International Classification of Diseases,Logistic Models,Male,Middle Aged,Predictive Value of Tests,Retrospective Studies,Risk Adjustment,Risk Adjustment: methods,United States,United States: epidemiology,Veterans,Veterans: statistics \& numerical data},
  number = {10},
  pmid = {12395026}
}

@article{Jovanovic2016,
  title = {Building Interpretable Predictive Models for Pediatric Hospital Readmission Using {{Tree}}-{{Lasso}} Logistic Regression},
  author = {Jovanovic, Milos and Radovanovic, Sandro and Vukicevic, Milan and Poucke, Sven Van and Delibasic, Boris},
  year = {2016},
  month = sep,
  volume = {72},
  pages = {12--21},
  publisher = {{Elsevier}},
  doi = {10.1016/J.ARTMED.2016.07.003},
  abstract = {OBJECTIVES Quantification and early identification of unplanned readmission risk have the potential to improve the quality of care during hospitalization and after discharge. However, high dimensionality, sparsity, and class imbalance of electronic health data and the complexity of risk quantification, challenge the development of accurate predictive models. Predictive models require a certain level of interpretability in order to be applicable in real settings and create actionable insights. This paper aims to develop accurate and interpretable predictive models for readmission in a general pediatric patient population, by integrating a data-driven model (sparse logistic regression) and domain knowledge based on the international classification of diseases 9th\textemdash revision clinical modification (ICD-9-CM) hierarchy of diseases. Additionally, we propose a way to quantify the interpretability of a model and inspect the stability of alternative solutions. MATERIALS AND METHODS The analysis was conducted on \textquestiondown 66,000 pediatric hospital discharge records from California, State Inpatient Databases, Healthcare Cost and Utilization Project between 2009 and 2011. We incorporated domain knowledge based on the ICD-9-CM hierarchy in a data driven, Tree-Lasso regularized logistic regression model, providing the framework for model interpretation. This approach was compared with traditional Lasso logistic regression resulting in models that are easier to interpret by fewer high-level diagnoses, with comparable prediction accuracy. RESULTS The results revealed that the use of a Tree-Lasso model was as competitive in terms of accuracy (measured by area under the receiver operating characteristic curve\textemdash AUC) as the traditional Lasso logistic regression, but integration with the ICD-9-CM hierarchy of diseases provided more interpretable models in terms of high-level diagnoses. Additionally, interpretations of models are in accordance with existing medical understanding of pediatric readmission. Best performing models have similar performances reaching AUC values 0.783 and 0.779 for traditional Lasso and Tree-Lasso, respectfully. However, information loss of Lasso models is 0.35 bits higher compared to Tree-Lasso model. CONCLUSIONS We propose a method for building predictive models applicable for the detection of readmission risk based on Electronic Health records. Integration of domain knowledge (in the form of ICD-9-CM taxonomy) and a data-driven, sparse predictive algorithm (Tree-Lasso Logistic Regression) resulted in an increase of interpretability of the resulting model. The models are interpreted for the readmission prediction problem in general pediatric population in California, as well as several important subpopulations, and the interpretations of models comply with existing medical understanding of pediatric readmission. Finally, quantitative assessment of the interpretability of the models is given, that is beyond simple counts of selected low-level features.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CCXQFQVT\\jovanovic_et_al_2016_building_interpretable_predictive_models_for_pediatric_hospital_readmission.pdf},
  journal = {Artificial Intelligence in Medicine}
}

@article{Jr1998,
  title = {Comparison of Strategies for Validating Binary Logistic Regression Models},
  author = {Jr, Frank E Harrell},
  year = {1998},
  journal = {Statistics},
  keywords = {\#nosource}
}

@article{Jullum2017,
  title = {Parametric or Nonparametric: {{The FIC}} Approach},
  author = {Jullum, Martin and Hjort, Nils Lid},
  year = {2017},
  volume = {27},
  pages = {951--981},
  issn = {10170405},
  doi = {10.5705/ss.202015.0364},
  abstract = {Should one rely on a parametric or nonparametric model when analysing a given data set? This classic question cannot be answered by traditional model selection criteria like AIC and BIC, since a nonparametric model has no likelihood. The purpose of the present paper is to develop a focused information criterion (FIC) for comparing general non-nested parametric models with a nonparametric alternative. It relies in part on the notion of a focus parameter, a population quantity of particular interest in the statistical analysis. The FIC compares and ranks candidate models based on estimated precision of the different model-based estimators for the focus parameter. It has earlier been developed for several classes of problems, but mainly involving parametric models. The new FIC, including also nonparametrics, is novel also in the mathematical context, being derived without the local neighbourhood asymptotics underlying previous versions of FIC. Certain average-weighted versions, called AFIC, allowing several focus parameters to be considered simultaneously, are also developed. We concentrate on the standard i.i.d. setting and certain direct extensions thereof, but also sketch further generalisations to other types of data. Theoretical and simulation-based results demonstrate desirable properties and satisfactory performance.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3MUDP2MF\\jullum_hjort_2017_parametric_or_nonparametric.pdf},
  journal = {Statistica Sinica},
  keywords = {Asymptotic theory,Focused information criterion,Model selection},
  number = {3}
}

@article{Jullum2019,
  title = {What Price Semiparametric {{Cox}} Regression?},
  author = {Jullum, Martin and Hjort, Nils Lid},
  year = {2019},
  volume = {25},
  pages = {406--438},
  publisher = {{Springer US}},
  issn = {15729249},
  doi = {10.1007/s10985-018-9450-7},
  abstract = {Cox's proportional hazards regression model is the standard method for modelling censored life-time data with covariates. In its standard form, this method relies on a semiparametric proportional hazards structure, leaving the baseline unspecified. Naturally, specifying a parametric model also for the baseline hazard, leading to fully parametric Cox models, will be more efficient when the parametric model is correct, or close to correct. The aim of this paper is two-fold. (a) We compare parametric and semiparametric models in terms of their asymptotic relative efficiencies when estimating different quantities. We find that for some quantities the gain of restricting the model space is substantial, while it is negligible for others. (b) To deal with such selection in practice we develop certain focused and averaged focused information criteria (FIC and AFIC). These aim at selecting the most appropriate proportional hazards models for given purposes. Our methodology applies also to the simpler case without covariates, when comparing Kaplan\textendash Meier and Nelson\textendash Aalen estimators to parametric counterparts. Applications to real data are also provided, along with analyses of theoretical behavioural aspects of our methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F24IUZP3\\jullum_hjort_2019_what_price_semiparametric_cox_regression.pdf},
  journal = {Lifetime Data Analysis},
  keywords = {Cox regression,Focused information criteria,Model selection,Parametrics and semiparametrics,Survival data},
  number = {3}
}

@article{jurgensBayesianGeneralizedAgeperiodcohort2014,
  title = {A {{Bayesian}} Generalized Age-Period-Cohort Power Model for Cancer Projections},
  author = {J{\"u}rgens, Verena and Ess, Silvia and Cerny, Thomas and Vounatsou, Penelope},
  year = {2014},
  volume = {33},
  pages = {4627--4636},
  issn = {10970258},
  doi = {10.1002/sim.6248},
  abstract = {Age-period-cohort (APC) models are the state of art in cancer projections, assessing past and recent trends and extrapolating mortality or incidence data into the future. Nordpred is a well-established software, assuming a Poisson distribution for the counts and a log-link or power-link function with fixed power; however, its predictive performance is poor for sparse data. Bayesian models with log-link function have been applied, but they can lead to extreme estimates. In this paper, we address criticisms of the aforementioned models by providing Bayesian formulations based on a power-link and develop a generalized APC power-link model, which assumes a random rather than fixed power parameter. In addition, a power model with a fixed power parameter of five was formulated in the Bayesian framework. The predictive performance of the new models was evaluated on Swiss lung cancer mortality data using model-based estimates of observed periods. Results indicated that the generalized APC power-link model provides best estimates for male and female lung cancer mortality. The gender-specific models were further applied to project lung cancer mortality in Switzerland during the periods 2009-2013 and 2014-2018.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BIQB26ZN\\jürgens_et_al_2014_a_bayesian_generalized_age-period-cohort_power_model_for_cancer_projections.pdf},
  journal = {Statistics in Medicine},
  keywords = {Bayesian inference,Cancer projection,Lung cancer mortality,Nordpred,Power model},
  number = {26},
  pmid = {24996118}
}

@article{Jurisson2017,
  title = {The Impact of Comorbidities on Hip Fracture Mortality: A Retrospective Population-Based Cohort Study},
  author = {J{\"u}risson, Mikk and Raag, Mait and Kallikorm, Riina and Lember, Margus and Uusk{\"u}la, Anneli},
  year = {2017},
  volume = {12},
  issn = {18623514},
  doi = {10.1007/s11657-017-0370-z},
  abstract = {Background: Estimates of hip fracture mortality in Eastern Europe are scarce. We aimed to estimate the magnitude and duration of excess mortality after hip fracture in Estonia. Methods: Retrospective, population-based 10-year study of persons aged {$\geq$}50 in two cohorts: with hip fracture and an age-and sex-matched (in a 1:4 ratio) random sample from the national health insurance fund database for comparison. Cumulative risks, excess risks and relative risks of death were estimated using Poisson regression with 95\% bootstrap confidence intervals (CI). Risks were adjusted for age and Charlson comorbidity index. Results: We identified 8298 (2383 men, 5915 women) incident hip fracture patients from 2005 to 2013 and 33,191 (9531 men, 23,660 women) individuals for the reference group. 5552 (1564 men, 3988 women) cases and 14,037 (3514 men, 10,523 women) reference individuals died during the 10-year follow-up period. Among hip fracture patients we observed a pronounced and durable excess risk of death that was highest within 3\textendash 6 months after fracture and persisted for the full 10-year follow-up period. After adjustment for age and Charlson index, hip fracture was associated with a 21.1\% (95\% CI 20.0\textendash 22.5\%) 10-year cumulative excess risk of death (RR 1.37, 95\% CI 1.35\textendash 1.40). We found a high immediate excess risk of death in older age groups ({$\geq$}80 years) and gradually accumulating excess risk in younger age groups (50\textendash 79 years). The excess risk was more pronounced among men than women. Conclusions: By the end of the 10-year follow-up, 1 in 4 deaths in the hip fracture group was attributable to the hip fracture. The results indicate a high attributable impact of hip fracture as an independent risk factor for death.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GQG6G5SN\\jürisson_et_al_2017_the_impact_of_comorbidities_on_hip_fracture_mortality.pdf},
  isbn = {1862-3522 1862-3514},
  journal = {Archives of Osteoporosis},
  number = {1},
  pmid = {618024935}
}

@article{Kallus2019,
  title = {{{MM}}-{{PCA}}: {{Integrative}} Analysis of Multi-Group and Multi-View Data},
  author = {Kallus, Jonatan and Johansson, Patrik and Nelander, Sven and J{\"o}rnsten, Rebecka},
  year = {2019},
  month = nov,
  abstract = {Data integration is the problem of combining multiple data groups (studies, cohorts) and/or multiple data views (variables, features). This task is becoming increasingly important in many disciplines due to the prevalence of large and heterogeneous data sets. Data integration commonly aims to identify structure that is consistent across multiple cohorts and feature sets. While such joint analyses can boost information from single data sets, it is also possible that a globally restrictive integration of heterogeneous data may obscure signal of interest. Here, we therefore propose a data adaptive integration method, allowing for structure in data to be shared across an a priori unknown subset of cohorts and views\vphantom\{\}. The method, Multi-group Multi-view Principal Component Analysis (MM-PCA), identifies partially shared, sparse low-rank components. This also results in an integrative bi-clustering across cohorts and views. The strengths of MM-PCA are illustrated on simulated data and on 'omics data from The Cancer Genome Atlas. MM-PCA is available as an R-package. Key words: Data integration, Multi-view, Multi-group, Bi-clustering},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LSEALQAJ\\kallus_et_al_2019_mm-pca.pdf}
}

@article{Kamarudin2017,
  title = {Time-Dependent {{ROC}} Curve Analysis in Medical Research: {{Current}} Methods and Applications},
  author = {Kamarudin, Adina Najwa and Cox, Trevor and {Kolamunnage-Dona}, Ruwanthi},
  year = {2017},
  volume = {17},
  pages = {1--19},
  publisher = {{BMC Medical Research Methodology}},
  issn = {14712288},
  doi = {10.1186/s12874-017-0332-6},
  abstract = {BACKGROUND ROC (receiver operating characteristic) curve analysis is well established for assessing how well a marker is capable of discriminating between individuals who experience disease onset and individuals who do not. The classical (standard) approach of ROC curve analysis considers event (disease) status and marker value for an individual as fixed over time, however in practice, both the disease status and marker value change over time. Individuals who are disease-free earlier may develop the disease later due to longer study follow-up, and also their marker value may change from baseline during follow-up. Thus, an ROC curve as a function of time is more appropriate. However, many researchers still use the standard ROC curve approach to determine the marker capability ignoring the time dependency of the disease status or the marker. METHODS We comprehensively review currently proposed methodologies of time-dependent ROC curves which use single or longitudinal marker measurements, aiming to provide clarity in each methodology, identify software tools to carry out such analysis in practice and illustrate several applications of the methodology. We have also extended some methods to incorporate a longitudinal marker and illustrated the methodologies using a sequential dataset from the Mayo Clinic trial in primary biliary cirrhosis (PBC) of the liver. RESULTS From our methodological review, we have identified 18 estimation methods of time-dependent ROC curve analyses for censored event times and three other methods can only deal with non-censored event times. Despite the considerable numbers of estimation methods, applications of the methodology in clinical studies are still lacking. CONCLUSIONS The value of time-dependent ROC curve methods has been re-established. We have illustrated the methods in practice using currently available software and made some recommendations for future research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NC23N3KU\\kamarudin_et_al_2017_time-dependent_roc_curve_analysis_in_medical_research.pdf},
  isbn = {1471-2288 (Electronic) 1471-2288 (Linking)},
  journal = {BMC Medical Research Methodology},
  keywords = {Biomarker evaluation,Event-time,Longitudinal data,ROC curve,Software,Time-dependent AUC},
  number = {1},
  pmid = {28388943}
}

@article{Kannegaard2010,
  title = {Excess Mortality in Men Compared with Women Following a Hip Fracture. {{National}} Analysis of Comedications, Comorbidity and Survival},
  author = {Kannegaard, P. N. and {van der Mark}, S. and Eiken, P. and Abrahamsen, B.},
  year = {2010},
  month = mar,
  volume = {39},
  pages = {203--209},
  publisher = {{Oxford University Press}},
  issn = {0002-0729},
  doi = {10.1093/ageing/afp221},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MC4C6HM3\\kannegaard_et_al_2010_excess_mortality_in_men_compared_with_women_following_a_hip_fracture.pdf},
  journal = {Age and Ageing},
  keywords = {comorbidity,fractures,hip fractures,mortality},
  number = {2}
}

@article{Kapadia2016,
  title = {Periprosthetic Joint Infection},
  author = {Kapadia, Bhaveen H and Berg, Richard A and Daley, Jacqueline A and Fritz, Jan and Bhave, Anil and Mont, Michael A},
  year = {2016},
  month = jan,
  volume = {387},
  pages = {386--394},
  issn = {01406736},
  doi = {10.1016/S0140-6736(14)61798-0},
  journal = {The Lancet},
  language = {en},
  number = {10016}
}

@article{Kaplan1958,
  title = {Nonparametric Estimation from Incomplete Observations},
  author = {Kaplan, E L and Meier, Paul},
  year = {1958},
  volume = {53},
  pages = {457--481},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {282}
}

@article{Kaplan2010,
  title = {An Extension of the Propensity Score Adjustment Method for the Analysis of Group Differences in {{MIMIC}} Models},
  author = {Kaplan, David},
  year = {2010},
  volume = {4},
  pages = {467--492},
  issn = {0027-3171},
  doi = {10.1207/S15327906MBR3404},
  abstract = {This article proposes an extension of the propensity score adjustment method to latent variable models. The propensity score was proposed by Rosenbaum and Rubin (1983) as a means of balancing treatment and control groups with respect to observed covariates in non-randomized studies. The propensity score is defined as the conditional probability of assignment to a treatment group given a set of observed covariates. In a typical application of this approach, each observation is associated with a propensity to be assigned to the treatment group. The distribution of propensity scores is then divided into strata and analyses of treatment group differences are conducted within strata. Comparisons of treatment group differences within and across strata provide evidence for whether or not the bias due to non-random selection into treatment groups has been accounted for by the propensity score adjustment. This article extends the application of the propensity score approach to the analysis o f group differences on latent variables. In particular, multi-sample MIMIC modeling is utilized to test hypotheses about treatment group differences on latent variables across strata. The role of factorial invariance as it relates to the approach advocated in this article is also discussed. An application to the problem of academic tracking differences in self-concept and locus-of-control, using data from the National Educational Longitudinal Study of 1988 (National Center for Education Statistics, 1988), illustrates the procedure. ABSTRACT FROM AUTHOR] of propensity scores is then divided into strata and analyses of treatment group differences are conducted within strata. Comparisons of treatment group differences within and across strata provide evidence for whether or not the bias due to non-random selection into treatment groups has been accounted for by the propensity score adjustment. This article extends the application of the propensity score approach to the analysis o},
  isbn = {00273171},
  journal = {Multivariate Behavioral Research},
  keywords = {\#nosource,LATENT variables,MULTIVARIATE analysis,STATISTIC},
  number = {January 2014}
}

@article{karlsoperDistributionCorrelationCoefficient1916,
  title = {On the Distribution of the Correlation Coefficient in Small Samples. {{Appendix II}} to the Papers of "{{Student}}" and r. {{A}}. {{Fisher}}},
  author = {Karl Soper, HE and Young, AW and Cave, BM and Lee, Alice and {Pearson}},
  year = {1916},
  volume = {11},
  pages = {328--413},
  issn = {00063444},
  doi = {10.2307/2331830},
  isbn = {0006-3444},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {4}
}

@article{Karlsson2019,
  title = {A Natural History Model for Planning Prostate Cancer Testing: {{Calibration}} and Validation Using {{Swedish}} Registry Data},
  author = {Karlsson, Andreas and Jauhiainen, Alexandra and Gulati, Roman and Eklund, Martin and Gr{\"o}nberg, Henrik and Etzioni, Ruth and Clements, Mark},
  year = {2019},
  volume = {14},
  pages = {1--23},
  issn = {19326203},
  doi = {10.1371/journal.pone.0211918},
  abstract = {Recent prostate cancer screening trials have given conflicting results and it is unclear how to reduce prostate cancer mortality while minimising overdiagnosis and overtreatment. Prostate cancer testing is a partially observable process, and planning for testing requires either extrapolation from randomised controlled trials or, more flexibly, modelling of the cancer natural history. An existing US prostate cancer natural history model (Gulati et al, Biostatistics 2010;11:707-719) did not model for differences in survival between Gleason 6 and 7 cancers and predicted too few Gleason 7 cancers for contemporary Sweden. We re-implemented and re-calibrated the US model to Sweden. We extended the model to more finely describe the disease states, their time to biopsy-detectable cancer and prostate cancer survival. We first calibrated the model to the incidence rate ratio observed in the European Randomised Study of Screening for Prostate Cancer (ERSPC) together with age-specific cancer staging observed in the Stockholm PSA (prostate-specific antigen) and Biopsy Register; we then calibrated age-specific survival by disease states under contemporary testing and treatment using the Swedish National Prostate Cancer Register. After calibration, we were able to closely match observed prostate cancer incidence trends in Sweden. Assuming that patients detected at an earlier stage by screening receive a commensurate survival improvement, we find that the calibrated model replicates the observed mortality reduction in a simulation of ERSPC. Using the resulting model, we predicted incidence and mortality following the introduction of regular testing. Compared with a model of the current testing pattern, organised 8 yearly testing for men aged 55-69 years was predicted to reduce prostate cancer incidence by 14\% and increase prostate cancer mortality by 2\%. The model is open source and suitable for planning for effective prostate cancer screening into the future.Copyright \textcopyright{} 2019 Karlsson et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DEFYC648\\karlsson_et_al_2019_a_natural_history_model_for_planning_prostate_cancer_testing.pdf},
  isbn = {1111111111},
  journal = {PLoS ONE},
  number = {2}
}

@article{Karres2015,
  title = {Predicting 30-Day Mortality Following Hip Fracture Surgery: {{Evaluation}} of Six Risk Prediction Models},
  author = {Karres, Julian and Heesakkers, Nicole A. and Ultee, Jan M. and Vrouenraets, Bart C.},
  year = {2015},
  volume = {46},
  pages = {371--377},
  publisher = {{Elsevier Ltd}},
  issn = {18790267},
  doi = {10.1016/j.injury.2014.11.004},
  abstract = {While predictors for mortality after hip fracture surgery have been widely studied, research regarding risk prediction models is limited. Risk models can predict mortality for individual patients, provide insight in prognosis, and be valuable in surgical audits. Existing models have not been validated independently. The purpose of this study is to evaluate the performance of existing risk models for predicting 30-day mortality following hip fracture surgery. Patients and methods: In this retrospective study, all consecutive hip fracture patients admitted between 2004 and 2010 were included. Predicted mortality was calculated for individual patients and compared to the observed outcome. The discriminative performance of the models was assessed using the area under the receiver operating characteristic curve (AUC). Calibration was analysed with the Hosmer-Lemeshow goodness-of-fit test. Results: A literature search yielded six risk prediction models: the Charlson Comorbidity Index (CCI), Orthopaedic Physiologic and Operative Severity Score for the enUmeration of Mortality and Morbidity (O-POSSUM), Estimation of Physiologic Ability and Surgical Stress (E-PASS), a risk model by Jiang et al., the Nottingham Hip Fracture Score (NHFS), and a model by Holt et al. The latter three models were specifically designed for the hip fracture population. All models except the O-POSSUM achieved an AUC greater than 0.70, demonstrating acceptable discriminative power. The score by Jiang et al. performed best with an AUC of 0.78, this was however not significantly different from the NHFS (0.77) or the model by Holt et al. (0.76). When applying the Hosmer-Lemeshow goodness-of-fit test, the model by Holt et al., the NHFS and the model by Jiang et al. showed a significant lack of fit (p \textexclamdown{} 0.05). The CCI, O-POSSUM and E-PASS did not demonstrate lack of calibration. Discussion: None of the existing models yielded excellent discrimination (AUC \textquestiondown{} 0.80). The best discrimination was demonstrated by the models designed for the hip fracture population, however, they had a lack of fit. The NHFS shows most promising results, with reasonable discrimination and extensive validation in earlier studies. Additional research is needed to examine recalibration and to determine the best risk model for predicting early mortality following hip fracture surgery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\397CNFU2\\karres_et_al_2015_predicting_30-day_mortality_following_hip_fracture_surgery.pdf},
  journal = {Injury},
  keywords = {Hip fractures,Mortality,Outcome,Risk prediction,Scoring,Surgery},
  number = {2},
  pmid = {25464983}
}

@article{Karrholm2010,
  title = {The Swedish Hip Arthroplasty Register (Www.Shpr.Se)},
  author = {K{\"a}rrholm, Johan},
  year = {2010},
  volume = {81},
  pages = {3--4},
  issn = {17453674},
  doi = {10.3109/17453671003635918},
  abstract = {In 1975, Peter Herberts initiated a national study of all reop-erations after total hip replacement (THR) in Sweden. This study was designed as a trial lasting for almost 2 years (1976\textendash{} 1977). The goal was to learn more about severe complications of THR and thereby improve on the results. It was considered impossible to collect all primary hip replacements because of the vast number of operations. The pilot study was designed as a retrospective one to evaluate whether a number of key parameters associated with reoperation of total hip arthroplasties could be collected for statistical analysis at a national level. Importantly, it was decided that any further operation after the primary procedure, regardless of whether the implants were exchanged (revision) or not, should be used as failure parameter. Later on, it turned out that the choice of data collected was well suited to analy-sis of outcome, which contributed to the future success of the Register, not least by stimulation of continuous learning and improvement. Almost all orthopedics departments performing hip replace-ments participated in this project, which eventually comprised 513 reoperations. One important experience was that compli-cations were far more common after reoperations than after primary surgery. About a third of all reoperations were associ-ated with further complications (Ahnfelt et al. 1980). Encouraged by the success of this pilot study, the orthope-dics profession in Sweden was again asked if the members would participate in a prospective and continuous national multicenter study of reoperations after THR. At the initiation of this National Register in January 1979, all (at that time 62) but 1 department, which joined somewhat later, accepted to participate. Peter Herberts, who initiated the pilot study, became the leader of the Register and continued in this capac-ity for 30 years. For the first 7 years, the Register was funded as a research project within an academic program. A research fellow, Lenn-art Ahnfelt, originally recruited for the pilot project, presented his thesis on this subject in 1986, which summarized the results up to 1983 (Ahnfelt et al. 1990). The project was pre-sented internationally for the first time at the SICOT confer-ence in London in 1984. From the beginning, all individual reoperations were identi-fied using the patient's social security number. Medical records on every reoperation were collected. More than 100 parameters including demographic data, details of surgical technique, the implant used, the operating unit, and the type and history of the previously used implant or implants were recorded by spe-cially trained secretaries. To enable calculation of implant sur-vival, each hospital delivered information about implants used from 1967 onwards. From 1979 and until 1991, the hospitals continued to deliver details about primary hip arthroplasties on an aggregated level and for each year. This meant that it was not possible to track each individual primary operation to a social security number, which resulted in the need for approxi-mations in order to calculate implant survival. This could, however, be done by the use of information from other govern-mental registers and statistically-based models (Herberts et al. 1989, Herberts and Malchau 1997). In a thorough evaluation, it turned out that the results from the first period (1979\textendash 1991) were valid (S\"oderman et al. 2000). From 1992, all primary total hip arthroplasties were also recorded in detail in the Register. This meant that each surgical procedure could be associated more firmly with patient demographics, the type of incision, a specific implant, and the technique of fixation. In 1999, the recording was extended further by including more details of the implants. Information about, for example, sizes, offset, and implant materials became available. Despite the fact that this increasing amount of data collection over the years also meant that each clinic had to use more resources related to data collection, the register continued to have almost complete coverage. Several factors were responsible for this success. One was the central secretarial unit that provided on-line support and recurring courses for the local secretaries, in addition to well-organized data collection and statistical support. Another key factor was continuous feedback of results to the profession. Initially, only reoperations and implant survival with respect to design and method of fixation were reported at the national level. During the later part of the 1980s, each participating unit also gained access to their own frequency of, and reasons for, reoperations related to the national average. Even though this information could be both encouraging and troublesome for the individual hospitals, the potential power of it to allow monitoring and improvement of outcome was understood, appreciated, and practiced.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9QYYIJSH\\kärrholm_2010_the_swedish_hip_arthroplasty_register_(www.pdf},
  isbn = {9789197711258},
  journal = {Acta Orthopaedica},
  number = {1},
  pmid = {20170435}
}

@techreport{Karrholm2016,
  title = {Svenska H\"oftprotesregistrets \AA rsrapport 2016},
  author = {K{\"a}rrholm, Johan and Lindahl, Hans and Malchau, Henrik and Mohaddes, Maziar and Rogmark, Cecilia and Rolfson, Ola and Malcahu, Henrik and Mohaddes, Maziar and Rogmark, Cecilia and Rolfson, Ola},
  year = {2016},
  institution = {{The Swedish Hip Arthroplasty Register}},
  city = {Gothenburg, Sweden},
  isbn = {9789198423907},
  keywords = {\#nosource}
}

@techreport{Karrholm2018,
  title = {Svenska H\"oftprotesregistret \AA rsrapport 2017},
  author = {K{\"a}rrholm, Johan and Mohaddes, Maziar and Odin, Daniel and Vinblad, Johanna and Rogmark, Cecilia and Rolfson, Ola},
  year = {2018},
  city = {Gothenburg, Sweden},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NTJUJIPB\\kärrholm_et_al_2018_svenska_höftprotesregistret_årsrapport_2017.pdf},
  isbn = {9789198423907}
}

@techreport{karrholmSvenskaHoftprotesregistretArsrapport2019,
  title = {Svenska H\"oftprotesregistret \AA rsrapport 2018},
  author = {K{\"a}rrholm, Johan and Rogmark, Cecilia and Naucl{\'e}r, Emma and Vinblad, Johanna and Mohaddes, Maziar and Rolfson, Ola},
  year = {2019},
  keywords = {\#nosource}
}

@article{Karrison2018,
  title = {Restricted Mean Survival Time: {{Does}} Covariate Adjustment Improve Precision in Randomized Clinical Trials?},
  author = {Karrison, Theodore and Kocherginsky, Masha},
  year = {2018},
  month = apr,
  volume = {15},
  pages = {178--188},
  issn = {1740-7745},
  doi = {10.1177/1740774518759281},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6YQLZU6H\\karrison_kocherginsky_2018_restricted_mean_survival_time.pdf},
  journal = {Clinical Trials},
  number = {2}
}

@article{Kattan2003,
  title = {Judging New Markers by Their Ability to Improve Predictive Accuracy},
  author = {Kattan, M. W.},
  year = {2003},
  month = may,
  volume = {95},
  pages = {634--635},
  publisher = {{Oxford University Press}},
  doi = {10.1093/jnci/95.9.634},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DHHDP4L5\\kattan_2003_judging_new_markers_by_their_ability_to_improve_predictive_accuracy.pdf},
  journal = {JNCI Journal of the National Cancer Institute},
  number = {9}
}

@article{Katz1996,
  title = {Can Comorbidity Be Measured by Questionnaire Rather than Medical Record Review?},
  author = {Katz, Jeeffrey N and Chang, Lily C and Sangha, Oliver and Fossel, Anne H and Bates, David W},
  year = {1996},
  volume = {34},
  issn = {0025-7079},
  abstract = {Comorbidity generally is measured by medical record abstraction, which is expensive and often impractical. The aim of this study was to assess the reproducibility and validity of a comorbidity questionnaire. The authors developed a brief comorbidity questionnaire that included items corresponding to each element of the medical record-based Charlson index. The questionnaire was administered to 170 inpatients. Charlson scores were abstracted from these patients' medical records. We assessed test-retest reliability of the questionnaire and the Charlson index, the correlation between the questionnaire and the Charlson index, and correlations between each comorbidity measure and indicators of health resource utilization including medication use, hospitalizations in the past year, and hospital charges. Test-retest reliability, assessed with the intraclass correlation coefficient, was 0.91 for the questionnaire and 0.92 for the chart-based Charlson index. The Spearman correlation between these two measures was 0.63. The correlation between comorbidity measures was weaker in less educated patients. Correlations with indicators of resource utilization were similar for the two comorbidity instruments. The authors found that a questionnaire version of the Charlson index is reproducible, valid, and offers practical advantages over medical record-based assessments.},
  journal = {Medical Care},
  keywords = {\#nosource,comorbidity,medical record,questionnaire,severity adjustment},
  number = {1}
}

@article{Kester2016,
  title = {The Association between Hospital Length of Stay and 90 Day Readmission Risk for Femoral Neck Fracture Patients: {{Within}} a Total Joint Replacement Bundled Payment Initiative},
  author = {Kester, Benjamin S. and Williams, Jarrett and Bosco, Joseph A. and Slover, James D. and Iorio, Richard and Schwarzkopf, Ran},
  year = {2016},
  volume = {31},
  pages = {2741--2745},
  publisher = {{Elsevier Ltd}},
  issn = {08835403},
  doi = {10.1016/j.arth.2016.05.035},
  abstract = {Background Hip arthroplasty is increasingly performed as a treatment for femoral neck fractures (FNFs). However, these cases have higher complication rates than elective total hip arthroplasties (THAs). The Center for Medicare and Medicaid Services has created the Comprehensive Care for Joint Replacement model to increase the value of patient care. This model risk stratifies FNF patients in an attempt to appropriately allocate resources, but the formula has not been disclosed. The goal of this study was to ascertain if patients with FNFs have different readmission rates compared to patients undergoing elective THA so that the resource utilization can be assessed. Methods We analyzed all patients undergoing THA at our institution during a 21-month period. Patients classified by a diagnosis-related group of 469 or 470 were included. Multivariate and survival analyses were performed to determine risk of 90-day readmission. Results Patients admitted for FNFs were older, had higher body mass indices, longer lengths of stay, and were more likely to be discharged to inpatient facilities than patients who underwent elective THA. Increased American Society of Anesthesiologists scores and FNF were also independent risk factors for 90-day readmission, and these patient were more likely to be readmitted during the latter 60 days following admission. Conclusion Results suggest that patients who undergo an arthroplasty following urgent or emergent FNFs have inferior outcomes to those receiving an arthroplasty for a diagnosis of arthritis. Fracture patients should either be risk stratified to allow appropriate resource allocation or be excluded from alternative payment initiatives such as Comprehensive Care for Joint Replacement.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UWWB9DGY\\kester_et_al_2016_the_association_between_hospital_length_of_stay_and_90_day_readmission_risk_for.pdf},
  journal = {The Journal of Arthroplasty},
  keywords = {femoral neck fracture,health care economics,practice management,readmissions,total hip arthroplasty},
  number = {12}
}

@techreport{Khan2015,
  title = {Cancerincidens i Sverige 2014},
  author = {Khan, Staffan and Ayoubi, Shiva},
  year = {2015},
  isbn = {9789175552484},
  keywords = {\#nosource}
}

@article{kildemoesDanishNationalPrescription2011,
  title = {The {{Danish}} National Prescription Registry},
  author = {Kildemoes, Helle Wallach and S\o rensen, Henrik Toft and Hallas, Jesper},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {38--41},
  issn = {14034948},
  doi = {10.1177/1403494810394717},
  abstract = {Introduction: Individual-level data on all prescription drugs sold in Danish community pharmacies has since 1994 been recorded in the Register of Medicinal Products Statistics of the Danish Medicines Agency. Content: The register subset, termed the Danish National Prescription Registry (DNPR), contains information on dispensed prescriptions, including variables at the level of the drug user, the prescriber, and the pharmacy. Validity and coverage: Reimbursement-driven record keeping, with automated bar-code-based data entry provides data of high quality, including detailed information on the dispensed drug. Conclusion: The possibility of linkage with many other nationwide individual-level data sources renders the DNPR a very powerful pharmacoepidemiological tool. \textcopyright{} 2010 the Nordic Societies of Public Health.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8IRJWSHV\\kildemoes_et_al_2011_the_danish_national_prescription_registry.pdf},
  journal = {Scandinavian Journal of Public Health},
  keywords = {Denmark,dispensed prescription drugs,individual-level data,nation-wide register},
  number = {7},
  pmid = {21775349}
}

@article{Kim2003,
  title = {Subsystem Identification through Dimensionality Reduction of Large-Scale Gene Expression Data},
  author = {Kim, P. M.},
  year = {2003},
  month = jul,
  volume = {13},
  pages = {1706--1718},
  issn = {1088-9051},
  doi = {10.1101/gr.903503},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\C6K84H9A\\kim_2003_subsystem_identification_through_dimensionality_reduction_of_large-scale_gene.pdf},
  journal = {Genome Research},
  number = {7}
}

@article{Kim2007,
  title = {Sparse Non-Negative Matrix Factorizations via Alternating Non-Negativity-Constrained Least Squares for Microarray Data Analysis},
  author = {Kim, Hyunsoo and Park, Haesun},
  year = {2007},
  volume = {23},
  pages = {1495--1502},
  issn = {13674803},
  doi = {10.1093/bioinformatics/btm134},
  abstract = {MOTIVATION: Many practical pattern recognition problems require non-negativity constraints. For example, pixels in digital images and chemical concentrations in bioinformatics are non-negative. Sparse non-negative matrix factorizations (NMFs) are useful when the degree of sparseness in the non-negative basis matrix or the non-negative coefficient matrix in an NMF needs to be controlled in approximating high-dimensional data in a lower dimensional space. RESULTS: In this article, we introduce a novel formulation of sparse NMF and show how the new formulation leads to a convergent sparse NMF algorithm via alternating non-negativity-constrained least squares. We apply our sparse NMF algorithm to cancer-class discovery and gene expression data analysis and offer biological analysis of the results obtained. Our experimental results illustrate that the proposed sparse NMF algorithm often achieves better clustering performance with shorter computing time compared to other existing NMF algorithms. AVAILABILITY: The software is available as supplementary material.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AUN73TVQ\\kim_park_2007_sparse_non-negative_matrix_factorizations_via_alternating.pdf},
  journal = {Bioinformatics},
  number = {12}
}

@article{Kim2009,
  title = {Estimating Classification Error Rate: {{Repeated}} Cross-Validation, Repeated Hold-out and Bootstrap},
  author = {Kim, Ji Hyun},
  year = {2009},
  volume = {53},
  pages = {3735--3745},
  issn = {01679473},
  doi = {10.1016/j.csda.2009.04.009},
  abstract = {We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the??.632+??bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the??.632+??bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the??.632+??bootstrap estimator suffers from a bias problem for large samples as well as for small samples. ?? 2009 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5JXVGMUQ\\kim_2009_estimating_classification_error_rate.pdf},
  isbn = {0167-9473},
  journal = {Computational Statistics and Data Analysis},
  number = {11}
}

@article{Kim2009,
  title = {Is One-Stage Bilateral Sequential Total Hip Replacement as Safe as Unilateral Total Hip Replacement?},
  author = {Kim, Y.-H. and Kwon, O.-R. and Kim, J.-S.},
  year = {2009},
  month = mar,
  volume = {91-B},
  pages = {316--320},
  publisher = {{The British Editorial Society of Bone and Joint Surgery}},
  issn = {0301-620X},
  doi = {10.1302/0301-620X.91B3.21817},
  abstract = {We investigated whether simultaneous bilateral sequential total hip replacement (THR) would increase the rate of mortality and complications compared with unilateral THR in both low- and high-risk groups of patients.We enrolled 978 patients with bilateral and 1666 with unilateral THR in the study. There were no significant pre-operative differences between the groups in regard to age, gender, body mass index, diagnosis, comorbidity as assessed by the grading of the American Society of Anesthesiologists (ASA), the type of prosthesis and the duration of follow-up. The mean follow-up was for 10.5 years (5 to 13) in the bilateral THR group and 9.8 years (5 to 14) in the unilateral group.The peri-operative mortality rate of patients who had simultaneous bilateral THR (0.31\%, three of 978 patients) was similar to that of patients with unilateral THR (0.18\%, three of 1666 patients). The peri-operative mortality rate of patients in the bilateral group was similar in high risk and low risk patients (0.70\%, two of ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\356VVXSB\\kim_et_al_2009_is_one-stage_bilateral_sequential_total_hip_replacement_as_safe_as_unilateral.pdf},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  number = {3}
}

@article{King2001,
  title = {Logistic Regression in Rare Events Data},
  author = {King, Gary and Zeng, Langche},
  year = {2001},
  month = jan,
  volume = {9},
  pages = {137--163},
  publisher = {{Cambridge University Press}},
  doi = {10.1093/oxfordjournals.pan.a004868},
  abstract = {We study rare events data, binary dependent variables with dozens to thousands of times fewer ones (events, such as wars, vetoes, cases of political activism, or epidemiological infections) than zeros (``nonevents''). In many literatures, these variables have proven difficult to explain and predict, a problem that seems to have at least two sources. First, popular statistical procedures, such as logistic regression, can sharply underestimate the probability of rare events. We recommend corrections that outperform existing methods and change the estimates of absolute and relative risks by as much as some estimated effects reported in the literature. Second, commonly used data collection strategies are grossly inefficient for rare events data. The fear of collecting data with too few events has led to data collections with huge numbers of observations but relatively few, and poorly measured, explanatory variables, such as in international conflict data with more than a quarter-million dyads, only a few of which are at war. As it turns out, more efficient sampling designs exist for making valid inferences, such as sampling all available events (e.g., wars) and a tiny fraction of nonevents (peace). This enables scholars to save as much as 99\% of their (nonfixed) data collection costs or to collect much more meaningful explanatory variables. We provide methods that link these two results, enabling both types of corrections to work simultaneously, and software that implements the methods developed.\textexclamdown/p\textquestiondown},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3M4LJUTU\\king_zeng_2001_logistic_regression_in_rare_events_data.pdf},
  journal = {Political Analysis},
  number = {02}
}

@article{King2001,
  title = {Explaining Rare Events in International Relations},
  author = {King, Gary and Zeng, Langche},
  year = {2001},
  volume = {55},
  pages = {693--715},
  abstract = {Many of the most signii cant events in international relations-wars, coups, revolutions , massive economic depressions, economic shocks-are rare events. They occur infrequently but are considered of great importance. In international relations, as in other disciplines, rare events-that is, binary dependent variables characterized by dozens to thousands of times fewer 1's (events such as wars or coups) than 0's (nonevents)-have proven diff cult to explain and predict. Though scholars have made substantial efforts to quantify rare events, they have devoted less attention to how these events are analyzed. We show that problems in explaining and predicting rare events stem primarily from two sources: popular statistical procedures that underestimate the probability of rare events and ineff cient data-collection strategies. We analyze the issues involved, cite examples from the international relations literature, and offer some solutions. The rst source of problems in rare-event analysis is researchers' reliance on logit coeff cients, which are biased in small samples (those with fewer than two hundred observations), as the statistical literature well documents. Not as widely understood is that the biases in probabilities can be substantively meaningful when sample sizes are in the thousands and are always in the same direction: estimated event probabilities are always too small. A separate, often overlooked problem is that the almost universally used method of computing probabilities of events in logit analysis is suboptimal in nite samples of rare-events data, leading to errors in the We thank},
  journal = {International Organization},
  keywords = {\#nosource}
}

@article{King2003,
  title = {Logistic Regression in Rare Events Data},
  author = {King, Gary and Zeng, Langche},
  year = {2003},
  volume = {8},
  doi = {10.18637/jss.v008.i02},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NYB7QRGN\\king_zeng_2003_logistic_regression_in_rare_events_data.pdf},
  journal = {Journal of Statistical Software},
  number = {2}
}

@article{Kirkland2011,
  title = {The Charlson Comorbidity Index Score as a Predictor of 30-{{Day}} Mortality after Hip Fracture Surgery},
  author = {Kirkland, Lisa L. and Kashiwagi, Deanne T. and Burton, M. Caroline and Cha, Stephen and Varkey, Prathibha},
  year = {2011},
  volume = {26},
  pages = {461--467},
  issn = {1062-8606},
  doi = {10.1177/1062860611402188},
  journal = {American Journal of Medical Quality},
  keywords = {\#nosource,1 with 3-month mortal-,an estimated 320 000,charlson,fractures yearly in the,hip,hip surgery,hyperglycemia,mortality,orthopedic,patients are hospitalized for,postoperative,risk factors,united states},
  number = {6},
  pmid = {21450939}
}

@article{Klabunde2000,
  title = {Development of a Comorbidity Index Using Physician Claims Data},
  author = {Klabunde, Carrie N. and Potosky, Arnold L. and Legler, Julie M. and Warren, Joan L.},
  year = {2000},
  volume = {53},
  pages = {1258--1267},
  issn = {08954356},
  doi = {10.1016/S0895-4356(00)00256-0},
  abstract = {Important comorbidities recorded on outpatient claims in administrative datasets may be missed in analyses when only inpatient care is considered. Using the comorbid conditions identified by Charlson and colleagues, we developed a comorbidity index that incorporates the diagnostic and procedure data contained in Medicare physician (Part B) claims. In the national cohorts of elderly prostate (n = 28,868) and breast cancer (n = 14,943) patients assessed in this study, less than 10\% of patients had comorbid conditions identified when only Medicare hospital (Part A) claims were examined. By incorporating physician claims, the proportion of patients with comorbid conditions increased to 25\%. The new physician claims comorbidity index significantly contributes to models of 2-year noncancer mortality and treatment received in both patient cohorts. We demonstrate the utility of a disease-specific index using an alternative method of construction employing study-specific weights. The physician claims index can be used in conjunction with a comorbidity index derived from inpatient hospital claims, or employed as a stand-alone measure. Copyright ?? 2000 Elsevier Science Inc.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5H2VXDEF\\klabunde_et_al_2000_development_of_a_comorbidity_index_using_physician_claims_data.pdf},
  isbn = {0895-4356 (Print){\r  }0895-4356 (Linking)},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Administrative data,Breast cancer,Claims data,Comorbidity,Medicare,Prostate cancer},
  number = {12},
  pmid = {11146273}
}

@techreport{Kleibergen2003,
  title = {Generalizied Reduced Rank Tests Using the Singular Value Decomposition},
  author = {Kleibergen, Frank and Paap, Richard},
  year = {2003},
  keywords = {\#nosource}
}

@book{Klein2003,
  title = {{{SURVIVAL ANALYSIS}} Techniques for Censored and Second Edition},
  author = {Klein, John P and Moeschberger, Melvin L},
  year = {2003},
  isbn = {0-387-95399-X},
  keywords = {\#nosource}
}

@article{Klein2008,
  title = {{{SAS}} and {{R}} Functions to Compute Pseudo-Values for Censored Data Regression},
  author = {Klein, John P. and Gerster, Mette and Andersen, Per Kragh and Tarima, Sergey and Perme, Maja Pohar},
  year = {2008},
  month = mar,
  volume = {89},
  pages = {289--300},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2007.11.017},
  abstract = {Recently, in a series of papers, a method based on pseudo-values has been proposed for direct regression modeling of the survival function, the restricted mean and cumulative incidence function with right censored data. The models, once the pseudo-values have been computed, can be fit using standard generalized estimating equation software. Here we present SAS macros and R functions to compute these pseudo-values. We illustrate the use of these routines and show how to obtain regression estimates for a study of bone marrow transplant patients. \textcopyright{} 2007 Elsevier Ireland Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3PL2AKQY\\klein_et_al_2008_sas_and_r_functions_to_compute_pseudo-values_for_censored_data_regression.pdf},
  journal = {Computer Methods and Programs in Biomedicine},
  keywords = {Cumulative incidence,GEE,Kaplan-Meier curves,Pseudo-values,Restricted mean survival},
  number = {3}
}

@book{kleinbaumSurvivalAnalysisSelflearning2012,
  title = {Survival Analysis: {{A}} Self-Learning Text},
  author = {Kleinbaum, David G and Klein, Mitchel},
  year = {2012},
  isbn = {978-1-4419-6645-2},
  keywords = {\#nosource}
}

@book{Knahr2013,
  title = {Total Hip Arthroplasty Tribological Considerations and Clinical Consequences},
  author = {Knahr, Karl},
  year = {2013},
  doi = {10.1007/978-3-642-35653-7},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PYZ243Q7\\knahr_2013_total_hip_arthroplasty_tribological_considerations_and_clinical_consequences.pdf},
  isbn = {978-3-642-35652-0}
}

@article{Knottnerus2016,
  title = {Editorial Comment: {{Ratios}} Should Be Multiplied, Not Added},
  author = {Knottnerus, J. Andr{\'e} and Tugwell, Peter and Wells, George},
  year = {2016},
  month = nov,
  volume = {79},
  pages = {30},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2016.11.007},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6D3VAVGD\\knottnerus_et_al_2016_editorial_comment.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@article{Kohavi1995,
  title = {A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection},
  author = {Kohavi, Ron},
  year = {1995},
  abstract = {We review accuracy estimation methods and compare the two most common methods: cross-validation and bootstrap. Recent experimen-tal results on artiicial data and theoretical re-sults in restricted settings have shown that for selecting a good classiier from a set of classi-(model selection), ten-fold cross-validation may be better than the more expensive leave-one-out cross-validation. We report on a large-scale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the eeects of diierent parameters on these al-gorithms on real-world datasets. For cross-validation, we vary the number of folds and whether the folds are stratiied or not; for boot-strap, we vary the number of bootstrap sam-ples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold stratiied cross validation, even if computation power allows using more folds.},
  journal = {International joint conference in artificial intelligence},
  keywords = {\#nosource}
}

@article{Kohl2010,
  title = {R Package {{distrMod}}: {{S4}} Classes and Methods for Probability Models},
  author = {Kohl, Matthias and Ruckdeschel, Peter},
  year = {2010},
  volume = {35},
  pages = {1--27},
  issn = {15487660},
  doi = {10.1002/wics.10},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UU5EVWDH\\kohl_ruckdeschel_2010_r_package_distrmod.pdf},
  journal = {Journal of Statistical Software},
  keywords = {maximum likelihood estimators,minimum criterion estimators,minimum distance estimators,probability models,s4 classes,s4 methods},
  number = {10}
}

@article{Konishi1978,
  title = {An Approximation to the Distribution of the Sample Correlation Coefficient},
  author = {Konishi, Sandnori},
  year = {1978},
  volume = {65},
  pages = {654--656},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {3}
}

@article{Koole2019,
  title = {First Real-World Experience with Mobile Health Telemonitoring in Adult Patients with Congenital Heart Disease},
  author = {Koole, M. A. C. and Kauw, D. and Winter, M. M. and Dohmen, D. A. J. and Tulevski, I. I. and {de Haan}, R. and Somsen, G. A. and Schijven, M. P. and {Robbers-Visser}, D. and Mulder, B. J. M. and Bouma, B. J. and Schuuring, M. J.},
  year = {2019},
  month = jan,
  volume = {27},
  pages = {30--37},
  publisher = {{Bohn Stafleu van Loghum}},
  issn = {1568-5888},
  doi = {10.1007/s12471-018-1201-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BFMLG3DB\\koole_et_al_2019_first_real-world_experience_with_mobile_health_telemonitoring_in_adult_patients.pdf},
  journal = {Netherlands Heart Journal},
  number = {1}
}

@article{Kork2015,
  title = {Association of Comorbidities with Postoperative In-Hospital Mortality: A Retrospective Cohort Study.},
  author = {Kork, Felix and Balzer, Felix and Krannich, Alexander and Weiss, Bj{\"o}rn and Wernecke, Klaus-Dieter and Spies, Claudia},
  year = {2015},
  month = feb,
  volume = {94},
  pages = {e576},
  issn = {1536-5964},
  doi = {10.1097/MD.0000000000000576},
  abstract = {The purpose of this article is to evaluate the American Society of Anesthesiologists Physical Status (ASA PS) and the Charlson comorbidity index (CCI) for the prediction of postoperative mortality. The ASA PS has been suggested to be equally good as the CCI in predicting postoperative outcome. However, these scores have never been compared in a broad surgical population. We conducted a retrospective cohort study in a German tertiary care university hospital. Predictive accuracy was compared using the area under the receiver-operating characteristic curves (AUROC). In a post hoc approach, a regression model was fitted and cross-validated to estimate the association of comorbidities and intraoperative factors with mortality. This model was used to improve prediction by recalibrating the CCI for surgical patients (sCCIs) and constructing a new surgical mortality score (SMS). The data of 182,886 patients with surgical interventions were analyzed. The CCI was superior to the ASA PS in predicting postoperative mortality (AUROCCCI 0.865 vs AUROCASAPS 0.833, P \textexclamdown{} 0.001). Predictive quality further improved after recalibration of the sCCI and construction of the new SMS (AUROCSMS 0.928 vs AUROCsCCI 0.896, P \textexclamdown{} 0.001). The SMS predicted postoperative mortality especially well in patients never admitted to an intensive care unit. The newly constructed SMS provides a good estimate of patient's risk of death after surgery. It is capable of identifying those patients at especially high risk and may help reduce postoperative mortality.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\H6RJ4C6Q\\kork_et_al_2015_association_of_comorbidities_with_postoperative_in-hospital_mortality.pdf},
  journal = {Medicine},
  number = {8},
  pmid = {25715258}
}

@article{Kosmidis2014,
  title = {Bias in Parametric Estimation: Reduction and Useful Side-Effects},
  author = {Kosmidis, Ioannis},
  year = {2014},
  month = may,
  volume = {6},
  pages = {185--196},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/wics.1296},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R64YHDY7\\kosmidis_2014_bias_in_parametric_estimation.pdf},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  number = {3}
}

@article{Kosmidis2018,
  title = {Mean and Median Bias Reduction in Generalized Linear Models},
  author = {Kosmidis, Ioannis and Pagui, Euloge Clovis Kenne and Sartori, Nicola},
  year = {2018},
  month = apr,
  abstract = {This paper presents an integrated framework for estimation and inference from generalized linear models using adjusted score equations that result in mean and median bias reduction. The framework unifies theoretical and methodological aspects of past research on mean bias reduction and accommodates, in a natural way, new advances on median bias reduction. General expressions for the adjusted score functions are derived in terms of quantities that are readily available in standard software for fitting generalized linear models. The resulting estimating equations are solved using a unifying quasi-Fisher scoring algorithm that is shown to be equivalent to iteratively re-weighted least squares with appropriately adjusted working variates. Formal links between the iterations for mean and median bias reduction are established. Core model invariance properties are used to develop a novel mixed adjustment strategy when the estimation of a dispersion parameter is necessary. It is also shown how median bias reduction in multinomial logistic regression can be done using the equivalent Poisson log-linear model. The estimates coming out from mean and median bias reduction are found to overcome practical issues related to infinite estimates that can occur with positive probability in generalized linear models with multinomial or discrete responses, and can result in valid inferences even in the presence of a high-dimensional nuisance parameter},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8KECUFC5\\kosmidis_et_al_2018_mean_and_median_bias_reduction_in_generalized_linear_models.pdf}
}

@article{Kowalski1972,
  title = {On the Effects of Non-Normality on the Distribution of the Sample Product-Moment Correlation Coefficient},
  author = {Kowalski, Charles J.},
  year = {1972},
  volume = {21},
  pages = {1},
  issn = {00359254},
  doi = {10.2307/2346598},
  abstract = {Samples from non-normal bivariate distributions are simulated and the densities of the sample product-moment correlation coefficient, r, estimated and compared with the corresponding normal theory densities. The results are contrasted with the literature on the subject and an attempt is made to reconcile some of the earlier conflicting conclusions regarding the robustness of the distribution of r.},
  isbn = {00359254},
  journal = {Journal of the Royal Statistical Society},
  keywords = {\#nosource,density estimation,distribution of correlation coefficient,non-normality,robustness,transformations},
  number = {1},
  pmid = {16917}
}

@article{Kramer1963,
  title = {Tables for Constructing Confidence Limits on the Multiple Correlation Coefficient},
  author = {Kramer, K. H.},
  year = {1963},
  volume = {58},
  pages = {1082--1085},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {01621459},
  doi = {10.2307/2283334},
  abstract = {The purpose of this paper is to present tables for the construction of confidence limits on the multiple correlation coefficient when sampling from a k-variate normal population. Ezekiel and Fox [3, pp. 296-8] prepared charts which serve this purpose when k is eight or less. The tables in this paper are for cases involving values of k that are larger than eight. Some brief historical comment is also given, and (in the next to the last paragraph) an illustration of the use of the tables.},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {304}
}

@article{Kreke2015,
  title = {{{pAnalysis}}: {{Benchmarking}} and Rescaling {{R2}} Using Noise Percentile Analysis},
  author = {Kreke, Joseph G and Khemlani, Sangeet and Trafton, Greg},
  year = {2015},
  keywords = {\#nosource}
}

@article{Kristensen2005,
  title = {The {{Copenhagen Burnout Inventory}}: {{A}} New Tool for the Assessment of Burnout},
  author = {Kristensen, Tage S. and Borritz, Marianne and Villadsen, Ebbe and Christensen, Karl B.},
  year = {2005},
  month = jul,
  volume = {19},
  pages = {192--207},
  publisher = {{Taylor \& Francis Group}},
  issn = {02678373},
  doi = {10.1080/02678370500297720},
  abstract = {So far, the large majority of studies on burnout in the international literature have employed the Maslach Burnout Inventory (MBI). In this paper we criticize the MBI on a number of points and present a new tool for the measurement of burnout: the Copenhagen Burnout Inventory (CBI). The CBI consists of three scales measuring personal burnout, work-related burnout, and client-related burnout, for use in different domains. On the basis of an ongoing prospective study of burnout in employees in the human service sector, the PUMA study (Project on Burnout, Motivation and Job Satisfaction; N/1914 at baseline), we analysed the validity and reliability of the CBI. All three scales were found to have very high internal reliability, and non-response rates were small. The scales differentiated well between occupational groups in the human service sector, and the expected pattern with regard to correlations with other measures of fatigue and psychological well-being was found. Furthermore, the three scales predicted future sickness absence, sleep problems, use of pain-killers, and intention to quit. Analyses of changes over time showed that substantial proportions of the employees changed with regard to burnout levels. It is concluded that the analyses indicate very satisfactory reliability and validity for the CBI instrument. The CBI is being used in a number of countries and translations into eight languages are available.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4ILGI2Y6\\kristensen_et_al_2005_the_copenhagen_burnout_inventory.pdf},
  isbn = {0267-8373 1464-5335},
  journal = {Work and Stress},
  keywords = {Burnout,CBI,Copenhagen Burnout Inventory,exhaustion,Exhaustion,fatigue,Fatigue,human service work,Human service work,psychosocial work environment,Psychosocial work environment,PUMA study,questionnaire validity,Questionnaire validity},
  number = {3},
  pmid = {18909025}
}

@article{Kruschke2018,
  title = {Rejecting or Accepting Parameter Values in {{Bayesian}} Estimation},
  author = {Kruschke, John K},
  year = {2018},
  doi = {10.1177/2515245918771304},
  abstract = {This article explains a decision rule for accepting or rejecting null values of parameters, based on Bayesian posterior distributions. The decision rule considers a range of plausible values indicated by the highest density in-terval (HDI) of the posterior distribution, and its relation to a region of practical equivalence (ROPE) around the null value. The article discusses considerations for setting the limits of a ROPE and emphasizes that analo-gous considerations apply to setting the decision thresholds for p values and Bayes factors.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CW36ZNRI\\kruschke_2018_rejecting_or_accepting_parameter_values_in_bayesian_estimation.pdf},
  journal = {Advances in Methods and Practices in Psychological Science}
}

@article{kucukdeveciStrategiesAssessmentOutcome2011,
  title = {Strategies for Assessment and Outcome Measurement in Physical and Rehabilitation Medicine: {{An}} Educational Review},
  author = {K{\"u}{\c c}{\"u}kdeveci, Ay{\c s}e A. and Tennant, Alan and Grimby, Gunnar and Franchignoni, Franco},
  year = {2011},
  volume = {43},
  pages = {661--672},
  issn = {16501977},
  doi = {10.2340/16501977-0844},
  abstract = {The aim of this educational review, which is based upon expert opinion, is to describe to clinicians training in Physical and Rehabilitation Medicine and research students training to work in the field, the appropriate attributes and standards required for assessment and outcome measurement. "What to assess" is discussed in the context of the conceptual framework provided by the International Classification of Functioning, Disability and Health, supplemented with quality of life as an additional construct. The reasons for making the assessment, and the context in which the assessment will be used, are then considered. Examples of recommendations of some international organizations regarding what and how to assess are presented. Suggestions are made about the selection of assessment tools, including examples from two diagnostic groups: stroke and rheumatoid arthritis. Finally, the basic psychometric standards required for any assessment tool, and additional requirements for outcome assessment, are explained.;},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\26QYK3MZ\\küçükdeveci_et_al_2011_strategies_for_assessment_and_outcome_measurement_in_physical_and.pdf},
  isbn = {1650-1977},
  journal = {Journal of Rehabilitation Medicine},
  keywords = {ICF,Outcome assessment,Psychometrics,Rehabilitation},
  number = {8},
  pmid = {21687922}
}

@article{Kuhn2008,
  title = {Building Predictive Models in r Using the Caret Package},
  author = {Kuhn, Max},
  year = {2008},
  volume = {28},
  pages = {1--26},
  issn = {15487660},
  doi = {10.1053/j.sodo.2009.03.002},
  abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Y7KVY8GV\\kuhn_2008_building_predictive_models_in_r_using_the_caret_package.pdf},
  isbn = {1548-7660},
  journal = {Journal Of Statistical Software},
  keywords = {model building,networkspaces,NetWorkSpaces,parallel processing,r,R,tuning parameters},
  number = {5},
  pmid = {18612375}
}

@book{Kullenberg2012,
  title = {The Quantification of Society},
  author = {Kullenberg, Christopher},
  year = {2012},
  doi = {10.1002/9780470060346.ch2},
  abstract = {This chapter contains sections titled:* Uncertain Quantities and Uncertain Events: Their Definition and* Probability: A Satisfactory Way to Quantify Uncertainty* Overview of the Different Interpretations of Probability * ExtendingRules of Probability: Law of Total Probability and Bayes' Law* The Bayesian Paradigm: A Prescription for Reliability, Risk andAnalysis * Probability Models, Parameters, Inference and* Testing Hypotheses: Posterior Odds and Bayes Factors* Utility as Probability and Maximization of Expected Utility * Decisionand Influence Diagrams for Risk Analysis},
  isbn = {978-0-470-06034-6},
  keywords = {\#nosource}
}

@article{Kunutsor2019,
  title = {Risk Factors for Dislocation after Primary Total Hip Replacement: A Systematic Review and Meta-Analysis of 125 Studies Involving Approximately Five Million Hip Replacements},
  shorttitle = {Risk Factors for Dislocation after Primary Total Hip Replacement},
  author = {Kunutsor, Setor K and Barrett, Matthew C and Beswick, Andrew D and Judge, Andrew and Blom, Ashley W and Wylde, Vikki and Whitehouse, Michael R},
  year = {2019},
  month = oct,
  volume = {1},
  pages = {e111-e121},
  issn = {26659913},
  doi = {10.1016/S2665-9913(19)30045-1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DTY882CI\\kunutsor2019.pdf},
  journal = {The Lancet Rheumatology},
  language = {en},
  number = {2}
}

@article{Kurtz2016,
  title = {Hospital, Patient, and Clinical Factors Influence 30- and 90-{{Day}} Readmission Following Primary Total Hip Replacement},
  author = {Kurtz, Steven M. and Lau, Edmund and Ong, Kevin and Adler, Edward and Kolisek, Frank and Manley, Michael},
  year = {2016},
  month = mar,
  publisher = {{Elsevier Ltd}},
  issn = {08835403},
  doi = {10.1016/j.arth.2016.03.041},
  abstract = {BACKGROUND The purpose of this study was to analyze the hospital, clinical, and patient factors associated with inpatient readmission following total hip arthroplasty (THA) in the Medicare population and to understand the primary reasons for readmission. METHODS The Medicare 100\% national hospital claims database was used to identify 442,333 older patients (65+) with a primary THA in 3,730 hospitals between 2010-2013. A multi-level logistic regression analysis with a clustered data structure was utilized to investigate the risk of all-cause 30- and 90-day readmission, incorporating hospital, clinical, and patient factors. RESULTS At 30 days, 5.8\% (median) of the patients were readmitted, whereas at 90 days, 10.5\% (median) were readmitted. Geographic census region, hospital procedure volume, and nonprofit ownership were the only significant hospital factors among those we studied. Overall, clinical factors explained more of the variation in readmission rates than general hospital factors. Use of a perioperative transfusion was associated with 14\% greater risk; patients discharged to home had 28\% lower risk; surgeon volume and LOS were also significant risk factors. The top five most frequently reported primary reasons for 30-day readmission in THA were procedure related: dislocation (5.9\%), deep infection (5.1\%), wound infection (4.8\%), periprosthetic fracture (4.4\%), or hematoma (3.4\%). CONCLUSIONS These findings support further optimization of the delivery of care\textemdash both intra-op and post-op\textemdash to reduce the broad variation in hospital readmissions.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7QP7X8HM\\kurtz_et_al_2016_hospital,_patient,_and_clinical_factors_influence_30-_and_90-day_readmission.pdf},
  journal = {The Journal of Arthroplasty},
  keywords = {30 days,90 days,complications,Medicare,readmission,total hip arthroplasty,Total hip replacement},
  pmid = {27129760}
}

@article{kvalsethCautionaryNoteR21985,
  title = {Cautionary Note about {{R2}}},
  author = {Kv\aa lseth, Tarald O.},
  year = {1985},
  volume = {39},
  pages = {279--285},
  issn = {0003-1305},
  doi = {10.1080/00031305.1985.10479448},
  abstract = {Abstract The coefficient of determination (R 2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R 2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R 2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
  isbn = {0003-1305},
  journal = {American Statistician},
  keywords = {\#nosource,coefficient},
  number = {4}
}

@article{Kymn1968,
  title = {The Distribution of the Sample Correlation Coefficient under the Null Hypothesis},
  author = {Kymn, Kern O .},
  year = {1968},
  volume = {36},
  pages = {187--189},
  issn = {0012-9682},
  doi = {10.2307/1909612},
  abstract = {Examines the distribution of the sample correlation coefficient under the null hypothesis. Assessment of an F measurement with (n-2,n-2) degrees of freedom; Evaluation of the S statistics; Definition of improper integral through Gamma function.},
  journal = {Econometrica},
  keywords = {\#nosource},
  number = {1}
}

@article{Kyriacou2020,
  title = {Important Perioperative Factors, Guidelines and Outcomes in the Management of Hip Fracture},
  author = {Kyriacou, Harry and Khan, Wasim S},
  year = {2020},
  month = apr,
  pages = {1750458920915656},
  publisher = {{SAGE Publications}},
  issn = {1750-4589},
  doi = {10.1177/1750458920915656},
  abstract = {Hip fractures are common injuries in the elderly and are associated with significant morbidity and mortality. There are multiple perioperative factors that must be considered when managing these patients. These include analgesia, timing of surgery, choice of operation, type of anaesthesia, postoperative complications and comorbidities. Guidelines from The National Institute for Health and Care Excellence and the National Hip Fracture Database have been updated to reflect many of the above, but the importance of psychosocial factors is still emerging. This article focuses on the evidence for the key perioperative factors in hip fracture management and the tools available to predict hip fracture outcome.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JSNMA328\\Kyriacou och Khan - 2020 - Important perioperative factors, guidelines and ou.pdf},
  journal = {Journal of Perioperative Practice},
  language = {en}
}

@article{Lai2007,
  title = {Presence of {{Medical Comorbidities}} in {{Patients With Infected Primary Hip}} or {{Knee Arthroplasties}}},
  author = {Lai, Kafai and Bohm, Eric R. and Burnell, Colin and Hedden, David R.},
  year = {2007},
  month = aug,
  volume = {22},
  pages = {651--656},
  issn = {08835403},
  doi = {10.1016/j.arth.2006.09.002},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {5}
}

@book{Lam2014,
  title = {'{{Content}} to Be Sad' or 'Runaway Apprentice'? {{The}} Psychological Contract and Career Agency of Young Scientists in the Entrepreneurial University},
  author = {Lam, A. and {de Campos}, A.},
  year = {2014},
  volume = {68},
  issn = {0018-7267},
  doi = {10.1177/0018726714545483},
  abstract = {This article examines employee agency in psychological contracts by exploring how young scientists proactively shape their careers in response to unmet expectations induced by academic entrepreneurialism. It uses the lens of social exchange to examine their relationships with the professors engaged in two types of activities: collaborative research characterized by diffuse/reciprocal exchange, and commercial ventures, by restricted/negotiated exchange. These two categories show how career agency varies in orientation, form and behavioural outcome depending on the relational context within which their psychological contracts evolve. Those involved in collaborative research experienced a relational psychological contract and responded to unfulfilled career promises by extended investment' in their current jobs. They use proxy agency' by enlisting the support of their professors. However, some become trapped' in perennial temporary employment and are content to be sad'. By contrast, those involved in research commercialization experienced a transactional contract and assert personal agency' by crafting their own entrepreneurial careers. They are runaways' who seek autonomy. The evidence is based on interviews with 24 doctoral/postdoctoral researchers and 16 professors from three leading UK universities. The article extends psychological contract theory by incorporating career agency and sheds new light on changing academic careers.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\34F3Q275\\lam_de_campos_2014_'content_to_be_sad'_or_'runaway_apprentice'.pdf},
  isbn = {0018726714545}
}

@book{Lam2015,
  title = {`{{Content}} to Be Sad' or `Runaway Apprentice'? {{The}} Psychological Contract and Career Agency of Young Scientists in the Entrepreneurial University},
  author = {Lam, Alice and {de Campos}, Andr{\'e}},
  year = {2015},
  volume = {68},
  issn = {1741282X},
  doi = {10.1177/0018726714545483},
  abstract = {This article examines employee agency in psychological contracts by exploring how young scientists proactively shape their careers in response to unmet expectations induced by academic entrepreneurialism. It uses the lens of social exchange to examine their relationships with the professors engaged in two types of activities: collaborative research characterized by diffuse/reciprocal exchange, and commercial ventures, by restricted/negotiated exchange. These two categories show how career agency varies in orientation, form and behavioural outcome depending on the relational context within which their psychological contracts evolve. Those involved in collaborative research experienced a relational psychological contract and responded to unfulfilled career promises by extended investment' in their current jobs. They use proxy agency' by enlisting the support of their professors. However, some become trapped' in perennial temporary employment and are content to be sad'. By contrast, those involved in research commercialization experienced a transactional contract and assert personal agency' by crafting their own entrepreneurial careers. They are runaways' who seek autonomy. The evidence is based on interviews with 24 doctoral/postdoctoral researchers and 16 professors from three leading UK universities. The article extends psychological contract theory by incorporating career agency and sheds new light on changing academic careers.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BYLPEEN2\\lam_de_campos_2015_‘content_to_be_sad’_or_‘runaway_apprentice’.pdf},
  isbn = {0018726714545},
  keywords = {academic scientists,career,career agency,entrepreneurial university,psychological contract,social exchange}
}

@article{Lambert2009,
  title = {Further Development of Flexible Parametric Models for Survival Analysis},
  author = {Lambert, Paul C. and Royston, Patrick},
  year = {2009},
  volume = {9},
  pages = {265--290},
  issn = {1536867X},
  doi = {10.1177/1536867x0900900206},
  abstract = {Royston and Parmar (2002. Statistics in Medicine 21: 2175-2197) developed a class of flexible parametric survival models that were programmed in Stata with the stpm command (Royston. 2001, Stata Journal 1: 1-28). In this article, we introduce a new command. stpm2, that extends the methodology. New features for stpm2 include improvement in the way time-dependent covariates are modeled, with these effects far less likely to be over parameterized; the ability to incorporate expected mortality and thus fit relative survival models; and a superior predict command that enables simple quantification of differences between any two covariate patterns through calculation of time-dependent hazard ratios, hazard differences, and survival differences. The ideas are illustrated through a study of breast cancer survival and incidence of hip fracture in prostate cancer patients. \textcopyright{} 2009 StataCorp LP.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PUECYRCP\\lambert_royston_2009_further_development_of_flexible_parametric_models_for_survival_analysis.pdf},
  journal = {Stata Journal},
  keywords = {Relative survival,StO165,Stpm2,Survival analysis,Time-dependent effects},
  number = {2}
}

@article{Lambert2018,
  title = {{{rFSA}}: {{An}} r Package for Finding Best Subsets and Interactions},
  author = {Lambert, Joshua and Gong, Liyu and Elliott, Corrine F and Thompson, Katherine and Stromberg, Arnold},
  year = {2018},
  volume = {10},
  pages = {295--308},
  abstract = {Herein we present the R package rFSA, which implements an algorithm for improved variable selection. The algorithm searches a data space for models of a user-specified form that are statistically optimal under a measure of model quality. Many iterations afford a set of feasible solutions (or candidate models) that the researcher can evaluate for relevance to his or her questions of interest. The algorithm can be used to formulate new or to improve upon existing models in bioinformatics, health care, and myriad other fields in which the volume of available data has outstripped researchers' practical and computational ability to explore larger subsets or higher-order interaction terms. The package accommodates linear and generalized linear models, as well as a variety of criterion functions such as Allen's PRESS and AIC. New modeling strategies and criterion functions can be adapted easily to work with rFSA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XRZEXP2R\\lambert_et_al_2018_rfsa.pdf},
  journal = {The R Journal},
  number = {2}
}

@article{Lan2016,
  title = {{{AAHKS}} Endorsed Co-Morbidity Coding for Total Joint Arthroplasty: {{How}} Often Did We Hit the Mark with {{ICD}}-9?},
  author = {Lan, Roy H. and Kamath, Atul F.},
  year = {2016},
  publisher = {{Elsevier Ltd}},
  issn = {08835403},
  doi = {10.1016/j.arth.2016.05.051},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UCU2T8H6\\lan_kamath_2016_aahks_endorsed_co-morbidity_coding_for_total_joint_arthroplasty.pdf},
  isbn = {0883-5403},
  journal = {The Journal of Arthroplasty},
  keywords = {coding (ICD),comorbidity,risk factors,total hip arthroplasty,total knee arthroplasty},
  pmid = {27378645}
}

@article{Lange2012,
  title = {A Simple Unified Approach for Estimating Natural Direct and Indirect Effects},
  author = {Lange, Theis and Vansteelandt, Stijn and Bekaert, Maarten},
  year = {2012},
  volume = {176},
  pages = {190--195},
  issn = {00029262},
  doi = {10.1093/aje/kwr525},
  abstract = {An important problem within both epidemiology and many social sciences is to break down the effect of a given treatment into different causal pathways and to quantify the importance of each pathway. Formal mediation analysis based on counterfactuals is a key tool when addressing this problem. During the last decade, the theoretical framework for mediation analysis has been greatly extended to enable the use of arbitrary statistical models for outcome and mediator. However, the researcher attempting to use these techniques in practice will often find implementation a daunting task, as it tends to require special statistical programming. In this paper, the authors introduce a simple procedure based on marginal structural models that directly parameterize the natural direct and indirect effects of interest. It tends to produce more parsimonious results than current techniques, greatly simplifies testing for the presence of a direct or an indirect effect, and has the advantage that it can be conducted in standard software. However, its simplicity comes at the price of relying on correct specification of models for the distribution of mediator (and exposure) and accepting some loss of precision compared with more complex methods. Web Appendixes 1 and 2, which are posted on the Journal's Web site (http://aje.oupjournals.org/), contain implementation examples in SAS software (SAS Institute, Inc., Cary, North Carolina) and R language (R Foundation for Statistical Computing, Vienna, Austria).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6N8BK83W\\lange_et_al_2012_a_simple_unified_approach_for_estimating_natural_direct_and_indirect_effects.pdf},
  isbn = {1476-6256},
  journal = {American Journal of Epidemiology},
  keywords = {causal inference,marginal structural models,mediation},
  number = {3},
  pmid = {22781427}
}

@article{Lange2014,
  title = {Assessing Natural Direct and Indirect Effects through Multiple Pathways},
  author = {Lange, Theis and Rasmussen, Mette and Thygesen, Lau Caspar},
  year = {2014},
  volume = {179},
  pages = {513--518},
  issn = {00029262},
  doi = {10.1093/aje/kwt270},
  abstract = {Within the fields of epidemiology, interventions research and social sciences researchers are often faced with the challenge of decomposing the effect of an exposure into different causal pathways working through defined mediator variables. The goal of such analyses is often to understand the mechanisms of the system or to suggest possible interventions. The case of a single mediator, thus implying only 2 causal pathways (direct and indirect) from exposure to outcome, has been extensively studied. By using the framework of counterfactual variables, researchers have established theoretical properties and developed powerful tools. However, in practical problems, it is not uncommon to have several distinct causal pathways from exposure to outcome operating through different mediators. In this article, we suggest a widely applicable approach to quantifying and ranking different causal pathways. The approach is an extension of the natural effect models proposed by Lange et al. (Am J Epidemiol. 2012;176(3):190-195). By allowing the analysis of distinct multiple pathways, the suggested approach adds to the capabilities of modern mediation techniques. Furthermore, the approach can be implemented using standard software, and we have included with this article implementation examples using R (R Foundation for Statistical Computing, Vienna, Austria) and Stata software (StataCorp LP, College Station, Texas).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5IKZRI26\\lange_et_al_2014_assessing_natural_direct_and_indirect_effects_through_multiple_pathways.pdf},
  isbn = {0002-9262},
  journal = {American Journal of Epidemiology},
  keywords = {causal inference,mediation,multiple mediators},
  number = {4},
  pmid = {24264291}
}

@article{Langholz2010,
  title = {Fitting General Relative Risk Models for Survival Time and Matched Case-Control Analysis.},
  author = {Langholz, Bryan and Richardson, David B},
  year = {2010},
  month = feb,
  volume = {171},
  pages = {377--83},
  publisher = {{Oxford University Press}},
  doi = {10.1093/aje/kwp403},
  abstract = {Cox proportional hazards regression analysis of survival data and conditional logistic regression analysis of matched case-control data are methods that are widely used by epidemiologists. Standard statistical software packages accommodate only log-linear model forms, which imply exponential exposure-response functions and multiplicative interactions. In this paper, the authors describe methods for fitting non-log-linear Cox and conditional logistic regression models. The authors use data from a study of lung cancer mortality among Colorado Plateau uranium miners (1950-1982) to illustrate these methods for fitting general relative risk models to matched case-control control data, countermatched data with weights, d:m matching, and full cohort Cox regression using the SAS statistical package (SAS Institute Inc., Cary, North Carolina).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\D5FQ3BGE\\langholz_richardson_2010_fitting_general_relative_risk_models_for_survival_time_and_matched_case-control.pdf},
  journal = {American journal of epidemiology},
  number = {3},
  pmid = {20044379}
}

@article{Larson1931,
  title = {The Shrinkage of the Coefficient of Multiple Correlation},
  author = {Larson, S. C.},
  year = {1931},
  volume = {22},
  pages = {45--55},
  issn = {00220663},
  doi = {10.1037/h0072400},
  abstract = {A study is made, on 800 cases, of the shrinkage attendant upon using a regression equation derived from one group to predict the criterion scores of a second group. It is found that "the theoretically expected shrinkage of R as derived by the multiple correlation formula is a fact." The shrinkage increases as the number of variables increases and as the size of R decreases. The Smith formula for shrinkage-deduction parallels the empirical findings, but consistently yields higher values. The results upon increase in number of test variables suggest that test batteries may have definite limitations in size. (PsycINFO Database Record (c) 2006 APA, all rights reserved). \textcopyright{} 1931 American Psychological Association.},
  isbn = {0022-0663},
  journal = {Journal of Educational Psychology},
  keywords = {\#nosource,BIOMETRY AND STATISTICS,CORRELATION,MULTIPLE,SHRINKAGE},
  number = {1}
}

@article{Lasch2010,
  title = {{{PRO}} Development: {{Rigorous}} Qualitative Research as the Crucial Foundation},
  author = {Lasch, Kathryn Eilene and Marquis, Patrick and Vigneux, Marc and Abetz, Linda and Arnould, Benoit and Bayliss, Martha and Crawford, Bruce and Rosa, Kathleen},
  year = {2010},
  volume = {19},
  pages = {1087--1096},
  issn = {09629343},
  doi = {10.1007/s11136-010-9677-6},
  abstract = {Recently published articles have described criteria to assess qualitative research in the health field in general, but very few articles have delineated qualitative methods to be used in the development of Patient-Reported Outcomes (PROs). In fact, how PROs are developed with subject input through focus groups and interviews has been given relatively short shrift in the PRO literature when compared to the plethora of quantitative articles on the psychometric properties of PROs. If documented at all, most PRO validation articles give little for the reader to evaluate the content validity of the measures and the credibility and trustworthiness of the methods used to develop them. Increasingly, however, scientists and authorities want to be assured that PRO items and scales have meaning and relevance to subjects. This article was developed by an international, interdisciplinary group of psychologists, psychometricians, regulatory experts, a physician, and a sociologist. It presents rigorous and appropriate qualitative research methods for developing PROs with content validity. The approach described combines an overarching phenomenological theoretical framework with grounded theory data collection and analysis methods to yield PRO items and scales that have content validity.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HMPAFMNR\\lasch_et_al_2010_pro_development.pdf},
  isbn = {0962-9343},
  journal = {Quality of Life Research},
  keywords = {Grounded theory methods,PRO development,Qualitative research},
  number = {8},
  pmid = {20512662}
}

@article{Latouche2013,
  title = {A Competing Risks Analysis Should Report Results on All Cause-Specific Hazards and Cumulative Incidence Functions},
  author = {Latouche, Aurelien and Allignol, Arthur and Beyersmann, Jan and Labopin, Myriam and Fine, Jason P},
  year = {2013},
  volume = {66},
  pages = {648--653},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2012.09.017},
  abstract = {Competing risks endpoints are frequently encountered in hematopoietic stem cell transplantation where patients are exposed to relapse and treatment-related mortality. Both cause-specific hazards and direct models for the cumulative incidence functions have been used for analyzing such competing risks endpoints. For both approaches, the popular models are of a proportional hazards type. Such models have been used for studying prognostic factors in acute and chronic leukemias. We argue that a complete understanding of the event dynamics requires that both hazards and cumulative incidence be analyzed side by side, and that this is generally the most rigorous scientific approach to analyzing competing risks data. That is, understanding the effects of covariates on cause-specific hazards and cumulative incidence functions go hand in hand. A case study illustrates our proposal.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CQ2B3HVR\\latouche_et_al_2013_a_competing_risks_analysis_should_report_results_on_all_cause-specific_hazards.pdf},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Bone marrow transplant,Competing risks,Cumulative incidence,Endpoints,Proportional hazards,Survival analysis},
  number = {6}
}

@article{Lau2009,
  title = {Competing Risk Regression Models for Epidemiologic Data},
  author = {Lau, Bryan and Cole, Stephen R and Gange, Stephen J},
  year = {2009},
  month = jul,
  volume = {170},
  pages = {244--256},
  issn = {0002-9262},
  abstract = {Competing events can preclude the event of interest from occurring in epidemiologic data and can be analyzed by using extensions of survival analysis methods. In this paper, the authors outline 3 regression approaches for estimating 2 key quantities in competing risks analysis: the cause-specific relative hazard (csRH) and the subdistribution relative hazard (sdRH). They compare and contrast the structure of the risk sets and the interpretation of parameters obtained with these methods. They also demonstrate the use of these methods with data from the Women's Interagency HIV Study established in 1993, treating time to initiation of highly active antiretroviral therapy or to clinical disease progression as competing events. In our example, women with an injection drug use history were less likely than those without a history of injection drug use to initiate therapy prior to progression to acquired immunodeficiency syndrome or death by both measures of association (csRH = 0.67, 95\% confidence interval: 0.57, 0.80 and sdRH = 0.60, 95\% confidence interval: 0.50, 0.71). Moreover, the relative hazards for disease progression prior to treatment were elevated (csRH = 1.71, 95\% confidence interval: 1.37, 2.13 and sdRH = 2.01, 95\% confidence interval: 1.62, 2.51). Methods for competing risks should be used by epidemiologists, with the choice of method guided by the scientific question.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PV697GIZ\\lau_et_al_2009_competing_risk_regression_models_for_epidemiologic_data.pdf},
  journal = {American Journal of Epidemiology},
  number = {2}
}

@article{Lavernia2009,
  title = {All-Patient Refined Diagnosis-Related Groups in Primary Arthroplasty},
  author = {Lavernia, Carlos J. and Laoruengthana, Artit and Contreras, Juan S. and Rossi, Mark D.},
  year = {2009},
  month = sep,
  volume = {24},
  pages = {19--23},
  issn = {08835403},
  doi = {10.1016/j.arth.2009.03.008},
  abstract = {Our objective was to determine if the All-Patient Refined Diagnosis-Related Groups (APR-DRGs) and other comorbidity scores correlate with pain level, functional abilities, and hospital cost after primary total joint arthroplasty (TJA). Three hundred three patients having TJA were evaluated with average follow-up of 21 months. Western Ontario and McMaster Universities osteoarthritis index, Short-Form 36, and Quality of Well-Being index were administered before and after surgery. The APR-DRG subclassification including severity of illness (SOI) subclass scores and risk of mortality (ROM), Charlson index, American Society of Anesthesiologist (ASA), Charnley score, length of stay, and hospital costs were reported. Patients in a higher SOI and ROM subclasses had a statistically significant decrease in functional outcomes scores, longer length of stay, and greater hospitals costs than those in lower subclasses. However, correlations of comorbidity categories with outcome scores were poor. The APR-DRG classification helps identify those individuals with worse function and is specially suited in identifying those patients who incur a higher hospital cost.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NQ9Y5MI4\\lavernia_et_al_2009_all-patient_refined_diagnosis-related_groups_in_primary_arthroplasty.pdf},
  journal = {The Journal of Arthroplasty},
  number = {6}
}

@article{Lawrence2019,
  title = {Difference in Restricted Mean Survival Time: {{Small}} Sample Distribution and Asymptotic Relative Efficiency},
  author = {Lawrence, John and Qiu, Junshan and Bai, Steven and Hung, H. M.James},
  year = {2019},
  volume = {11},
  pages = {61--66},
  issn = {19466315},
  doi = {10.1080/19466315.2018.1527249},
  abstract = {The difference between two arms in the restricted mean survival time is an alternative to the hazard ratio. It provides a more easily understood measure of the treatment effect of an intervention in a controlled clinical trial with a time to event endpoint. In this article, we consider the distribution of the estimate for small or moderate sample sizes or when the event rate is low and compare the asymptotic relative efficiency (ARE) and relative efficiency for practical sample sizes of the test to the standard logrank test for Weibull parent distributions. We find that for small sample sizes, the distribution can depart markedly from the normal distribution. We propose a method to approximate the correct null distribution using the Cornish\textendash Fisher expansion and provide an example. For Weibull parent distributions, we consider two scenarios with either proportional hazards or nonproportional hazards where the hazard functions and survival distribution curves crossover. The ARE is compared for these two scenarios.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KLN5PUNT\\lawrence_et_al_2019_difference_in_restricted_mean_survival_time.pdf},
  journal = {Statistics in Biopharmaceutical Research},
  keywords = {Active controlled trial,Cornish–Fisher expansion,Logrank test,Noninferiority testing,Proportional hazards model,Weibull distribution},
  number = {1}
}

@article{Lawton2019,
  title = {Policy: {{A}} Novel Modelling Technique to Predict Resource \-requirements in Critical Care \textendash{} a Case Study},
  author = {Lawton, Tom and McCooe, Michael},
  year = {2019},
  month = feb,
  volume = {6},
  pages = {17--20},
  publisher = {{Royal College of Physicians}},
  issn = {2514-6645},
  doi = {10.7861/futurehosp.6-1-17},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EAEVRSFC\\lawton_mccooe_2019_policy.pdf},
  journal = {Future Healthcare Journal},
  number = {1}
}

@article{Learmonth2007,
  title = {The Operation of the Century: Total Hip Replacement},
  author = {Learmonth, Ian D. and Young, Claire and Rorabeck, Cecil},
  year = {2007},
  volume = {370},
  pages = {1508--1519},
  issn = {01406736},
  doi = {10.1016/S0140-6736(07)60457-7},
  abstract = {In the 1960s, total hip replacement revolutionised management of elderly patients crippled with arthritis, with very good long-term results. Today, young patients present for hip-replacement surgery hoping to restore their quality of life, which typically includes physically demanding activities. Advances in bioengineering technology have driven development of hip prostheses. Both cemented and uncemented hips can provide durable fixation. Better materials and design have allowed use of large-bore bearings, which provide an increased range of motion with enhanced stability and very low wear. Minimally invasive surgery limits soft-tissue damage and facilitates accelerated discharge and rehabilitation. Short-term objectives must not compromise long-term performance. Computer-assisted surgery will contribute to reproducible and accurate placement of implants. Universal economic constraints in healthcare services dictate that further developments in total hip replacement will be governed by their cost-effectiveness. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9GTUCYYQ\\learmonth_et_al_2007_the_operation_of_the_century.pdf},
  isbn = {1474-547X (Electronic)0140-6736 (Linking)},
  journal = {Lancet},
  number = {9597},
  pmid = {17964352}
}

@article{Lee1971,
  title = {Some Results on the Sampling Distribution of the Multiple Correlation Coefficient},
  author = {Lee, Yoong-Sin},
  year = {1971},
  volume = {33},
  pages = {117--130},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {00359246},
  abstract = {Recurrence formulae for the density function and the probability integral of the multiple correlation coefficient from a normal sample are obtained. When the number of independent variates is odd these formulae are related to the distribution of the simple correlation. Asymptotic expansions in terms of the non-central beta and of the non-central {$\chi$}2 distributions are derived. Methods of approximation by the central and the non-central F distributions, as well as by the normal distribution, are proposed. Numerical investigations of the accuracies of these approximations are carried out.},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  keywords = {\#nosource},
  number = {1}
}

@article{Lee1999,
  title = {Learning the Parts of Objects by Non-Negative Matrix Factorization},
  author = {Lee, Daniel D. and Seung, H. Sebastian},
  year = {1999},
  month = oct,
  volume = {401},
  pages = {788--791},
  issn = {0028-0836},
  doi = {10.1038/44565},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DC346Y2Z\\lee_seung_1999_learning_the_parts_of_objects_by_non-negative_matrix_factorization.pdf},
  journal = {Nature},
  number = {6755}
}

@book{Lee2003,
  title = {Statistical Methods for Survival Data Analysis},
  author = {Lee, Elisa T and Wang, John Wenyu},
  year = {2003},
  isbn = {3-17-572399-3},
  keywords = {\#nosource}
}

@article{Lee2004,
  title = {Conditional and {{Marginal Models}}: {{Another View}}},
  shorttitle = {Conditional and {{Marginal Models}}},
  author = {Lee, Youngjo and Neider, John A.},
  year = {2004},
  volume = {19},
  pages = {219--228},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237},
  abstract = {There has existed controversy about the use of marginal and conditional models, particularly in the analysis of data from longitudinal studies. We show that alleged differences in the behavior of parameters in so-called marginal and conditional models are based on a failure to compare like with like. In particular, these seemingly apparent differences are meaningless because they are mainly caused by preimposed unidentifiable constraints on the random effects in models. We discuss the advantages of conditional models over marginal models. We regard the conditional model as fundamental, from which marginal predictions can be made.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FDLM2H4D\\Lee och Neider - 2004 - Conditional and Marginal Models Another View.pdf},
  journal = {Statistical Science},
  number = {2}
}

@article{Lee2014,
  title = {Bayesian Semiparametric Analysis of Semicompeting Risks Data: Investigating Hospital Readmission after a Pancreatic Cancer Diagnosis},
  author = {Lee, Kyu Ha and Haneuse, Sebastien and Schrag, Deborah and Dominici, Francesca},
  year = {2014},
  month = sep,
  volume = {64},
  pages = {253--273},
  publisher = {{Wiley/Blackwell (10.1111)}},
  issn = {0035-9254},
  doi = {10.1111/rssc.12078},
  abstract = {Summary In the USA, the Centers for Medicare and Medicaid Services use 30-day readmission, following hospitalization, as a proxy outcome to monitor quality of care. These efforts generally focus on treatable health conditions, such as pneumonia and heart failure. Expanding quality-of-care systems to monitor conditions for which treatment options are limited or non-existent, such as pancreatic cancer, is challenging because of the non-trivial force of mortality; 30-day mortality for pancreatic cancer is approximately 30\%. In the statistical literature, data that arise when the observation of the time to some non-terminal event is subject to some terminal event are referred to as ?semicompeting risks data?. Given such data, scientific interest may lie in at least one of three areas: estimation or inference for regression parameters, characterization of dependence between the two events and prediction given a covariate profile. Existing statistical methods focus almost exclusively on the first of these; methods are sparse or non-existent, however, when interest lies with understanding dependence and performing prediction. We propose a Bayesian semiparametric regression framework for analysing semicompeting risks data that permits the simultaneous investigation of all three of the aforementioned scientific goals. Characterization of the induced posterior and posterior predictive distributions is achieved via an efficient Metropolis?Hastings?Green algorithm, which has been implemented in an R package. The framework proposed is applied to data on 16051 individuals who were diagnosed with pancreatic cancer between 2005 and 2008, obtained from Medicare part A. We found that increased risk for readmission is associated with a high comorbidity index, a long hospital stay at initial hospitalization, non-white race, being male and discharge to home care.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TQH7UAUX\\lee_et_al_2014_bayesian_semiparametric_analysis_of_semicompeting_risks_data.pdf},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  keywords = {Bayesian survival analysis,Illness–death models,Reversible jump Markov chain Monte Carlo methods,Semicompeting risks,Shared frailty},
  number = {2}
}

@article{Lee2016,
  title = {Hierarchical Models for Semicompeting Risks Data with Application to Quality of End-of-Life Care for Pancreatic Cancer},
  author = {Lee, Kyu Ha and Dominici, Francesca and Schrag, Deborah and Haneuse, Sebastien},
  year = {2016},
  month = jul,
  volume = {111},
  pages = {1075--1095},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1164052},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4BJ4XGVP\\lee_et_al_2016_hierarchical_models_for_semicompeting_risks_data_with_application_to_quality_of.pdf},
  journal = {Journal of the American Statistical Association},
  number = {515}
}

@article{Lee2017,
  title = {Accelerated Failure Time Models for Semi-Competing Risks Data in the Presence of Complex Censoring},
  author = {Lee, Kyu Ha and Rondeau, Virginie and Haneuse, Sebastien},
  year = {2017},
  month = apr,
  volume = {73},
  pages = {1401--1412},
  publisher = {{Wiley/Blackwell (10.1111)}},
  issn = {0006-341X},
  doi = {10.1111/biom.12696},
  abstract = {Summary Statistical analyses that investigate risk factors for Alzheimer's disease (AD) are often subject to a number of challenges. Some of these challenges arise due to practical considerations regarding data collection such that the observation of AD events is subject to complex censoring including left-truncation and either interval or right-censoring. Additional challenges arise due to the fact that study participants under investigation are often subject to competing forces, most notably death, that may not be independent of AD. Towards resolving the latter, researchers may choose to embed the study of AD within the ?semi-competing risks? framework for which the recent statistical literature has seen a number of advances including for the so-called illness-death model. To the best of our knowledge, however, the semi-competing risks literature has not fully considered analyses in contexts with complex censoring, as in studies of AD. This is particularly the case when interest lies with the accelerated failure time (AFT) model, an alternative to the traditional multiplicative Cox model that places emphasis away from the hazard function. In this article, we outline a new Bayesian framework for estimation/inference of an AFT illness-death model for semi-competing risks data subject to complex censoring. An efficient computational algorithm that gives researchers the flexibility to adopt either a fully parametric or a semi-parametric model specification is developed and implemented. The proposed methods are motivated by and illustrated with an analysis of data from the Adult Changes in Thought study, an on-going community-based prospective study of incident AD in western Washington State.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XRHMFLZ8\\lee_et_al_2017_accelerated_failure_time_models_for_semi-competing_risks_data_in_the_presence.pdf},
  journal = {Biometrics},
  keywords = {Accelerated failure time model,Bayesian survival analysis,Illness-death models,Interval-censoring,Left-truncation,Semi-competing risks},
  number = {4}
}

@book{Leek2016,
  title = {How to Be a Modern Scientist},
  author = {Leek, Jeffrey},
  year = {2016},
  keywords = {\#nosource}
}

@article{Legendre1988,
  title = {Numerical Ecology, Volume 24},
  author = {Legendre, Pierre and Legendre, Louis},
  year = {1988},
  volume = {24},
  pages = {870},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \AA{} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\P4C7J9KI\\legendre_legendre_1988_numerical_ecology,_volume_24.pdf},
  isbn = {9788578110796},
  journal = {(Developments in Environmental Modelling)},
  pmid = {25246403}
}

@article{Lehman1953,
  title = {The Power of Rank Tests},
  author = {Lehman, E L},
  year = {1953},
  volume = {24},
  pages = {23--43},
  journal = {The Annals of Mathematical Statistics},
  keywords = {\#nosource},
  number = {1}
}

@article{Lemmens2006,
  title = {Bagging and Boosting Classification Trees to Predict Churn},
  author = {Lemmens, Aur{\'e}lie and Croux, Christophe},
  year = {2006},
  month = may,
  volume = {43},
  pages = {276--286},
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  doi = {10.1509/jmkr.43.2.276},
  abstract = {In this article, the authors explore the bagging and boosting classification techniques. They apply the two techniques to a customer database of an anonymous U.S. wireless telecommunications company, and both significantly improve accuracy in predicting churn. This higher predictive performance could ultimately lead to incremental profits for companies that use these methods. Furthermore, the results recommend the use of a balanced sampling scheme when predicting a rare event from large data sets, but this requires an appropriate bias correction.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7EF684AQ\\lemmens_croux_2006_bagging_and_boosting_classification_trees_to_predict_churn.pdf},
  journal = {Journal of Marketing Research},
  number = {2}
}

@article{Lepo2017,
  title = {The Emergence of Ambivalent Leisure Consumers e {{The}} Case of Boating along the {{Swedish West Coast}}},
  author = {Lepo, Neva},
  year = {2017},
  volume = {145},
  pages = {35--44},
  doi = {10.1016/j.jclepro.2017.01.002},
  abstract = {Through a case study of leisure boating along the Swedish West Coast, this study explores how two conflicting roles e consumers and environmental citizens e produce and are produced by a highly ambivalent neoliberal discourse. On the one hand, this discourse supports economic growth and increasing consumption, while on the other hand it expects consumers to consider the environmental impacts of their actions and make pro-environmental choices. Through a mixed-method approach based on the application of consumer value theory (CVT) in combination with a motivation-opportunity-ability (MOA) model, this study demonstrates how the consumer role is predominantly produced and reproduced through social pressure and market forces as well as emotional and habitual attachment to boat-life and boating. This (re)production of the consumer role conflicts with the environmental citizenship role, as boaters agree that protection is needed while they also put high value on the sea as a place of freedom. The study suggests that there is a need for an environmental policy that recognises how the consumer role is produced and reproduced. Such policy should move beyond the assumption of the sovereignty of the individual and focus more closely on the interaction between humans and the sea.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\44PDC8KP\\lepo_2017_the_emergence_of_ambivalent_leisure_consumers_e_the_case_of_boating_along_the.pdf},
  journal = {Journal of Cleaner Production}
}

@article{levesqueProblemImmortalTime2010,
  title = {Problem of Immortal Time Bias in Cohort Studies: Example Using Statins for Preventing Progression of Diabetes},
  author = {L{\'e}vesque, Linda E and Hanley, James A and Kezouh, Abbas and Suissa, Samy},
  year = {2010},
  volume = {340},
  journal = {BMJ: British Medical Journal},
  keywords = {\#nosource}
}

@book{Levitt2009,
  title = {Super Freakonomics},
  author = {Levitt, Steven D and Dubner, Stephen J},
  year = {2009},
  keywords = {\#nosource}
}

@book{Levitt2014,
  title = {Freakonomics},
  author = {Levitt, Steven D and Dubner, Stephen J},
  year = {2014},
  keywords = {\#nosource}
}

@article{Lew2012,
  title = {Bad Statistical Practice in Pharmacology (and Other Basic Biomedical Disciplines): You Probably Don't Know {{P}}.},
  author = {Lew, Michael J},
  year = {2012},
  month = jul,
  volume = {166},
  pages = {1559--67},
  issn = {1476-5381},
  doi = {10.1111/j.1476-5381.2012.01931.x},
  abstract = {Statistical analysis is universally used in the interpretation of the results of basic biomedical research, being expected by referees and readers alike. Its role in helping researchers to make reliable inference from their work and its contribution to the scientific process cannot be doubted, but can be improved. There is a widespread and pervasive misunderstanding of P-values that limits their utility as a guide to inference, and a change in the manner in which P-values are specified and interpreted will lead to improved outcomes. This paper explains the distinction between Fisher's P-values, which are local indices of evidence against the null hypothesis in the results of a particular experiment, and Neyman-Pearson {$\alpha$} levels, which are global rates of false positive errors from unrelated experiments taken as an aggregate. The vast majority of papers published in pharmacological journals specify P-values, either as exact-values or as being less than a value (usually 0.05), but they are interpreted in a hybrid manner that detracts from their Fisherian role as indices of evidence without gaining the control of false positive and false negative error rate offered by a strict Neyman-Pearson approach. An informed choice between those approaches offers substantial advantages to the users of statistical tests over the current accidental hybrid approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RPL2VKLS\\lew_2012_bad_statistical_practice_in_pharmacology_(and_other_basic_biomedical.pdf},
  journal = {British journal of pharmacology},
  keywords = {Biomedical Research,Biomedical Research: statistics \& numerical data,Pharmacology,Pharmacology: statistics \& numerical data,Statistics as Topic},
  number = {5},
  pmid = {22394284}
}

@article{Li2006,
  title = {Using the Open-Source Statistical Language {{R}} to Analyze the Dichotomous {{Rasch}} Model},
  author = {Li, Yuelin},
  year = {2006},
  volume = {38},
  pages = {532--541},
  issn = {1554351X},
  doi = {10.3758/BF03192809},
  abstract = {R, an open-source statistical language and data analysis tool, is gaining popularity among psychologists currently teaching statistics. R is especially suitable for teaching advanced topics, such as fitting the dichotomous Rasch model-a topic that involves transforming complicated mathematical formulas into statistical computations. This article describes R's use as a teaching tool and a data analysis software program in the analysis of the Rasch model in item response theory. It also explains the theory behind, as well as an educator's goals for, fitting the Rasch model with joint maximum likelihood estimation. This article also summarizes the R syntax for parameter estimation and the calculation of fit statistics. The results produced by R is compared with the results obtained from MINISTEP and the output of a conditional logit model. The use of R is encouraged because it is free, supported by a network of peer researchers, and covers both basic and advanced topics in statistics frequently used by psychologists.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RWM25A93\\li_2006_using_the_open-source_statistical_language_r_to_analyze_the_dichotomous_rasch.pdf},
  isbn = {1554-351x},
  journal = {Behavior Research Methods},
  number = {3},
  pmid = {17186765}
}

@book{Li2012,
  title = {Behavioral Reasearch Data Analysis with {{R}}},
  author = {Li, Yuelin and Baron, Jonathan},
  year = {2012},
  issn = {9780387938363},
  doi = {10.1007/978-1-4614-1238-0},
  abstract = {This book is written for behavioral scientists who want to consider adding R to their existing set of statistical tools, or want to switch to R as their main computation tool. The authors aim primarily to help practitioners of behavioral research make the transition to R. The focus is to provide practical advice on some of the widely-used statistical methods in behavioral research, using a set of notes and annotated examples. The book will also help beginners learn more about statistics and behavioral research. These are statistical techniques used by psychologists who do research on human subjects, but of course they are also relevant to researchers in others fields that do similar kinds of research.},
  isbn = {978-1-4614-1237-3},
  keywords = {\#nosource},
  pmid = {22057480}
}

@article{Li2014,
  title = {A Conversation with Donald b. {{Rubin}}},
  author = {Li, Fan and Mealli, Fabrizia},
  year = {2014},
  volume = {29},
  pages = {439--457},
  doi = {10.1214/14-STS489},
  abstract = {Donald Bruce Rubin is John L. Loeb Professor of Statis-tics at Harvard University. He has made fundamental contributions to statistical methods for missing data, causal inference, survey sam-pling, Bayesian inference, computing and applications to a wide range of disciplines, including psychology, education, policy, law, economics, epidemiology, public health and other social and biomedical sciences. Don was born in Washington, D.C. on Decem-ber 22, 1943, to Harriet and Allan Rubin. One year later, his family moved to Evanston, Illinois, where he grew up. He developed a keen interest in physics and mathematics in high school. In 1961, he went to college at Princeton University, intending to ma-jor in physics, but graduated in psychology in 1965. He began graduate school in psychology at Harvard, then switched to Computer Science (MS, 1966) and eventually earned a Ph.D. in Statistics under the direction of Bill Cochran in 1970. After graduating from Harvard, he taught for a year in Harvard's De-partment of Statistics, and then in 1971 he began working at Educational Testing Service (ETS) and served as a visiting faculty member at Princeton's new Statistics Department. He held several visiting academic appointments in the next decade at Har-vard, UC Berkeley, University of Texas at Austin and the University of Wisconsin at Madison. He was a full professor at the University of Chicago in 1981\textendash{} 1983, and in 1984 moved back to the Harvard Statis-tics Department, where he remains until now, and where he served as chair from},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QDLHRS4U\\li_mealli_2014_a_conversation_with_donald_b.pdf},
  journal = {Statistical Science},
  number = {3}
}

@article{Li2015,
  title = {The Flare Package for High Dimensional Linear Regression and Precision Matrix Estimation in r *},
  author = {Li, Xingguo and Zhao, Tuo and Liu, Han and Yuan, Xiaoming and Liu, Han},
  year = {2015},
  volume = {16},
  pages = {553--557},
  issn = {15337928},
  abstract = {This paper describes an R package named flare, which implements a family of new high dimensional regression methods (LAD Lasso, SQRT Lasso, q Lasso, and Dantzig selector) and their extensions to sparse precision matrix estimation (TIGER and CLIME). These methods exploit different nonsmooth loss functions to gain modeling flexibility, estimation robustness, and tuning insensitiveness. The developed solver is based on the alternating direction method of multipliers (ADMM). The package flare is coded in double precision C, and called from R by a user-friendly interface. The memory usage is optimized by using the sparse matrix output. The experiments show that flare is efficient and can scale up to large problems.},
  journal = {Journal of Machine Learning Research},
  keywords = {\#nosource,alternating di-rection method of multipliers,robustness,sparse linear regression,sparse precision matrix estimation,tuning insensitiveness},
  number = {1}
}

@article{Liddle2014,
  title = {Adverse Outcomes after Total and Unicompartmental Knee Replacement in 101 330 Matched Patients: A Study of Data from the {{National Joint Registry}} for {{England}} and {{Wales}}},
  author = {Liddle, Alexander D and Judge, Andrew and Pandit, Hemant and Murray, David W},
  year = {2014},
  volume = {384},
  pages = {1437--1445},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(14)60419-0},
  abstract = {Summary Background Total knee replacement (TKR) or unicompartmental knee replacement (UKR) are options for end-stage osteoarthritis. However, comparisons between the two procedures are confounded by differences in baseline characteristics of patients undergoing either procedure and by insufficient reporting of endpoints other than revision. We aimed to compare adverse outcomes for each procedure in matched patients. Methods With propensity score techniques, we compared matched patients undergoing TKR and UKR in the National Joint Registry for England and Wales. The National Joint Registry started collecting data in April 1, 2003, and is continuing. The last operation date in the extract of data used in our study was Aug 28, 2012. We linked data for multiple potential confounders from the National Health Service Hospital Episode Statistics database. We used regression models to compare outcomes including rates of revision, revision/reoperation, complications, readmission, mortality, and length of stay. Findings 25 334 UKRs were matched to 75 996 TKRs on the basis of propensity score. UKRs had worse implant survival both for revision (subhazard ratio [SHR] 2{$\cdot$}12, 95\% CI 1{$\cdot$}99\textendash 2{$\cdot$}26) and for revision/reoperation (1{$\cdot$}38, 1{$\cdot$}31\textendash 1{$\cdot$}44) than TKRs at 8 years. Mortality was significantly higher for TKR at all timepoints than for UKR (30 day: hazard ratio 0{$\cdot$}23, 95\% CI 0{$\cdot$}11\textendash 0{$\cdot$}50; 8 year: 0{$\cdot$}85, 0{$\cdot$}79\textendash 0{$\cdot$}92). Length of stay, complications (including thromboembolism, myocardial infarction, and stroke), and rate of readmission were all higher for TKR than for UKR. Interpretation In decisions about which procedure to offer, the higher revision/reoperation rate of UKR than of TKR should be balanced against a lower occurrence of complications, readmission, and mortality, together with known benefits for UKR in terms of postoperative function. If 100 patients receiving TKR received UKR instead, the result would be around one fewer death and three more reoperations in the first 4 years after surgery. Funding Royal College of Surgeons of England and Arthritis Research UK.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FUM4NF53\\liddle_et_al_2014_adverse_outcomes_after_total_and_unicompartmental_knee_replacement_in_101_330.pdf},
  journal = {The Lancet},
  number = {9952}
}

@article{Lie2000,
  title = {Mortality after Total Hip Replacement: 0-10-Year Follow-up of 39,543 Patients in the {{Norwegian Arthroplasty Register}}.},
  author = {a Lie, S and Engesaeter, L B and Havelin, L I and Gjessing, H K and Vollset, S E},
  year = {2000},
  volume = {71},
  pages = {19--27},
  issn = {1745-3674},
  doi = {10.1080/00016470052943838},
  abstract = {We have studied the mortality after total hip replacement (THR) of 39,543 patients, having a mean age of 69 years, who were reported to the Norwegian Arthroplasty Register. The median follow-up time was 5.2 (0-10.4) years. 323 of 6201 deaths occurred during the first 60 postoperative days. The patient mortality was compared with the mortality in the Norwegian population, using standardized mortality ratios (SMR). The SMRs were compared and adjusted for age, gender, and other possible confounders in a Cox regression model incorporating the population mortality. We observed a lower mortality in patients with THR than in the Norwegian population (8-year patient mortality was 25\%, versus 30\% in the corresponding Norwegian population. SMR = 0.81). There was an increased standardized mortality ratio in patients less than 50 years (SMR = 2.50), patients 50-59 years (SMR = 1.16), patients with THR due to rheumatoid arthritis (SMR = 1.48), and patients with femoral neck fracture (SMR = 1.11). The SMR decreased with increasing age at the time of THR surgery. After revision surgery, the SMR was similar to that after the first primary operation, whereas a second primary operation in the opposite hip was associated with a further reduction in the SMR (SMR = 0.65). During the first 60 postoperative days, all patient categories had a higher mortality than the general population (0.8\% mortality, SMR = 1.39).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7THIUGWT\\lie_et_al_2000_mortality_after_total_hip_replacement.pdf},
  isbn = {0001-6470 (Print) 0001-6470 (Linking)},
  journal = {Acta orthopaedica Scandinavica},
  number = {1},
  pmid = {10743987}
}

@article{Lie2004,
  title = {Dependency Issues in Survival Analyses of 55 782 Primary Hip Replacements from 47 355 Patients},
  author = {Lie, Stein Atle and Enges\ae ter, Lars B. and Havelin, Leif I. and Gjessing, H\aa kon K. and Vollset, Stein E.},
  year = {2004},
  volume = {23},
  pages = {3227--3240},
  issn = {02776715},
  doi = {10.1002/sim.1905},
  abstract = {Artificial hip joints are used in only one hip for about 85 per cent of the patients and in both hips (bilateral) for about 15 per cent of the patients. The occurrence of bilateral prostheses and the influence they have in survival analyses of joint arthroplasties are seldom considered. In this study we therefore focus on issues related to bilateral primary hip prostheses, time to revision surgery, and some commonly used statistical methods. We used information from 47355 patients with 55782 primary hip prostheses reported to the Norwegian Arthroplasty Register between 1987 and 2000. Due to the large number of diagnoses, fixation techniques for the prostheses, and combination of prostheses brands, we furthermore considered a 'homogeneous' subset of 8703 prostheses from 7930 patients with primary osteoarthritis, and Charnley prosthesis fixed with antibiotic-containing Palacos cement. Kaplan-Meier curves for all prostheses, ignoring that some patients have bilateral prostheses, were compared with Kaplan-Meier curves using only the first inserted prostheses, and with survival curves modified for patients with bilateral prostheses. Cox regression analyses were used to assess explanatory variables and to adjust for confounding factors. The results from the ordinary Cox regression analyses were compared with results from a marginal model, a shared gamma frailty model, and a model using a time dependent covariate to condition on failures in the opposite hip. We found no practical difference between the three calculated survival curves for the hip replacement data. The ordinary Cox-model and the marginal model gave equivalent results. In the shared gamma frailty model estimates for the risk factors were comparable with the former two approaches. The estimated frailty variance was higher when all data were used, even after adjustment for confounding factors. For the 'homogeneous' data the estimated frailty variance was negligible. Using a time dependent covariate to condition on previous revisions in the opposite hip, we found a higher risk of revision for the remaining primary hip prosthesis if the opposite hip had been revised (RR = 3.49, p \textexclamdown{} 0.0001). There was no difference in risk for revision between right and left hip prostheses. If the time interval between the two primary operations was more than two years, for the full data, the first hip prosthesis had an increased risk of revision compared to prostheses in patients with only one prosthesis (RR = 1.25, p=0.01). For the 'homogeneous' data no statistically significant difference was found between unilateral and bilateral prostheses. A revision in one hip, for patients with bilateral prostheses, is a risk factor for revision of the other hip. Thus, in analyses of prostheses survival, dependencies between two hip prostheses from one patient should be considered. However, ignoring possible dependencies does not necessarily have an impact on the results on standard risk factors. Copyright \&\#xa9; 2004 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZPQMVRIQ\\lie_et_al_2004_dependency_issues_in_survival_analyses_of_55_782_primary_hip_replacements_from.pdf},
  journal = {Statistics in Medicine},
  keywords = {Bilateral,Frailty,Hip,Marginal,Prostheses,Survival},
  number = {20}
}

@article{Lieffers2011,
  title = {A Comparison of Charlson and Elixhauser Comorbidity Measures to Predict Colorectal Cancer Survival Using Administrative Health Data},
  author = {Lieffers, Jessica R. and Baracos, Vickie E. and Winget, Marcy and Fassbender, Konrad},
  year = {2011},
  month = may,
  volume = {117},
  pages = {1957--1965},
  publisher = {{Wiley Subscription Services, Inc., A Wiley Company}},
  issn = {0008543X},
  doi = {10.1002/cncr.25653},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4356XG2L\\lieffers_et_al_2011_a_comparison_of_charlson_and_elixhauser_comorbidity_measures_to_predict.pdf},
  journal = {Cancer},
  keywords = {administrative health data,Charlson comorbidity index,colorectal cancer,comorbidity,Elixhauser comorbidity method,risk adjustment,survival},
  number = {9}
}

@article{Lijmer2002,
  title = {Exploring Sources of Heterogeneity in Systematic Reviews of Diagnostic Tests},
  author = {Lijmer, Jeroen G. and Bossuyt, Patrick M. M. and Heisterkamp, Siem H.},
  year = {2002},
  volume = {21},
  pages = {1525--1537},
  issn = {1097-0258},
  doi = {10.1002/sim.1185},
  abstract = {It is indispensable for any meta-analysis that potential sources of heterogeneity are examined, before one considers pooling the results of primary studies into summary estimates with enhanced precision. In reviews of studies on the diagnostic accuracy of tests, variability beyond chance can be attributed to between-study differences in the selected cutpoint for positivity, in patient selection and clinical setting, in the type of test used, in the type of reference standard, or any combination of these factors. In addition, heterogeneity in study results can also be caused by flaws in study design. This paper critically examines some of the potential reasons for heterogeneity and the methods to explore them. Empirical support for the existence of different sources of variation is reviewed. Incorporation of sources of variability explicitly into systematic reviews on diagnostic accuracy is demonstrated with data from a recent review. Application of regression techniques in meta-analysis of diagnostic tests can provide relevant additional information. Results of such analyses will help understand problems with the transferability of diagnostic tests and to point out flaws in primary studies. As such, they can guide the design of future studies. Copyright \textcopyright{} 2002 John Wiley \& Sons, Ltd.},
  copyright = {Copyright \textcopyright{} 2002 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AJ8BXP58\\Lijmer m. fl. - 2002 - Exploring sources of heterogeneity in systematic r.pdf;C\:\\Users\\erik_\\Zotero\\storage\\VW343PKV\\sim.html},
  journal = {Statistics in Medicine},
  keywords = {acta review,diagnostic accuracy,diagnostic tests,meta-analysis,systematic review},
  language = {en},
  number = {11}
}

@book{Lin2007,
  title = {Stochastic Analysis of File-Swarming Systems},
  author = {Lin, Minghong and Fan, Bin and Lui, John C S and Chiu, Dah Ming},
  year = {2007},
  volume = {64},
  issn = {01665316},
  doi = {10.1016/j.peva.2007.06.006},
  abstract = {File swarming (or file sharing) is one of the most important applications in P2P networks. In this paper, we propose a stochastic framework to analyze a file-swarming system under realistic setting: constraints in upload/download capacity, collaboration among peers and incentive for chunk exchange. We first extend the results in the coupon system [L. Massoulie, M. Vojnovic, Coupon replication systems, in: Proc. ACM SIGMETRICS, Banff, Alberta, Canada, 2005] by providing a tighter performance bound. Then we generalize the coupon system by considering peers with limited upload and download capacity. We illustrate the last-piece problem and show the effectiveness of using forward error-correction (FEC) code and/or multiple requests to improve the performance. Lastly, we propose a framework to analyze an incentive-based file-swarming system. The stochastic framework we propose can serve as a basis for other researchers to analyze and design more advanced features of file-swarming systems. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\438UCRUX\\lin_et_al_2007_stochastic_analysis_of_file-swarming_systems.pdf},
  isbn = {978-0-387-78188-4},
  keywords = {BitTorrent,P2P file sharing,Performance modeling},
  pmid = {10911016}
}

@article{Lind2002,
  title = {Receiver Operating Characteristic Curves to Assess Predictors of Radiation-Induced Symptomatic Lung Injury},
  author = {Lind, Pehr A. and Marks, Lawrence B. and Hollis, Donna and Fan, Ming and Zhou, Su Min and Munley, Michael T. and Shafman, Timothy D. and Jaszczak, Ronald J. and Coleman, R. Edward},
  year = {2002},
  volume = {54},
  pages = {340--347},
  issn = {03603016},
  doi = {10.1016/S0360-3016(02)02932-2},
  abstract = {Purpose: To assess the utility of dosimetric/functional metrics as predictors of symptomatic radiation pneumonitis using receiver operating characteristic curves. Methods: Between 1991 and 1999, 277 patients were enrolled on a prospective clinical study to relate radiation therapy (RT) induced changes in lung function with dosimetric and functional metrics. Pre-RT whole and regional functional assessments included pulmonary function tests and single photon emission computed tomography lung perfusion scans. Patients had three-dimensional planning scans and dose calculations (reflecting tissue density heterogeneity) to provide a dose-volume histogram of the lung and associated dosimetric parameters (MLD = mean lung dose, V30 = \% of lung receiving {$\geq$}30 Gy). Fusion of single photon emission computed tomography and computed tomography scans provides perfusion-weighted dose-function histograms and associated dosimetric parameters (mean perfusion-weighted lung dose). The incidence of clinically relevant radiation pneumonitis requiring steroids was related to the dosimetric and functional metrics. The predictive abilities of models (sensitivity and specificity) were calculated and compared based on the area beneath receiver operating characteristic (ROC) curves (Wilcoxon rank-sum and chi-square). Results: Twenty-seven of 162 evaluable patients with {$\geq$}6 months' follow-up developed pneumonitis requiring steroids. Single metrics were typically not good predictors for pneumonitis ( area under ROC curve = 0.5-0.68). The two-dimensional models (e.g., MLD and pre-RT diffusion capacity for carbon monoxide) generally provided greater ROC areas (0.61-0.72). Overall, the models that considered a measure of pre-RT lung function (i.e., pulmonary function tests), the MLD, and mean perfusion-weighted lung dose were best correlated with outcome (ROC area: 0.7) (p \textexclamdown{} 0.05 compared to unidimensional models). However, because the area under the ROC curve for these models was \textexclamdown\textexclamdown 1, they too seemed not to be ideal. Conclusion: Predicting symptomatic radiation pneumonitis remains difficult. Multiparameter models that consider pre-RT pulmonary function and the three-dimensional dose distribution seem to be best able to predict outcome. Additional studies are needed to better understand the dosimetric/functional determinants of radiation pneumonitis. \textcopyright{} 2002 Elsevier Science Inc.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8SJ2ZHIK\\lind_et_al_2002_receiver_operating_characteristic_curves_to_assess_predictors_of.pdf},
  isbn = {0360-3016},
  journal = {International Journal of Radiation Oncology Biology Physics},
  keywords = {Predictive models,Pulmonary function tests,Radiation pneumonitis,Receiver operating characteristic curves,Three-dimensional planning},
  number = {2},
  pmid = {12243806}
}

@article{Loacker2015,
  ids = {Loacker2016},
  title = {'{{Moving}} to Stay in the Same Place?' {{Academics}} and Theatrical Artists as Exemplars of the 'Mobile Middle'},
  author = {Loacker, B. and Sliwa, M.},
  year = {2015},
  pages = {1--23},
  issn = {1350-5084},
  doi = {10.1177/1350508415598247},
  abstract = {This article provides insights into mobility in the context of geographical, economic, professional, temporal and imaginary movements of academics and theatrical artists. It explores how these dimensions of mobility intersect in the narratives of academics and theatrical artists, thereby producing a position `in between' choice and necessity, and privilege and disadvantage with regard to movement. The analysis shows how both academics and theatrical artists engage in mobility to secure, maintain or improve their professional and economic position. On this basis, we suggest that they are part of an emerging category of professionals: the `mobile middle', for whom mobility is a crucial part and principle of life. We argue that the phenomenon of the `mobile middle' and mobility in general have wide-ranging implications for our understanding of contemporary careers, work and life organisation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HPYA8EU3\\loacker_sliwa_2015_'moving_to_stay_in_the_same_place.pdf},
  journal = {Organization},
  keywords = {academics,Academics,careers,mobile middle,mobility dimensions,theatrical artists,work and life,work and life organisation}
}

@article{Lobo2008,
  title = {{{AUC}}: {{A}} Misleading Measure of the Performance of Predictive Distribution Models},
  author = {Lobo, Jorge M. and {Jim{\'e}nez-valverde}, Alberto and Real, Raimundo},
  year = {2008},
  volume = {17},
  pages = {145--151},
  issn = {1466822X},
  doi = {10.1111/j.1466-8238.2007.00358.x},
  abstract = {The area under the receiver operating characteristic (ROC) curve, known as the AUC, is currently considered to be the standard method to assess the accuracy of predictive distribution models. It avoids the supposed subjectivity in the threshold selection process, when continuous probability derived scores are converted to a binary presence\textendash absence variable, by summarizing overall model performance over all possible thresholds. In this manuscript we review some of the features of this measure and bring into question its reliability as a comparative measure of accuracy between model results. We do not recommend using AUC for five reasons: (1) it ignores the predicted probability values and the goodness-of-fit of the model; (2) it summarises the test performance over regions of the ROC space in which one would rarely operate; (3) it weights omission and commission errors equally; (4) it does not give information about the spatial distribution of model errors; and, most importantly, (5) the total extent to which models are carried out highly influences the rate of well-predicted absences and the AUC scores.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6AMRDX4H\\lobo_et_al_2008_auc.pdf},
  isbn = {1466-8238},
  journal = {Global Ecology and Biogeography},
  keywords = {AUC,Distribution models,Ecological statistics,Goodness-of-fit,Model accuracy,ROC curve},
  number = {2},
  pmid = {19857948}
}

@generic{lofvenNyDataskyddslagProp2018,
  title = {Ny Dataskyddslag, {{Prop}}. 2017/18:105},
  author = {L{\"o}fven, Stefan and Johansson, Morgan},
  year = {2018},
  abstract = {Propositionens huvudsakliga inneh\aa ll Regeringen f\"oresl\aa r att personuppgiftslagen upph\"avs och att en ny lag med kompletterande best\"ammelser till EU:s dataskyddsf\"orordning inf\"ors. Vidare f\"oresl\aa s att vissa best\"ammelser i offentlighets-och sekretesslagen \"andras. Den f\"oreslagna lagen inneh\aa ller bl.a. best\"ammelser om att dataskydds-f\"orordningen med vissa undantag ska g\"alla \"aven utanf\"or sitt egentliga till\"ampningsomr\aa de, t.ex. i verksamhet som r\"or nationell s\"akerhet. Lagen ska dock vara subsidi\"ar i f\"orh\aa llande till annan lag eller f\"orordning, vilket m\"ojligg\"or avvikande best\"ammelser i s.k. registerf\"orfattningar. Lagf\"orslaget f\"ortydligar under vilka f\"oruts\"attningar personuppgifter f\aa r behandlas med st\"od av dataskyddsf\"orordningen. Regeringen f\"oresl\aa r bl.a. att ett barn som \"ar minst 13 \aa r ska kunna samtycka till behandling av personuppgifter i samband med anv\"andning av informationssamh\"allets tj\"anster, t.ex. sociala medier. Vidare f\"oresl\aa s att sanktionsavgifter ska kunna tas ut \"aven d\aa{} en myndighet bryter mot dataskyddsf\"orordningen. F\"orslaget till ny lag inneh\aa ller ocks\aa{} vissa best\"ammelser om begr\"ansning av de registrerades r\"attigheter samt om skadest\aa nd och \"overklagande av bl.a. tillsynsmyndighetens beslut. Slutligen anges att dataskyddsf\"orordningen och den nya lagen inte ska till\"ampas i den utstr\"ackning det strider mot tryckfrihetsf\"orordningen eller yttrandefrihetsgrundlagen. Lag\"andringarna f\"oresl\aa s tr\"ada i kraft den 25 maj 2018.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\U6SSPS5G\\löfven_johansson_2018_ny_dataskyddslag,_prop.pdf}
}

@article{lofvenRegeringensPropositionBehandling2018,
  title = {Regeringens Proposition Behandling Av Personuppgifter F\"or Forsknings\"andam\aa l Inneh\aa llsf\"orteckning},
  author = {L{\"o}fven, Stefan},
  year = {2018},
  pages = {1--338},
  keywords = {\#nosource}
}

@article{lopez-de-andresPredictorsInhospitalMortality2016,
  title = {Predictors of In-Hospital Mortality Following Major Lower Extremity Amputations in Type 2 Diabetic Patients Using Artificial Neural Networks},
  author = {{Lopez-de-Andres}, Ana and {Hernandez-Barrera}, Valentin and Lopez, Roberto and {Martin-Junco}, Pablo and {Jimenez-Trujillo}, Isabel and {Alvaro-Meca}, Alejandro and {Salinero-Fort}, Miguel Angel and {Jimenez-Garcia}, Rodrigo},
  year = {2016},
  volume = {16},
  pages = {160},
  publisher = {{BMC Medical Research Methodology}},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0265-5},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6EM3BZY9\\lopez-de-andres_et_al_2016_predictors_of_in-hospital_mortality_following_major_lower_extremity_amputations.pdf},
  journal = {BMC Medical Research Methodology},
  keywords = {ana,artificial neural networks,C,charlson comorbidity index,correspondence,elixhauser comorbidity,es,in-hospital mortality,index,lopez,major lower extremity amputation,Major lower extremity amputation,type 2 diabetes,Type 2 diabetes,urjc},
  number = {1}
}

@article{ludeckeGgeffectsCreateTidy2018,
  title = {Ggeffects: {{Create}} Tidy Data Frames of Marginal Effects for 'ggplot' from Model Outputs},
  author = {L{\"u}decke, D.},
  year = {2018},
  volume = {3},
  pages = {1--5},
  issn = {2475-9066},
  doi = {10.21105/joss.00772},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CI46RTKG\\lüdecke_2018_ggeffects.pdf},
  journal = {The Journal of open source software}
}

@article{Ludvigsson2009,
  title = {The {{Swedish}} Personal Identity Number: {{Possibilities}} and Pitfalls in Healthcare and Medical Research},
  author = {Ludvigsson, Jonas F. and {Otterblad-Olausson}, Petra and Pettersson, Birgitta U. and Ekbom, Anders},
  year = {2009},
  volume = {24},
  pages = {659--667},
  issn = {03932990},
  doi = {10.1007/s10654-009-9350-y},
  abstract = {Swedish health care and national health registers are dependent on the presence of a unique identifier. This paper describes the Swedish personal identity number (PIN) and explores ethical issues of its use in medical research. A ten-digit-PIN is maintained by the National Tax Board for all individuals that have resided in Sweden since 1947. Until January 2008, an estimated 75,638 individuals have changed PIN. The most common reasons for change of PIN are incorrect recording of date of birth or sex among immigrants or newborns. Although uncommon, change of sex always leads to change of PIN since the PIN is sex-specific. The most common reasons for re-use of PIN (n = 15,887), is when immigrants are assigned a PIN that has previously been assigned to someone else. This is sometimes necessary since there is a shortage of certain PIN combinations referring to dates of birth in the 1950s and 1960s. Several ethical issues can be raised pro and con the use of PIN in medical research. The Swedish PIN is a useful tool for linkages between medical registers and allows for virtually 100\% coverage of the Swedish health care system. We suggest that matching of registers through PIN and matching of national health registers without the explicit approval of the individual patient is to the benefit for both the individual patient and for society.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XNJL8I7D\\ludvigsson_et_al_2009_the_swedish_personal_identity_number.pdf},
  isbn = {1065400993},
  journal = {European Journal of Epidemiology},
  keywords = {Civil registration number,Identification,Personal identity number,Pin,Population,Review,Sweden},
  number = {11},
  pmid = {19504049}
}

@article{Ludvigsson2011,
  title = {External Review and Validation of the {{Swedish}} National Inpatient Register},
  author = {Ludvigsson, Jonas F and Andersson, Eva and Ekbom, Anders and Feychting, Maria and Kim, Jeong-Lim and Reuterwall, Christina and Heurgren, Mona and Olausson, Petra Otterblad},
  year = {2011},
  month = dec,
  volume = {11},
  pages = {450},
  issn = {1471-2458},
  doi = {10.1186/1471-2458-11-450},
  abstract = {BACKGROUND: The Swedish National Inpatient Register (IPR), also called the Hospital Discharge Register, is a principal source of data for numerous research projects. The IPR is part of the National Patient Register. The Swedish IPR was launched in 1964 (psychiatric diagnoses from 1973) but complete coverage did not begin until 1987. Currently, more than 99\% of all somatic (including surgery) and psychiatric hospital discharges are registered in the IPR. A previous validation of the IPR by the National Board of Health and Welfare showed that 85-95\% of all diagnoses in the IPR are valid. The current paper describes the history, structure, coverage and quality of the Swedish IPR.AND RESULTS: In January 2010, we searched the medical databases, Medline and HighWire, using the search algorithm "validat* (inpatient or hospital discharge) Sweden". We also contacted 218 members of the Swedish Society of Epidemiology and an additional 201 medical researchers to identify papers that had validated the IPR. In total, 132 papers were reviewed. The positive predictive value (PPV) was found to differ between diagnoses in the IPR, but is generally 85-95\%.: In conclusion, the validity of the Swedish IPR is high for many but not all diagnoses. The long follow-up makes the register particularly suitable for large-scale population-based research, but for certain research areas the use of other health registers, such as the Swedish Cancer Register, may be more suitable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MDXZE8GX\\ludvigsson_et_al_2011_external_review_and_validation_of_the_swedish_national_inpatient_register.pdf},
  isbn = {1471-2458 (Electronic)1471-2458 (Linking)},
  journal = {BMC Public Health},
  keywords = {Adult,Aged,Disease,Disease: classification,Epidemiology,Female,Humans,Inpatients,Inpatients: statistics \& numerical data,Male,Middle Aged,Morbidity,Registries,Registries: standards,Sweden,Sweden: epidemiology,Young Adult},
  number = {1},
  pmid = {21658213}
}

@article{Ludvigsson2016,
  title = {Registers of the {{Swedish}} Total Population and Their Use in Medical Research},
  author = {Ludvigsson, Jonas F. and Almqvist, Catarina and Bonamy, Anna Karin Edstedt and Ljung, Rickard and Micha{\"e}lsson, Karl and Neovius, Martin and Stephansson, Olof and Ye, Weimin},
  year = {2016},
  pages = {1--12},
  issn = {15737284},
  doi = {10.1007/s10654-016-0117-y},
  abstract = {The primary aim of the Swedish national population registration system is to obtain data that (1) reflect the composition, relationship and identities of the Swedish population and (2) can be used as the basis for correct decisions and measures by government and other regulatory authorities. For this purpose, Sweden has established two population registers: (1) The Population Register, maintained by the Swedish National Tax Agency ("Folkbokf\"oringsregistret"); and (2) The Total Population Register (TPR) maintained by the government agency Statistics Sweden ("Registret \"over totalbefolkningen"). The registers contain data on life events including birth, death, name change, marital status, family relationships and migration within Sweden as well as to and from other countries. Updates are transmitted daily from the Tax Agency to the TPR. In this paper we describe the two population registers and analyse their strengths and weaknesses. Virtually 100 \% of births and deaths, 95 \% of immigrations and 91 \% of emigrations are reported to the Population Registers within 30 days and with a higher proportion over time. The over-coverage of the TPR, which is primarily due to underreported emigration data, has been estimated at up to 0.5 \% of the Swedish population. Through the personal identity number, assigned to all residents staying at least 1 year in Sweden, data from the TPR can be used for medical research purposes, including family design studies since each individual can be linked to his or her parents, siblings and offspring. The TPR also allows for identification of general population controls, participants in cohort studies, as well as calculation of follow-up time.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZN9YD2XM\\ludvigsson_et_al_2016_registers_of_the_swedish_total_population_and_their_use_in_medical_research.pdf},
  journal = {European Journal of Epidemiology},
  keywords = {Population,Public health,Register,Registry},
  pmid = {26769609}
}

@article{Ludvigsson2019,
  title = {The Longitudinal Integrated Database for Health Insurance and Labour Market Studies ({{LISA}}) and Its Use in Medical Research},
  author = {Ludvigsson, Jonas F. and Svedberg, Pia and Ol{\'e}n, Ola and Bruze, Gustaf and Neovius, Martin},
  year = {2019},
  month = apr,
  volume = {34},
  pages = {423--437},
  publisher = {{Springer Netherlands}},
  issn = {0393-2990},
  doi = {10.1007/s10654-019-00511-8},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9Y73VK73\\ludvigsson_et_al_2019_the_longitudinal_integrated_database_for_health_insurance_and_labour_market.pdf},
  journal = {European Journal of Epidemiology},
  number = {4}
}

@article{Lukacs2010,
  title = {Model Selection Bias and {{Freedman}}'s Paradox},
  author = {Lukacs, Paul M. and Burnham, Kenneth P. and Anderson, David R.},
  year = {2010},
  month = feb,
  volume = {62},
  pages = {117--125},
  publisher = {{Springer-Verlag}},
  issn = {0020-3157},
  doi = {10.1007/s10463-009-0234-4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4VXXGJRP\\lukacs_et_al_2010_model_selection_bias_and_freedman’s_paradox.pdf},
  journal = {Annals of the Institute of Statistical Mathematics},
  number = {1}
}

@article{Lunardon2014,
  title = {{{ROSE}}: {{A}} Package for Binary Imbalanced Learning},
  author = {Lunardon, Nicola and Menardi, Giovanna and Torelli, Nicola},
  year = {2014},
  volume = {6},
  abstract = {The ROSE package provides functions to deal with binary classification problems in the presence of imbalanced classes. Artificial balanced samples are generated according to a smoothed bootstrap approach and allow for aiding both the phases of estimation and accuracy evaluation of a binary classifier in the presence of a rare class. Functions that implement more traditional remedies for the class imbalance and different metrics to evaluate accuracy are also provided. These are estimated by holdout, bootstrap, or cross-validation methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WFPRH4V3\\lunardon_et_al_2014_rose.pdf},
  journal = {The R Journal},
  number = {1}
}

@book{lundenSamfalligheter2017,
  title = {Samf\"alligheter},
  author = {Lund{\'e}n, Bj{\"o}rn},
  year = {2017},
  keywords = {\#nosource}
}

@article{Luo2007,
  title = {Oral Use of {{Swedish}} Moist Snuff (Snus) and Risk for Cancer of the Mouth, Lung, and Pancreas in Male Construction Workers: A Retrospective Cohort Study},
  author = {Luo, Juhua and Ye, Weimin and Zendehdel, Kazem and Adami, Johanna and Adami, Hans Olov and Boffetta, Paolo and Nyr{\'e}n, Olof},
  year = {2007},
  volume = {369},
  pages = {2015--2020},
  issn = {01406736},
  doi = {10.1016/S0140-6736(07)60678-3},
  abstract = {Background: Although classified as carcinogenic, snuff is used increasingly in several populations. Scandinavian moist snuff (snus) has been proposed as a less harmful alternative to smoking, but precise data on the independent associations of snus use with site-specific cancers are sparse. We aimed to assess the risks for cancer of the oral cavity, lung, and pancreas. Methods: Detailed information about tobacco smoking and snus use was obtained from 279 897 male Swedish construction workers in 1978-92. Complete follow-up until end of 2004 was accomplished through links with population and health registers. To distinguish possible effects of snus from those of smoking, we focused on 125 576 workers who were reported to be never-smokers at entry. Adjusted relative risks were derived from Cox proportional hazards regression models. Findings: 60 cases of oral, 154 of lung, and 83 of pancreatic cancer were recorded in never-smokers. Snus use was independently associated with increased risk of pancreatic cancer (relative risk for ever-users of snus 2{$\cdot$}0; 95\% CI 1{$\cdot$}2-3{$\cdot$}3, compared with never-users of any tobacco), but was unrelated to incidence of oral (0{$\cdot$}8, 95\% CI 0{$\cdot$}4-1{$\cdot$}7) and lung cancer (0{$\cdot$}8, 0{$\cdot$}5-1{$\cdot$}3). Interpretation: Use of Swedish snus should be added to the list of tentative risk factors for pancreatic cancer. We were unable to confirm any excess of oral or lung cancer in snus users. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B2I4KSNZ\\luo_et_al_2007_oral_use_of_swedish_moist_snuff_(snus)_and_risk_for_cancer_of_the_mouth,_lung,.pdf},
  isbn = {1474-547X (Electronic)},
  journal = {Lancet},
  number = {9578},
  pmid = {17498797}
}

@article{Lutter2016,
  title = {Who Becomes a Tenured Professor, and Why? {{Panel}} Data Evidence from {{German}} Sociology, 1980-2013},
  author = {Lutter, Mark and Schr{\"o}der, Martin},
  year = {2016},
  volume = {45},
  pages = {999--1013},
  publisher = {{Elsevier B.V.}},
  issn = {00487333},
  doi = {10.1016/j.respol.2016.01.019},
  abstract = {Prior studies that try to explain who gets tenure and why remain inconclusive, especially on whether non-meritocratic factors influence who becomes a professor. Based on career and publication data of virtually all sociologists working in German sociology departments, we test how meritocratic factors (academic productivity) as well as non-meritocratic factors (ascription, symbolic and social capital) influence the chances of getting a permanent professorship in sociology. Our findings show that getting tenure in sociology is strongly related to scholarly output, as previous studies have shown. Improving on existing studies, however, we show specifically that each refereed journal article and each monograph increases a sociologist's chance for tenure by 10 to 15 percent, while other publications affect odds for tenure only marginally and in some cases even negatively. Regarding non-meritocratic factors, we show that network size, individual reputation, and gender matters. Women get their first permanent position as university professor with on average 23 to 44 percent fewer publications than men; all else being equal, they are about 1.4 times more likely to get tenure than men. The article generally contributes to a better understanding of the role of meritocratic and non-meritocratic factors in achieving scarce and highly competitive job positions in academia.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\M26PH4XP\\lutter_schröder_2016_who_becomes_a_tenured_professor,_and_why.pdf},
  isbn = {0048-7333},
  journal = {Research Policy},
  keywords = {Academic careers,Gender,Human capital,Social capital,Symbolic capital,Tenure},
  number = {5}
}

@article{Lystad2018,
  title = {``{{Death}} Is Certain, the Time Is Not'': Mortality and Survival in {{Game}} of {{Thrones}}},
  author = {Lystad, Reidar P. and Brown, Benjamin T.},
  year = {2018},
  volume = {5},
  pages = {44},
  issn = {2197-1714},
  doi = {10.1186/S40621-018-0174-7},
  abstract = {Game of Thrones is a popular television series known for its violent and graphic portrayal of the deaths of its characters. This study aimed to examine the mortality and survival of important characters in Game of Thrones. Important characters appearing in Seasons 1 to 7 of Game of Thrones were included, and data on sociodemographic factors, time to death, and circumstances of death were recorded. Kaplan-Meier survival analysis with Cox proportional hazard regression modelling were used to quantify survival times and probabilities and to identify independent predictors of mortality, respectively. Of the 330 characters that were included, 186 (56.4\%) had died by the end of the study period. All but 2 deaths were due to injury, burns, or poisoning, with the majority being caused by assault (63.0\%) or operations of war (24.4\%). The survival time ranged from 11\^A s to 57\^A h and 15\^A min, with the median survival time estimated to be 28\^A h and 48\^A min. The probability of surviving at least 1\^A h in the show was 0.86 (95\% CI 0.82 to 0.89). The analyses revealed worse survival for characters who were male (P \textexclamdown{} 0.001), lowborn (P \textexclamdown{} 0.001), had not switched allegiance during the show (P \textexclamdown{} 0.001), and who featured more prominently in the show (P \textexclamdown{} 0.001). After adjusting for other factors, whether or not a character had switched allegiance during the show and how prominently a character featured in the show were revealed to be independent predictors of death. The mortality risk is high among characters in Game of Thrones. The probability of dying within the first hour after first appearing on screen was about 14\%. By the end of the seventh season, more than half of the important characters had died, with violent deaths being the most common by far. The probability of survival was worse for characters who were male or lowborn, who had not switched allegiance during the show, and who featured more prominently. There is great potential for preventing violent deaths in the world of Game of Thrones.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EFLPQUS4\\lystad_brown_2018_“death_is_certain,_the_time_is_not”.pdf},
  journal = {Injury Epidemiology 2018 5:1},
  number = {1}
}

@article{Maas2005,
  title = {Sufficient Sample Sizes for Multilevel Modeling. [{{References}}].},
  author = {Maas, Cora J. and Hox, Joop},
  year = {2005},
  volume = {1},
  pages = {86--92},
  issn = {1614-1881},
  doi = {10.1027/1614-1881.1.3.86},
  abstract = {An important problem in multilevel modeling is what constitutes a sufficient sample size for accurate estimation. In multilevel analysis, the major restriction is often the higher-level sample size. In this paper, a simulation study is used to determine the influence of different sample sizes at the group level on the accuracy of the estimates (regression coefficients and variances) and their standard errors. In addition, the influence of other factors, such as the lowest-level sample size and different variance distributions between the levels (different intraclass correlations), is examined. The results show that only a small sample size at level two (meaning a sample of 50 or less) leads to biased estimates of the second-level standard errors. In all of the other simulated conditions the estimates of the regression coefficients, the variance components, and the standard errors are unbiased and accurate. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract).},
  isbn = {1614-1881},
  journal = {Journal of Research Methods for the Behavioral and Social Sciences},
  keywords = {\#nosource,cluster sampling,hierarchical linear model,multilevel modeling,sample size}
}

@article{Maddams2012,
  title = {Projections of Cancer Prevalence in the {{United Kingdom}}, 2010\textendash 2040},
  author = {Maddams, J and Utley, M and M\o ller, H},
  year = {2012},
  month = sep,
  volume = {107},
  pages = {1195--1202},
  issn = {0007-0920},
  doi = {10.1038/bjc.2012.366},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\97BPJKVG\\maddams_et_al_2012_projections_of_cancer_prevalence_in_the_united_kingdom,_2010–2040.pdf},
  journal = {British Journal of Cancer},
  number = {7}
}

@article{Madigan2014,
  title = {A Systematic Statistical Approach to Evaluating Evidence from Observational Studies},
  author = {Madigan, David and Stang, Paul E. and Berlin, Jesse A. and Schuemie, Martijn and Overhage, J. Marc and Suchard, Marc A. and Dumouchel, Bill and Hartzema, Abraham G. and Ryan, Patrick B.},
  year = {2014},
  month = jan,
  volume = {1},
  pages = {11--39},
  publisher = {{Annual Reviews}},
  doi = {10.1146/annurev-statistics-022513-115645},
  abstract = {Threats to the validity of observational studies on the effects of interventions raise questions about the appropriate role of such studies in decision making. Nonetheless, scholarly journals in fields such as medicine, education, and the social sciences feature many such studies, often with limited exploration of these threats, and the lay press is rife with news stories based on these studies. Consumers of these studies rely on the expertise of the study authors to conduct appropriate analyses, and on the thoroughness of the scientific peer-review process to check the validity, but the introspective and ad hoc nature of the design of these analyses appears to elude any meaningful objective assessment of their performance. Here, we review some of the challenges encountered in observational studies and review an alternative, data-driven approach to observational study design, execution, and analysis. Although much work remains, we believe this research direction shows promise.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XRAJFTQL\\madigan_et_al_2014_a_systematic_statistical_approach_to_evaluating_evidence_from_observational.pdf},
  journal = {Annual Review of Statistics and Its Application},
  number = {1}
}

@article{Magneli2019,
  title = {Validation of Adverse Events after Hip Arthroplasty: A {{Swedish}} Multi-Centre Cohort Study.},
  author = {Magn{\'e}li, Martin and Unbeck, Maria and Rogmark, Cecilia and Rolfson, Ola and Hommel, Ami and Samuelsson, Bodil and Schildmeijer, Kristina and Sj{\"o}strand, Desir{\'e}e and Gordon, Max and Sk{\"o}ldenberg, Olof},
  year = {2019},
  month = mar,
  volume = {9},
  pages = {e023773},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2018-023773},
  abstract = {OBJECTIVES Preventing adverse events (AEs) after orthopaedic surgery is a field with great room for improvement. A Swedish instrument for measuring AEs after hip arthroplasty based on administrative data from the national patient register is used by both the Swedish Hip Arthroplasty Register and the Swedish Association of Local Authorities and Regions. It has never been validated and its accuracy is unknown. The aim of this study was to validate the instrument's ability to detect AEs, and to calculate the incidence of AEs following primary hip arthroplasties. DESIGN Retrospective cohort study using retrospective record review with Global Trigger Tool methodology in combination with register data. SETTING 24 different hospitals in four major regions of Sweden. PARTICIPANTS 2000 patients with either total or hemi-hip arthroplasty were recruited from the SHAR. We included both acute and elective patients. PRIMARY AND SECONDARY OUTCOME MEASURES The sensitivity and specificity of the instrument. Adjusted cumulative incidence and incidence rate. RESULTS The sensitivity for all identified AEs was 5.7\% (95\% CI: 4.9\% to 6.7\%) for 30 days and 14.8\% (95\% CI: 8.2 to 24.3) for 90 days, and the specificity was 95.2\% (95\% CI: 93.5\% to 96.6\%) for 30 days and 92.1\% (95\% CI: 89.9\% to 93.8\%) for 90 days. The adjusted cumulative incidence for all AEs was 28.4\% (95\% CI: 25.0\% to 32.3\%) for 30 days and 29.5\% (95\% CI: 26.0\% to 33.8\%) for 90 days. The incidence rate was 0.43 AEs per person-month (95\% CI: 0.39 to 0.47). CONCLUSIONS The AE incidence was high, and most AEs occurred within the first 30 days. The instrument sensitivity for AEs was very low for both 30 and 90 days, but the specificity was high for both 30 and 90 days. The studied instrument is insufficient for valid measurements of AEs after hip arthroplasty.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\W4LN6M8E\\magnéli_et_al_2019_validation_of_adverse_events_after_hip_arthroplasty.pdf},
  journal = {BMJ open},
  keywords = {adverse events,global trigger tool,hip arthroplasty,orthopaedics,validation},
  number = {3},
  pmid = {30850403}
}

@article{Magone2017,
  title = {The New Surgical Technique for Improving Total Knee and Hip Arthroplasty Outcomes: {{Patient}} Selection},
  author = {Magone, K. and Kemker, B. and Pilipenko, N. and O'Connor, Erin and Walter, N. and Atkinson, T. and Blyth, M. and Leach, W.J.},
  year = {2017},
  month = mar,
  volume = {1},
  pages = {17},
  publisher = {{Elsevier}},
  issn = {08835403},
  doi = {10.1016/j.arth.2017.02.034},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BUZUTYZ3\\magone_et_al_2017_the_new_surgical_technique_for_improving_total_knee_and_hip_arthroplasty.pdf},
  journal = {The Journal of Arthroplasty},
  keywords = {Outcomes,Patient Satisfaction,Quality of Life,sf36,THA,TKA},
  number = {0}
}

@book{Maindonald2012,
  title = {Data Mining with Rattle and r: {{The}} Art of Excavating Data for Knowledge Discovery by Graham Williams},
  author = {Maindonald, John H.},
  year = {2012},
  volume = {80},
  issn = {03067734},
  doi = {10.1111/j.1751-5823.2012.00179_23.x},
  abstract = {Data mining is the art and science of intelligent data analysis. By building knowledge from information, data mining adds considerable value to the ever increasing stores of electronic data that abound today. In performing data mining many decisions need to be made regarding the choice of methodology, the choice of data, the choice of tools, and the choice of algorithms.Throughout this book the reader is introduced to the basic concepts and some of the more popular algorithms of data mining. With a focus on the hands-on end-to-end process for data mining, Williams guides the reader through various capabilities of the easy to use, free, and open source Rattle Data Mining Software built on the sophisticated R Statistical Software. The focus on doing data mining rather than just reading about data mining is refreshing.The book covers data understanding, data preparation, data refinement, model building, model evaluation, and practical deployment. The reader will learn to rapidly deliver a data mining project using software easily installed for free from the Internet. Coupling Rattle with R delivers a very sophisticated data mining environment with all the power, and more, of the many commercial offerings.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5AXLER2I\\maindonald_2012_data_mining_with_rattle_and_r.pdf},
  isbn = {978-1-4419-9889-7},
  pmid = {22057480}
}

@article{Mair2007,
  title = {Extended Rasch Modeling: {{The}} r Package {{eRm}}},
  author = {Mair, Patrik and Hatzinger, Reinhold and Maier, Marco J.},
  year = {2007},
  volume = {20},
  pages = {1--20},
  abstract = {Item response theory models (IRT) are increasingly becoming established in social science research, particularly in the analysis of performance or attitudinal data in psy- chology, education, medicine, marketing and other fields where testing is relevant. We propose the R package eRm (extended Rasch modeling) for computing Rasch models and several extensions. A main characteristic of some IRT models, the Rasch model being the most prominent, concerns the separation of two kinds of parameters, one that describes qualities of the subject under investigation, and the other relates to qualities of the situation under which the response of a subject is observed. Using conditional maximum likelihood (CML) estimation both types of parameters may be estimated independently from each other. IRT models are well suited to cope with dichotomous and polytomous responses, where the response categories may be unordered as well as ordered. The incorporation of linear structures allows for modeling the effects of covariates and enables the analysis of repeated categorical measurements. The eRm package fits the following models: the Rasch model, the rating scale model (RSM), and the partial credit model (PCM) as well as linear reparameterizations through covariate structures like the linear logistic test model (LLTM), the linear rating scale model (LRSM), and the linear partial credit model (LPCM). We use an unitary, efficient CML approach to estimate the item parameters and their standard errors. Graphical and numeric tools for assessing goodness-of-fit are provided. Keywords:},
  journal = {Journal of Statistical Software},
  keywords = {\#nosource,Scoring,SIN Project},
  number = {9}
}

@inproceedings{Makoul2006,
  title = {An Integrative Model of Shared Decision Making in Medical Encounters},
  author = {Makoul, Gregory and Clayman, Marla L.},
  year = {2006},
  volume = {60},
  pages = {301--312},
  issn = {07383991},
  doi = {10.1016/j.pec.2005.06.010},
  abstract = {Objective: Given the fluidity with which the term shared decision making (SDM) is used in teaching, assessment and research, we conducted a focused and systematic review of articles that specifically address SDM to determine the range of conceptual definitions. Methods: In April 2005, we ran a Pubmed (Medline) search to identify articles published through 31 December 2003 with the words shared decision making in the title or abstract. The search yielded 681 citations, 342 of which were about SDM in the context of physician-patient encounters and published in English. We read and reviewed the full text of all 342 articles, and got any non-redundant references to SDM, which yielded an additional 76 articles. Results: Of the 418 articles examined, 161 (38.5\%) had a conceptual definition of SDM. We identified 31 separate concepts used to explicate SDM, but only "patient values/preferences" (67.1\%) and "options" (50.9\%) appeared in more than half the 161 definitions. Relatively few articles explicitly recognized and integrated previous work. Conclusion: Our review reveals that there is no shared definition of SDM. We propose a definition that integrates the extant literature base and outlines essential elements that must be present for patients and providers to engage in the process of SDM. Practice implications: The integrative definition of SDM is intended to provide a useful foundation for describing and operationalizing SDM in further research. ?? 2005 Elsevier Ireland Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PJJYJYDY\\makoul_clayman_2006_an_integrative_model_of_shared_decision_making_in_medical_encounters.pdf},
  isbn = {0738-3991},
  keywords = {Physician-patient relationship,Shared decision making},
  pmid = {16051459},
  series = {Patient {{Education}} and {{Counseling}}}
}

@article{Malchau2015,
  title = {The next Critical Role of Orthopedic Registries},
  author = {Malchau, Henrik and Graves, Stephen E. and Porter, Martyn and Harris, William H. and Troelsen, Anders},
  year = {2015},
  volume = {86},
  pages = {3--4},
  issn = {17453682},
  doi = {10.3109/17453674.2014.1002184},
  abstract = {There is an urgent need for the introduction of new implant technology in orthopedic surgery to be conducted in a more controlled manner than in the past. Inadequate regulation and lack of effective post-market surveillance have meant that patients have not been protected from potentially harm-ful implants and procedures. Compounding the problem is a lack of questioning, a lack of critical appraisal, and lack of a requirement for clinical evidence by both surgeons and manu-facturers before large-scale introduction of new technology to the market. There is a long and growing history of failed innovation, demonstrated by the failure or recall of individual prod-ucts such as Boneloc (bone cement), The Capital Hip (total hip arthroplasty), and the ASR hip system (total hip arthro-plasty) among others, as well as whole classes of devices such as large-head metal-on-metal bearings. This demonstrates simple, yet severe flaws in the mechanisms that should pro-tect patients from increased risk associated with introduction of new technology. Insufficient or inadequate preclinical data, a lack of clinical data from timely RSA (radiostereometric analysis) studies, and limited larger, multicenter cohort stud-ies prior to general release all increase the risk to patients. The 510k process, where the majority of so-called innovative new designs have been cleared or approved by FDA-or CE-notified bodies for clinical use, is based on similarities to pre-viously used implants. In the 510k process, there is no require-ment for specific clinical evidence, so manufactures have not obtained clinical data. Registry post-market surveillance has proven to be a powerful method for detection of increased risk of implant failure, but this is not available in all countries. When registries do identify poor-performing devices, regula-tors and manufacturers are often slow to respond. The main problem with the current approach to the introduction of new technology is the inability to identify unanticipated failures before wider release (Bauer 1992). It is 20 years since the stepwise introduction of new implants was first described (Malchau 1995). The basic con-cept of this approach is that the smallest possible numbers of patients (after sufficient preclinical testing) are exposed to the implant prior to general release. Stepwise introduction uses a combination of (1) outcome measurements with high-pre-cision metrics in small cohorts, such as RSA, and (2) limited clinical introduction in a larger cohort, prospectively monitor-ing outcomes and revisions. Adoption of this concept would certainly have reduced the large number of poor-performing new implants introduced in recent years. The concept has, however, never been implemented due to lack of support from surgeons, manufacturers, and regulatory authorities. Now trends have changed, with increasing focus on imple-menting an effective approach to pre-release clinical assess-ment. The ongoing work and discussions in the International Society of Arthroplasty Registries (ISAR), the reports from the Australian Orthopaedic Association total joint registry, and the actions taken in the UK to put a " beyond compliance " pro-gram into action will facilitate a more cautious market intro-duction. In addition, the Arthroplastywatch project (www. arthroplastywatch.com) is in action: data are collected on the web through a specially developed search routine. Based on examination in several steps using medical and statistical expertise, a caution could be warranted or a warning declared. These combined initiatives say one thing: that close monitor-ing of new implants by well-established registries during a phase of controlled introduction must be a universal require-ment. We propose a structured model for clinical trials involv-ing 4 levels: (1) a pure observational study using reopera-tion data from multiple registries, as shown in several papers by the Nordic Arthroplasty Register Association (NARA); (2) patient-reported outcome measures, either from national implant registries or from other registries for specific stud-ies; (3) radiographic data plus other parameters such as blood levels of metal ions, based on specific needs for a new technol-ogy; and (4) options for randomized studies with use of, for example, RSA in the evaluation. The cornerstone in this struc-tural model should be the expanded use of existing and future registries with a high degree of coverage and completeness. While registries have a strong tradition in arthroplasty sur-gery, this is not as well developed in other areas of orthope-dic surgery. It is the responsibility of orthopedic surgeons and their professional bodies to support and implement registries where they can be of benefit. The arthroplasty registry experi-ence has shown that it is possible to use registries to effectively monitor the introduction of new technology. Without this reg-istry-based surveillance, identification of many of the failed innovations would have been delayed or might even have gone unrecognized. It is encouraging that registries in fracture sur-gery are now emerging, where implants are inserted in large and increasing numbers.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\87M27HIB\\malchau_et_al_2015_the_next_critical_role_of_orthopedic_registries.pdf},
  journal = {Acta Orthopaedica},
  number = {1},
  pmid = {25583041}
}

@article{Malenka1993,
  title = {The Framing Effect of Relative and Absolute Risk},
  author = {Malenka, David J and Baron, John A and Johansen, Sarah and Wahrenberger, Jon W and Ross, Jonathan M},
  year = {1993},
  volume = {8},
  pages = {543--548},
  issn = {1525-1497},
  doi = {10.1007/BF02599636},
  abstract = {Objective: To test whether a patient's perception of benefit is influenced by whether the benefit is presented in relative or absolute terms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ATMHCLBB\\malenka_et_al_1993_the_framing_effect_of_relative_and_absolute_risk.pdf},
  journal = {Journal of General Internal Medicine},
  number = {10}
}

@article{Malinzak2009,
  title = {Morbidly {{Obese}}, {{Diabetic}}, {{Younger}}, and {{Unilateral Joint Arthroplasty Patients Have Elevated Total Joint Arthroplasty Infection Rates}}},
  author = {Malinzak, Robert A. and Ritter, Merrill A. and Berend, Michael E. and Meding, John B. and Olberding, Emily M. and Davis, Kenneth E.},
  year = {2009},
  month = sep,
  volume = {24},
  pages = {84--88},
  issn = {08835403},
  doi = {10.1016/j.arth.2009.05.016},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {6}
}

@article{Malmquist2002,
  title = {Risk Och Odds \textendash{} Hur Man R\"aknar Med H\"andelser},
  author = {Malmquist, J{\"o}rgen},
  year = {2002},
  volume = {99},
  pages = {751--756},
  issn = {00237205},
  journal = {L\"akartidningen},
  keywords = {\#nosource},
  number = {8}
}

@article{Maltenfort2017,
  title = {Statistics in Brief: {{Minimum}} Clinically Important {{Difference}}\textemdash{{Availability}} of Reliable Estimates},
  author = {Maltenfort, Mitchell and {D{\'i}az-Ledezma}, Claudio},
  year = {2017},
  pages = {933--946},
  issn = {0009-921X},
  doi = {10.1007/s11999-016-5204-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BLYXTHTS\\maltenfort_díaz-ledezma_2017_statistics_in_brief.pdf},
  isbn = {1199901652},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  pmid = {28050812}
}

@article{Malvezzi2016,
  title = {European Cancer Mortality Predictions for the Year 2016 with Focus on Leukaemias},
  author = {Malvezzi, M. and Carioli, G. and Bertuccio, P. and Rosso, T. and Boffetta, P. and Levi, F. and Vecchia, C. La and Negri, E.},
  year = {2016},
  volume = {27},
  pages = {725--731},
  issn = {15698041},
  doi = {10.1093/annonc/mdw022},
  abstract = {Mortality figures become available after some years.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\958L98ME\\malvezzi_et_al_2016_european_cancer_mortality_predictions_for_the_year_2016_with_focus_on_leukaemias.pdf},
  isbn = {1569-8041 (Electronic)0923-7534 (Linking)},
  journal = {Annals of Oncology},
  keywords = {Cancer,Europe,Leukaemia,Mortality,Projections,Time trends},
  number = {4},
  pmid = {21303801}
}

@article{Manning2016,
  title = {Risk Prediction Tools for Hip and Knee Arthroplasty.},
  author = {Manning, David W and Edelstein, Adam I and Alvi, Hasham M},
  year = {2016},
  month = jan,
  volume = {24},
  pages = {19--27},
  issn = {1940-5480},
  doi = {10.5435/JAAOS-D-15-00072},
  abstract = {The current healthcare environment in America is driven by the concepts of quality, cost containment, and value. In this environment, primary hip and knee arthroplasty procedures have been targeted for cost containment through quality improvement initiatives intended to reduce the incidence of costly complications and readmissions. Accordingly, risk prediction tools have been developed in an attempt to quantify the patient-specific assessment of risk. Risk prediction tools may be useful for the informed consent process, for enhancing risk mitigation efforts, and for risk-adjusting data used for reimbursement and the public reporting of outcomes. The evaluation of risk prediction tools involves statistical measures such as discrimination and calibration to assess accuracy and utility. Furthermore, prediction tools are tuned to the source dataset from which they are derived, require validation with external datasets, and should be recalibrated over time. However, a high-quality, externally validated risk prediction tool for adverse outcomes after primary total joint arthroplasty remains an elusive goal.},
  journal = {The Journal of the American Academy of Orthopaedic Surgeons},
  keywords = {\#nosource},
  number = {1},
  pmid = {26604220}
}

@article{Mao2018,
  title = {On the Propensity Score Weighting Analysis with Survival Outcome: {{Estimands}}, Estimation, and Inference: {{On}} the Propensity Score Weighting Analysis with Survival Outcome: {{Estimands}}, Estimation, and Inference},
  shorttitle = {On the Propensity Score Weighting Analysis with Survival Outcome},
  author = {Mao, Huzhang and Li, Liang and Yang, Wei and Shen, Yu},
  year = {2018},
  month = nov,
  volume = {37},
  pages = {3745--3763},
  issn = {02776715},
  doi = {10.1002/sim.7839},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3UNQ6WIY\\Mao m. fl. - 2018 - On the propensity score weighting analysis with su.pdf},
  journal = {Statistics in Medicine},
  keywords = {simonsson},
  language = {en},
  number = {26}
}

@article{Maoz2015,
  title = {The {{Otto Aufranc Award}}: {{Modifiable}} versus {{Nonmodifiable Risk Factors}} for {{Infection After Hip Arthroplasty}}},
  shorttitle = {The {{Otto Aufranc Award}}},
  author = {Maoz, Guy and Phillips, Michael and Bosco, Joseph and Slover, James and Stachel, Anna and Inneh, Ifeoma and Iorio, Richard},
  year = {2015},
  month = feb,
  volume = {473},
  pages = {453--459},
  issn = {0009-921X, 1528-1132},
  doi = {10.1007/s11999-014-3780-x},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5W3KBZS5\\Maoz et al_2015_The Otto Aufranc Award.pdf},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  language = {en},
  number = {2}
}

@article{Marie2015,
  title = {Fitdistrplus : {{An}} r Package for Fitting Distributions},
  author = {Marie, Author and {Delignette-muller}, Laure and Dutang, Christophe and Denis, Jean-baptiste and {Delignette-muller}, Maintainer Marie Laure and Dutang, Christophe},
  year = {2015},
  volume = {64},
  pages = {1--34},
  issn = {1548-7660},
  doi = {10.18637/jss.v064.i04},
  abstract = {Description Extends the fitdistr() function (of the MASS package) with several func-tions to help the fit of a parametric distribution to non-censored or censored data. Cen-sored data may contain left censored, right censored and interval censored values, with sev-eral lower and upper bounds. In addition to maximum likelihood estimation (MLE), the pack-age provides moment matching (MME), quantile matching (QME) and maximum goodness-of-fit estimation (MGE) methods (available only for non-censored data). Weighted ver-sions of MLE, MME and QME are available. Depends R (\textquestiondown = 3.2.0), MASS, grDevices, survival, methods Imports stats Suggests actuar, rgenoud, mc2d, gamlss.dist, knitr, knitcitations VignetteBuilder knitr BuildVignettes true License GPL (\textquestiondown = 2) URL http://riskassessment.r-forge.r-project.org},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S8ICYD67\\marie_et_al_2015_fitdistrplus.pdf},
  isbn = {9781420065213},
  journal = {Journal of Statistical Software},
  keywords = {bootstrap,censored data,distributions,maximum goodness-of-fit,maximum likelihood,moment matching,probability distribution fitting,quantile matching,r},
  number = {4}
}

@article{Marschner2012,
  title = {Relative Risk Regression: {{Reliable}} and Flexible Methods for Log-Binomial Models},
  author = {Marschner, Ian C. and Gillett, Alexandra C.},
  year = {2012},
  volume = {13},
  pages = {179--192},
  issn = {14654644},
  doi = {10.1093/biostatistics/kxr030},
  abstract = {Relative risks (RRs) are generally considered preferable to odds ratios in prospective studies. However, unlike logistic regression for odds ratios, the standard log-binomial model for RR regression does not respect the natural parameter constraints and is therefore often subject to numerical instability. In this paper, we develop a reliable and flexible method for fitting log-binomial models. We use an Expectation-Maximization (EM) algorithm where the multiplicative event probability is viewed as the joint probability for a collection of latent binary outcomes. This gives a simple iterative scheme that provides stable convergence to the maximum likelihood estimate. In addition to reliability, the method offers some flexible generalizations, including models with unspecified isotonic regression functions. We examine the method's performance using simulations and data analyses of the age-specific RR of mortality following heart attack. These analyses demonstrate the potential for numerical instability in RR regression and show how this can be overcome using the proposed approach. Source code to implement the method in R is provided as supplementary material available at Biostatistics online.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F35IB68X\\marschner_gillett_2012_relative_risk_regression.pdf},
  isbn = {1465-4644},
  journal = {Biostatistics},
  keywords = {Binomial regression,EM algorithm,Generalized linear models,Isotonic regression,Relative risk},
  number = {1},
  pmid = {21914729}
}

@article{Marschner2015,
  title = {Relative Risk Regression for Binary Outcomes: {{Methods}} and Recommendations},
  author = {Marschner, Ian C.},
  year = {2015},
  month = dec,
  volume = {57},
  pages = {437--462},
  doi = {10.1111/anzs.12131},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V4SWMJWV\\marschner_2015_relative_risk_regression_for_binary_outcomes.pdf},
  journal = {Australian \& New Zealand Journal of Statistics},
  number = {4}
}

@article{Marwick2018,
  title = {Packaging Data Analytical Work Reproducibly Using r (and Friends)},
  author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
  year = {2018},
  month = jan,
  volume = {72},
  pages = {80--88},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1375986},
  abstract = {ABSTRACTComputers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensur...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\N7RBRYWI\\marwick_et_al_2018_packaging_data_analytical_work_reproducibly_using_r_(and_friends).pdf},
  journal = {The American Statistician},
  keywords = {Computational science,Data science,Open source software,Reproducible research},
  number = {1}
}

@article{Matloff2013,
  title = {From Algorithms to Z-Scores : {{Probabilistic}} and Statistical Modeling in Computer Science},
  author = {Matloff, Norm},
  year = {2013},
  pages = {464},
  issn = {09252312},
  doi = {10.1016/j.peva.2007.06.006},
  abstract = {Dr. Norm Matloff is a professor of computer science at the University of California at Davis, and was formerly a professor of statistics at that university. He is a former database software developer in Silicon Valley, and has been a statistical consultant for firms such as the Kaiser ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DWWUDKLQ\\matloff_2013_from_algorithms_to_z-scores.pdf},
  isbn = {978-1616100360},
  pmid = {10911016}
}

@article{May1986,
  title = {Downloaded from {{http://rsta.royalsocietypublishing.org/}} on {{February}} 26 , 2016},
  author = {{Anderson} and {May}},
  year = {1986},
  journal = {Society, The Royal Transactions, Philosophical Society, Royal Sciences, Physical},
  keywords = {\#nosource}
}

@inproceedings{May2016,
  title = {Statistical Methods in Epidemiology \textendash{} beyond the {{Cox}} Model {{Course}} Schedule},
  author = {May, Monday and Lambert, Paul},
  year = {2016},
  keywords = {\#nosource}
}

@article{Mayer2009,
  title = {Funnel Plots and Their Emerging Application in Surgery},
  author = {Mayer, Erik K. and Bottle, Alex and Rao, Christopher and Darzi, Ara W. and Athanasiou, Thanos},
  year = {2009},
  volume = {249},
  pages = {376--383},
  issn = {00034932},
  doi = {10.1097/SLA.0b013e31819a47b1},
  abstract = {OBJECTIVE: To familiarize surgeons with the use of funnel plots as a control tool to assess quality in surgery.BACKGROUND DATA: Surgical outcomes are an important component of quality in healthcare delivery. Several control tools have been introduced and tested including the use of graphical tools such as funnel plots. More recently, their application in healthcare to assess quality has become more evident. Ranking in surgical performance has significant limitations, risks, and implications which can be addressed by the use of funnel plots.: This methodological review explores the principles and existing application of funnel plots within surgery and emphasizes their advantages, limitations, public health implications, and their use to assess the evidence in the literature and potential future applications.: Funnel plots are practical tools, easy to use, and offer the opportunity to statistically define control limits around measurable outcomes, allowing for adjustment of unmeasured factors. This makes them extremely useful for the monitoring of performance in surgery either at a surgeon, institutional, regional, or national level, by means of qualifying aggregated data in reported literature (meta-analysis). Increasing transparency is required in healthcare outcomes and performance, which means that funnel plots will most likely play an increasingly important role as a quality control tool.: More widespread application of funnel plots in surgery will help to overcome some of the existing difficulties in assessing and reporting performance and identifying evidence-based information. The assessment and changes in future healthcare delivery could be partly influenced by further development of funnel plot methodology.},
  isbn = {1528-1140},
  journal = {Annals of Surgery},
  keywords = {\#nosource},
  number = {3},
  pmid = {19247021}
}

@article{Mazzola2016,
  title = {Hip Fracture Surgery and Survival in Centenarians},
  author = {Mazzola, Paolo and Rea, Federico and Merlino, Luca and Bellelli, Giuseppe and Dubner, Lauren and Corrao, Giovanni and Pasinetti, Giulio M. and Annoni, Giorgio},
  year = {2016},
  volume = {71},
  pages = {1514--1518},
  issn = {1758535X},
  doi = {10.1093/gerona/glw016},
  abstract = {Background: Hip fracture (HF) is increasingly frequent with advancing age. Studies describing the HF incidence rate and survival after surgery in centenarians are scanty. To fill this gap, we performed a large population-based investigation on Lombardy centenarians (Italy). Methods: Retrospective observational cohort study based on information from the Healthcare Utilization Database. Among the cohort of 7,830 residents that reached 100 years of age between 2004 and 2011, incidence rate of HF was calculated. Two hundred fifty-nine patients were discharged alive from a hospital after HF and surgical repair (HF cohort). For each HF cohort member, a control was randomly selected from the initial cohort to be matched for gender and date of birth, and who did not experience HF from the date of their hundredth birthday until the date of hospital discharge of the corresponding HF cohort member. The survival curves and the hazard functions of HF and control cohort were calculated within 2 years. Results: Over a mean follow-up of 1.85 years, HF incidence rate was 23.1 per 1,000 centenarians per year. Survival probability was significantly lower in HF cohort than in control cohort (31.5 vs 48.1\%, p \textexclamdown{} .001). Hazard functions showed an increased risk of death in HF cohort than in control cohort, especially in the 3 months after surgery. Conclusion: Survival analysis exhibited an excess mortality in the first 3 months among HF cohort members, but not beyond this period. Every effort to counteract HF is warranted, including prevention of falls and high quality of care, especially in the early postsurgical time.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RMK4PZ8R\\mazzola_et_al_2016_hip_fracture_surgery_and_survival_in_centenarians.pdf},
  journal = {Journals of Gerontology - Series A Biological Sciences and Medical Sciences},
  keywords = {Centenarians,Hip fracture,Hip fracture surgery,Orthogeriatric,Survival},
  number = {11}
}

@article{McCaffrey2005,
  title = {Propensity Score Estimation with Boosted Regression for Evaluating Causal Effects in Observational Studies},
  author = {McCaffrey, Daniel and Ridgeway, Greg and Morral, Andrew R},
  year = {2005},
  doi = {10.1037/1082-989X.9.4.403},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Y88L4IMD\\McCaffrey m. fl. - 2005 - Propensity score estimation with boosted regressio.pdf},
  journal = {Psychological Methods},
  keywords = {simonsson}
}

@article{McCaffrey2013,
  title = {A Tutorial on Propensity Score Estimation for Multiple Treatments Using Generalized Boosted Models},
  author = {McCaffrey, Daniel F and Griffin, Beth Ann and Almirall, Daniel and Slaughter, Mary Ellen and Ramchand, Rajeev and Burgette, Lane F},
  year = {2013},
  volume = {32},
  pages = {3388--3414},
  doi = {10.1002/sim.5753.A},
  journal = {Statistics in Medicine},
  keywords = {\#nosource,causal effects,causal modeling,gbm,inverse probability of treatment,twang,weighting},
  number = {19}
}

@article{McCaffrey2013a,
  title = {A Tutorial on Propensity Score Estimation for Multiple Treatments Using Generalized Boosted Models},
  author = {McCaffrey, Daniel F. and Griffin, Beth Ann and Almirall, Daniel and Slaughter, Mary Ellen and Ramchand, Rajeev and Burgette, Lane F.},
  year = {2013},
  month = aug,
  volume = {32},
  pages = {3388--3414},
  issn = {02776715},
  doi = {10.1002/sim.5753},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BUZN7LKQ\\McCaffrey m. fl. - 2013 - A tutorial on propensity score estimation for mult.pdf},
  journal = {Statistics in Medicine},
  keywords = {simonsson},
  language = {en},
  number = {19}
}

@article{McKenna2005,
  title = {The Translation and Cultural Adaptation of Patient-Reported Outcome Measures},
  author = {McKenna, Stephen P. and Doward, Lynda C.},
  year = {2005},
  volume = {8},
  pages = {89--91},
  publisher = {{International Society for Pharmacoeconomics and Outcomes Research (ISPOR)}},
  issn = {10983015},
  doi = {10.1111/j.1524-4733.2005.08203.x},
  abstract = {With the need for standardized patient-reported outcome (PRO) for use in multinational studies it was probably recognized that there was a requirement for determining the quality of the target version by some sort of "scientific" method. Despite this need, back translation has no clear scientific basis and its use casts doubts on the ability of translators. It should also be noted that translation is just one step in the production of new language versions of an instrument. Full adaptation requires that the scaling and psychometric properties of the new language version are also assessed. It is indeed bad practice to simply assume that a translated version shares the same psychometric properties as the original source version. It may be that this is an area still to be addressed by the working group, although this seems unlikely as the guidelines they reviewed do not include such quality controls and such validation is rarely reported. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TETW8GUF\\mckenna_doward_2005_the_translation_and_cultural_adaptation_of_patient-reported_outcome_measures.pdf},
  isbn = {1098-3015},
  journal = {Value in Health},
  number = {2},
  pmid = {15804316}
}

@article{McNeish2014,
  title = {Modeling Sparsely Clustered Data: {{Design}}-Based, Model-Based, and Single-Level Methods.},
  author = {McNeish, Daniel M. and M., Daniel},
  year = {2014},
  volume = {19},
  pages = {552--563},
  publisher = {{American Psychological Association}},
  doi = {10.1037/met0000024},
  journal = {Psychological Methods},
  keywords = {\#nosource},
  number = {4}
}

@article{McNutt2003,
  title = {Estimating the Relative Risk in Cohort Studies and Clinical Trials of Common Outcomes},
  author = {McNutt, Louise Anne and Wu, Chuntao and Xue, Xiaonan and Hafner, Jean Paul},
  year = {2003},
  volume = {157},
  pages = {940--943},
  issn = {00029262},
  doi = {10.1093/aje/kwg074},
  abstract = {Logistic regression yields an adjusted odds ratio that approximates the adjusted relative risk when disease incidence is rare (\textexclamdown 10\%), while adjusting for potential confounders. For more common outcomes, the odds ratio always overstates the relative risk, sometimes dramatically. The purpose of this paper is to discuss the incorrect application of a proposed method to estimate an adjusted relative risk from an adjusted odds ratio, which has quickly gained popularity in medical and public health research, and to describe alternative statistical methods for estimating an adjusted relative risk when the outcome is common. Hypothetical data are used to illustrate statistical methods with readily accessible computer software},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YJIYDK4S\\mcnutt_et_al_2003_estimating_the_relative_risk_in_cohort_studies_and_clinical_trials_of_common.pdf},
  isbn = {0002-9262 (Print) 0002-9262 (Linking)},
  journal = {American Journal of Epidemiology},
  keywords = {Clinical trials,Cohort studies,Odds ratio,Relative risk},
  number = {10},
  pmid = {12746247}
}

@article{Mehta2016,
  title = {Regression Coefficient\textendash Based Scoring System Should Be Used to Assign Weights to the Risk Index},
  author = {Mehta, Hemalkumar B. and Mehta, Vinay and Girman, Cynthia J. and Adhikari, Deepak and Johnson, Michael L.},
  year = {2016},
  month = nov,
  volume = {79},
  pages = {22--28},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/J.JCLINEPI.2016.03.031},
  abstract = {OBJECTIVE Some previously developed risk scores contained a mathematical error in their construction: risk ratios were added to derive weights to construct a summary risk score. This study demonstrates the mathematical error and derived different versions of the Charlson comorbidity score (CCS) using regression coefficient\textendash based and risk ratio\textendash based scoring systems to further demonstrate the effects of incorrect weighting on performance in predicting mortality. STUDY DESIGN AND SETTING This retrospective cohort study included elderly people from the Clinical Practice Research Datalink. Cox proportional hazards regression models were constructed for time to 1-year mortality. Weights were assigned to 17 comorbidities using regression coefficient\textendash based and risk ratio\textendash based scoring systems. Different versions of CCS were compared using Akaike information criteria (AIC), McFadden's adjusted R2, and net reclassification improvement (NRI). RESULTS Regression coefficient\textendash based models (Beta, Beta10/integer, Beta/Schneeweiss, Beta/Sullivan) had lower AIC and higher R2 compared to risk ratio\textendash based models (HR/Charlson, HR/Johnson). Regression coefficient\textendash based CCS reclassified more number of people into the correct strata (NRI range, 9.02\textendash 10.04) compared to risk ratio\textendash based CCS (NRI range, 8.14\textendash 8.22). CONCLUSION Previously developed risk scores contained an error in their construction adding ratios instead of multiplying them. Furthermore, as demonstrated here, adding ratios fail to even work adequately from a practical standpoint. CCS derived using regression coefficients performed slightly better than in fitting the data compared to risk ratio\textendash based scoring systems. Researchers should use a regression coefficient\textendash based scoring system to develop a risk index, which is theoretically correct.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WVHRDAC7\\mehta_et_al_2016_regression_coefficient–based_scoring_system_should_be_used_to_assign_weights_to.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@article{Meier1975,
  title = {Estimation of a Distribution Function from Incomplete Observations},
  author = {Meier, Paul},
  year = {1975},
  volume = {12},
  pages = {67--87},
  issn = {1532415X},
  doi = {10.1080/03610928208828280},
  abstract = {Kaplan and Meier (1958) give a maximum likelihood estimator of the distribution function based on a univariate right censored sample. Here we investigate the extension of their results to the case of bivariate right censored samples. Following Efron (1967), we provide ``self-consistent'' estimators for the bivariate distribution function. \textcopyright{} 1982, Taylor \& Francis Group, LLC. All rights reserved.},
  journal = {Journal of Applied Probability291},
  keywords = {\#nosource,right censored sample}
}

@article{Meier2004,
  title = {The Price of Kaplan-Meier},
  author = {Meier, Paul and Karrison, Theodore and Chappell, Rick and Xie, Hui},
  year = {2004},
  volume = {99},
  pages = {890--896},
  issn = {01621459},
  doi = {10.1198/016214504000001259},
  abstract = {Miller has studied the asymptotic efficiency of the nonparametric, Kaplan-Meier survival estimator relative to parametric estimates based on the exponential and Weibull distributions. He concluded that in certain cases, the asymptotic efficiency is low and recommended that analysts give more consideration to parametric estimators, particularly for estimation of small tail probabilities. In this article we revisit this issue and examine the performance of the nonparametric procedure for estimation not only of a point on the survival curve, but also of the mean (or restricted mean) lifetime. In addition to the exponential and Weibull families, we consider the performance of the Kaplan-Meier procedure relative to a more flexible parametric model proposed by Efron. We find that the reduction in efficiency of the Kaplan-Meier survival estimate becomes negligible fairly quickly as the number of parameters in the parametric model increases. Moreover, for estimation of the mean or restricted mean, the loss in efficiency, even relative to the exponential distribution, is small or nil. We conclude that a parametric estimate of the survival curve may be necessary in certain extreme situations, such as when the sample size is very small. In these cases, careful attention must be given to considering the degree of fit, although with sparse data, this must be assessed from outside sources. For certain functional of the survival curve, such as the mean or restricted mean, the nonparametric approach is unbiased and entails little or no loss in efficiency, and therefore would generally be preferred over a parametric-based estimate.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XWLY6CPA\\meier_et_al_2004_the_price_of_kaplan-meier.pdf},
  journal = {Journal of the American Statistical Association},
  keywords = {Efficiency,Kaplan-Meier estimator,Mean squared error,Parametric modeling,Restricted mean},
  number = {467}
}

@article{Meinshausen2006,
  title = {High-Dimensional Graphs and Variable Selection with the Lasso},
  author = {Meinshausen, Nicolai and B{\"u}hlmann, Peter and Buhlmann, Peter and Zurich, Eth},
  year = {2006},
  volume = {34},
  pages = {1436--1462},
  doi = {10.1214/009053606000000281},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. The pattern of zero entries in the inverse covariance matrix of a multivari ate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the con ditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty pa rameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8T2RHIW3\\meinshausen_et_al_2006_high-dimensional_graphs_and_variable_selection_with_the_lasso.pdf},
  journal = {Source: The Annals of Statistics The Annals of Statistics},
  number = {3}
}

@article{Meinshausen2010,
  title = {Stability Selection},
  author = {Meinshausen, Nicolai and B{\"u}hlmann, Peter},
  year = {2010},
  month = sep,
  volume = {72},
  pages = {417--473},
  issn = {1467-9868},
  doi = {10.1111/J.1467-9868.2010.00740.X@10.1111/(ISSN)1467-9868.TOP_SERIES_B_RESEARCH},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {\#nosource,High dimensional data,Resampling,Stability selection,Structure estimation},
  number = {4}
}

@article{Melamed2018,
  title = {Survival after Minimally Invasive Radical Hysterectomy for Early-Stage Cervical Cancer},
  author = {Melamed, Alexander and Margul, Daniel J. and Chen, Ling and Keating, Nancy L. and {del Carmen}, Marcela G. and Yang, Junhua and Seagle, Brandon-Luke L. and Alexander, Amy and Barber, Emma L. and Rice, Laurel W. and Wright, Jason D. and Kocherginsky, Masha and Shahabi, Shohreh and {Rauh-Hain}, J. Alejandro},
  year = {2018},
  month = nov,
  volume = {379},
  pages = {1905--1914},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1804923},
  journal = {New England Journal of Medicine},
  keywords = {\#nosource},
  number = {20}
}

@article{Mellon2013,
  title = {Hip Replacement: {{Landmark}} Surgery in Modern Medical History},
  author = {Mellon, Stephen J. and Liddle, Alexander D. and Pandit, Hemant},
  year = {2013},
  volume = {75},
  pages = {221--226},
  publisher = {{Elsevier Ireland Ltd}},
  issn = {03785122},
  doi = {10.1016/j.maturitas.2013.04.011},
  abstract = {Total hip replacement (THR) is most often performed to treat end-stage symptomatic osteoarthritis. Patients typically present with increasing pain, restricted mobility and stiffness. In this procedure, the femoral head and part of the femoral neck are excised. The acetabulum is enlarged and an acetabular cup is inserted. The femoral head is replaced by a femoral component, the stem of which is inserted into the medullary canal of the femur. The components can be either cemented in place or press-fit (cementless). The THR concept was popularised by Sir John Charnley in the 1960s and although, over half a century of development has resulted in incremental improvements, the procedure is not dramatically different from the one he described. However, over the last two decades there have been significant changes in the types of bearing surfaces used. Metal on polyethylene continues to be the workhorse for the majority of cases. In the young and active, bearing surfaces with low wear rate are increasingly used. Since the early 1960s, THR has played an important role in alleviating pain and restoring mobility to millions of people. The cost-effectiveness of THR in treating advanced osteoarthritis makes it one of the most successful of all surgical interventions. \textcopyright{} 2013 Elsevier Ireland Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3L8KZ68M\\mellon_et_al_2013_hip_replacement.pdf},
  isbn = {0378-5122},
  journal = {Maturitas},
  keywords = {Hip replacement,Osteoarthritis,Total hip replacement},
  number = {3},
  pmid = {23693138}
}

@article{Memtsoudis2012,
  title = {Epidemiology and Risk Factors for Perioperative Mortality after Total Hip and Knee Arthroplasty.},
  author = {Memtsoudis, Stavros G and Pumberger, Matthias and Ma, Yan and Chiu, Ya-Lin and Fritsch, Gerhard and Gerner, Peter and Poultsides, Lazaros and Valle, Alejandro Gonzalez Della},
  year = {2012},
  volume = {30},
  pages = {1811--21},
  issn = {1554-527X},
  doi = {10.1002/jor.22139},
  abstract = {The perioperative mortality of total knee and hip arthroplasties (TKA, THA) remains a major concern among health care providers and their patients. The increase in utilization of TKA and THA makes it imperative to be aware of factors that are associated with this unfortunate event. Therefore we analyzed the Nationwide Inpatient Sample data from 1998 to 2008 and compared admissions with perioperative mortality to those that survived their hospitalization. An estimated total of 4,438,213 TKA and 2,182,121 THA procedures were performed in the United States between 1998 and 2008. The average mortality rate for TKA was 0.13\% and 0.18\% for THA, or 0.34 and 0.44 events per 1,000 inpatient days, respectively. Independent risk factors for in-hospital mortality were advanced age, male gender, ethnic minority background, emergency admission as well as a number of comorbidities and complications. Furthermore, we demonstrated that the timing of death occurred earlier after TKA when compared to THA, with 50\% of fatalities occurring by day 4 versus day 6 of the hospitalization, respectively. This study provides nationally representative information on risk factors for and timing of perioperative mortality after TKA and THA. Our data can be used to assess the risk for perioperative mortality and to develop targeted intervention to decrease such risk.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A7CUC8RH\\memtsoudis_et_al_2012_epidemiology_and_risk_factors_for_perioperative_mortality_after_total_hip_and.pdf},
  journal = {Journal of orthopaedic research : official publication of the Orthopaedic Research Society},
  keywords = {Adolescent,Adult,Age Factors,Aged,Arthroplasty,Child,Comorbidity,Female,Hip,Hip: mortality,Hospital Mortality,Humans,Infant,Knee,Knee: mortality,Male,Middle Aged,Multivariate Analysis,Perioperative Period,Preschool,Replacement,Risk Factors,United States,United States: epidemiology,Young Adult},
  number = {11},
  pmid = {22517400}
}

@article{Menendez2014,
  title = {The {{Elixhauser}} Comorbidity Method Outperforms the {{Charlson}} Index in Predicting Inpatient Death after Orthopaedic Surgery.},
  author = {Menendez, Mariano E. and Neuhaus, Valentin and {van Dijk}, C. Niek and Ring, David},
  year = {2014},
  month = sep,
  volume = {472},
  pages = {2878--86},
  publisher = {{Springer}},
  issn = {15281132},
  doi = {10.1007/s11999-014-3686-7},
  abstract = {BACKGROUND: Scores derived from comorbidities can help with risk adjustment of quality and safety data. The Charlson and Elixhauser comorbidity measures are well-known risk adjustment models, yet the optimal score for orthopaedic patients remains unclear. QUESTIONS/PURPOSES: We determined whether there was a difference in the accuracy of the Charlson and Elixhauser comorbidity-based measures in predicting (1) in-hospital mortality after major orthopaedic surgery, (2) in-hospital adverse events, and (3) nonroutine discharge. METHODS: Among an estimated 14,007,813 patients undergoing orthopaedic surgery identified in the National Hospital Discharge Survey (1990-2007), 0.80\% died in the hospital. The association of each Charlson comorbidity measure and Elixhauser comorbidity measure with mortality was assessed in bivariate analysis. Two main multivariable logistic regression models were constructed, with in-hospital mortality as the dependent variable and one of the two comorbidity-based measures (and age, sex, and year of surgery) as independent variables. A base model that included only age, sex, and year of surgery also was evaluated. The discriminative ability of the models was quantified using the area under the receiver operating characteristic curve (AUC). The AUC quantifies the ability of our models to assign a high probability of mortality to patients who die. Values range from 0.50 to 1.0, with 0.50 indicating no ability to discriminate and 1.0 indicating perfect discrimination. RESULTS: Elixhauser comorbidity adjustment provided a better prediction of in-hospital case mortality (AUC, 0.86; 95\% CI, 0.86-0.86) compared with the Charlson model (AUC, 0.83; 95\% CI, 0.83-0.84) and to the base model with no comorbidities (AUC, 0.81; 95\% CI, 0.81-0.81). In terms of relative improvement in predictive performance, the Elixhauser measure performed 60\% better than the Charlson score in predicting mortality. The Elixhauser model discriminated inpatient morbidity better than the Charlson measure, but the discriminative ability of the model was poor and the difference in the absolute improvement in predictive power between the two models (AUC, 0.01) is of dubious clinical importance. Both comorbidity models exhibited the same degree of discrimination for estimating nonroutine discharge (AUC, 0.81; 95\% CI, 0.81-0.82 for both models). CONCLUSIONS: Provider-specific outcomes, particularly inpatient mortality, may be evaluated differently depending on the comorbidity risk adjustment model selected. Future research assessing and comparing the performance of the Charlson and Elixhauser measures in predicting long-term outcomes would be of value. LEVEL OF EVIDENCE: Level II, prognostic study. See the Instructions for Authors for a complete description of levels of evidence.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\47FRKUNY\\menendez_et_al_2014_the_elixhauser_comorbidity_method_outperforms_the_charlson_index_in_predicting.pdf},
  isbn = {1528-1132 (Electronic){\r  }0009-921X (Linking)},
  journal = {Clinical orthopaedics and related research},
  number = {9},
  pmid = {24867450}
}

@article{Menendez2015,
  title = {Inpatient Mortality after Orthopaedic Surgery},
  author = {Menendez, Mariano E. and Neuhaus, Valentin and Ring, David},
  year = {2015},
  month = jul,
  volume = {39},
  pages = {1307--1314},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {0341-2695},
  doi = {10.1007/s00264-015-2702-1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6GE7I786\\menendez_et_al_2015_inpatient_mortality_after_orthopaedic_surgery.pdf},
  journal = {International Orthopaedics},
  number = {7}
}

@article{michaelssonMilkIntakeRisk2014,
  title = {Milk Intake and Risk of Mortality and Fractures in Women and Men: Cohort Studies},
  author = {Micha{\"e}lsson, Karl and Wolk, Alicja and Langenski{\"o}ld, Sophie and Basu, Samar and Lemming, Eva Warensj{\"o} and Melhus, H\aa kan and Byberg, Liisa},
  year = {2014},
  month = oct,
  volume = {349},
  pages = {g6015},
  publisher = {{British Medical Journal Publishing Group}},
  doi = {10.1136/BMJ.G6015},
  abstract = {Objective To examine whether high milk consumption is associated with mortality and fractures in women and men. Design Cohort studies. Setting Three counties in central Sweden. Participants Two large Swedish cohorts, one with 61 433 women (39-74 years at baseline 1987-90) and one with 45 339 men (45-79 years at baseline 1997), were administered food frequency questionnaires. The women responded to a second food frequency questionnaire in 1997. Main outcome measure Multivariable survival models were applied to determine the association between milk consumption and time to mortality or fracture. Results During a mean follow-up of 20.1 years, 15 541 women died and 17 252 had a fracture, of whom 4259 had a hip fracture. In the male cohort with a mean follow-up of 11.2 years, 10 112 men died and 5066 had a fracture, with 1166 hip fracture cases. In women the adjusted mortality hazard ratio for three or more glasses of milk a day compared with less than one glass a day was 1.93 (95\% confidence interval 1.80 to 2.06). For every glass of milk, the adjusted hazard ratio of all cause mortality was 1.15 (1.13 to 1.17) in women and 1.03 (1.01 to 1.04) in men. For every glass of milk in women no reduction was observed in fracture risk with higher milk consumption for any fracture (1.02, 1.00 to 1.04) or for hip fracture (1.09, 1.05 to 1.13). The corresponding adjusted hazard ratios in men were 1.01 (0.99 to 1.03) and 1.03 (0.99 to 1.07). In subsamples of two additional cohorts, one in males and one in females, a positive association was seen between milk intake and both urine 8-iso-PGF2{$\alpha$} (a biomarker of oxidative stress) and serum interleukin 6 (a main inflammatory biomarker). Conclusions High milk intake was associated with higher mortality in one cohort of women and in another cohort of men, and with higher fracture incidence in women. Given the observational study designs with the inherent possibility of residual confounding and reverse causation phenomena, a cautious interpretation of the results is recommended.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QXR8XZ4A\\michaëlsson_et_al_2014_milk_intake_and_risk_of_mortality_and_fractures_in_women_and_men.pdf},
  journal = {BMJ: British Medical Journal},
  pmid = {25352269}
}

@article{Michelis2012,
  title = {Tradional versus Non-Traditional Boosting Algorithms},
  author = {Michelis, Alexandre},
  year = {2012},
  keywords = {\#nosource}
}

@article{Michet2016,
  title = {Cause-Specific Mortality Trends Following Total Hip and Knee Arthroplasty},
  author = {Michet, C.J. and Schleck, C.D. and Larson, D.R. and {Maradit-Kremers}, H. and Berry, D.J. and Lewallen, D.G.},
  year = {2016},
  publisher = {{Elsevier Ltd}},
  issn = {08835403},
  doi = {10.1016/j.arth.2016.10.009},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B2FC5JV2\\michet_et_al_2016_cause-specific_mortality_trends_following_total_hip_and_knee_arthroplasty.pdf},
  journal = {The Journal of Arthroplasty}
}

@article{Middleton2014,
  title = {Peri-Operative Mortality after Hemiarthroplasty for Fracture of the Hip},
  author = {Middleton, R. G. and Uzoigwe, C. E. and Young, P. S. and Smith, R. and Gosal, H. S. and Holt, G.},
  year = {2014},
  volume = {96-B},
  journal = {Bone \& Joint Journal},
  keywords = {\#nosource},
  number = {9}
}

@article{Middleton2014,
  title = {Peri-Operative Mortality after Hemiarthroplasty for Fracture of the Hip : {{Does}} Cement Make a Difference?},
  author = {Middleton, R. G. and Uzoigwe, C. E. and Young, P. S. and Smith, R. and Gosal, H. S. and Holt, G.},
  year = {2014},
  volume = {69B},
  pages = {1185--1191},
  issn = {20494408},
  doi = {10.1302/0301-620X.96B9.33935$2.00},
  abstract = {We aimed to determine whether cemented hemiarthroplasty is associated with a higher post-operative mortality and rate of re-operation when compared with uncemented hemiarthroplasty. Data on 19 669 patients, who were treated with a hemiarthroplasty following a fracture of the hip in a nine-year period from 2002 to 2011, were extracted from NHS Scotland's acute admission database (Scottish Morbidity Record, SMR01). We investigated the rate of mortality at day 0, 1, 7, 30, 120 and one-year post-operatively using 12 case-mix variables to determine the independent effect of the method of fixation. At day 0, those with a cemented hemiarthroplasty had a higher rate of mortality (p \textexclamdown{} 0.001) compared with those with an uncemented hemiarthroplasty, equivalent to one extra death per 424 procedures. By day one this had become one extra death per 338 procedures. Increasing age and the five-year co-morbidity score were noted as independent risk factors. By day seven, the cumulative rate of mortality was less for cemented hemiarthroplasty though this did not reach significance until day 120. The rate of re-operation was significantly higher for uncemented hemiarthroplasty. Despite adjusting for 12 confounding variables, these only accounted for 15\% of the observed variability. The debate about the choice of the method of fixation for a hemiarthroplasty with respect to the rate of mortality or the risk of re-operation may be largely superfluous. Our results suggest that uncemented hemiarthroplasties may have a role to play in elderly patients with significant co-morbid disease.},
  isbn = {2049-4408{\r  }2049-4394},
  journal = {Bone and Joint Journal},
  keywords = {\#nosource},
  number = {9},
  pmid = {25183588}
}

@article{Milfont2008,
  title = {Burnout and Wellbeing: {{Testing}} the {{Copenhagen}} Burnout Inventory in {{New Zealand}} Teachers},
  author = {Milfont, Taciano L. and Denny, Simon and Ameratunga, Shanthi and Robinson, Elizabeth and Merry, Sally},
  year = {2008},
  volume = {89},
  pages = {169--177},
  issn = {03038300},
  doi = {10.1007/s11205-007-9229-9},
  abstract = {For the confirmatory factor model a series of inequalities is given with respect to the mean square error (MSE) of three main factor score predictors. The eigenvalues of these MSE matrices are a monotonic function of the eigenvalues of the matrix `` p = \textbrokenbar{} 1/2 \guilsinglright{} p [variant prime] \textasciidieresis{} p -1 \guilsinglright{} p \textbrokenbar{} 1/2 . This matrix increases with the number of observable variables p . A necessary and sufficient condition for mean square convergence of predictors is divergence of the smallest eigenvalue of `` p or, equivalently, divergence of signal-to-noise (Schneeweiss \& Mathes, 1995). The same condition is necessary and sufficient for convergence to zero of the positive definite MSE differences of factor predictors, convergence to zero of the distance between factor predictors, and convergence to the unit value of the relative efficiencies of predictors. Various illustrations and examples of the convergence are given as well as explicit recommendations on the problem of choosing between the three main factor score predictors.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E86DLBAL\\milfont_et_al_2008_burnout_and_wellbeing.pdf},
  isbn = {1133600412207},
  journal = {Social Indicators Research},
  keywords = {Burnout,Copenhagen Burnout Inventory,New Zealand,Reliability,Secondary school teachers,Validity,Wellbeing},
  number = {1},
  pmid = {12658535}
}

@article{Miller1991,
  title = {Validation Techniques for Logistic Regression Models},
  author = {Miller, Michael E. and Hui, Siu L. and Tierney, William M.},
  year = {1991},
  month = aug,
  volume = {10},
  pages = {1213--1226},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/sim.4780100805},
  journal = {Statistics in Medicine},
  keywords = {\#nosource},
  number = {8}
}

@article{millerWhatPriceKaplanmeier1983,
  title = {What Price Kaplan-Meier?},
  author = {Miller, Jr Rupert G.},
  year = {1983},
  volume = {39},
  pages = {1077--1081},
  journal = {Biometrics},
  keywords = {\#nosource},
  number = {4}
}

@article{Mistry2011,
  title = {Cancer Incidence in the {{United Kingdom}}: Projections to the Year 2030},
  author = {Mistry, M and Parkin, D M and Ahmad, A S and Sasieni, P},
  year = {2011},
  volume = {105},
  pages = {1795--1803},
  publisher = {{Nature Publishing Group}},
  issn = {0007-0920},
  doi = {10.1038/bjc.2011.430},
  abstract = {BACKGROUND: Projections of cancer incidence are important for planning health services and to provide a baseline for assessing the impact of public health interventions. METHODS: Rates estimated from smooth function age-period-cohort modelling of cancer incidence data from Great Britain 1975 to 2007 are extrapolated to 2030 and applied to UK population projections. Prostate and breast cancer projections take into account the effect of screening. RESULTS: Overall rates of cancer are projected to be stable over the next 20 years, but this masks individual changes. In both sexes, age-standardised rates of cancers of the stomach, larynx, bladder and leukaemia are projected to fall by \textquestiondown/=1\% per year, whereas cancers of the lip, mouth and pharynx (ICD-10 C00-C14) and melanoma are projected to increase by \textquestiondown/=1\% per year. The growing and aging populations will have a substantial impact: numbers of cancers in men and women are projected to increase by 55\% (from 149,169 to 231,026) and 35\% (from 148,716 to 200,929), respectively, between 2007 and 2030. The model used yields similar results to those of Nordpred, but is more flexible. CONCLUSION: Without new initiatives for smoking and obesity reduction, the number of cancers in the United Kingdom will increase substantially reflecting the growing and aging populations.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RIK3LEGF\\mistry_et_al_2011_cancer_incidence_in_the_united_kingdom.pdf},
  isbn = {1532-1827 (Electronic){\r  }0007-0920 (Linking)},
  journal = {British Journal of Cancer},
  keywords = {80 and over,Adolescent,Adult,Age Factors,Aged,Child,Cohort Studies,Female,Forecasting,Great Britain/epidemiology,Humans,Male,Middle Aged,Neoplasms/*epidemiology,Public Health,Young Adult},
  number = {11},
  pmid = {22033277}
}

@article{Mnatzaganian2012,
  title = {Accuracy of Hospital Morbidity Data and the Performance of Comorbidity Scores as Predictors of Mortality},
  author = {Mnatzaganian, George and Ryan, Philip and Norman, Paul E. and Hiller, Janet E.},
  year = {2012},
  volume = {65},
  pages = {107--115},
  publisher = {{Elsevier Inc}},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2011.03.014},
  abstract = {Objectives: The main objectives of this study were to validate the hospital morbidity data (HMD) and to compare the performance of three comorbidity adjusting methods in predicting 1-year and 5-year all-cause mortality in a male general hospital population in Western Australia (WA). Study Design and Setting: Population-based data were integrated with WA-linked data system. Deyo-Charlson Index, Enhanced-Charlson Index, and Elixhauser's method measured comorbidity. Mortality was modeled using Cox regression, and model discrimination was assessed by Harrell's C statistics. Results: The HMD were most likely to identify major comorbidities, such as cancer, myocardial infarction, diabetes mellitus, and major operations. The presence of comorbidity was independently associated with an increased risk of adverse outcomes. All models achieved acceptable levels of discrimination (Harrell's C: 0.70-0.76). The Enhanced-Charlson Index matched the Deyo-Charlson Index in predicting mortality. Elixhauser's method outperformed the other two. Including information from past admissions achieved nonsignificant improvement in model discrimination. A dose-response effect was observed in the effect of repeated episodes on risk of 5-year mortality. Conclusion: Comorbidities diagnosed at different points in time may have different associations with the risk of adverse outcomes. More research is required to integrate the effect of repeated episodes in currently used methods that measure and adjust for comorbidity. \textcopyright{} 2012 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4KWGJFKG\\mnatzaganian_et_al_2012_accuracy_of_hospital_morbidity_data_and_the_performance_of_comorbidity_scores.pdf},
  isbn = {6188313066},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Charlson Comorbidity Index,Concordance of databases,Elixhauser comorbidities,Hospital morbidity data,Model fit,Mortality},
  number = {1},
  pmid = {21803545}
}

@article{Mnatzaganian2014,
  title = {Does Co-Morbidity Provide Significant Improvement on Age Adjustment When Predicting Medical Outcomes?},
  author = {Mnatzaganian, George and Ryan, P. and Hiller, J. E.},
  year = {2014},
  volume = {53},
  pages = {115--120},
  issn = {00261270},
  doi = {10.3414/ME13-01-0095},
  abstract = {OBJECTIVE: Using three risk-adjustment methods we evaluated whether co-morbidity derived from electronic hospital patient data provided significant improvement on age adjustment when predicting major outcomes following an elective total joint replacement (TJR) due to osteoarthritis. METHODS: Longitudinal data from 819 elderly men who had had a TJR were integrated with hospital morbidity data (HMD) and mortality records. For each participant, any morbidity or health-related outcome was retrieved from the linked data in the period 1970 through to 2007 and this enabled us to better account for patient co-morbidities. Co-morbidities recorded in the HMD in all admissions preceding the index TJR admission were used to construct three risk-adjustment methods, namely Charlson co-morbidity index (CCI), Elixhauser's adjustment method, and number of co-morbidities. Postoperative outcomes evaluated included length of hospital stay, 90-day readmission, and 1-year and 2-year mortality. These were modelled using Cox proportional hazards regression as a function of age for the baseline models, and as a function of age and each of the risk-adjustment methods. The difference in the statistical performance between the models that included age alone and those that also included the co-morbidity adjustment method was assessed by measuring the difference in the Harrell's C estimates between pairs of models applied to the same patient data using Bootstrap analysis with 1000 replications. RESULTS: Number of co-morbidities did not provide any significant improvement in model discrimination when added to baseline models observed in all outcomes. CCI significantly improved model discrimination when predicting post-operative mortality but not when length of stay or readmission was modelled. For every one point increase in CCI, postoperative 1- and 2-year mortality increased by 37\% and 30\%, respectively. Elixhauser's method outperformed the other two providing significant improvement on age adjustment in all outcomes. CONCLUSION: The predictive performance of co-morbidity derived from electronic hospital data is outcome and risk-adjustment method specific.},
  journal = {Methods of Information in Medicine},
  keywords = {\#nosource,Age,Co-morbidity adjustment method,Hospital morbidity data,Length of stay,Model discrimination,Mortality,Readmission},
  number = {2},
  pmid = {24514895}
}

@generic{Moeller1998,
  title = {Edward r. {{Tufte}}, Visual Explanations: {{Images}} and Quantities, Evidence and Narrative [{{Book}} Review]},
  author = {Moeller, E.W.},
  year = {1998},
  volume = {41},
  pages = {156--157},
  issn = {0361-1434},
  doi = {10.1109/TPC.1998.678564},
  abstract = {As a practitioner and researcher, I looked forward to reading Ed- ward Tufte's latest effort, Visual Explanations. Overall, the book is well written and well produced with many creative illustrations. There also are quite a few inter- esting ideas for those who create images which need to tell a story. Unfortunately, these ideas often get lost within the drawn-out dis- cussions of rehashed topics and misplaced information. Many of these ideas may be directly applied to online information. But I was disappointed that this application to online displays was not explored more thoroughly. The},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CJCIZ4ME\\moeller_1998_edward_r.pdf},
  isbn = {02768739},
  journal = {IEEE Transactions on Professional Communication},
  number = {2},
  pmid = {1659109}
}

@article{Mohaddes2017,
  title = {Use of Dual-Mobility Cup in Revision Hip Arthroplasty Reduces the Risk for Further Dislocation: Analysis of Seven Hundred and Ninety One First-Time Revisions Performed Due to Dislocation, Reported to the {{Swedish Hip Arthroplasty Register}}},
  author = {Mohaddes, Maziar and Cnudde, Peter and Rolfson, Ola and Wall, Alexander and K{\"a}rrholm, Johan},
  year = {2017},
  volume = {41},
  pages = {583--588},
  publisher = {{International Orthopaedics}},
  issn = {14325195},
  doi = {10.1007/s00264-016-3381-2},
  abstract = {PURPOSE Dislocation after total hip arthroplasty (THA) is a common reason for revision. The last decade fostered a significant increase in the use of dual-mobility cups (DMCs). Here we report our study on the short-term survival rate of a cemented DMC reported to the Swedish Hip Arthroplasty Register (SHAR) compared with other cemented designs used in first-time revision due to dislocation. METHODS During 2005-2015, 984 first-time revisions for dislocation were reported to SHAR. In 436 of these cases a cemented dual articular cup was used. During the same time period, 355 revisions performed with a standard cemented cup (femoral head size 28-36 mm) were reported to the SHAR. Patients receiving a DMC were slightly older (75 years, p = 0.005). Re-revision for all reasons was used as primary endpoint. We also anlaysed risk for re-revision of the acetabular component and re-revision due to dislocation. Kaplan-Meier implant survival and a Cox regression analyses adjusted for age and gender were performed. RESULTS Implant survival at 4 years for all reasons (91\% {$\pm$} 3.7\% vs 86\% {$\pm$} 4.1\%, p = 0.02), and especially for re-operation because of dislocation, favours the DMC group (96\% {$\pm$} 3.0\% vs 92\% {$\pm$} 3.3\%, p = 0.001). DISCUSSION Our findings indicate that use of a cemented DMC reduces the short- to mid-term risk of a second revision in first-time revisions compared with classic cup designs. Longer follow-up is needed to establish any long-term clinical advantages when DMCs are used in revisions performed due to dislocation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3Q4WT3CC\\mohaddes_et_al_2017_use_of_dual-mobility_cup_in_revision_hip_arthroplasty_reduces_the_risk_for.pdf},
  journal = {International Orthopaedics},
  keywords = {Dislocation,Register studies,Revision},
  number = {3},
  pmid = {28078362}
}

@article{mollerPredictionCancerIncidence2002,
  title = {Prediction of Cancer Incidence in the {{Nordic}} Countries up to the Year 2020},
  author = {M\o ller, Bj\o rn and Fekj\ae r, Harald and Hakulinen, Timo and Tryggvad{\'o}ttir, Laufey and Storm, Hans H and Talb{\"a}ck, Mats and Haldorsen, Tor},
  year = {2002},
  volume = {11},
  pages = {S1-S96},
  issn = {0959-8278},
  abstract = {Tel: (+44) 1256 882564; Tel/Fax: (+44) 1722 328885 Fax: (+44) 1256 880416 AIMS AND SCOPE With its fast publication of the latest developments and discoveries in this important field of medicine, the European Journal of Cancer Prevention aims to promote an increased awareness of all aspects of cancer prevention and to stimulate new ideas and innovations. The journal has a wide-ranging scope, covering such aspects as descriptive and metabolic epidemiology, histopathol-ogy, genetics, biochemistry, molecular biology, microbiology, clinical medicine, intervention trials and public education, basic laboratory studies and special group studies. European Journal of Cancer Prevention is the official journal of the European Cancer Prevention Organisation (ECP), which was formed in 1981 to exploit the wide range of cancer incidence, and exposure to numerous factors associated with increased cancer risk (eg diet, sunlight, exogenous hormones and cigarette smoking), within Europe in the study of the causation and prevention of human cancer.},
  isbn = {0959-8278},
  journal = {Eur J Cancer Prev.},
  keywords = {\#nosource},
  number = {Suppl},
  pmid = {12442806}
}

@article{mollerPredictionCancerIncidence2003,
  title = {Prediction of Cancer Incidence in the {{Nordic}} Countries: {{Empirical}} Comparison of Different Approaches},
  author = {M\o ller, Bj\o rn and Fekj\ae r, Harald and Hakulinen, Timo and Sigvaldason, Helgi and Storm, Hans H. and Talb{\"a}ck, Mats and Haldorsen, Tor},
  year = {2003},
  volume = {22},
  pages = {2751--2766},
  issn = {02776715},
  doi = {10.1002/sim.1481},
  abstract = {Prediction of the future number of cancer cases is of great interest to society. The classical approach is to use the age-period-cohort model for making cancer incidence predictions. We made an empirical comparison of different versions of this model, using data from cancer registries in the Nordic countries for the period 1958\textendash 1997. We have applied 15 different methods to 20 sites for each sex in Denmark, Finland, Norway and Sweden. Median absolute value of the relative difference between observed and predicted numbers of cases for these 160 combinations of site, sex and country was calculated. The medians varied between 10.4 per cent and 15.3 per cent in predictions 10 years ahead, and between 15.1 per cent and 32.0 per cent for 20 year predictions. We have four main conclusions: (i) projecting current trends worked better than assuming that future rates are equal to present rates; (ii) the method based on the multiplicative APC model often overestimated the number of cancer cases due to its exponential growth over time, but using a power function to level off this growth improved the predictions; (iii) projecting only half of the trend after the first 10 years also gave better long-term predictions; (iv) methods that emphasize trends in the last decade seem to perform better than those that include earlier time trends. Copyright \textcopyright{} 2003 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KESP27AI\\møller_et_al_2003_prediction_of_cancer_incidence_in_the_nordic_countries.pdf},
  isbn = {0959-8278},
  journal = {Statistics in Medicine},
  keywords = {Age-period-cohort model,Cancer incidence,Evaluation,Forecast,Prediction,Projection},
  number = {17},
  pmid = {12939784}
}

@techreport{mollerSvenskaFrakturregistretArsrapport2016,
  title = {Svenska Frakturregistret: {{\AA rsrapport}} 2015},
  author = {M{\"o}ller, Michael and Ekholm, Carl and Rogmark, Cecilia and B{\"o}gl, Hans Peter and Lagergren, Johan and L{\"o}nn, Katarina and Liljeros, Maria and Andersson, Mats and Sundfeldt, Mikael and Wolf, Olof and Morberg, Per and {\"O}stling, Simon and Backteman, Torsten and Ambring, Annelie and Eklund, Jan},
  year = {2016},
  pages = {89},
  institution = {{Svenska Frakturregistret}},
  issn = {1098-6596},
  city = {Gothenburg, Sweden},
  isbn = {0296847542},
  keywords = {\#nosource}
}

@article{moltoComorbidityIndices2014,
  title = {Comorbidity Indices},
  author = {Molt{\'o}, Anna and Dougados, Maxime},
  year = {2014},
  volume = {32},
  pages = {S131-S134},
  issn = {1593098X},
  abstract = {Comorbidities are conditions that coexist with a disease of interest, and may lead to a delayed diagnosis, be confounders in analysis of clinical status and course, and increase morbidity and mortality. Therefore, it appears desirable to summarise efficiently one or multiple comorbidities into a single score in an efficient manner, using comorbidity indices and self-administered comorbidity questionnaires. The two most commonly used comorbidity indices are the Charlson Comorbidity Index (CCI) and the Elixhauser et al. comorbidity measure (ECM). The CCI was constructed based on the mortality rates of 607 patients admitted to the general internal medicine service over 1 month; sixteen diseases were included in this index, with different weights, and were selected and weighted based on the strength of their association with mortality. Elixhauser et al. used administrative data to identify the 30 comorbidities that had a major impact on short-term outcomes in acutely hospitalised patients. Although ECM appeared to have better performance in all aspects of validity, difficulty in terms of feasibility in collecting 30 comorbidities may encourage investigators to use the CCI. Self-administered questionnaires could be a valid and reliable alternative approach to assess comorbidities, and a tool to be included in prospective studies.},
  isbn = {0392-856X (Print) 0392-856x},
  journal = {Clinical and Experimental Rheumatology},
  keywords = {\#nosource,Comorbidity,Indices},
  pmid = {25365102}
}

@article{Momohara2011,
  title = {Prosthetic Joint Infection after Total Hip or Knee Arthroplasty in Rheumatoid Arthritis Patients Treated with Nonbiologic and Biologic Disease-Modifying Antirheumatic Drugs},
  author = {Momohara, Shigeki and Kawakami, Kosei and Iwamoto, Takuji and Yano, Koichiro and Sakuma, Yu and Hiroshima, Ryo and Imamura, Hitoshi and Masuda, Ikuko and Tokita, Asami and Ikari, Katsunori},
  year = {2011},
  month = oct,
  volume = {21},
  pages = {469--475},
  issn = {1439-7595, 1439-7609},
  doi = {10.3109/s10165-011-0423-x},
  journal = {Modern Rheumatology},
  language = {en},
  number = {5}
}

@article{Montgomery1973,
  title = {A Note on Adjusting {{R2}}},
  author = {Montgomery, David B. and Morrison, Donald G.},
  year = {1973},
  volume = {28},
  pages = {1009--1013},
  journal = {American Finance Association},
  keywords = {\#nosource},
  number = {4}
}

@article{Mood2010,
  title = {Logistic Regression: {{Why}} We Cannot Do What We Think We Can Do, and What We Can Do about It},
  author = {Mood, C.},
  year = {2010},
  month = feb,
  volume = {26},
  pages = {67--82},
  publisher = {{Oxford University Press}},
  issn = {0266-7215},
  doi = {10.1093/esr/jcp006},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9BUXBCHA\\mood_2010_logistic_regression.pdf},
  journal = {European Sociological Review},
  number = {1}
}

@article{Moons2002,
  title = {Should Scoring Rules Be Based on Odds Ratios or Regression Coefficients?},
  author = {Moons, Karel G M and Harrell, Frank E and Steyerberg, Ewout W},
  year = {2002},
  volume = {55},
  pages = {1054--1055},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(02)00453-5},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WL84MWAI\\moons_et_al_2002_should_scoring_rules_be_based_on_odds_ratios_or_regression_coefficients.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {10}
}

@article{Moons2009,
  title = {Prognosis and Prognostic Research: What, Why, and How?},
  author = {Moons, K. G M and Royston, P. and Vergouwe, Y. and Grobbee, D. E and Altman, D. G},
  year = {2009},
  month = feb,
  volume = {338},
  pages = {b375-b375},
  issn = {0959-8138},
  doi = {10.1136/bmj.b375},
  journal = {BMJ: British Medical Journal},
  keywords = {\#nosource},
  number = {feb23 1}
}

@article{Moons2009a,
  title = {Prognosis and Prognostic Research: Application and Impact of Prognostic Models in Clinical Practice.},
  author = {Moons, Karel G M and Altman, Douglas G and Vergouwe, Yvonne and Royston, Patrick},
  year = {2009},
  month = jun,
  volume = {338},
  pages = {b606},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.b606},
  abstract = {An accurate prognostic model is of no benefit if it is not generalisable or doesn't change behaviour. In the last article in their series Karel Moons and colleagues discuss how to determine the practical value of models Prognostic models are developed to be applied in new patients, who may come from different centres, countries, or times. Hence, new patients are commonly referred to as different from but similar to the patients used to develop the models.1 2 3 4 But what exactly does this mean? When can a new patient population be considered similar (enough) to the development population to justify validation and eventually application of a model? We have already considered the design, development, and validation of prognostic research and models.5 6 7 In the final article of our series, we discuss common limitations to the application and generalisation of prognostic models and what evidence beyond validation is needed before practitioners can confidently apply a model to their patients. These issues also apply to prediction models with a diagnostic outcome (presence of a disease). \#\#\#\# Summary points \#\#\# Extrapolation versus validation Most prediction models are developed in secondary care, and it is common to want to \ldots},
  journal = {BMJ (Clinical research ed.)},
  keywords = {\#nosource},
  pmid = {19502216}
}

@article{Moons2014,
  title = {Critical {{Appraisal}} and {{Data Extraction}} for {{Systematic Reviews}} of {{Prediction Modelling Studies}}: {{The CHARMS Checklist}}},
  shorttitle = {Critical {{Appraisal}} and {{Data Extraction}} for {{Systematic Reviews}} of {{Prediction Modelling Studies}}},
  author = {Moons, Karel G. M. and de Groot, Joris A. H. and Bouwmeester, Walter and Vergouwe, Yvonne and Mallett, Susan and Altman, Douglas G. and Reitsma, Johannes B. and Collins, Gary S.},
  year = {2014},
  month = oct,
  volume = {11},
  pages = {e1001744},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001744},
  abstract = {Carl Moons and colleagues provide a checklist and background explanation for critically appraising and extracting data from systematic reviews of prognostic and diagnostic prediction modelling studies. Please see later in the article for the Editors' Summary},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HUCTMG37\\Moons m. fl. - 2014 - Critical Appraisal and Data Extraction for Systema.pdf;C\:\\Users\\erik_\\Zotero\\storage\\DWZXIF6V\\article.html},
  journal = {PLOS Medicine},
  keywords = {acta review,Breast cancer,Cancer detection and diagnosis,Diagnostic medicine,Forecasting,Machine learning,Research reporting guidelines,Systematic reviews,Type 2 diabetes},
  language = {en},
  number = {10}
}

@article{Moore2017,
  title = {Identifying Increased Risk of Readmission and In-Hospital Mortality Using Hospital Administrative Data},
  author = {Moore, Brian J. and White, Susan and Washington, Raynard and Coenen, Natalia and Elixhauser, Anne},
  year = {2017},
  month = jul,
  volume = {55},
  pages = {698--705},
  issn = {0025-7079},
  doi = {10.1097/MLR.0000000000000735},
  journal = {Medical Care},
  keywords = {\#nosource},
  number = {7}
}

@article{Morabia2013,
  title = {Epidemiology's 350th Anniversary: 1662-2012},
  author = {Morabia, Alfredo},
  year = {2013},
  month = mar,
  volume = {24},
  pages = {179--183},
  issn = {1531-5487},
  doi = {10.1097/EDE.0b013e31827b5359},
  abstract = {Between 1600 and 1700, sudden, profound, and multifarious changes occurred in philosophy, science, medicine, politics, and society. In an extremely convulsed century, these profound and convergent upheavals produced the equivalent of a cultural big bang, which opened a new domain of knowledge acquisition based on population thinking and group comparisons. In 1662, when John Graunt applied-for the first time-the new approach to the analysis of causes of death in London, he gave epidemiology a singular date of birth. This was exactly 350 years ago.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HRNIJPYR\\morabia_2013_epidemiology's_350th_anniversary.pdf},
  journal = {Epidemiology (Cambridge, Mass.)},
  number = {2}
}

@article{Morey2016,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D. and Hoekstra, Rink and Rouder, Jeffrey N. and Lee, Michael D. and Wagenmakers, Eric Jan},
  year = {2016},
  volume = {23},
  pages = {103--123},
  issn = {15315320},
  doi = {10.3758/s13423-015-0947-8},
  abstract = {Traditional Null Hypothesis Testing procedures are poorly adapted to theory testing. The methodology can mislead researchers in several ways, including: (a) a lack of power can result in an erroneous rejection of the theory; (b) the focus on directionality (ordinal tests) rather than more precise quantitative predictions limits the information gained; and (c) the misuse of probability values to indicate effect size. An alternative approach is proposed which involves employing the theory to generate explicit effect size predictions that are compared to the effect size estimates and related confidence intervals to test the theoretical predictions. This procedure is illustrated employing the Transtheoretical Model. Data from a sample (N = 3,967) of smokers from a large New England HMO system were used to test the model. There were a total of 15 predictions evaluated, each involving the relation between Stage of Change and one of the other 15 Transtheoretical Model variables. For each variable, omega-squared and the related confidence interval were calculated and compared to the predicted effect sizes. Eleven of the 15 predictions were confirmed, providing support for the theoretical model. Quantitative predictions represent a much more direct, informative, and strong test of a theory than the traditional test of significance.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FFYQZNIL\\morey_et_al_2016_the_fallacy_of_placing_confidence_in_confidence_intervals.pdf},
  isbn = {1069-9384},
  journal = {Psychonomic Bulletin and Review},
  keywords = {Bayesian inference and parameter estimation,Bayesian statistics,Statistical inference,Statistics},
  number = {1},
  pmid = {22837590}
}

@article{Morgan2018,
  title = {Reducing Bias Using Propensity Score Matching},
  author = {Morgan, Charity J.},
  year = {2018},
  volume = {25},
  pages = {404--406},
  publisher = {{Springer US}},
  issn = {15326551},
  doi = {10.1007/s12350-017-1012-y},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9WXW46DI\\morgan_2018_reducing_bias_using_propensity_score_matching.pdf},
  journal = {Journal of Nuclear Cardiology},
  number = {2}
}

@article{Morgenstern1982,
  title = {A {{METHOD FOR USING EPIDEMIOLOGIC DATA TO ESTIMATE THE POTENTIAL IMPACT OF AN INTERVENTION ON THE HEALTH STATUS OF A TARGET POPULATION}}},
  author = {Morgenstern, Hal and Bursic, Elaine S},
  year = {1982},
  volume = {7},
  pages = {292--309},
  isbn = {1400029252},
  journal = {Journal of Community Health},
  keywords = {\#nosource},
  number = {4}
}

@book{Moriyama2011,
  title = {History of the Statistical Classification of Diseases and Causes of Death (2011)},
  author = {Moriyama, Iwao M. and Loy, Ruth M. and {Robb-Smith}, Alastair H. T.},
  year = {2011},
  abstract = {This report describes the historic development of the disease nomenclatures and classifications that ultimately became the major international standard known as the World Health Organization's (WHO) International Classification of Diseases (ICD). Written largely at the initiative of Dr. Iwao Moriyama, a participant in these developments for much of the 20th century, the report describes the historical, cultural, and scientific environment in which ICD evolved, expanded, and improved. Although the report focuses on the application of ICD to mortality, it also touches on nonmortality applications, particularly as these affected the classification for mortality.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ET8CV23V\\moriyama_et_al_2011_history_of_the_statistical_classification_of_diseases_and_causes_of_death_(2011).pdf},
  isbn = {978-0-8406-0644-0},
  keywords = {Causes,Death,Diseases}
}

@article{Mortensen2014,
  title = {Association of Azithromycin with Mortality and Cardiovascular Events among Older Patients Hospitalized with Pneumonia},
  author = {Mortensen, Eric M. and Halm, Ethan A. and Pugh, Mary Jo and Copeland, Laurel A. and Metersky, Mark and Fine, Michael J. and Johnson, Christopher S. and Alvarez, Carlos A. and Frei, Christopher R. and Good, Chester and Restrepo, Marcos I. and Downs, John R. and Anzueto, Antonio},
  year = {2014},
  volume = {311},
  pages = {2199},
  issn = {0098-7484},
  doi = {10.1001/jama.2014.4304},
  abstract = {IMPORTANCE: Although clinical practice guidelines recommend combination therapy with macrolides, including azithromycin, as first-line therapy for patients hospitalized with pneumonia, recent research suggests that azithromycin may be associated with increased cardiovascular events. OBJECTIVE: To examine the association of azithromycin use with all-cause mortality and cardiovascular events for patients hospitalized with pneumonia. DESIGN: Retrospective cohort study comparing older patients hospitalized with pneumonia from fiscal years 2002 through 2012 prescribed azithromycin therapy and patients receiving other guideline-concordant antibiotic therapy. SETTING: This study was conducted using national Department of Veterans Affairs administrative data of patients hospitalized at any Veterans Administration acute care hospital. PARTICIPANTS: Patients were included if they were aged 65 years or older, were hospitalized with pneumonia, and received antibiotic therapy concordant with national clinical practice guidelines. MAIN OUTCOMES AND MEASURES: Outcomes included 30- and 90-day all-cause mortality and 90-day cardiac arrhythmias, heart failure, myocardial infarction, and any cardiac event. Propensity score matching was used to control for the possible effects of known confounders with conditional logistic regression. RESULTS: Of 73,690 patients from 118 hospitals identified, propensity-matched groups were composed of 31,863 patients exposed to azithromycin and 31,863 matched patients who were not exposed. There were no significant differences in potential confounders between groups after matching. Ninety-day mortality was significantly lower in those who received azithromycin (exposed, 17.4\%, vs unexposed, 22.3\%; odds ratio [OR], 0.73; 95\% CI, 0.70-0.76). However, we found significantly increased odds of myocardial infarction (5.1\% vs 4.4\%; OR, 1.17; 95\% CI, 1.08-1.25) but not any cardiac event (43.0\% vs 42.7\%; OR, 1.01; 95\% CI, 0.98-1.05), cardiac arrhythmias (25.8\% vs 26.0\%; OR, 0.99; 95\% CI, 0.95-1.02), or heart failure (26.3\% vs 26.2\%; OR, 1.01; 95\% CI, 0.97-1.04). CONCLUSIONS AND RELEVANCE: Among older patients hospitalized with pneumonia, treatment that included azithromycin compared with other antibiotics was associated with a lower risk of 90-day mortality and a smaller increased risk of myocardial infarction. These findings are consistent with a net benefit associated with azithromycin use.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\D832EFE7\\mortensen_et_al_2014_association_of_azithromycin_with_mortality_and_cardiovascular_events_among.pdf},
  isbn = {10849513},
  journal = {Jama},
  number = {21},
  pmid = {24893087}
}

@article{Mosimann2014,
  title = {Biometrika Trust},
  author = {Mosimann, James E},
  year = {2014},
  volume = {72},
  pages = {241--252},
  keywords = {\#nosource},
  number = {2}
}

@article{Mouchti2018,
  title = {The Association of Body Mass Index with Risk of Long-Term Revision and 90-{{Day}} Mortality Following Primary Total Hip Replacement},
  author = {Mouchti, Sofia and Whitehouse, Michael R. and Sayers, Adrian and Hunt, Linda P. and MacGregor, Alexander and Blom, Ashley W.},
  year = {2018},
  month = dec,
  volume = {100},
  pages = {2140--2152},
  publisher = {{Lippincott Williams and Wilkins}},
  issn = {0021-9355},
  doi = {10.2106/JBJS.18.00120},
  abstract = {The influence of obesity on outcomes following total hip replacement is unclear. Restriction of total hip replacement on the basis of body mass index (BMI) has been suggested. The purpose of this study was to assess the influence of BMI on the risk of revision and 90-day mortality.Methods:This was a population-based, longitudinal cohort study of the National Joint Registry (NJR) for England, Wales, Northern Ireland and the Isle of Man. Using data recorded from April 2003 to December 2015, linked to Office for National Statistics data, we ascertained revision and 90-day mortality rates following primary total hip replacement by BMI category. The probability of revision was estimated using Kaplan-Meier methods. Associations of BMI with revision and mortality were explored using adjusted Cox proportional hazards regression models.Results:We investigated revision and 90-day mortality among 415,598 and 413,741 primary total hip replacements, respectively. Each data set accounts for approximately 52\% of the total number of recorded operations in the NJR. Thirty-eight percent of the patients were classified as obese. At 10 years, class-III obese patients had the highest cumulative probability of revision (6.7\% [95\% confidence interval (CI), 5.5\% to 8.2\%]), twice that of the underweight group (3.3\% [95\% CI, 2.2\% to 4.9\%]). When the analysis was adjusted for age, sex, American Society of Anesthesiologists [ASA] grade, year of operation, indication, and fixation type, compared with patients with normal BMI, significantly elevated hazard ratios (HRs) for revision were observed for patients in the BMI categories of class-I obese ({$\geq$}30 to \textexclamdown 35 kg/m2) (HR, 1.14 [95\% CI, 1.07 to 1.22]), class-II obese ({$\geq$}35 to \textexclamdown 40 kg/m2) (HR, 1.30 [95\% CI, 1.19 to 1.40]), and class-III obese ({$\geq$}40 to {$\leq$}60 kg/m2) (HR, 1.43 [95\% CI, 1.27 to 1.61]) (p \textexclamdown{} 0.0005 for all). Underweight patients had a substantially higher cumulative probability of 90-day mortality (1.17\%; 95\% CI, 0.86\% to 1.58\%) compared with patients with normal BMI (0.43\%; 95\% CI, 0.39\% to 0.48\%). The risk of 90-day mortality was significantly higher for the underweight group (HR, 2.09 [95\% CI, 1.51 to 2.89]; p \textexclamdown{} 0.0005) and significantly lower for patients who were categorized as overweight (HR, 0.70; 95\% CI, 0.61 to 0.81; p \textexclamdown{} 0.0005), class-I obese (HR, 0.69 [95\% CI, 0.59 to 0.81]; p \textexclamdown{} 0.0005), and class-II obese (HR, 0.79 [95\% CI, 0.63 to 0.98]; p = 0.049) compared with patients with normal BMI.Conclusions:Although long-term revision rates following total hip replacement were higher among obese patients, we believe that the rates remained acceptable by contemporary standards and were balanced by a lower risk of 90-day mortality.Level of Evidence:Prognostic Level III. See Instructions for Authors for a complete description of levels of evidence.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZGYE84G4\\mouchti_et_al_2018_the_association_of_body_mass_index_with_risk_of_long-term_revision_and_90-day.pdf},
  journal = {The Journal of Bone and Joint Surgery},
  number = {24}
}

@article{Mraovic2011,
  title = {Perioperative {{Hyperglycemia}} and {{Postoperative Infection}} after {{Lower Limb Arthroplasty}}},
  author = {Mraovic, Boris and Suh, Donghun and Jacovides, Christina and Parvizi, Javad},
  year = {2011},
  month = mar,
  volume = {5},
  pages = {412--418},
  issn = {1932-2968, 1932-2968},
  doi = {10.1177/193229681100500231},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2HZIHV86\\Mraovic et al_2011_Perioperative Hyperglycemia and Postoperative Infection after Lower Limb.pdf},
  journal = {Journal of Diabetes Science and Technology},
  language = {en},
  number = {2}
}

@article{Ms1993,
  title = {Kaplan-{{Meier}}, Marginal or Conditional Probability Curves in Summarizing Competing Risks Failure Time Data?},
  author = {Ms, Pepe and Mori, M},
  year = {1993},
  volume = {12},
  pages = {737--751},
  abstract = {In the context of competing risks the Kaplan-Meier estimator is often unsuitable for summarizing failure time data. We discuss some alternative descriptive methods including marginal probability and conditional probability estimators. Two-sample test statistics are also presented.},
  isbn = {2019031108},
  journal = {Statistics in medicine},
  keywords = {\#nosource},
  number = {8}
}

@article{Muff2016,
  title = {Marginal or Conditional Regression Models for Correlated Non-Normal Data?},
  author = {Muff, Stefanie and Held, Leonhard and Keller, Lukas F.},
  year = {2016},
  volume = {7},
  pages = {1514--1524},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12623},
  abstract = {Correlated data are ubiquitous in ecological and evolutionary research, and appropriate statistical analysis requires that these correlations are taken into account. For regressions with correlated, non-normal outcomes, two main approaches are used: conditional and marginal modelling. The former leads to generalized linear mixed models (GLMMs), while the latter are estimated using generalized estimating equations (GEEs), or marginalized multilevel regression models. Differences, advantages and drawbacks of conditional and marginal models have been discussed extensively in the statistical and applied literature, and there is some agreement that the choice of the model must depend on the question under study. Yet, there still appears to be a lot of confusion and disagreement over when to choose which model. We start with a review of conditional and marginal models, and the differences in the interpretation of the resulting parameter estimates. We highlight that the two types of models propagate different linear relations between the covariates and the response. Moreover, while conditional models explicitly account for heterogeneity among clustered observations, marginal models yield averages over such heterogeneities and are therefore often interpreted as population-averaged models. We point out theoretically and with an example that when modelling non-normal outcomes no unambiguous definition of a marginal model generally exists. Instead, marginal model parameters are marginal only with respect to unaccounted differences among clusters and thus depend on the fixed effects in the model. Therefore, marginal model parameters should not be loosely interpreted as population-averaged parameters. In addition, we explain how marginal modelling is mathematically analogous to deliberately omitting covariates with explanatory power, and to deliberately introducing a Berkson measurement error into covariates. We also reiterate that marginal modelling is related to a well-known statistical phenomenon, the Simpson's paradox. In most cases, therefore, we regard the conditional model as the more powerful choice to explain how covariates are associated with a non-normal response. Still, marginal models can be useful, given that the scientific question explicitly requires such a model formulation.},
  copyright = {\textcopyright{} 2016 The Authors. Methods in Ecology and Evolution \textcopyright{} 2016 British Ecological Society},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5F8XQMYQ\\2041-210X.12623.pdf;C\:\\Users\\erik_\\Zotero\\storage\\LPKA7H26\\Muff m. fl. - 2016 - Marginal or conditional regression models for corr.pdf;C\:\\Users\\erik_\\Zotero\\storage\\PFK8DBVI\\2041-210X.html},
  journal = {Methods in Ecology and Evolution},
  keywords = {attenuation,Berkson measurement error,conditional model,generalized estimating equations,generalized linear mixed model,omitted covariates,Simpson's paradox},
  language = {en},
  number = {12}
}

@article{Muggeo2003,
  title = {Estimating Regression Models with Unknown Break-Points},
  author = {Muggeo, Vito M R},
  year = {2003},
  volume = {22},
  pages = {3055--3071},
  issn = {02776715},
  doi = {10.1002/sim.1545},
  abstract = {This paper deals with fitting piecewise terms in regression models where one or more break-points are true parameters of the model. For estimation, a simple linearization technique is called for, taking advantage of the linear formulation of the problem. As a result, the method is suitable for any regression model with linear predictor and so current software can be used; threshold modelling as function of explanatory variables is also allowed. Differences between the other procedures available are shown and relative merits discussed. Simulations and two examples are presented to illustrate the method.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E4SKWEV9\\muggeo_2003_estimating_regression_models_with_unknown_break-points.pdf},
  isbn = {1097-0258},
  journal = {Statistics in Medicine},
  keywords = {Break-point,Non-linear model,Segmented regression,Taylor expansion,Threshold value},
  number = {19},
  pmid = {12973787}
}

@article{Muggeo2008,
  title = {Segmented: {{An}} r Package to Fit Regression Models with Broken-Line Relationships},
  author = {Muggeo, Vito M R},
  year = {2008},
  volume = {8},
  pages = {20--25},
  issn = {16093631},
  doi = {10.1159/000323281},
  abstract = {Segmented or broken-line models are regression models where the relationships between the response and one or more explanatory variables are piecewise linear, namely represented by two or more straight lines connected at unknown values: these values are usually referred as breakpoints, changepoints or even joinpoints. Hereafter we use such words indistinctly. Broken-line relationships are common in many fields, including epidemiology, occupational medicine, toxicology, and ecology, where sometimes it is of interest to assess threshold value where the effect of the covariate changes (Ulm, 1991; Betts et al., 2007).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ACWZ3IRY\\muggeo_2008_segmented.pdf},
  isbn = {0387947256},
  journal = {R News},
  number = {May},
  pmid = {21196786}
}

@article{Muggeo2010,
  title = {Efficient Change Point Detection for Genomic Sequences of Continuous Measurements},
  author = {Muggeo, Vito M.R. R and Adelfio, Giada},
  year = {2010},
  volume = {27},
  pages = {161--166},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btq647},
  abstract = {MOTIVATION: Knowing the exact locations of multiple change points in genomic sequences serves several biological needs, for instance when data represent aCGH profiles and it is of interest to identify possibly damaged genes involved in cancer and other diseases. Only a few of the currently available methods deal explicitly with estimation of the number and location of change points, and moreover these methods may be somewhat vulnerable to deviations of model assumptions usually employed. RESULTS: We present a computationally efficient method to obtain estimates of the number and location of the change points. The method is based on a simple transformation of data and it provides results quite robust to model mis-specifications. The efficiency of the method guarantees moderate computational times regardless of the series length and the number of change points. AVAILABILITY: The methods described in this paper are implemented in the new R package cumSeg available from the Comprehensive R Archive Network at http://CRAN.R-project.org/package=cumSeg. CONTACT: vito.muggeo@unipa.it.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VTIAUTI9\\muggeo_adelfio_2010_efficient_change_point_detection_for_genomic_sequences_of_continuous.pdf},
  journal = {Bioinformatics},
  number = {2},
  pmid = {21088029}
}

@article{Mukaka2012,
  title = {Statistics Corner: {{A}} Guide to Appropriate Use of Correlation Coefficient in Medical Research},
  author = {Mukaka, M. M.},
  year = {2012},
  volume = {24},
  pages = {69--71},
  issn = {19957262},
  abstract = {Correlation is a statistical method used to assess a possible linear association between two continuous variables. It is simple both to calculate and to interpret. However, misuse of correlation is so common among researchers that some statisticians have wished that the method had never been devised at all. The aim of this article is to provide a guide to appropriate use of correlation in medical research and to highlight some misuse. Examples of the applications of the correlation coefficient have been provided using data from statistical simulations as well as real data. Rule of thumb for interpreting size of a correlation coefficient has been provided.},
  journal = {Malawi Medical Journal},
  keywords = {\#nosource},
  number = {3},
  pmid = {23638278}
}

@article{Murphy2008,
  title = {Lifetime Risk of Symptomatic Knee Osteoarthritis},
  author = {Murphy, Louise and Schwartz, Todd A. and Helmick, Charles G. and Renner, Jordan B. and Tudor, Gail and Koch, Gary and Dragomir, Anca and Kalsbeek, William D. and Luta, Gheorghe and Jordan, Joanne M.},
  year = {2008},
  volume = {59},
  pages = {1207--1213},
  issn = {21514658},
  doi = {10.1002/art.24021},
  abstract = {OBJECTIVE: To estimate the lifetime risk of symptomatic knee osteoarthritis (OA), overall and stratified by sex, race, education, history of knee injury, and body mass index (BMI).: The lifetime risk of symptomatic OA in at least 1 knee was estimated from logistic regression models with generalized estimating equations among 3,068 participants of the Johnston County Osteoarthritis Project, a longitudinal study of black and white women and men age \textquestiondown or=45 years living in rural North Carolina. Radiographic, sociodemographic, and symptomatic knee data measured at baseline (1990-1997) and first followup (1999-2003) were analyzed.: The lifetime risk of symptomatic knee OA was 44.7\% (95\% confidence interval [95\% CI] 40.0-49.3\%). Cohort members with history of a knee injury had a lifetime risk of 56.8\% (95\% CI 48.4-65.2\%). Lifetime risk rose with increasing BMI, with a risk of 2 in 3 among those who were obese.: Nearly half of the adults in Johnston County will develop symptomatic knee OA by age 85 years, with lifetime risk highest among obese persons. These current high risks in Johnston County may suggest similar risks in the general US population, especially given the increase in 2 major risk factors for knee OA, aging, and obesity. This underscores the immediate need for greater use of clinical and public health interventions, especially those that address weight loss and self-management, to reduce the impact of having knee OA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CUPKVB2L\\murphy_et_al_2008_lifetime_risk_of_symptomatic_knee_osteoarthritis.pdf},
  isbn = {0004-3591 (Print){\r  }0004-3591 (Linking)},
  journal = {Arthritis Care and Research},
  number = {9},
  pmid = {18759314}
}

@article{Murray1993,
  title = {Survival Analysis of Joint Replacements.},
  author = {Murray, D W and Carr, a J and Bulstrode, C},
  year = {1993},
  volume = {75},
  pages = {697--704},
  issn = {0301-620X},
  abstract = {Survival analysis is a powerful tool for analysing the results of total joint replacement, but it has major drawbacks when the failure rates are very low. We have reviewed 35 recent survival analyses of joint replacements to assess the magnitude of these problems and make recommendations as to how they may be avoided.},
  isbn = {0301-620X (Print){\r  }0301-620X (Linking)},
  journal = {The Journal of bone and joint surgery. British volume},
  keywords = {\#nosource},
  number = {5},
  pmid = {8376423}
}

@book{Musahl2019,
  title = {A Practical Guide and Case Based Research Approach Basic Methods Handbook for Clinical Orthopaedic Research},
  author = {Musahl, Volker and Karlsson, J{\'o}n and Hirschmann, Michael T and Ayeni, Olufemi R and Marx, Robert G and Koh, Jason L and Nakamura, Norimasa},
  year = {2019},
  keywords = {\#nosource}
}

@article{Muskus2018,
  title = {Bilateral Hip Arthroplasty: {{When}} Is It Safe to Operate the Second Hip? {{A}} Systematic Review.},
  author = {Muskus, Meilyn and Rojas, Jorge and Guti{\'e}rrez, Camilo and Guio, Juan and Bonilla, Guillermo and Llin{\'a}s, Adolfo},
  year = {2018},
  volume = {2018},
  pages = {3150349},
  publisher = {{Hindawi Limited}},
  issn = {2314-6141},
  doi = {10.1155/2018/3150349},
  abstract = {Introduction Patients with degenerative hip disease frequently present with bilateral involvement that requires surgical management. The main goal when treating these patients is to achieve the maximum efficiency without increasing risk of perioperative complications; therefore, the decision regarding the best moment to operate the second hip becomes relevant. Although studies have addressed this topic, whether a simultaneous or staged surgery should be performed remains controversial. The purpose of this study was to determine, based on available evidence, the optimum strategy in terms of safety to operate the second hip in patients with bilateral involvement. Materials and Methods A meta-analysis was planned. A systematic review of the literature was performed including clinical trials or observational analytical studies comparing the safety of bilateral arthroplasty performed simultaneously or staged by measuring major and minor complications. The appropriateness of a meta-analysis was evaluated through the detailed analysis of the risk of bias and clinical heterogeneity of the included studies. Results Thirteen studies were selected after the systematic review. A wide variability in the methodological designs was found with a critical risk of bias in most of them. Considerable heterogeneity was detected in defining staged surgery in the cointerventions and how the outcomes were defined and measured. In response to these findings, a meta-analysis was considered not appropriate. The results showed no differences in the risk of mortality or systemic complications in young and healthy patients between simultaneous or staged surgeries. However, increased risk of complications for staged surgeries performed during the same hospitalization was observed. Conclusions Available evidence is very heterogeneous and the quality of evidence is low. The available evidence supports the performance of simultaneous hip arthroplasty in selected patients (not older than 65 years, ASA 1-2, without cardiovascular comorbidities) and suggests the avoidance of staged surgeries within the same hospitalization.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\97MRXRL9\\muskus_et_al_2018_bilateral_hip_arthroplasty.pdf},
  journal = {BioMed research international},
  pmid = {29682533}
}

@book{Must2000,
  title = {The Disease Burden Associated with Overweight and Obesity},
  author = {Must, Aviva and McKeown, Nicola M},
  year = {2000},
  abstract = {Many epidemiological studies have considered the impact of increasing body weight, body mass index (BMI), and other anthropometric measurements on the risk of chronic disease (1, 2), including coronary heart disease (CHD), type 2 diabetes mellitus (T2DM), hypertension, stroke, and cancers of the breast, endometrium, and colon (3, 4). Because body fat distribution is linked to obesity and is of particular importance in the etiology of certain chronic diseases, this chapter provides the reader with an overview of the epidemiological evidence linking both excess body weight and body fat distribution to the risk of several chronic diseases in adults. This chapter complements Chapter 1, in which the indicators of obesity are covered in detail, and Chapter 13, which provides a full discussion of the pathophysiology of obesity-related health conditions.},
  keywords = {\#nosource},
  pmid = {25905320}
}

@article{Nachega2015,
  title = {Association between Antiretroviral Therapy Adherence and Employment Status: Systematic Review and Meta-Analysis},
  author = {Nachega, Jean B and Uthman, Olalekan A and Peltzer, Karl and Richardson, Lindsey A and Mills, Edward J and Amekudzi, Kofi and Ou{\'e}draogo, Alice},
  year = {2015},
  month = jan,
  volume = {93},
  pages = {29--41},
  publisher = {{World Health Organization}},
  issn = {0042-9686},
  doi = {10.2471/BLT.14.138149},
  abstract = {Objective To assess the association between the employment status of human immunodeficiency virus (HIV)-infected individuals and adherence to antiretroviral therapy (ART). Methods We searched the Medline, Embase and Cochrane Central Register of Controlled Trials databases for studies reporting ART adherence and employment status published between January 1980 and September 2014. Information from a wide range of other sources, including the grey literature, was also analysed. Two independent reviewers extracted data on treatment adherence and study characteristics. Study data on the association between being employed and adhering to ART were pooled using a random-effects model. Between-study heterogeneity and sources of bias were evaluated. Findings The meta-analysis included 28 studies published between 1996 and 2014 that together involved 8743 HIV-infected individuals from 14 countries. The overall pooled odds ratio (OR) for the association between being employed and adhering to ART was 1.27 (95\% confidence interval, CI: 1.04\textendash 1.55). The association was significant for studies from low-income countries (OR: 1.85, 95\% CI: 1.58\textendash 2.18) and high-income countries (OR: 1.33, 95\% CI: 1.02\textendash 1.74) but not middle-income countries (OR: 0.94, 95\% CI: 0.62\textendash 1.42). In addition, studies published after 2011 and larger studies showed less association between employment and adherence than earlier and small studies, respectively. Conclusion Employed HIV-infected individuals, particularly those in low- and high-income countries, were more likely to adhere to ART than unemployed individuals. Further research is needed on the mechanisms by which employment and ART adherence affect each other and on whether employment-creation interventions can positively influence ART adherence, HIV disease progression and quality of life.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DP3JFJRE\\nachega_et_al_2015_association_between_antiretroviral_therapy_adherence_and_employment_status.pdf},
  journal = {Bulletin of the World Health Organization},
  number = {1}
}

@article{Nadarajah2003,
  title = {Reliability for Lifetime Distributions},
  author = {Nadarajah, S.},
  year = {2003},
  volume = {37},
  pages = {683--688},
  issn = {08957177},
  doi = {10.1016/S0895-7177(03)00074-8},
  abstract = {In the area of stress-strength models, there has been a large amount of work as regards estimation of the reliability R = Pr (X2 \textexclamdown{} X1) when X1 and X2 are independent random variables belonging to the same univariate family of distributions. The algebraic form for R = Pr (X2 \textexclamdown{} X1) has been worked out for the majority of the well-known distributions including normal, uniform, exponential, gamma, Weibull, and Pareto. However, there are still many other distributions for which the form of R is not known. We have identified at least some 30 distributions with no known form for R. In this paper, we consider the class of lift-time distributions (in particular, exponential and gamma) and derive the corresponding forms for the reliability R. The calculations involve the use of various special functions. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SWAU6NGD\\nadarajah_2003_reliability_for_lifetime_distributions.pdf},
  journal = {Mathematical and Computer Modelling},
  keywords = {Exponential distributions,Gamma distributions,Hypergeometric functions,Incomplete beta function,Incomplete gamma function,Reliability},
  number = {7-8}
}

@article{Nagelkerke1991,
  title = {A Note on a General Definition of the Coefficient of Determination},
  author = {Nagelkerke, N. J D},
  year = {1991},
  volume = {78},
  pages = {691--692},
  issn = {00063444},
  doi = {10.1093/biomet/78.3.691},
  abstract = {A generalization of the coefficient of determination R2 to general regression models is discussed. A modification of an earlier definition to allow for discrete models is proposed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IR32NM9N\\nagelkerke_1991_a_note_on_a_general_definition_of_the_coefficient_of_determination.pdf},
  isbn = {0006-3444},
  journal = {Biometrika},
  keywords = {Discrete probability,Log likelihood,Multiple correlation coefficient,Regression model,Residual variation},
  number = {3},
  pmid = {339}
}

@article{Naghavi2015,
  title = {Global, Regional, and National Age-Sex Specific All-Cause and Cause-Specific Mortality for 240 Causes of Death, 1990-2013: {{A}} Systematic Analysis for the {{Global Burden}} of {{Disease Study}} 2013},
  author = {Naghavi, Mohsen and Wang, Haidong and Lozano, Rafael and Davis, Adrian and Liang, Xiaofeng and Zhou, Maigeng and Vollset, Stein Emil and Ozgoren, Ayse Abbasoglu and Abdalla, Safa and {Abd-Allah}, Foad and Aziz, Muna I. Abdel and Abera, Semaw Ferede and Aboyans, Victor and Abraham, Biju and Abraham, Jerry P. and Abuabara, Katrina E. and Abubakar, Ibrahim and {Abu-Raddad}, Laith J. and {Abu-Rmeileh}, Niveen M.E. and Achoki, Tom and Adelekan, Ademola and Ademi, Zanfina and Adofo, Koranteng and Adou, Ars{\'e}ne Kouablan and Adsuar, Jos{\'e} C. and {\"A}rnlov, Johan and Agardh, Emilie Elisabet and Akena, Dickens and Khabouri, Mazin J. Al and Alasfoor, Deena and Albittar, Mohammed and Alegretti, Miguel Angel and Aleman, Alicia V. and Alemu, Zewdie Aderaw and {Alfonso-Cristancho}, Rafael and Alhabib, Samia and Ali, Mohammed K. and Ali, Raghib and Alla, Francois and Lami, Faris Al and Allebeck, Peter and AlMazroa, Mohammad A. and Salman, Rustam Al-Shahi and Alsharif, Ubai and Alvarez, Elena and {Alviz-Guzman}, Nelson and Amankwaa, Adansi A. and Amare, Azmeraw T. and Ameli, Omid and Amini, Hassan and Ammar, Walid and Anderson, H. Ross and Anderson, Benjamin O. and Antonio, Carl Abelardo T. and Anwari, Palwasha and Apfel, Henry and Cunningham, Solveig Argeseanu and Arsenijevic, Valentina S. Arsic and Artaman, Al and Asad, Majed Masoud and Asghar, Rana J. and Assadi, Reza and Atkins, Lydia S. and Atkinson, Charles and Badawi, Alaa and Bahit, Maria C. and Bakfalouni, Talal and Balakrishnan, Kalpana and Balalla, Shivanthi and Banerjee, Amitava and Barber, Ryan M. and {Barker-Collo}, Suzanne L. and Barquera, Simon and Barregard, Lars and Barrero, Lope H. and {Barrientos-Gutierrez}, Tonatiuh and Basu, Arindam and Basu, Sanjay and Basulaiman, Mohammed Omar and Beardsley, Justin and Bedi, Neeraj and Beghi, Ettore and Bekele, Tolesa and Bell, Michelle L. and Benjet, Corina and Bennett, Derrick A. and Bensenor, Isabela M. and Benzian, Habib and {Bertozzi-Villa}, Amelia and Beyene, Tariku Jibat and Bhala, Neeraj and Bhalla, Ashish and Bhutta, Zulfiqar A. and Bikbov, Boris and Abdulhak, Aref Bin and Biryukov, Stan and Blore, Jed D. and Blyth, Fiona M. and Bohensky, Megan A. and Borges, Guilherme and Bose, Dipan and Boufous, Soufiane and Bourne, Rupert R. and Boyers, Lindsay N. and Brainin, Michael and Brauer, Michael and Brayne, Carol E.G. and Brazinova, Alexandra and Breitborde, Nicholas and Brenner, Hermann and Briggs, Adam D.M. and Brown, Jonathan C. and Brugha, Traolach S. and Buckle, Geoffrey C. and Bui, Linh Ngoc and Bukhman, Gene and Burch, Michael and Nonato, Ismael Ricardo Campos and Carabin, H{\'e}l{\`e}ne and C{\'a}rdenas, Rosario and Carapetis, Jonathan and Carpenter, David O. and Caso, Valeria and {Casta{\~n}eda-Orjuela}, Carlos A. and Castro, Ruben Estanislao and {Catal{\'a}-L{\'o}pez}, Ferr{\'a}n and Cavalleri, Fiorella and Chang, Jung Chen and Charlson, Fiona C. and Che, Xuan and Chen, Honglei and Chen, Yingyao and Chen, Jian Sheng and Chen, Zhengming and Chiang, Peggy Pei Chia and {Chimed-Ochir}, Odgerel and Chowdhury, Rajiv and Christensen, Hanne and Christophi, Costas A. and Chuang, Ting Wu and Chugh, Sumeet S. and Cirillo, Massimo and Coates, Matthew M. and Coffeng, Luc Edgar and Coggeshall, Megan S. and Cohen, Aaron and Colistro, Valentina and Colquhoun, Samantha M. and Colomar, Mercedes and Cooper, Leslie Trumbull and Cooper, Cyrus and Coppola, Luis M. and Cortinovis, Monica and Courville, Karen and Cowie, Benjamin C. and Criqui, Michael H. and Crump, John A. and {Cuevas-Nasu}, Lucia and Leite, Iuri Da Costa and Dabhadkar, Kaustubh C. and Dandona, Lalit and Dandona, Rakhi and Dansereau, Emily and Dargan, Paul I. and Dayama, Anand and {Cruz-G{\'o}ngora}, Vanessa De La and Vega, Shelley F. De La and Leo, Diego De and Degenhardt, Louisa and {Pozo-Cruz}, Borja Del and Dellavalle, Robert P. and Deribe, Kebede and Jarlais, Don C. Des and Dessalegn, Muluken and Veber, Gabrielle A. De and Dharmaratne, Samath D. and Dherani, Mukesh and {Diaz-Ortega}, Jose Luis and {Diaz-Torne}, Cesar and Dicker, Daniel and Ding, Eric L. and Dokova, Klara and Dorsey, E. Ray and Driscoll, Tim R. and Duan, Leilei and Duber, Herbert C. and Durrani, Adnan M. and Ebel, Beth E. and Edmond, Karen M. and Ellenbogen, Richard G. and Elshrek, Yousef and Ermakov, Sergey Petrovich and Erskine, Holly E. and Eshrati, Babak and Esteghamati, Alireza and Estep, Kara and F{\"u}rst, Thomas and Fahimi, Saman and Fahrion, Anna S. and Faraon, Emerito Jose A. and Farzadfar, Farshad and Fay, Derek F.J. and Feigl, Andrea B. and Feigin, Valery L. and Felicio, Manuela Mendonca and Fereshtehnejad, Seyed Mohammad and Fernandes, Jefferson G. and Ferrari, Alize J. and Fleming, Thomas D. and Foigt, Nataliya and Foreman, Kyle and Forouzanfar, Mohammad H. and Fowkes, F. Gerry R. and Paleo, Urbano Fra and Franklin, Richard C. and Futran, Neal D. and Gaffikin, Lynne and Gambashidze, Ketevan and Gankp{\'e}, Fortun{\'e} Gb{\`e}toho and {Garc{\'i}a-Guerra}, Francisco Armando and Garcia, Ana Cristina and Geleijnse, Johanna M. and Gessner, Bradford D. and Gibney, Katherine B. and Gillum, Richard F. and Gilmour, Stuart and Ginawi, Ibrahim Abdelmageem Mohamed and Giroud, Maurice and Glaser, Elizabeth L. and Goenka, Shifalika and Dantes, Hector Gomez and Gona, Philimon and {Gonzalez-Medina}, Diego and Guinovart, Caterina and Gupta, Rahul Rajeev and Gupta, Rahul Rajeev and Gosselin, Richard A. and Gotay, Carolyn C. and Goto, Atsushi and Gouda, Hebe N. and Graetz, Nicholas and Greenwell, K. Fern and Gugnani, Harish Chander and Gunnell, David and Guti{\'e}rrez, Reyna A. and Haagsma, Juanita and {Hafezi-Nejad}, Nima and Hagan, Holly and Hagstromer, Maria and Halasa, Yara A. and Hamadeh, Randah Ribhi and Hamavid, Hannah and Hammami, Mouhanad and Hancock, Jamie and Hankey, Graeme J. and Hansen, Gillian M. and Harb, Hilda L. and Harewood, Heather and Haro, Josep Maria and Havmoeller, Rasmus and Hay, Roderick J. and Hay, Simon I. and Hedayati, Mohammad T. and Pi, Ileana B. Heredia and Heuton, Kyle R. and Heydarpour, Pouria and Higashi, Hideki and Hijar, Martha and Hoek, Hans W. and Hoffman, Howard J. and Hornberger, John C. and Hosgood, H. Dean and Hossain, Mazeda and Hotez, Peter J. and Hoy, Damian G. and Hsairi, Mohamed and Hu, Guoqing and Huang, John J. and Huffman, Mark D. and Hughes, Andrew J. and Husseini, Abdullatif and Huynh, Chantal and Iannarone, Marissa and Iburg, Kim M. and Idrisov, Bulat T. and Ikeda, Nayu and Innos, Kaire and Inoue, Manami and Islami, Farhad and Ismayilova, Samaya and Jacobsen, Kathryn H. and Jassal, Simerjot and Jayaraman, Sudha P. and Jensen, Paul N. and Jha, Vivekanand and Jiang, Guohong and Jiang, Ying and Jonas, Jost B. and Joseph, Jonathan and Juel, Knud and Kabagambe, Edmond Kato and Kan, Haidong and Karch, Andr{\'e} and Karimkhani, Chante and Karthikeyan, Ganesan and Kassebaum, Nicholas and Kaul, Anil and Kawakami, Norito and Kazanjan, Konstantin and Kazi, Dhruv S. and Kemp, Andrew H. and Kengne, Andre Pascal and Keren, Andre and Kereselidze, Maia and Khader, Yousef Saleh and Khalifa, Shams Eldin Ali Hassan and Khan, Ejaz Ahmed and Khan, Gulfaraz and Khang, Young Ho and Kieling, Christian and Kinfu, Yohannes and Kinge, Jonas M. and Kim, Daniel and Kim, Sungroul and Kivipelto, Miia and Knibbs, Luke and Knudsen, Ann Kristin and Kokubo, Yoshihiro and Kosen, Sowarta and Kotagal, Meera and Kravchenko, Michael A. and Krishnaswami, Sanjay and Krueger, Hans and Defo, Barthelemy Kuate and Kuipers, Ernst J. and Bicer, Burcu Kucuk and Kulkarni, Chanda and Kulkarni, Veena S. and Kumar, Kaushalendra and Kumar, Ravi B. and Kwan, Gene F. and Kyu, Hmwe and Lai, Taavi and Balaji, Arjun Lakshmana and Lalloo, Ratilal and Lallukka, Tea and Lam, Hilton and Lan, Qing and Lansingh, Van C. and Larson, Heidi J. and Larsson, Anders and Lavados, Pablo M. and Lawrynowicz, Alicia E.B. and Leasher, Janet L. and Lee, Jong Tae and Leigh, James and Leinsalu, Mall and Leung, Ricky and Levitz, Carly and Li, Bin and Li, Yichong Yongmei and Li, Yichong Yongmei and Liddell, Chelsea and Lim, Stephen S. and Lima, Gra{\c c}a Maria Ferreira De and Lind, Maggie L. and Lipshultz, Steven E. and Liu, Shiwei and Liu, Yang and Lloyd, Belinda K. and Lofgren, Katherine T. and Logroscino, Giancarlo and London, Stephanie J. and {Lortet-Tieulent}, Joannie and Lotufo, Paulo A. and Lucas, Robyn M. and Lunevicius, Raimundas and Lyons, Ronan Anthony and Ma, Stefan and Machado, Vasco Manuel Pedro and MacIntyre, Michael F. and Mackay, Mark T. and MacLachlan, Jennifer H. and {Magis-Rodriguez}, Carlos and Mahdi, Abbas A. and Majdan, Marek and Malekzadeh, Reza and Mangalam, Srikanth and Mapoma, Christopher Chabila and Marape, Marape and Marcenes, Wagner and Margono, Christopher and Marks, Guy B. and Marzan, Melvin Barrientos and Masci, Joseph R. and Mashal, Mohammad Taufiq and Masiye, Felix and {Mason-Jones}, Amanda J. and Matzopolous, Richard and Mayosi, Bongani M. and Mazorodze, Tasara T. and McGrath, John J. and McKay, Abigail C. and McKee, Martin and McLain, Abigail and Meaney, Peter A. and Mehndiratta, Man Mohan and {Mejia-Rodriguez}, Fabiola and Melaku, Yohannes Adama and Meltzer, Michele and Memish, Ziad A. and Mendoza, Walter and Mensah, George A. and Meretoja, Atte and Mhimbira, Francis A. and Miller, Ted R. and Mills, Edward J. and Misganaw, Awoke and Mishra, Santosh K. and Mock, Charles N. and Moffitt, Terrie E. and Ibrahim, Norlinah Mohamed and Mohammad, Karzan Abdulmuhsin and Mokdad, Ali H. and Mola, Glen Liddell and Monasta, Lorenzo and Monis, Jonathan De La Cruz and Hernandez, Julio C. Monta{\~n}ez and Montico, Marcella and Montine, Thomas J. and Mooney, Meghan D. and Moore, Ami R. and {Moradi-Lakeh}, Maziar and Moran, Andrew E. and Mori, Rintaro and Moschandreas, Joanna and Moturi, Wilkister Nyaora and Moyer, Madeline L. and Mozaffarian, Dariush and Mueller, Ulrich O. and Mukaigawara, Mitsuru and Mullany, Erin C. and Murray, Joseph and Mustapha, Adetoun and Naghavi, Paria and Naheed, Aliya and Naidoo, Kovin S. and Naldi, Luigi and Nand, Devina and Nangia, Vinay and Narayan, K. M.Venkat and Nash, Denis and Nasher, Jamal and Nejjari, Chakib and Nelson, Robert G. and Neuhouser, Marian and Neupane, Sudan Prasad and Newcomb, Polly A. and Newman, Lori and Newton, Charles R. and Ng, Marie and Ngalesoni, Frida Namnyak and Nguyen, Grant and Nguyen, Nhung Thi Trang and Nisar, Muhammad Imran and Nolte, Sandra and Norheim, Ole F. and Norman, Rosana E. and Norrving, Bo and Nyakarahuka, Luke and Odell, Shaun and O'Donnell, Martin and Ohkubo, Takayoshi and Ohno, Summer Lockett and Olusanya, Bolajoko O. and Omer, Saad B. and Opio, John Nelson and Orisakwe, Orish Ebere and Ortblad, Katrina F. and Ortiz, Alberto and Otayza, Maria Lourdes K. and Pain, Amanda W. and Pandian, Jeyaraj D. and Panelo, Carlo Irwin and Panniyammakal, Jeemon and Papachristou, Christina and Caicedo, Angel J. Paternina and Patten, Scott B. and Patton, George C. and Paul, Vinod K. and Pavlin, Boris and Pearce, Neil and Pellegrini, Carlos A. and Pereira, David M. and Peresson, Sophie C. and {Perez-Padilla}, Rogelio and {Perez-Ruiz}, Fernando P. and Perico, Norberto and Pervaiz, Aslam and Pesudovs, Konrad and Peterson, Carrie B. and Petzold, Max and Phillips, Bryan K. and Phillips, David E. and Phillips, Michael R. and Plass, Dietrich and Piel, Fr{\'e}d{\'e}ric Bernard and Poenaru, Dan and Polinder, Suzanne and Popova, Svetlana and Poulton, Richie G. and Pourmalek, Farshad and Prabhakaran, Dorairaj and Qato, Dima and Quezada, Amado D. and Quistberg, D. Alex and Rabito, Felicia and Rafay, Anwar and Rahimi, Kazem and {Rahimi-Movaghar}, Vafa and Rahman, Sajjad U.R. and Raju, Murugesan and Rakovac, Ivo and Rana, Saleem M. and Refaat, Amany and Remuzzi, Giuseppe and Ribeiro, Antonio L. and Ricci, Stefano and Riccio, Patricia M. and Richardson, Lee and Richardus, Jan Hendrik and Roberts, Bayard and Roberts, D. Allen and Robinson, Margaret and Roca, Anna and Rodriguez, Alina and {Rojas-Rueda}, David and Ronfani, Luca and Room, Robin and Roth, Gregory A. and Rothenbacher, Dietrich and Rothstein, David H. and Rowley, Jane T.F. and Roy, Nobhojit and Ruhago, George M. and Rushton, Lesley and Sambandam, Sankar and S\o reide, Kjetil and Saeedi, Mohammad Yahya and Saha, Sukanta and Sahathevan, Ramesh and Sahraian, Mohammad Ali and Sahle, Berhe Weldearegawi and Salomon, Joshua A. and Salvo, Deborah and Samonte, Genesis May J. and Sampson, Uchechukwu and Sanabria, Juan Ramon and Sandar, Logan and Santos, Itamar S. and Satpathy, Maheswar and Sawhney, Monika and Saylan, Mete and Scarborough, Peter and Sch{\"o}ttker, Ben and Schmidt, J{\"u}rgen C. and Schneider, Ione J.C. and Schumacher, Austin E. and Schwebel, David C. and Scott, James G. and Sepanlou, Sadaf G. and {Servan-Mori}, Edson E. and Shackelford, Katya and Shaheen, Amira and Shahraz, Saeid and {Shakh-Nazarova}, Marina and Shangguan, Siyi and She, Jun and Sheikhbahaei, Sara and Shepard, Donald S. and Shibuya, Kenji and Shinohara, Yukito and Shishani, Kawkab and Shiue, Ivy and Shivakoti, Rupak and Shrime, Mark G. and Sigfusdottir, Inga Dora and Silberberg, Donald H. and Silva, Andrea P. and Simard, Edgar P. and Sindi, Shireen and Singh, Jasvinder A. and Singh, Lavanya and Sioson, Edgar and Skirbekk, Vegard and Sliwa, Karen and So, Samuel and Soljak, Michael and Soneji, Samir and Soshnikov, Sergey S. and Sposato, Luciano A. and Sreeramareddy, Chandrashekhar T. and Stanaway, Jeffrey D. and Stathopoulou, Vasiliki Kalliopi and Steenland, Kyle and Stein, Claudia and Steiner, Caitlyn and Stevens, Antony and St{\"o}ckl, Heidi and Straif, Kurt and Stroumpoulis, Konstantinos and Sturua, Lela and Sunguya, Bruno F. and Swaminathan, Soumya and Swaroop, Mamta and Sykes, Bryan L. and Tabb, Karen M. and Takahashi, Ken and Talongwa, Roberto Tchio and Tan, Feng and Tanne, David and Tanner, Marcel and Tavakkoli, Mohammad and Ao, Braden Te and Teixeira, Carolina Maria and Templin, Tara and Tenkorang, Eric Yeboah and Terkawi, Abdullah Sulieman and Thomas, Bernadette A. and {Thorne-Lyman}, Andrew L. and Thrift, Amanda G. and Thurston, George D. and Tillmann, Taavi and Tirschwell, David L. and Tleyjeh, Imad M. and Tonelli, Marcello and Topouzis, Fotis and Towbin, Jeffrey A. and Toyoshima, Hideaki and Traebert, Jefferson and Tran, Bach X. and Truelsen, Thomas and Trujillo, Ulises and Trillini, Matias and Dimbuene, Zacharie Tsala and Tsilimbaris, Miltiadis and Tuzcu, E. Murat and Ubeda, Clotilde and Uchendu, Uche S. and Ukwaja, Kingsley N. and Undurraga, Eduardo A. and Vallely, Andrew J. and Vijver, Steven Van De and Gool, Coen H. Van and Varakin, Yuri Y. and Vasankari, Tommi J. and Vasconcelos, Ana Maria Nogales and Vavilala, Monica S. and Venketasubramanian, N. and Vijayakumar, Lakshmi and Villalpando, Salvador and Violante, Francesco S. and Vlassov, Vasiliy Victorovich and Wagner, Gregory R. and Waller, Stephen G. and Wang, Jian Li and Wang, Linhong and Wang, Xiao Rong and Wang, Yanping and Warouw, Tati Suryati and Weichenthal, Scott and Weiderpass, Elisabete and Weintraub, Robert G. and Wenzhi, Wang and Werdecker, Andrea and Wessells, K. Ryan R. and Westerman, Ronny and Whiteford, Harvey A. and Wilkinson, James D. and Williams, Thomas Neil and Woldeyohannes, Solomon Meseret and Wolfe, Charles D.A. and Wolock, Timothy M. and Woolf, Anthony D. and Wong, John Q. and Wright, Jonathan L. and Wulf, Sarah and Wurtz, Brittany and Xu, Gelin and Yang, Yang C. and Yano, Yuichiro and Yatsuya, Hiroshi and Yip, Paul and Yonemoto, Naohiro and Yoon, Seok Jun and Younis, Mustafa and Yu, Chuanhua and Jin, Kim Yun and Zaki, Maysaa El Sayed and Zamakhshary, Mohammed Fouad and Zeeb, Hajo and Zhang, Yong and Zhao, Yong and Zheng, Yingfeng and Zhu, Jun and Zhu, Shankuan and Zonies, David and Zou, Xiao Nong and Zunt, Joseph R. and Vos, Theo and Lopez, Alan D. and Murray, Christopher J.L. and {Alcal{\'a}-Cerra}, G. and Hu, H. and Karam, N. and Sabin, N. and Temesgen, A. M.},
  year = {2015},
  volume = {385},
  pages = {117--171},
  publisher = {{Elsevier Ltd}},
  issn = {1474547X},
  doi = {10.1016/S0140-6736(14)61682-2},
  abstract = {Background Up-to-date evidence on levels and trends for age-sex-specific all-cause and cause-specific mortality is essential for the formation of global, regional, and national health policies. In the Global Burden of Disease Study 2013 (GBD 2013) we estimated yearly deaths for 188 countries between 1990, and 2013. We used the results to assess whether there is epidemiological convergence across countries. Methods We estimated age-sex-specific all-cause mortality using the GBD 2010 methods with some refinements to improve accuracy applied to an updated database of vital registration, survey, and census data. We generally estimated cause of death as in the GBD 2010. Key improvements included the addition of more recent vital registration data for 72 countries, an updated verbal autopsy literature review, two new and detailed data systems for China, and more detail for Mexico, UK, Turkey, and Russia. We improved statistical models for garbage code redistribution. We used six different modelling strategies across the 240 causes; cause of death ensemble modelling (CODEm) was the dominant strategy for causes with sufficient information. Trends for Alzheimer's disease and other dementias were informed by meta-regression of prevalence studies. For pathogen-specific causes of diarrhoea and lower respiratory infections we used a counterfactual approach. We computed two measures of convergence (inequality) across countries: the average relative difference across all pairs of countries (Gini coefficient) and the average absolute difference across countries. To summarise broad findings, we used multiple decrement life-tables to decompose probabilities of death from birth to exact age 15 years, from exact age 15 years to exact age 50 years, and from exact age 50 years to exact age 75 years, and life expectancy at birth into major causes. For all quantities reported, we computed 95\% uncertainty intervals (UIs). We constrained cause-specific fractions within each age-sex-country-year group to sum to all-cause mortality based on draws from the uncertainty distributions. Findings Global life expectancy for both sexes increased from 65{$\cdot$}3 years (UI 65{$\cdot$}0-65{$\cdot$}6) in 1990, to 71{$\cdot$}5 years (UI 71{$\cdot$}0-71{$\cdot$}9) in 2013, while the number of deaths increased from 47{$\cdot$}5 million (UI 46{$\cdot$}8-48{$\cdot$}2) to 54{$\cdot$}9 million (UI 53{$\cdot$}6-56{$\cdot$}3) over the same interval. Global progress masked variation by age and sex: for children, average absolute differences between countries decreased but relative differences increased. For women aged 25-39 years and older than 75 years and for men aged 20-49 years and 65 years and older, both absolute and relative differences increased. Decomposition of global and regional life expectancy showed the prominent role of reductions in age-standardised death rates for cardiovascular diseases and cancers in high-income regions, and reductions in child deaths from diarrhoea, lower respiratory infections, and neonatal causes in low-income regions. HIV/AIDS reduced life expectancy in southern sub-Saharan Africa. For most communicable causes of death both numbers of deaths and age-standardised death rates fell whereas for most non-communicable causes, demographic shifts have increased numbers of deaths but decreased age-standardised death rates. Global deaths from injury increased by 10{$\cdot$}7\%, from 4{$\cdot$}3 million deaths in 1990 to 4{$\cdot$}8 million in 2013; but age-standardised rates declined over the same period by 21\%. For some causes of more than 100 000 deaths per year in 2013, age-standardised death rates increased between 1990 and 2013, including HIV/AIDS, pancreatic cancer, atrial fibrillation and flutter, drug use disorders, diabetes, chronic kidney disease, and sickle-cell anaemias. Diarrhoeal diseases, lower respiratory infections, neonatal causes, and malaria are still in the top five causes of death in children younger than 5 years. The most important pathogens are rotavirus for diarrhoea and pneumococcus for lower respiratory infections. Country-specific probabilities of death over three phases of life were substantially varied between and within regions. Interpretation For most countries, the general pattern of reductions in age-sex specific mortality has been associated with a progressive shift towards a larger share of the remaining deaths caused by non-communicable disease and injuries. Assessing epidemiological convergence across countries depends on whether an absolute or relative measure of inequality is used. Nevertheless, age-standardised death rates for seven substantial causes are increasing, suggesting the potential for reversals in some countries. Important gaps exist in the empirical data for cause of death estimates for some countries; for example, no national data for India are available for the past decade. Funding Bill \& Melinda Gates Foundation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ETBHMJBT\\naghavi_et_al_2015_global,_regional,_and_national_age-sex_specific_all-cause_and_cause-specific.pdf},
  isbn = {0140-6736},
  journal = {The Lancet},
  number = {9963},
  pmid = {25530442}
}

@article{Nair1941,
  title = {Distribution of Students 't' and the Correlation Coefficient in Samples from Non-Normal Populations},
  author = {Nair, A N Krishnan},
  year = {1941},
  volume = {5},
  pages = {383--400},
  journal = {The Indian Journal of Statistics},
  keywords = {\#nosource},
  number = {4}
}

@article{Nakagawa1992,
  title = {Distribution of the Sample Correlation Coefficient for Nonnormal Populations},
  author = {Nakagawa, Shigekazu and Niki, Naoto},
  year = {1992},
  volume = {5},
  pages = {1--19},
  doi = {10.5183/jjscs1988.5.1},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JACG6M4W\\nakagawa_niki_1992_distribution_of_the_sample_correlation_coefficient_for_nonnormal_populations.pdf},
  journal = {Journal of the Japanese Society of Computational Statistics},
  number = {1}
}

@article{Nakash2006,
  title = {Maximising Response to Postal Questionnaires - {{A}} Systematic Review of Randomised Trials in Health Research},
  author = {Nakash, Rachel A. and Hutton, Jane L. and {J\o rstad-Stein}, Ellen C. and Gates, Simon and Lamb, Sarah E.},
  year = {2006},
  volume = {6},
  pages = {1--9},
  issn = {14712288},
  doi = {10.1186/1471-2288-6-5},
  abstract = {BACKGROUND: Postal self-completion questionnaires offer one of the least expensive modes of collecting patient based outcomes in health care research. The purpose of this review is to assess the efficacy of methods of increasing response to postal questionnaires in health care studies on patient populations. METHODS: The following databases were searched: Medline, Embase, CENTRAL, CDSR, PsycINFO, NRR and ZETOC. Reference lists of relevant reviews and relevant journals were hand searched. Inclusion criteria were randomised trials of strategies to improve questionnaire response in health care research on patient populations. Response rate was defined as the percentage of questionnaires returned after all follow-up efforts. Study quality was assessed by two independent reviewers. The Mantel-Haenszel method was used to calculate the pooled odds ratios. RESULTS: Thirteen studies reporting fifteen trials were included. Implementation of reminder letters and telephone contact had the most significant effect on response rates (odds ratio 3.7, 95\% confidence interval 2.30 to 5.97 p = or \textexclamdown 0.00001). Shorter questionnaires also improved response rates to a lesser degree (odds ratio 1.4, 95\% confidence interval 1.19 to 1.54). No evidence was found that incentives, re-ordering of questions or including an information brochure with the questionnaire confer any additional advantage. CONCLUSION: Implementing repeat mailing strategies and/or telephone reminders may improve response to postal questionnaires in health care research. Making the questionnaire shorter may also improve response rates. There is a lack of evidence to suggest that incentives are useful. In the context of health care research all strategies to improve response to postal questionnaires require further evaluation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SX8XJ34Q\\nakash_et_al_2006_maximising_response_to_postal_questionnaires_-_a_systematic_review_of.pdf},
  isbn = {1471-2288 (Electronic){\r  }1471-2288 (Linking)},
  journal = {BMC Medical Research Methodology},
  pmid = {16504090}
}

@article{Namba2012,
  title = {Risk Factors Associated with Surgical Site Infection in 30 491 Primary Total Hip Replacements},
  author = {Namba, R. S. and Inacio, M. C. S. and Paxton, E. W.},
  year = {2012},
  month = oct,
  volume = {94-B},
  pages = {1330--1338},
  issn = {0301-620X, 2044-5377},
  doi = {10.1302/0301-620X.94B10.29184},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  language = {en},
  number = {10}
}

@article{Nattino2014,
  title = {A New Calibration Test and a Reappraisal of the Calibration Belt for the Assessment of Prediction Models Based on Dichotomous Outcomes},
  author = {Nattino, Giovanni and Finazzi, Stefano and Bertolini, Guido},
  year = {2014},
  month = jun,
  volume = {33},
  pages = {2390--2407},
  issn = {02776715},
  doi = {10.1002/sim.6100},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JHYME3EZ\\nattino_et_al_2014_a_new_calibration_test_and_a_reappraisal_of_the_calibration_belt_for_the.pdf},
  journal = {Statistics in Medicine},
  number = {14}
}

@article{Nattino2016,
  title = {A New Test and Graphical Tool to Assess the Goodness of Fit of Logistic Regression Models},
  author = {Nattino, Giovanni and Finazzi, Stefano and Bertolini, Guido},
  year = {2016},
  month = feb,
  volume = {35},
  pages = {709--720},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/sim.6744},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\H4KFL5PI\\nattino_et_al_2016_a_new_test_and_graphical_tool_to_assess_the_goodness_of_fit_of_logistic.pdf},
  journal = {Statistics in Medicine},
  keywords = {calibration test,dichotomous outcome models,goodness of fit,graphical methods,logistic regression models},
  number = {5}
}

@article{Nemes2009,
  title = {Bias in Odds Ratios by Logistic Regression Modelling and Sample Size.},
  author = {Nemes, Szilard and Jonasson, Junmei Miao and Genell, Anna and Steineck, Gunnar},
  year = {2009},
  volume = {9},
  pages = {56},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-9-56},
  abstract = {BACKGROUND: In epidemiological studies researchers use logistic regression as an analytical tool to study the association of a binary outcome to a set of possible exposures.: Using a simulation study we illustrate how the analytically derived bias of odds ratios modelling in logistic regression varies as a function of the sample size.: Logistic regression overestimates odds ratios in studies with small to moderate samples size. The small sample size induced bias is a systematic one, bias away from null. Regression coefficient estimates shifts away from zero, odds ratios from one.: If several small studies are pooled without consideration of the bias introduced by the inherent mathematical properties of the logistic regression model, researchers may be mislead to erroneous interpretation of the results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V2MMIIKA\\nemes_et_al_2009_bias_in_odds_ratios_by_logistic_regression_modelling_and_sample_size.pdf},
  isbn = {1471-2288 (Electronic){\r  }1471-2288 (Linking)},
  journal = {BMC medical research methodology},
  keywords = {Bias (Epidemiology),Computer Simulation,Female,Humans,Logistic Models,Models,Odds Ratio,Pregnancy,Sample Size,Statistical},
  pmid = {19635144}
}

@article{Nemes2013,
  title = {A Diagnostic Algorithm to Identify Paired Tumors with Clonal Origin},
  author = {Nemes, Szil{\'a}rd and Danielsson, Anna and Parris, Toshima Z and Jonasson, Junmei Miao and B{\"u}low, Erik and Karlsson, Per and Steineck, Gunnar and Helou, Khalil},
  year = {2013},
  volume = {52},
  pages = {1007--1016},
  issn = {10452257},
  doi = {10.1002/gcc.22096},
  abstract = {Despite practical implications we still lack standardized methods for clonality testing of tumor pairs. Each tumor is characterized by a set of chromosomal abnormalities, nonrandom changes preferentially involving specific chromosomes and chromosomal regions. Although tumors accumulate chromosomal abnormalities during their development, the majority of these alterations is specific and characteristic for each individual tumor is not exhibited at the population level. Assumingly, secondary tumors that develop from disseminated cells from the primary tumor inherit not only chromosomal changes specific for the cancerous process but also random chromosomal changes that accumulate during tumor development. Based on this assumption, we adopted an intuitive index for genomic similarities of paired tumors, which ranges between zero (completely different genomic profiles) and one (identical genomic profiles). To test the assumption that two tumors have clonal origins if they share a higher degree of genomic similarity than two randomly paired tumors, we built a permutation-based null-hypothesis procedure. The procedure is demonstrated using two publicly available data sets. The article highlights the complexities of clonality testing and aims to offer an easy to follow blueprint that will allow researchers to test genomic similarities of paired tumors, with the proposed index or any other index that fits their need. \textcopyright{} 2013 Wiley Periodicals, Inc.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EIGKKR22\\nemes_et_al_2013_a_diagnostic_algorithm_to_identify_paired_tumors_with_clonal_origin.pdf},
  journal = {Genes Chromosomes and Cancer},
  number = {11}
}

@article{Nemes2014,
  title = {Projections of Total Hip Replacement in {{Sweden}} from 2013 to 2030},
  author = {Nemes, Szil{\'a}rd and Gordon, Max and Rogmark, Cecilia and Rolfson, Ola},
  year = {2014},
  volume = {85},
  pages = {238--243},
  issn = {17453682},
  doi = {10.3109/17453674.2014.913224},
  abstract = {Background and purpose \textemdash{} The continuously increasing demand for joint replacement surgery in the past decades imposes higher constraints on the budgets of hospitals and healthcare providers. We undertook an analysis of historical trends in total hip replace-ment performed in Sweden between 1968 and 2012 in order to provide projections of future demand. Data and methods \textemdash{} We obtained data on total hip replace-ments registered every year and on the evolution of the Swedish population between 1968 and 2012. We assumed the existence of a maximum incidence. So we adopted a regression framework that assumes the existence of an upper limit of total hip replacement incidence. Results \textemdash{} We found that the incidence of total hip replacement will continue to increase until a projected upper incidence level of about 400 total hip replacements per 10 5 Swedish residents aged 40 years and older will be reached around the year 2107. In 2020, the estimated incidence of total hip replacement will be 341 (95\% prediction interval (PI): 302\textendash 375) and in 2030 it will be 358 (PI: 317\textendash 396). Using official forecasted population growth data, about 18,000 operations would be expected to be performed in 2020 and 20,000 would be expected to be performed in 2030. Interpretation \textemdash{} Growing incidence, population growth, and increasing life expectancy will probably result in increased demand for hip replacement surgery. Our findings could serve as a basis for decision making. },
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VFST3ZU7\\nemes_et_al_2014_projections_of_total_hip_replacement_in_sweden_from_2013_to_2030.pdf},
  isbn = {10.3109/17453674.2014.913224},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {24758323}
}

@article{Nemes2015,
  title = {Historical View and Future Demand for Knee Arthroplasty in {{Sweden}}},
  author = {Nemes, Szil{\'a}rd and Rolfson, Ola and {W-Dahl}, Annette and Garellick, G{\"o}ran and Sundberg, Martin and K{\"a}rrholm, Johan and Robertsson, Otto},
  year = {2015},
  volume = {86},
  pages = {426--431},
  issn = {17453682},
  doi = {10.3109/17453674.2015.1034608},
  abstract = {Background and purpose \textemdash{} The incidence of knee osteoarthritis will most likely increase. We analyzed historical trends in the inci-dence of knee arthroplasty in Sweden between 1975 and 2013, in order to be able to provide projections of future demand. Patients and methods \textemdash{} We obtained information on all knee arthroplasties in Sweden in the period 1975\textendash 2013 from the Swed-ish Knee Arthroplasty Register, and used public domain data from Statistics Sweden on the evolution of and forecasts for the Swedish population. We forecast the incidence, presuming the existence of a maximum incidence. Results \textemdash{} We found that the incidence of knee arthroplasty will continue to increase until a projected upper incidence level of about 469 total knee replacements per 10 5 Swedish residents aged 40 years and older is reached around the year 2130. In 2020, the estimated incidence of total knee arthroplasties per 10 5 Swed-ish residents aged 40 years and older will be 334 (95\% prediction interval (PI): 281\textendash 374) and in 2030 it will be 382 (PI: 308\textendash 441). Using officially forecast population growth data, around 17,500 operations would be expected to be performed in 2020 and around 21,700 would be expected to be performed in 2030. Interpretation \textemdash{} Today's levels of knee arthroplasty are well below the expected maximum incidence, and we expect a contin-ued annual increase in the total number of knee arthroplasties performed. },
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ISQCHWNK\\nemes_et_al_2015_historical_view_and_future_demand_for_knee_arthroplasty_in_sweden.pdf},
  isbn = {1745-3674},
  journal = {Acta Orthopaedica},
  number = {4},
  pmid = {25806653}
}

@article{Nemes2015,
  title = {Summary Statistics for {{Patient}}-Reported {{Outcome Measures}}: The Improvement Ratio},
  author = {Nemes, Szilard and Greene, Meridith E and Bulow, Erik and Rolfson, Ola},
  year = {2015},
  month = sep,
  volume = {3},
  pages = {334},
  issn = {2052-5656},
  doi = {10.5750/ejpch.v3i3.1000},
  abstract = {Rationale, aims and objective: Patient-reported outcomes measures (PROMs) can facilitate objective comparisons of alternative treatments and can aid clinicians, researchers, decision-makers and members of the general public in gauging different healthcare providers' performance. However, this assumes an easy to use and understand summary measure. Methods: Using PROMs (EQ-5D index, EQ VAS and VAS Pain) from 1799 patients in 7 Swedish hospitals with at least 200 hip arthroplasty surgeries in 2009, we illustrated the possibility of summarizing pre- and post-treatment PROM values with the help of a simple index. This index expressed the attained improvement as a percentage of the total possible improvement. Change score, Cohen's effect size and Standardized Response Means served as alternative measures. Results: The Improvement Ratio index proved capable of offering a vivid and easy to understand summary of healthcare providers' performance. The alternative measures indicated similar patterns as the Improvement Index. The routines of statistical inference made possible null-hypothesis testing of the improvement in different groups or testing for trends. Conclusions: This simple improvement index gives an easy to understand summary measure that appeals not only to researchers, but also to laymen for consulting healthcare provider comparisons or countrywide white papers. We recommend using the Improvement Ratio index to summarize the PROMs outcome of elective surgeries.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AWGMD2B4\\nemes_et_al_2015_summary_statistics_for_patient-reported_outcome_measures.pdf},
  journal = {European Journal for Person Centered Healthcare},
  keywords = {Arthoplasty,measurement precision,outcome interpretation,Patient-reported Outcome Measures,person-centered healthcare,quality improvement,socioeconomic factors},
  number = {3}
}

@article{Nemes2018,
  title = {Development and Validation of a Shared Decision-Making Instrument for Health-Related Quality of Life One Year after Total Hip Replacement Based on Quality Registries Data},
  author = {Nemes, Szilard and Rolfson, Ola and Garellick, G{\"o}ran},
  year = {2018},
  volume = {24},
  pages = {13--21},
  issn = {13652753},
  doi = {10.1111/jep.12603},
  abstract = {RATIONALE, AIMS AND OBJECTIVES: Clinicians considering improvements in health-related quality of life (HRQoL) after total hip replacement (THR) must account for multiple pieces of information. Evidence-based decisions are important to best assess the effect of THR on HRQoL. This work aims at constructing a shared decision-making tool that helps clinicians assessing the future benefits of THR by offering predictions of 1-year postoperative HRQoL of THR patients. METHODS: We used data from the Swedish Hip Arthroplasty Register. Data from 2008 were used as training set and data from 2009 to 2012 as validation set. We adopted two approaches. First, we assumed a continuous distribution for the EQ-5D index and modelled the postoperative EQ-5D index with regression models. Second, we modelled the five dimensions of the EQ-5D and weighted together the predictions using the UK Time Trade-Off value set. As predictors, we used preoperative EQ-5D dimensions and the EQ-5D index, EQ visual analogue scale, visual analogue scale pain, Charnley classification, age, gender, body mass index, American Society of Anesthesiologists, surgical approach and prosthesis type. Additionally, the tested algorithms were combined in a single predictive tool by stacking. RESULTS: Best predictive power was obtained by the multivariate adaptive regression splines (R(2) = 0.158). However, this was not significantly better than the predictive power of linear regressions (R(2) = 0.157). The stacked model had a predictive power of 17\%. CONCLUSIONS: Successful implementation of a shared decision-making tool that can aid clinicians and patients in understanding expected improvement in HRQoL following THR would require higher predictive power than we achieved. For a shared decision-making tool to succeed, further variables, such as socioeconomics, need to be considered.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2RUYMY8Z\\nemes_et_al_2018_development_and_validation_of_a_shared_decision-making_instrument_for.pdf},
  isbn = {1356-1294},
  journal = {Journal of Evaluation in Clinical Practice},
  keywords = {health services research,healthcare,informatics,medical,medical informatics,public health},
  number = {1},
  pmid = {27461743}
}

@article{Nemes2018a,
  title = {Relative Survival Following Hemi-and Total Hip Arthroplasty for Hip Fractures in {{Sweden}}},
  author = {Nemes, Szilard and Lind, Dennis and Cnudde, Peter and B{\"u}low, Erik and Rolfson, Ola and Rogmark, Cecilia},
  year = {2018},
  month = dec,
  volume = {19},
  pages = {407},
  issn = {1471-2474},
  doi = {10.1186/s12891-018-2321-2},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GG7J54ZV\\Nemes m. fl. - 2018 - Relative survival following hemi-and total hip art.pdf},
  journal = {BMC Musculoskeletal Disorders},
  keywords = {coder},
  language = {en},
  number = {1}
}

@article{Neovius2006,
  title = {National Prevalence of Obesity Prevalence of Obesity in Sweden},
  author = {Neovius, M and Janson, A and R{\"o}ssner, S},
  year = {2006},
  volume = {7},
  pages = {-33},
  journal = {obesity reviews},
  keywords = {\#nosource}
}

@article{Neuburger2011,
  title = {Funnel Plots for Comparing Provider Performance Based on Patient-Reported Outcome Measures},
  author = {Neuburger, Jenny and Cromwell, David A. and Hutchings, Andrew and Black, Nick and Meulen, Jan H. Van Der},
  year = {2011},
  volume = {20},
  pages = {1020--1026},
  issn = {20445415},
  doi = {10.1136/bmjqs-2011-000197},
  abstract = {BACKGROUND: Patient-reported outcome measures (PROMs) often produce skewed distributions of individual scores after a healthcare intervention. For health performance indicators derived from skewed distributions, funnel plots designed with symmetric control limits may increase the risk of false alarms about poor performance.: To investigate the accuracy of funnel plots with symmetric control limits when comparing provider performance based on PROMs.: The authors used a database containing condition-specific PROMs for 17,453 hip replacements and 7656 varicose vein procedures performed by providers in the English NHS. The mean postoperative PROM score, adjusted for patient characteristics, was used as the measure of performance. To compare performance, symmetric 99.8\% control limits were calculated on funnel plots, 3 SDs away from the overall mean on either side. These were compared to control limits derived directly from percentiles of simulated (bootstrap) distributions of mean scores.: The simulated control limits on funnel plots for both procedures were asymmetric. The empirical probability of falling outside the symmetric 99.8\% 'poor performance' control limit was inflated from the stipulated rate of 0.1\% to 0.2-0.3\% for provider sample sizes of up to 150 procedures. The authors observed that, out of 237 providers of hip replacement, eight had adjusted mean scores that exceeded the symmetric 'poor performance' limit compared with only five that exceeded the corresponding simulated limit. In other words, three (1.3\%) were differently classified. For varicose vein surgery, five out of 160 providers exceeded the symmetric limit and four exceeded the simulated limit, that is, 1 (0.6\%) was differently classified.: When designing funnel plots for comparisons of provider performance based on highly skewed data, the use of simulated control limits should be considered.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\U9HLRNPQ\\neuburger_et_al_2011_funnel_plots_for_comparing_provider_performance_based_on_patient-reported.pdf},
  isbn = {2044-5423},
  journal = {BMJ Quality and Safety},
  number = {12},
  pmid = {21680560}
}

@article{Neuhaus2013,
  title = {Charlson Comorbidity Indices and In-Hospital Deaths in Patients with Hip Fractures Trauma},
  author = {Neuhaus, Valentin and King, John and Hageman, Michiel G. and Ring, David C.},
  year = {2013},
  volume = {471},
  pages = {1712--1719},
  issn = {0009921X},
  doi = {10.1007/s11999-012-2705-9},
  abstract = {BACKGROUND: The Charlson Comorbidity Index (CCI) and its modifications are comorbidity-based measures that predict mortality. It was developed for patients without trauma and inconsistently predicted mortality and adverse events in several previous studies of patients with trauma.: We therefore (1) determined whether the three different CCIs were predictors for in-hospital deaths in patients with hip fractures, (2) verified if the CCI mortality prediction had changed with time, (3) evaluated other predictors of in-hospital death in patients with hip fractures, and (4) determined if the CCI has predicted in-hospital adverse events.: We retrospectively reviewed a nationwide probability sample survey, the National Hospital Discharge Survey. More than 6 million adult patients with hip fractures and their associated comorbidities were scored by the original 1987 CCI, the 1994 age-adjusted CCI, and the 2011 updated, reweighted CCI. The three mortality indices' predictive values and predictors of in-hospital adverse events were compared.: For patients with hip fractures, all three CCI variations predicted in-hospital mortality. The receiver operating curves (ROC) of the models were less than 0.68, but they improved when we used statistical models that included age, sex, concomitant injuries, and other comorbidities not contained in the CCI models (ROC \textquestiondown{} 0.74). The age-adjusted CCI accuracy was slightly better than the other two CCIs. Adverse events during hospital stays were associated with a higher CCI, pertrochanteric fracture (versus transcervical), abdominal, chest, or head trauma, atrial fibrillation, multiple fractures, female sex, and longer hospital stays; however, the accuracy of this model was poor (ROC = 0.65).: While all three CCI variations predicted in-hospital mortality in patients with hip fractures, other factors may be of value in patients with trauma.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\74AWMCSK\\neuhaus_et_al_2013_charlson_comorbidity_indices_and_in-hospital_deaths_in_patients_with_hip.pdf},
  isbn = {0009-921X},
  journal = {Clinical Orthopaedics and Related Research},
  number = {5},
  pmid = {23179125}
}

@article{Newman2008,
  title = {A Physiologic Index of Comorbidity: Relationship to Mortality and Disability.},
  author = {Newman, Anne B and Boudreau, Robert M and Naydeck, Barbara L and Fried, Linda F and Harris, Tamara B},
  year = {2008},
  month = jun,
  volume = {63},
  pages = {603--9},
  publisher = {{Oxford University Press}},
  issn = {1079-5006},
  abstract = {BACKGROUND In older adults, there is often substantial undiagnosed chronic disease detectable on noninvasive testing, not accounted for by most comorbidity indices. We developed a simple physiologic index of comorbidity by scoring five noninvasive tests across the full range of values. We examined the predictive validity of this index for mortality and disability. METHODS There were 2928 (mean age 74.5 years, 60\% women, 85\% white, and 15\% black) participants in the Cardiovascular Health Study (1992-1993) who had carotid ultrasound, pulmonary function testing, brain magnetic resonance scan, serum cystatin-C, and fasting glucose. These were combined into a single physiologic index of comorbid chronic disease on a scale of 0-10. Cox proportional hazard models were used to predict mortality, mobility limitation, and activities of daily living (ADL) difficulty after a maximum of 9 years. RESULTS The range of the physiologic index was quite broad, with very few individuals having total scores of either 0 or 10. Those with an index of 7-10 had a hazard ratio of 3.80 (95\% confidence interval, 2.82-5.13) for mortality compared to those with scores of 0-2, after adjustment for demographics, behavioral risk factors, and clinically diagnosed conditions. Associations with mobility limitation and ADL difficulty were also significant. The index explained about 40\% of the age effect on mortality risk. CONCLUSION Older adults with low levels of markers of chronic disease are rather rare but have remarkably good health outcomes. The ability of such an index to distinguish usual from low risk might provide an opportunity to better understand optimal health in old age.},
  journal = {The journals of gerontology. Series A, Biological sciences and medical sciences},
  keywords = {\#nosource},
  number = {6},
  pmid = {18559635}
}

@techreport{NJR2019,
  title = {16th Annual Report},
  author = {{NJR}},
  year = {2019},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S6L35TMY\\njr_2019_16th_annual_report.pdf},
  number = {December 2018}
}

@article{Nordin2016,
  title = {Minimal Important Differences for Fatigue Patient Reported Outcome Measures\textemdash a Systematic Review},
  author = {Nordin, \AA sa and Taft, Charles and {Lundgren-Nilsson}, \AA sa and Dencker, Anna},
  year = {2016},
  volume = {16},
  pages = {62},
  publisher = {{BMC Medical Research Methodology}},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0167-6},
  abstract = {Background: Fatigue is the most frequent symptom reported by patients with chronic illnesses. As a subjective experience, fatigue is commonly assessed with patient-reported outcome measures (PROMs). Currently, there are more than 40 generic and disease-specific PROMs for assessing fatigue in use today. The interpretation of changes in PROM scores may be enhanced by estimates of the so-called minimal important difference (MID). MIDs are not fixed attributes of PROMs but rather vary in relation to estimation method, clinical and demographic characteristics of the study group, etc. The purpose of this paper is to compile published MIDs for fatigue PROMs, spanning diagnostic/patient groups and estimation methods, and to provide information relevant for appraising their appropriateness for use in specific clinical trials and in monitoring fatigue in defined patient groups in routine clinical practice. Methods: A systematic search of three databases (Scopus, CINAHL and Cochrane) for studies published between January 2000 to April 2015 using fatigue and variations of the term MID, e.g. MCID, MIC, etc. Two authors screened search hits and extracted data independently. Data regarding MIDs, anchors used and study designs were compiled in tables. Results: Included studies (n = 41) reported 60 studies or substudies estimating MID for 28 fatigue scales, subscales or single item measures in a variety of diagnostic groups and study designs. All studies used anchor-based methods, 21/60 measures also included distribution-based methods and 17/60 used triangulation of methods. Both similarities and dissimilarities were seen within the MIDs. Conclusions: Magnitudes of published MIDs for fatigue PROMs vary considerably. Information about the derivation of fatigue MIDs is needed to evaluate their applicability and suitability for use in clinical practice and research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YCQFL7SU\\nordin_et_al_2016_minimal_important_differences_for_fatigue_patient_reported_outcome_measures—a.pdf},
  journal = {BMC Medical Research Methodology},
  keywords = {fatigue,Fatigue,mcid,mcii,mid,MID,minimal important difference,Minimal important difference,prom,PROM,Syst,systematic review},
  number = {1},
  pmid = {27387456}
}

@techreport{Norman2014,
  title = {Lagr\aa dsremiss {{\"Andringar}} Av Statistiksekretessen},
  author = {Norman, Peter},
  year = {2014},
  pages = {1--24},
  keywords = {\#nosource}
}

@article{Normand2016,
  title = {League Tables for Hospital Comparisons},
  author = {Normand, Sharon-Lise T. and Ash, Arlene S. and Fienberg, Stephen E. and Stukel, Th{\'e}r{\`e}se A. and Utts, Jessica and Louis, Thomas A.},
  year = {2016},
  volume = {3},
  pages = {21--50},
  issn = {2326-8298},
  doi = {10.1146/annurev-statistics-022513-115617},
  abstract = {We review statistical methods for estimating and interpreting league tables used to infer hospital quality with a primary focus on methods for partitioning variation into two types: (a) that associated with within-hospital variation for a homogeneous group of patients and (b) that produced by between-hospital variation. We discuss the types of covariates included in the model, hierarchical and nonhierarchical logistic regression models for conducting inferences in a low-information context and their associated trade-offs, and the role of hospital volume. We use all-cause mortality rates for US hospitals to illustrate concepts and methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YYKT6B6Y\\normand_et_al_2016_league_tables_for_hospital_comparisons.pdf},
  journal = {Annual Review of Statistics and Its Application},
  number = {1}
}

@article{Nur2010,
  title = {Modelling Relative Survival in the Presence of Incomplete Data: {{A}} Tutorial},
  author = {Nur, Ula and Shack, Lorraine G. and Rachet, Bernard and Carpenter, James R. and Coleman, Michel P.},
  year = {2010},
  volume = {39},
  pages = {118--128},
  issn = {03005771},
  doi = {10.1093/ije/dyp309},
  abstract = {Missing data frequently create problems in the analysis of population-based data sets, such as those collected by cancer registries. Restriction of analysis to records with complete data may yield inferences that are substantially different from those that would have been obtained had no data been missing. 'Naive' methods for handling missing data, such as restriction of the analysis to complete records or creation of a 'missing' category, have drawbacks that can invalidate the conclusions from the analysis. We offer a tutorial on modern methods for handling missing data in relative survival analysis.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\N3L5H7FP\\nur_et_al_2010_modelling_relative_survival_in_the_presence_of_incomplete_data.pdf},
  isbn = {1464-3685},
  journal = {International Journal of Epidemiology},
  keywords = {Cancer registry,Colorectal cancer,Missing data,Multiple imputation,Relative survival,Stage},
  number = {1},
  pmid = {19858106}
}

@article{Nurminen1995,
  title = {To Use or Not to Use the Odds Ratio in Epidemiologic Analysis},
  author = {Nurminen, Markku},
  year = {1995},
  volume = {11},
  pages = {365--371},
  journal = {European Journal of Epidemiology},
  keywords = {\#nosource,biometry,epidemiologic methods,odds ratio,risk difference,risk ratio},
  number = {365-371}
}

@article{obrienNonparametricTestAssociation1978,
  title = {A Nonparametric Test for Association with Censored Data},
  author = {O'Brien, Peter C. and O'Brien, Peter C.},
  year = {1978},
  month = jun,
  volume = {34},
  pages = {243--250},
  issn = {0006341X},
  doi = {10.2307/2530014},
  journal = {Biometrics},
  keywords = {\#nosource},
  number = {2}
}

@article{oconnorExplorationMasculinitiesAcademic2015,
  title = {Exploration of Masculinities in Academic Organisations: {{A}} Tentative Typology Using Career and Relationship Commitment},
  author = {O'Connor, Pat and O'Hagan, Clare and Brannen, Julia and O'Connor, Pat and O'Hagan, Clare and Brannen, Julia},
  year = {2015},
  volume = {63},
  pages = {528--546},
  issn = {14617064},
  doi = {10.1177/0011392115574859},
  abstract = {In the Irish context and internationally a good deal of attention has been paid to the performance of masculinity among school students. However with a small number of notable exceptions, relatively little attention has been paid to masculinities in academic organisations. Drawing on a qualitative study in one university, this article proposes a tentative typology of masculinities in such an organisation. This typology involves two axes: career commitment and relationship commitment (with respondents classified as strong or weak on each dimension). Four types of masculinities are identified: Type 1: Careerist masculinity: Strong career and weak relationship commitment; Type 2: Enterprising masculinity: Strong career and strong relationship commitment; Type 3: Pure scientific masculinity: Weak career and weak relationship commitment; Type 4: Family oriented breadwinning masculinity: Weak career and strong relationship commitment. The titles careerist masculinity and family oriented breadwinning masculinity reflect generic characteristics. The titles of the other two types reflect the data derived from this particular sample. Since one of the important contributions of this article is an understanding of masculinities in an academic organisation, labels which relate to that context have been used. Although three of these types modify hegemonic careerist masculinity, they all reflect the persistence of an underlying system of male privileging in the changing landscape of higher education. This typology is seen as potentially having implications for theories and practices of motivation and management in academic organisations. [ABSTRACT FROM AUTHOR]},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FVJX597M\\o'connor_et_al_2015_exploration_of_masculinities_in_academic_organisations.pdf},
  journal = {Current Sociology},
  keywords = {Academic organisations,career,carrière,engagement relationnel,institutions universitaires,masculinidades,masculinités,masculinities,organizaciones académicas,profesionales,relaciones de compromiso,relational commitment,Tipología,Typologie,typology},
  number = {4}
}

@article{odquistLowerAgeIncreases2018,
  title = {Lower Age Increases the Risk of Revision for Stemmed and Resurfacing Shoulder Hemi Arthroplasty: {{A}} Study from the {{Swedish}} Shoulder Arthroplasty Register},
  shorttitle = {Lower Age Increases the Risk of Revision for Stemmed and Resurfacing Shoulder Hemi Arthroplasty},
  author = {{\"O}dquist, Magnus and Hallberg, Kristofer and Rahme, Hans and Salomonsson, Bj{\"o}rn and Rosso, Aldana},
  year = {2018},
  month = jan,
  volume = {89},
  pages = {3--9},
  issn = {1745-3674, 1745-3682},
  doi = {10.1080/17453674.2017.1411081},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SG4JDNRV\\Ödquist et al_2018_Lower age increases the risk of revision for stemmed and resurfacing shoulder.pdf},
  journal = {Acta Orthopaedica},
  language = {en},
  number = {1}
}

@article{Oja2004,
  title = {Blind Separation of Positive Sources by Globally Convergent Gradient Search},
  author = {Oja, Erkki and Plumbley, Mark},
  year = {2004},
  month = sep,
  volume = {16},
  pages = {1811--1825},
  issn = {0899-7667},
  doi = {10.1162/0899766041336413},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EGGR3JMF\\oja_plumbley_2004_blind_separation_of_positive_sources_by_globally_convergent_gradient_search.pdf},
  journal = {Neural Computation},
  number = {9}
}

@article{Olczak2017,
  title = {Artificial Intelligence for Analyzing Orthopedic Trauma Radiographs: {{Deep}} Learning Algorithms\textemdash Are They on Par with Humans for Diagnosing Fractures?},
  author = {Olczak, Jakub and Fahlberg, Niklas and Maki, Atsuto and Razavian, Ali Sharif and Jilert, Anthony and Stark, Andr{\'e} and Sk{\"o}ldenberg, Olof and Gordon, Max},
  year = {2017},
  issn = {17453682},
  doi = {10.1080/17453674.2017.1344459},
  abstract = {Correspondence: max.gordon@ki.se Submitted 2017-03-01. Accepted 2017-06-06. Background and purpose \textemdash{} Recent advances in artifi cial intel-ligence (deep learning) have shown remarkable performance in classifying non-medical images, and the technology is believed to be the next technological revolution. So far it has never been applied in an orthopedic setting, and in this study we sought to determine the feasibility of using deep learning for skeletal radio-graphs. Methods \textemdash{} We extracted 256,000 wrist, hand, and ankle radiographs from Danderyd's Hospital and identifi ed 4 classes: fracture, laterality, body part, and exam view. We then selected 5 openly available deep learning networks that were adapted for these images. The most accurate network was benchmarked against a gold standard for fractures. We furthermore compared the network's performance with 2 senior orthopedic surgeons who reviewed images at the same resolution as the network. Results \textemdash{} All networks exhibited an accuracy of at least 90\% when identifying laterality, body part, and exam view. The fi nal accuracy for fractures was estimated at 83\% for the best perform-ing network. The network performed similarly to senior orthope-dic surgeons when presented with images at the same resolution as the network. The 2 reviewer Cohen's kappa under these condi-tions was 0.76. Interpretation \textemdash{} This study supports the use for orthopedic radiographs of artifi cial intelligence, which can perform at a human level. While current implementation lacks important fea-tures that surgeons require, e.g. risk of dislocation, classifi cations, measurements, and combining multiple exam views, these prob-lems have technical solutions that are waiting to be implemented for orthopedics.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\W4CLBQHY\\olczak_et_al_2017_artificial_intelligence_for_analyzing_orthopedic_trauma_radiographs.pdf},
  journal = {Acta Orthopaedica},
  pmid = {28681679}
}

@article{Olkin1958,
  title = {Unbiased Estimation of Certain Correlation Coefficients},
  author = {Olkin, Ingram and Pratt, John W. J.W.},
  year = {1958},
  volume = {29},
  pages = {201--211},
  issn = {00034851},
  doi = {10.2307/2237306},
  abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a p-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order 1/n and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It ha...},
  isbn = {1177706717},
  journal = {The Annals of Mathematical Statistics},
  keywords = {\#nosource},
  number = {1}
}

@article{Olkin1995,
  title = {Correlations Redux.},
  author = {Olkin, Ingram and Finn, Jeremy D.},
  year = {1995},
  volume = {118},
  pages = {155--164},
  abstract = {Correlational analysis is a cornerstone method of statistical analysis, yet most presentations of correlational techniques deal primarily with tests of significance. The focus of this article is obtaining explicit expressions for confidence intervals for functions of simple, partial, and multiple correlations. Not only do these permit tests of hypotheses about differences but they also allow a clear statement about the degree to which correlations differ. Several important differences of correlations for which tests and confidence intervals are not widely known are included among the procedures discussed. Among these is the comparison of 2 multiple correlations based on independent samples.},
  journal = {Psychological Bulletin},
  keywords = {\#nosource},
  number = {1}
}

@article{Olmos2015,
  title = {Propensity Scores: {{A}} Practical Introduction Using r},
  author = {Olmos, Antonio and Govindasamy, Priyalatha},
  year = {2015},
  volume = {11},
  pages = {1556--8180},
  issn = {1556-?-8180},
  abstract = {Background: This paper provides an introduction to propensity scores for evaluation practitioners. Purpose: The purpose of this paper is to provide the reader with a conceptual and practical introduction to propensity scores, matching using propensity scores, and its implementation using statistical R program/software. Setting: Not applicable Intervention: Not applicable Research Design: Not applicable Data Collection and Analysis: Not applicable Findings: In this demonstration paper, we describe the context in which propensity scores are used, including the conditions under which the use of propensity scores is recommended, as well as the basic assumptions needed for a correct implementation of the technique . Next , we describe some of the more common techniques used to conduct propensity score matching . We conclude with a description of the recommended steps associated with the implementation of propensity score matching using several packages developed in R , including syntax and brief interpretations of the output associated with every step .},
  journal = {Journal of MultiDisciplinary Evaluation},
  keywords = {\#nosource,propensity score analysis,propensity score matching,R},
  number = {25}
}

@article{Olshausen1996,
  title = {Emergence of Simple-Cell Receptive Field Properties by Learning a Sparse Code for Natural Images},
  author = {Olshausen, Bruno A. and Field, David J.},
  year = {1996},
  month = jun,
  volume = {381},
  pages = {607--609},
  issn = {0028-0836},
  doi = {10.1038/381607a0},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DZBMJ87B\\olshausen_field_1996_emergence_of_simple-cell_receptive_field_properties_by_learning_a_sparse_code.pdf},
  journal = {Nature},
  number = {6583}
}

@article{Ondeck2018,
  title = {Discriminative {{Ability}} of {{Elixhauser}}'s {{Comorbidity Measure}} Is {{Superior}} to {{Other Comorbidity Scores}} for {{Inpatient Adverse Outcomes After Total Hip Arthroplasty}}},
  author = {Ondeck, Nathaniel T. and Bohl, Daniel D. and Bovonratwet, Patawut and McLynn, Ryan P. and Cui, Jonathan J. and Grauer, Jonathan N.},
  year = {2018},
  month = jan,
  volume = {33},
  pages = {250--257},
  issn = {08835403},
  doi = {10.1016/j.arth.2017.08.032},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JY9SSAQH\\Ondeck et al_2018_Discriminative Ability of Elixhauser's Comorbidity Measure is Superior to Other.pdf},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {1}
}

@article{Ong2009,
  title = {Prosthetic {{Joint Infection Risk After Total Hip Arthroplasty}} in the {{Medicare Population}}},
  author = {Ong, Kevin L. and Kurtz, Steven M. and Lau, Edmund and Bozic, Kevin J. and Berry, Daniel J. and Parvizi, Javad},
  year = {2009},
  month = sep,
  volume = {24},
  pages = {105--109},
  issn = {08835403},
  doi = {10.1016/j.arth.2009.04.027},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {6}
}

@book{organizationICD10ClassificationMental1992,
  title = {The {{ICD}}-10 Classification of Mental and Behavioural Disorders : Clinical Descriptions and Diagnostic Guidelines.},
  author = {Organization, World Health},
  year = {1992},
  publisher = {{World Health Organization}},
  abstract = {Includes index. Notes on selected categories in the classification of mental and behavioural disorders in ICD-10 \textendash{} List of categories \textendash{} Clinical descriptions and diagnostic guidelines \textendash{} Annex. other conditions from ICD-10 often associated with mental and behavioural disorders \textendash{} List of principal investigators.},
  city = {Geneva},
  isbn = {92-4-154422-8},
  keywords = {\#nosource}
}

@article{Overgaard2015,
  title = {Regression Analysis of Censored Data Using Pseudo-Observations: {{An}} Update},
  author = {Overgaard, Morten and Andersen, Per K. and Parner, Erik T.},
  year = {2015},
  volume = {15},
  pages = {809--821},
  issn = {1536867X},
  doi = {10.1177/1536867x1501500313},
  abstract = {We present updated versions of the stpsurv, stpci, and stpmean commands, which were introduced in Parner and Andersen (2010, Stata Journal 10: 408-422), along with a new command, stplost. The commands generate pseudo-observations of the survival function, the cumulative incidence function under competing risks, the restricted mean survival-time function, and the causespecific lost-lifetime function. The pseudo-observations can be used to assess the effects of covariates on their respective functions at different times by fitting generalized linear models to the pseudo-observations. The updated commands feature new options, an increase in computational speed, and the ability to handle survival data with delayed entry.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\N26VXHUJ\\overgaard_et_al_2015_regression_analysis_of_censored_data_using_pseudo-observations.pdf},
  journal = {Stata Journal},
  keywords = {Pseudovalues,St0202₁,stpci,stplost,stpmean,stpsurv,Survival analysis,Time to event},
  number = {3}
}

@article{Ozenne2017,
  title = {{{riskRegression}} : {{Predicting}} the Risk of an Event Using Cox Regression Models},
  author = {Ozenne, Brice and S\o rensen, Anne Lyngholm and Scheike, Thomas and {Torp-pedersen}, Christian},
  year = {2017},
  volume = {9},
  pages = {440--460},
  issn = {20734859},
  doi = {10.1113/jphysiol.1992.sp019284},
  abstract = {In the presence of competing risks a prediction of the time-dynamic absolute risk of an event can be based on cause-specific Cox regression models for the event and the competing risks (Benichou and Gail, 1990). We present computationally fast and memory optimized C++ functions with an R inter-face for predicting the covariate specific absolute risks, their confidence intervals, and their confidence bands based on right censored time to event data. We provide explicit formulas for our implementation of the estimator of the (stratified) baseline hazard function in the presence of tied event times. As a by-product we obtain fast access to the baseline hazards (compared to survival::basehaz()) and predictions of survival probabilities, their confidence intervals and confidence bands. Confidence intervals and confidence bands are based on point-wise asymptotic expansions of the corresponding statistical functionals. The software presented here is implemented in the riskRegression package.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RC22DQRH\\ozenne_et_al_2017_riskregression.pdf},
  journal = {The R Journal},
  number = {2}
}

@article{Ozer1985,
  title = {Correlation and the Coefficient of Determination.},
  author = {Ozer, Daniel J.},
  year = {1985},
  volume = {97},
  pages = {307--315},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.97.2.307},
  abstract = {Contends that both the interpretation of an effect size and the actual estimation of a coefficient of determination are partially theory-dependent. Two theoretical models for the variables cases are considered. In a variety of circumstances where the square of the correlation is used, the required assumptions are not tenable. In the alternate model, the absolute value of the correlation provides a coefficient of determination. The correlation coefficient is recommended for use as an effect-size indicator, because evaluating effect size in terms of variance accounted for may lead to interpretations that grossly underestimate the magnitude of a relation. (25 ref) (PsycINFO Database Record (c) 2010 APA )},
  isbn = {0033-2909},
  journal = {Psychological Bulletin},
  keywords = {\#nosource},
  number = {2}
}

@article{Ozturk2010,
  title = {The Risk Factors for Mortality in Elderly Patients with Hip Fractures: Postoperative One-Year Results},
  author = {Ozturk, A and Ozkan, Y and Akgoz, S and Yalcyn, N and Ozdemir, R M and Aykut, S},
  year = {2010},
  volume = {51},
  pages = {137--143},
  issn = {00375675},
  abstract = {INTRODUCTION: Hip fractures in the elderly are associated with significant mortality. This study aimed to investigate the risk factors for mortality in elderly patients with hip fractures during a one-year period. METHODS: This was a prospective study which included consecutive isolated nonpathologic hip fractures in 74 (52 female, 22 male) patients in a level-1 trauma centre. These patients were 65 years or older and were ambulatory before the fracture. The patients were treated with hemiarthroplasty. The factors investigated were age, gender, nutritional status determined by blood albumin and total lymphocyte count, haemoglobin levels on the day of admission, mobilisation time after surgery, length of hospital stay, comorbidities, American Society of Anaesthesiologists (ASA) rating of operative risk, and the time period between injury and surgery. The patients were followed up for one year after surgery, or until death. RESULTS: In total, 15 patients died during the one-year period. Patient survival was 94.6 percent at 3 months, 81.1 percent at 6 months and 79.7 percent at 12 months. There were two in-hospital deaths. The factors significantly associated with mortality were patients with more than two comorbidities, an ASA score of III-IV, a blood albumin level of less than 3.5 g/dl and a total lymphocyte count of less than 1500 cells/ml on admission. However, after the multivariate analysis, an ASA score of III-IV, low total lymphocyte count, female gender and low haemoglobin levels on admission remained the independent and significant risk factors associated with a one-year mortality. CONCLUSION: This study confirms that a high ASA score, female gender, a lower lymphocyte count and low haemoglobin levels on admission are significant factors in assessing the one-year mortality in elderly patients with hip fractures. Predicting these risk factors improves the case management.},
  isbn = {0037-5675},
  journal = {Singapore Medical Journal},
  keywords = {*Anemia,*Hemoglobins/an [Analysis],*Hip Fractures/mo [Mortality],*Lymphocyte Count,\#nosource,0 (Hemoglobins),80 and over,Aged,Arthroplasty,Female,Hip,Hip Fractures/su [Surgery],Humans,Kaplan-Meier Estimate,Male,Prospective Studies,Replacement,Risk Factors,Sex Factors,Turkey/ep [Epidemiology]},
  number = {2},
  pmid = {20358153}
}

@article{Paatero1994,
  title = {Positive Matrix Factorization: {{A}} Non-Negative Factor Model with Optimal Utilization of Error Estimates of Data Values},
  author = {Paatero, Pentti and Tapper, Unto},
  year = {1994},
  month = jun,
  volume = {5},
  pages = {111--126},
  issn = {11804009},
  doi = {10.1002/env.3170050203},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MBEPKNFY\\paatero_tapper_1994_positive_matrix_factorization.pdf},
  journal = {Environmetrics},
  number = {2}
}

@article{Paksima2008,
  title = {Predictors of Mortality after Hip Fracture: {{A}} 10-{{Year}} Prospective Study},
  author = {Paksima, Nader and Koval, Kenneth J K.J. and Aharanoff, Gina and Walsh, Michael and Kubiak, Erik N E.N. and Zuckerman, Joseph D J.D. and Egol, K.A. Kenneth A},
  year = {2008},
  volume = {66},
  pages = {111--117},
  issn = {19369719 19369727},
  doi = {10.1016/j.ejim.2013.08.595},
  abstract = {The role of medical, social, and functional covariates on mortality after hip fracture was examined over a 16-year period. A total of 1109 patients with hip fractures were included in a prospective database. The inclusion criteria were patients who were age 65 years or older, ambulatory prior to fracture, cognitively intact, living in their own home at the time of the fracture, and had sustained a nonpathological femoral neck or intertrochanteric hip fracture. Data were analyzed using a Cox proportional hazards model. Mortality was compared with a standardized population, and standardized mortality ratios were calculated for 1, 2, 3, 5, and 10 years, respectively. The 1-, 2-, 5- and 10-year mortality rates were 11.9\%, 18.5\%, 41.2\%, and 75.3\%, respectively. The predictors of mortality were advanced age, male gender, high American Society of Anesthesiologists (ASA) classification, the presence of a major postoperative complication, a history of cancer, chronic obstructive pulmonary disorder, a history of congestive heart failure, ambulating with an assistive device, or being a household ambulator prior to hip fracture. The increased mortality risk was highest during the first year after hip fracture and returned to the risk of the standard population 3 years postoperatively. Males who are 65 to 84 years had the highest mortality risk.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Q2WX8WJQ\\paksima_et_al_2008_predictors_of_mortality_after_hip_fracture.pdf},
  journal = {Bulletin of the NYU Hospital for Joint Diseases},
  number = {2}
}

@article{Palan2018,
  title = {Surgical Approaches for Primary Total Hip Replacement},
  author = {Palan, Jeya and Manktelow, Andrew},
  year = {2018},
  volume = {32},
  pages = {1--12},
  publisher = {{Elsevier Ltd}},
  issn = {18771335},
  doi = {10.1016/j.mporth.2017.11.003},
  abstract = {Excellent exposure is an essential requirement for successful hip surgery. The surgical approach selected should provide appropriate exposure of the acetabulum together with safe mobilization and exposure of the proximal femur. The approach should be versatile, allowing adequate release and exposure in the various circumstances in which primary hip arthroplasty is indicated. It should be extensile, allowing intraoperative flexibility, safe, avoiding significant risk to adjacent neurovascular structures and limit soft tissue damage and blood loss. This review article describes the common surgical approaches used for primary total hip replacement, reviewing those in common use and discussing reduced access variations on those approaches. Newer trends, such as the direct anterior approach and the direct superior approaches will be described. The strengths, limitations and clinical evidence related to each option will be discussed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JK3G2CYY\\palan_manktelow_2018_surgical_approaches_for_primary_total_hip_replacement.pdf},
  journal = {Orthopaedics and Trauma},
  keywords = {Direct anterior approach,Hardinge approach,McFarlane and Osborne approach,posterior approach,primary total hip replacement,supercapsular percutaneous assisted total hip (Sup},
  number = {1}
}

@article{Palm2012,
  title = {A New Algorithm for Hip Fracture Surgery},
  author = {Palm, Henrik and Krasheninnikoff, Michael and Holck, Kim and Lemser, Tom and Foss, Nicolai Bang and Jacobsen, Steffen and Kehlet, Henrik and Gebuhr, Peter},
  year = {2012},
  volume = {83},
  pages = {26--30},
  issn = {17453674},
  doi = {10.3109/17453674.2011.652887},
  abstract = {Treatment of hip fracture patients is controversial. We implemented a new operative and supervision algorithm (the Hvidovre algorithm) for surgical treatment of all hip fractures, primarily based on own previously published results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6TT5A487\\palm_et_al_2012_a_new_algorithm_for_hip_fracture_surgery.pdf},
  isbn = {1745-3682 (Electronic){\r  }1745-3674 (Linking)},
  journal = {Acta Orthopaedica},
  number = {1},
  pmid = {22248165}
}

@incollection{Palm2017,
  title = {Hip {{Fracture}}: {{The Choice}} of {{Surgery}}},
  shorttitle = {Hip {{Fracture}}},
  booktitle = {Orthogeriatrics},
  author = {Palm, Henrik},
  editor = {Falaschi, Paolo and Marsh, David R.},
  year = {2017},
  pages = {81--96},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-43249-6_6},
  abstract = {Hip fractures are operated with either prosthesis or various kinds of fracture fixation devices, with the aim of immediate mobilisation with full weight-bearing. Challenges are osteoporotic bone, bone vascularity, muscle-attachments, maintaining fracture reduction and slow fracture healing in the often-elderly population and, although reduced in recent years, still 5\textendash 20 \% of patients need a reoperation, mainly depending on fracture type and choice of surgery. The extensive literature has created partial treatment consensus: Undisplaced femoral neck fractures seem adequately treated with parallel screws/pins or a sliding hip screw, while the displaced femoral neck fractures should be given a prosthesis in elderly patients. The stable trochanteric fractures are well treated with a sliding hip screw, while intramedullary nails seem superior for the unstable trochanteric and the sub-trochanteric fractures. During the last decades surgical guidelines have gained ground, along with national surgical quality standards and registries with possible identification of positive and negative outliers \textendash{} which is expected to further improve the surgical outcome.},
  isbn = {978-3-319-43249-6},
  keywords = {Femoral Head,Femoral Neck Fracture,Intramedullary Nail,Trochanteric Fracture,Unstable Trochanteric Fracture},
  language = {en},
  series = {Practical {{Issues}} in {{Geriatrics}}}
}

@article{Panula2011,
  title = {Mortality and Cause of Death in Hip Fracture Patients Aged 65 or Older - a Population-Based Study},
  author = {Panula, Jorma and Pihlajam{\"a}ki, Harri and Mattila, Ville M and Jaatinen, Pekka and Vahlberg, Tero and Aarnio, Pertti and Kivel{\"a}, Sirkka-Liisa},
  year = {2011},
  volume = {12},
  pages = {105},
  issn = {1471-2474},
  doi = {10.1186/1471-2474-12-105},
  abstract = {The high mortality of hip fracture patients is well documented, but sex- and cause-specific mortality after hip fracture has not been extensively studied. The purpose of the present study was to evaluate mortality and cause of death in patients after hip fracture surgery and to compare their mortality and cause of death to those in the general population.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E4JSZP4D\\panula_et_al_2011_mortality_and_cause_of_death_in_hip_fracture_patients_aged_65_or_older_-_a.pdf},
  isbn = {1471-2474},
  journal = {BMC Musculoskeletal Disorders},
  number = {1},
  pmid = {21599967}
}

@article{Panzram1987,
  title = {Mortality and Survival in {{Type}} 2 (Non-Insulin-Dependent) Diabetes Mellitus},
  author = {Panzram, G.},
  year = {1987},
  volume = {30},
  pages = {123--131},
  issn = {0012-186X},
  doi = {10.1007/BF00274216},
  abstract = {The prognosis of a patient with Type 2 (non-insulin-de-pendent) diabetes mellitus varies considerably from one individual to another. The reasons for the variability in the individual prognoses include (1)the possibility that Type 2 diabetes in a given patient represents a clinically inconsequential metabolic disorder without any seque-lae for length and quality of life; (2) the occurrence of severe, life-shortening vascular complications in asso-ciation with Type 2 diabetes; and (3) the development of acute life-threatening events such as (hyperosomolar or ketoacidotic) coma or iatrogenic complications, e.g. hy-poglycaemia. As with other chronic diseases, general-isations of the prognoses of Type 2 diabetes by means of mortality and survival statistics are of limited predictive value for individual outcomes. However, knowledge about its course and natural history characterises the impact of the disease on public health, thus forming an essential basis for improved prevention and therapy strategies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PH7E8M3I\\panzram_1987_mortality_and_survival_in_type_2_(non-insulin-dependent)_diabetes_mellitus.pdf},
  isbn = {1432-0428},
  journal = {Diabetologia},
  number = {3},
  pmid = {3556287}
}

@book{Pardo2005,
  title = {Statistical Inference Based on Divergence Measures},
  author = {Pardo, Leandro},
  year = {2005},
  volume = {185},
  issn = {0964-1998},
  doi = {10.1201/9781420034813},
  abstract = {The idea of using functionals of Information Theory, such as entropies or divergences, in statistical inference is not new. However, in spite of the fact that divergence statistics have become a very good alternative to the classical likelihood ratio test and the Pearson-type statistic in discrete models, many statisticians remain unaware of this powerful approach.Statistical Inference Based on Divergence Measures explores classical problems of statistical inference, such as estimation and hypothesis testing, on the basis of measures of entropy and divergence. The first two chapters form an overview, from a statistical perspective, of the most important measures of entropy and divergence and study their properties. The author then examines the statistical analysis of discrete multivariate data with emphasis is on problems in contingency tables and loglinear models using phi-divergence test statistics as well as minimum phi-divergence estimators. The final chapter looks at testing in general populations, presenting the interesting possibility of introducing alternative test statistics to classical ones like Wald, Rao, and likelihood ratio. Each chapter concludes with exercises that clarify the theoretical results and present additional results that complement the main discussions.Clear, comprehensive, and logically developed, this book offers a unique opportunity to gain not only a new perspective on some standard statistics problems, but the tools to put it into practice.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DIV8URNJ\\pardo_2005_statistical_inference_based_on_divergence_measures.pdf},
  isbn = {978-1-58488-600-6},
  pmid = {14011859}
}

@article{Park1964,
  title = {Variations of the Non-Central t and Beta Distributions},
  author = {Park, John H Jr},
  year = {1964},
  volume = {35},
  pages = {1583--1593},
  journal = {The Annals of Mathematical Statistics},
  keywords = {\#nosource},
  number = {4}
}

@article{Park2016,
  title = {Current Management of Aneurysmal Bone Cysts},
  author = {Park, Howard Y. and Yang, Sara K. and Sheppard, William L. and Hegde, Vishal and Zoller, Stephen D. and Nelson, Scott D. and Federman, Noah and Bernthal, Nicholas M.},
  year = {2016},
  month = dec,
  volume = {9},
  pages = {435--444},
  publisher = {{Springer US}},
  doi = {10.1007/s12178-016-9371-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EBS2GVXW\\park_et_al_2016_current_management_of_aneurysmal_bone_cysts.pdf},
  journal = {Current Reviews in Musculoskeletal Medicine},
  number = {4}
}

@article{Parkin1991,
  title = {Chapter 12. {{Analysis}} of Survival},
  author = {Parkin, D M and Hakulinen, T},
  year = {1991},
  pages = {159--176},
  journal = {Cancer registration principles and methods},
  keywords = {\#nosource}
}

@article{Parner2010,
  title = {Regression Analysis of Censored Data Using Pseudo-Observations},
  author = {Parner, Erik T and Andersen, Per K},
  year = {2010},
  volume = {10},
  pages = {408--422},
  journal = {The Stata Journal},
  keywords = {\#nosource,pseudovalues,st0202,stpci,stpmean,stpsurv,survival,time-to-event},
  number = {3}
}

@article{Parry2011,
  title = {Cancer Survivors: {{A}} Booming Population},
  author = {Parry, C. and Kent, E. E. and Mariotto, A. B. and Alfano, C. M. and Rowland, J. H.},
  year = {2011},
  month = oct,
  volume = {20},
  pages = {1996--2005},
  issn = {1055-9965},
  doi = {10.1158/1055-9965.EPI-11-0729},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\A6F4IYKR\\parry_et_al_2011_cancer_survivors.pdf},
  journal = {Cancer Epidemiology Biomarkers \& Prevention},
  number = {10}
}

@article{Partridge2012,
  title = {Frailty in the Older Surgical Patient: {{A}} Review},
  author = {Partridge, Judith S L and Harari, Danielle and Dhesi, Jugdeep K.},
  year = {2012},
  volume = {41},
  pages = {142--147},
  issn = {00020729},
  doi = {10.1093/ageing/afr182},
  abstract = {The rate of surgical procedures in the older population is rising. Despite surgical, anaesthetic and medical advances, older surgical patients continue to suffer from adverse postoperative outcomes. Comorbidities and reduction in physiological reserve are consistently identified as major predictors of poor postoperative outcome in this population. Frailty can be defined as a lack of physiological reserve seen across multiple organ systems and is an independent predictor of mortality, morbidity and institutionalisation after surgery. Despite this identification of frailty as a significant predictor of adverse postoperative outcome, there is not yet a consensus on the definition of frailty or how best to assess and diagnose it. This review describes our current definitions of frailty and discusses the available methods of assessing frailty, the impact on the older surgical population and the emerging potential for modification of this important syndrome.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JEGVAVSF\\partridge_et_al_2012_frailty_in_the_older_surgical_patient.pdf},
  isbn = {0002-07291468-2834},
  journal = {Age and Ageing},
  keywords = {Elderly,Frailty,Interventions,Older adults,Outcomes,Surgery},
  number = {2},
  pmid = {22345294}
}

@article{Parvizi2006,
  title = {One-Stage Bilateral Total Hip Arthroplasty Compared with Unilateral Total Hip Arthroplasty: {{A}} Prospective Study},
  author = {Parvizi, Javad and Pour, Aidin Eslam and Peak, E. Louis and Sharkey, Peter F. and Hozack, William J. and Rothman, Richard H.},
  year = {2006},
  month = sep,
  volume = {21},
  pages = {26--31},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2006.04.013},
  abstract = {It is believed that patients undergoing 1-stage bilateral joint arthroplasty are at higher risk for developing cardiopulmonary and possibly other complications. The aim of this prospective matched study was to evaluate and compare the morbidity profile of patients undergoing 1-stage bilateral uncemented total hip arthroplasty (BTHA) vs unilateral uncemented THA (UTHA). One hundred consecutive patients undergoing 1-stage bilateral THA (50 patients, 100 hips) and unilateral THA (50 patients) were recruited and prospectively followed. There were no statistically significant differences in 90-day mortality, individual major (BTHA, 8\%; UTHA, 10\%) or minor (BTHA, 20\%; UTHA, 26\%) complications between the 2 groups. Bilateral THA patients required more autologous and allogenic blood transfusion and had lower hemoglobin at discharge than UTHA patients. Patients undergoing BTHA should expect a slightly higher incidence of complications related to postoperative anemia.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J6G3VJ4E\\parvizi_et_al_2006_one-stage_bilateral_total_hip_arthroplasty_compared_with_unilateral_total_hip.pdf},
  journal = {The Journal of Arthroplasty},
  number = {6}
}

@article{Parvizi2006,
  title = {Bilateral Total Hip Arthroplasty},
  author = {Parvizi, Javad and Tarity, T David and Sheikh, Ednan and Sharkey, Peter F and Hozack, William J and Rothman, Richard H},
  year = {2006},
  month = dec,
  volume = {453},
  pages = {137--141},
  issn = {0009-921X},
  doi = {10.1097/01.blo.0000246529.14135.2b},
  journal = {Clinical Orthopaedics and Related Research},
  keywords = {\#nosource}
}

@article{Patel2015,
  title = {The Epidemiology of Revision Total Knee and Hip Arthroplasty in {{England}} and {{Wales}}: {{A}} Comparative Analysis with Projections for the {{United States}}. a Study Using the National Joint Registry Dataset},
  author = {Patel, A. and Pavlou, G. and {M{\'u}jica-Mota}, R. E. and Toms, A. D.},
  year = {2015},
  volume = {97-B},
  pages = {1076--1081},
  issn = {20494408},
  doi = {10.1302/0301-620X.97B8.35170},
  abstract = {Total knee arthroplasty (TKA) and total hip arthroplasty (THA) are recognised and proven interventions for patients with advanced arthritis. Studies to date have demonstrated a steady increase in the requirement for primary and revision procedures. Projected estimates made for the United States show that by 2030 the demand for primary TKA will grow by 673\% and for revision TKA by 601\% from the level in 2005. For THA the projected estimates are 174\% and 137\% for primary and revision surgery, respectively. The purpose of this study was to see if those predictions were similar for England and Wales using data from the National Joint Registry and the Office of National Statistics. Analysis of data for England and Wales suggest that by 2030, the volume of primary and revision TKAs will have increased by 117\% and 332\%, respectively between 2012 and 2030. The data for the United States translates to a 306\% cumulative rate of increase between 2012 and 2030 for revision surgery, which is similar to our predictions for England and Wales. The predictions from the United States for primary TKA were similar to our upper limit projections. For THA, we predicted an increase of 134\% and 31\% for primary and revision hip surgery, respectively. Our model has limitations, however, it highlights the economic burden of arthroplasty in the future in England and Wales as a real and unaddressed problem. This will have significant implications for the provision of health care and the management of orthopaedic services in the future.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MZBCCQ6C\\patel_et_al_2015_the_epidemiology_of_revision_total_knee_and_hip_arthroplasty_in_england_and.pdf},
  isbn = {2049-4394},
  journal = {Bone and Joint Journal},
  number = {8},
  pmid = {26224824}
}

@article{Patrick2011,
  title = {Content Validity - {{Establishing}} and Reporting the Evidence in Newly Developed Patient-Reported Outcomes ({{PRO}}) Instruments for Medical Product Evaluation: {{ISPOR PRO}} Good Research Practices Task Force Report: {{Part}} 2 - {{Assessing}} Respondent Understanding},
  author = {Patrick, Donald L. and Burke, Laurie B. and Gwaltney, Chad J. and Leidy, Nancy Kline and Martin, Mona L. and Molsen, Elizabeth and Ring, Lena},
  year = {2011},
  volume = {14},
  pages = {978--988},
  publisher = {{Elsevier Inc.}},
  issn = {10983015},
  doi = {10.1016/j.jval.2011.06.013},
  abstract = {The importance of content validity in developing patient reported outcomes (PRO) instruments is stressed by both the US Food and Drug Administration and the European Medicines Agency. Content validity is the extent to which an instrument measures the important aspects of concepts developers or users purport it to assess. A PRO instrument measures the concepts most relevant and important to a patient's condition and its treatment. For PRO instruments, items and domains as reflected in the scores of an instrument should be important to the target population and comprehensive with respect to patient concerns. Documentation of target population input in item generation, as well as evaluation of patient understanding through cognitive interviewing, can provide the evidence for content validity. Part 1 of this task force report covers elicitation of key concepts using qualitative focus groups and/or interviews to inform content and structure of a new PRO instrument. Building on qualitative interviews and focus groups used to elicit concepts, cognitive interviews help developers craft items that can be understood by respondents in the target population and can ultimately confirm that the final instrument is appropriate, comprehensive, and understandable in the target population. Part 2 details: 1) the methods for conducting cognitive interviews that address patient understanding of items, instructions, and response options; and 2) the methods for tracking item development through the various stages of research and preparing this tracking for submission to regulatory agencies. The task force report's two parts are meant to be read together. They are intended to offer suggestions for good practice in planning, executing, and documenting qualitative studies that are used to support the content validity of PRO instruments to be used in medical product evaluation. \textcopyright{} 2011 International Society for Pharmacoeconomics and Outcomes Research (ISPOR).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VP7JLXLH\\patrick_et_al_2011_content_validity_-_establishing_and_reporting_the_evidence_in_newly_developed.pdf},
  isbn = {1524-4733 (Electronic)1098-3015 (Linking)},
  journal = {Value in Health},
  keywords = {content validity,instrument development,patient-reported outcomes,qualitative research,regulatory},
  number = {8},
  pmid = {22152166}
}

@article{paulkaplanNonparametricEstimationIncomplete2016,
  title = {Nonparametric Estimation from Incomplete Observations Authors ( s ): {{E}} . {{L}} . {{Kaplan}} and Paul Meier Source : {{Journal}} of the American Statistical Association , Vol . 53 , No . 282 ( Jun ., 1958 ), Pp . {{Published}} by : {{Taylor}} \& Francis , Ltd . on Behalf of Th},
  author = {Paul Kaplan, E.L; Meier},
  year = {2016},
  volume = {53},
  pages = {457--481},
  isbn = {0864311893},
  journal = {Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {282}
}

@book{Pavliscak2015,
  title = {Data-Informed Product Design},
  author = {Pavliscak, Pamela},
  year = {2015},
  isbn = {978-1-4919-3129-5},
  keywords = {\#nosource}
}

@article{Pavlou2015,
  title = {How to Develop a More Accurate Risk Prediction Model When There Are Few Events.},
  author = {Pavlou, Menelaos and Ambler, Gareth and Seaman, Shaun R and Guttmann, Oliver and Elliott, Perry and King, Michael and Omar, Rumana Z},
  year = {2015},
  month = aug,
  volume = {351},
  pages = {h3868},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.h3868},
  abstract = {When the number of events is low relative to the number of predictors, standard regression could produce overfitted risk models that make inaccurate predictions. Use of penalised regression may improve the accuracy of risk prediction \#\#\#\# Summary points Risk prediction models that typically use a number of predictors based on patient characteristics to predict health outcomes are a cornerstone of modern clinical medicine.1 Models developed using data with few events compared with the number of predictors often underperform when applied to new patient cohorts.2 A key statistical reason for this is ``model overfitting.'' Overfitted models tend to underestimate the probability of an event in low risk patients and overestimate it in high risk patients, which could affect clinical decision making. In this paper, we discuss the potential of penalised regression methods to alleviate this problem and thus develop more accurate prediction models. Statistical models are often used to predict the probability that an individual with a given set of risk factors will experience a health outcome, usually termed an ``event.'' These risk prediction models can help in clinical decision making and help patients make an informed choice regarding their treatment.3 4 5 6 Risk models are developed using several risk factors typically based on patient characteristics that are thought to be associated with the health event of interest (box \ldots},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TK72I6SH\\pavlou_et_al_2015_how_to_develop_a_more_accurate_risk_prediction_model_when_there_are_few_events.pdf},
  journal = {BMJ (Clinical research ed.)},
  pmid = {26264962}
}

@article{Paxton2015,
  title = {Risk Calculators Predict Failures of Knee and Hip Arthroplasties: {{Findings}} from a Large Health Maintenance Organization},
  author = {Paxton, Elizabeth W. and Inacio, Maria C. S. and Khatod, Monti and Yue, Eric and Funahashi, Tadashi and Barber, Thomas},
  year = {2015},
  volume = {473},
  pages = {3965--3973},
  publisher = {{Springer US}},
  issn = {0009-921X},
  doi = {10.1007/s11999-015-4506-4},
  abstract = {Background Considering the cost and risk associated with revision Total knee arthroplasty (TKAs) and Total hip arthroplasty (THAs), steps to prevent these operations will help patients and reduce healthcare costs. Revision risk calculators for patients may reduce revision surgery by supporting clinical decision-making at the point of care. Questions/purposes We sought to develop a TKA and THA revision risk calculator using data from a large health-maintenance organization's arthroplasty registry and determine the best set of predictors for the revision risk calculator. Methods Revision risk calculators for THAs and TKAs were developed using a patient cohort from a total joint replacement registry and data from a large US integrated healthcare system. The cohort included all patients who had primary procedures performed in our healthcare system between April 2001 and July 2008 and were followed until January 2014 (TKAs, n = 41,750; THAs, n = 22,721), During the study period, 9\% of patients (TKA = 3066/34,686; THA=1898/20,285) were lost to followup and 7\% died (TKA= 2350/41,750; THA=1419/20,285). The outcome of interest was revision surgery and was defined as replacement of any component for any reason within 5 years postoperatively. Candidate predictors for the revision risk calculator were limited to preoperative patient demographics, comorbidities, and procedure diagnoses. Logistic regression models were used to identify predictors and the Hosmer-Lemeshow goodness-of-fit test and c-statistic were used to choose final models for the revision risk calculator. Results The best predictors for the TKA revision risk calculator were age (odds ratio [OR], 0.96; 95\% CI, 0.95-0.97; p \textexclamdown{} 0.001), sex (OR, 0.84; 95\% CI, 0.75-0.95; p = 0.004), square-root BMI (OR, 1.05; 95\% CI, 0.99-1.11; p = 0.140), diabetes (OR, 1.32; 95\% CI, 1.17-1.48; p \textexclamdown{} 0.001), osteoarthritis (OR, 1.16; 95\% CI, 0.84-1.62; p = 0.368), posttraumatic arthritis (OR, 1.66; 95\% CI, 1.07-2.56; p = 0.022), and osteonecrosis (OR, 2.54; 95\% CI, 1.31-4.92; p = 0.006). The best predictors for the THA revision risk calculator were sex (OR, 1.24; 95\% CI, 1.05-1.46; p = 0.010), age (OR, 0.98; 95\% CI, 0.98-0.99; p \textexclamdown{} 0.001), square-root BMI (OR, 1.07; 95\% CI, 1.00-1.15; p = 0.066), and osteoarthritis (OR, 0.85; 95\% CI, 0.66-1.09; p = 0.190). Conclusions Study model parameters can be used to create web-based calculators. Surgeons can enter personalized patient data in the risk calculators for identification of risk of revision which can be used for clinical decision making at the point of care. Future prospective studies will be needed to validate these calculators and to refine them with time.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JRNUWY9S\\paxton_et_al_2015_risk_calculators_predict_failures_of_knee_and_hip_arthroplasties.pdf},
  isbn = {0009-921x},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  number = {12},
  pmid = {26324831}
}

@article{Paxton2015,
  title = {Are There Modifiable Risk Factors for Hospital Readmission after Total Hip Arthroplasty in a {{US}} Healthcare System?},
  author = {Paxton, Elizabeth W. and Inacio, Maria C. S. and Singh, Jasvinder A. and Love, Rebecca and Bini, Stefano A. and Namba, Robert S.},
  year = {2015},
  month = nov,
  volume = {473},
  pages = {3446--3455},
  issn = {0009-921X},
  doi = {10.1007/s11999-015-4278-x},
  abstract = {BACKGROUND: Although total hip arthroplasty (THA) is a successful procedure, 4\% to 11\% of patients who undergo THA are readmitted to the hospital. Prior studies have reported rates and risk factors of THA readmission but have been limited to single-center samples, administrative claims data, or Medicare patients. As a result, hospital readmission risk factors for a large proportion of patients undergoing THA are not fully understood./PURPOSES: (1) What is the incidence of hospital readmissions after primary THA and the reasons for readmission? (2) What are the risk factors for hospital readmissions in a large, integrated healthcare system using current perioperative care protocols?: The Kaiser Permanente (KP) Total Joint Replacement Registry (TJRR) was used to identify all patients with primary unilateral THAs registered between January 1, 2009, and December 31, 2011. The KPTJRR's voluntary participation is 95\%. A logistic regression model was used to study the relationship of risk factors (including patient, clinical, and system-related) and the likelihood of 30-day readmission. Readmissions were identified using electronic health and claims records to capture readmissions within and outside the system. Odds ratio (OR) and 95\% confidence intervals (CIs) were calculated. Of the 12,030 patients undergoing primary THAs included in the study, 59\% (n = 7093) were women and average patient age was 66.5 years ({$\pm$} 10.7).: There were 436 (3.6\%) patients with hospital readmissions within 30 days of the index procedure. The most common reasons for readmission were infection and inflammatory reaction resulting from internal joint prosthetic (International Classification of Diseases, 9(th) Revision, Clinical Modification [ICD-9-CM] 996.66, 7.0\%); other postoperative infection (ICD-9-CM 998:59, 5.5\%); unspecified septicemia (ICD-9-CM 038.9, 4.9\%); and dislocation of a prosthetic joint (ICD-9-CM 996.42, 4.7\%). In adjusted models, the following factors were associated with an increased likelihood of 30-day readmission: medical complications (OR, 2.80; 95\% CI, 1.59-4.93); discharge to facilities other than home (OR, 1.89; 95\% CI, 1.39-2.58); length of stay of 5 or more days (OR, 1.80; 95\% CI, 1.22-2.65) versus 3 days; morbid obesity (OR, 1.74; 95\% CI, 1.25-2.43); surgeries performed by high-volume surgeons compared with medium volume (OR, 1.53; 95\% CI, 1.14-2.08); procedures at lower-volume (OR, 1.41; 95\% CI, 1.07-1.85) and medium-volume hospitals (OR, 1.81; 95\% CI, 1.20-2.72) compared with high-volume ones; sex (men: OR, 1.51; 95\% CI, 1.18-1.92); obesity (OR, 1.32; 95\% CI, 1.02-1.72); race (black: OR, 1.26; 95\% CI, 1.02-1.57); increasing age (OR, 1.03; 95\% CI, 1.01-1.04); and certain comorbidities (pulmonary circulation disease, chronic pulmonary disease, hypothyroidism, and psychoses).: The 30-day hospital readmission rate after primary THA was 3.6\%. Modifiable factors, including obesity, comorbidities, medical complications, and system-related factors (hospital), have the potential to be addressed by improving the health of patients before this elective procedure, patient and family education and planning, and with the development of high-volume centers of excellence. Nonmodifiable factors such as age, sex, and race can be used to establish patient and family expectations regarding risk of readmission after THA. Contrary to other studies and the finding of increased hospital volume associated with lower risk of readmission, higher volume surgeons had a higher risk of patient readmission, which may be attributable to the referral patterns in our organization.OF EVIDENCE: Level III, therapeutic study.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XQCEZXSY\\paxton_et_al_2015_are_there_modifiable_risk_factors_for_hospital_readmission_after_total_hip.pdf},
  isbn = {1528-1132 (Electronic){\r  }0009-921X (Linking)},
  journal = {Clinical Orthopaedics and Related Research\textregistered},
  keywords = {Age Factors,Aged,Arthroplasty,California,California: epidemiology,Comorbidity,Female,Hawaii,Hawaii: epidemiology,Health Maintenance Organizations,High-Volume,Hip,Hip: adverse effects,Hospitals,Humans,Incidence,Logistic Models,Low-Volume,Male,Middle Aged,Odds Ratio,Patient Readmission,Postoperative Complications,Postoperative Complications: diagnosis,Postoperative Complications: epidemiology,Postoperative Complications: therapy,Registries,Replacement,Risk Factors,Sex Factors,Time Factors,Treatment Outcome},
  number = {11},
  pmid = {25845947}
}

@article{Pearson1895,
  title = {Note on Regression and Inheritance in the Case of Two Parents},
  author = {Pearson, Karl},
  year = {1895},
  volume = {58},
  pages = {240--242},
  issn = {0370-1662},
  doi = {10.1098/rspl.1895.0041},
  abstract = {In statistics, the Pearson product-moment correlation coefficient (/{$\Elzverts$}pɪ{$\Elzschwa$}rsɨn/) (sometimes referred to as the PPMCC or PCC or Pearson's r) is a measure of the linear correlation (dependence) between two variables X and Y. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ULRF8RZX\\pearson_1895_note_on_regression_and_inheritance_in_the_case_of_two_parents.pdf},
  isbn = {0370-1662},
  journal = {Proceedings of the Royal Society of London (1854-1905)}
}

@article{Pearson1896,
  title = {Mathematical Contributions to the Theory of Evolution. - on a Form of Spurious Correlation Which May Arise When Indices Are Used in the Measurement of Organs},
  author = {Pearson, Karl},
  year = {1896},
  volume = {60},
  pages = {489--498},
  issn = {0370-1662},
  doi = {10.1098/rspl.1896.0076},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IM3QBEZN\\pearson_1896_mathematical_contributions_to_the_theory_of_evolution.pdf},
  isbn = {03701662},
  journal = {Proceedings of the Royal Society of London}
}

@article{Pearson1896,
  title = {Mathematical Contributions to the Theory of Evolution. {{III}}. {{Regression}}, Heredity, and Panmixia},
  author = {Pearson, Karl},
  year = {1896},
  volume = {187},
  journal = {Philosophical transactions of the royal society A},
  keywords = {\#nosource}
}

@article{Pedersen2010,
  title = {Risk of Revision of a Total Hip Replacement in Patients with Diabetes Mellitus: {{A POPULATION}}-{{BASED FOLLOW UP STUDY}}},
  shorttitle = {Risk of Revision of a Total Hip Replacement in Patients with Diabetes Mellitus},
  author = {Pedersen, A. B. and Mehnert, F. and Johnsen, S. P. and S\o rensen, H. T.},
  year = {2010},
  month = jul,
  volume = {92-B},
  pages = {929--934},
  issn = {0301-620X, 2044-5377},
  doi = {10.1302/0301-620X.92B7.24461},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4WGKX3FY\\Pedersen et al_2010_Risk of revision of a total hip replacement in patients with diabetes mellitus.pdf},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  language = {en},
  number = {7}
}

@article{Pedersen2010a,
  title = {Risk Factors for Revision Due to Infection after Primary Total Hip Arthroplasty: {{A}} Population-Based Study of 80,756 Primary Procedures in the {{Danish Hip Arthroplasty Registry}}},
  shorttitle = {Risk Factors for Revision Due to Infection after Primary Total Hip Arthroplasty},
  author = {Pedersen, Alma B and Svendsson, Jens E and Johnsen, S\o ren P and Riis, Anders and Overgaard, S\o ren},
  year = {2010},
  month = oct,
  volume = {81},
  pages = {542--547},
  issn = {1745-3674, 1745-3682},
  doi = {10.3109/17453674.2010.519908},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GIH2NR39\\Pedersen et al_2010_Risk factors for revision due to infection after primary total hip arthroplasty.pdf},
  journal = {Acta Orthopaedica},
  language = {en},
  number = {5}
}

@article{Pedersen2011,
  title = {Short- and Long-Term Mortality Following Primary Total Hip Replacement for Osteoarthritis},
  author = {Pedersen, A. B. and Baron, J. A. and Overgaard, S. and Johnsen, S. P.},
  year = {2011},
  month = feb,
  volume = {93-B},
  pages = {172--177},
  publisher = {{The British Editorial Society of Bone and Joint Surgery}},
  issn = {0301-620X},
  doi = {10.1302/0301-620X.93B2.25629},
  abstract = {We evaluated the short-term of 0 to 90 days and the longer term, up to 12.7 years, mortality for patients undergoing primary total hip replacement (THR) in Denmark in comparison to the general popu...},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  keywords = {\#nosource},
  number = {2}
}

@article{Pencina2008,
  title = {Evaluating the Added Predictive Ability of a Newmarker: {{From}} Area under the {{ROC}} Curve to Reclassification and Beyond},
  author = {Pencina, Michael J. and Agostino, Ralph B. D' and Agostino, Ralph B. D' and Vasan, Ramachandran S. and Sr, Ralph B. D'Agostino and Jr, Ralph B. D'Agostino and Vasan, Ramachandran S.},
  year = {2008},
  month = jan,
  volume = {27},
  pages = {157--172},
  publisher = {{John Wiley \& Sons, Ltd.}},
  issn = {02776715},
  doi = {10.1002/sim.2929},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\H4MANX4X\\pencina_et_al_2008_evaluating_the_added_predictive_ability_of_a_newmarker.pdf},
  isbn = {2007090091480},
  journal = {Statistics in medicine},
  keywords = {AUC,biomarker,discrimination,model performance,risk prediction},
  number = {June 2007}
}

@article{Peng2015,
  title = {Report Writing for Data Science in r},
  author = {Peng, Roger D.},
  year = {2015},
  pages = {114},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {This book teaches the concepts and tools behind reporting modern data analyses in a reproducible manner.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KXEPT9KX\\peng_2015_report_writing_for_data_science_in_r.pdf},
  isbn = {9788578110796},
  pmid = {25246403}
}

@article{Peng2015,
  title = {The Art of Data Science: {{A}} Guide for Anyone Who Works with Data},
  author = {Peng, Roger D and Matsui, Elizabeth},
  year = {2015},
  pages = {159},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Data analysis / Exploratory data analysis / inference / modeling},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DND5QEVZ\\peng_matsui_2015_the_art_of_data_science.pdf},
  isbn = {9788578110796},
  pmid = {25246403}
}

@article{Penna2019,
  title = {Impact of Co-Morbidities on the Cost of Care in Primary Elective Joint Arthroplasty},
  author = {Penna, Sreeram and Bell, Kerri L. and Kuo, Feng-Chih and Henderson, Robert Andrew and Foltz, Carol and Chen, Antonia F.},
  year = {2019},
  month = may,
  volume = {34},
  pages = {834--838},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2019.01.038},
  abstract = {BACKGROUND The Comprehensive Care for Joint Replacement model is the newest iteration of the bundled payment methodology introduced by the Centers for Medicare and Medicaid Services. Comprehensive Care for Joint Replacement model, while incentivizing providers to deliver care at a lower cost, does not incorporate any patient-level risk stratification. Our study evaluated the impact of specific medical co-morbidities on the cost of care in total joint arthroplasty (TJA) patients. METHODS A retrospective study was conducted on 1258 Medicare patients who underwent primary elective TJA between January 2015 and July 2016 at a single institution. There were 488 males, 552 hips, and the mean age was 71 years. Cost data were obtained from the Centers for Medicare and Medicaid Services. Co-morbidity information was obtained from a manual review of patient records. Fourteen co-morbidities were included in our final multiple linear regression models. RESULTS The regression models significantly predicted cost variation (P \textexclamdown{} .001). For index hospital costs, a history of cardiac arrhythmias (P \textexclamdown{} .001), valvular heart disease (P = .014), and anemia (P = .020) significantly increased costs. For post-acute care costs, a history of neurological conditions like Parkinson's disease or seizures (P \textexclamdown{} .001), malignancy (P = .001), hypertension (P = .012), depression (P = .014), and hypothyroidism (P = .044) were associated with increases in cost. Similarly, for total episode cost, a history of neurological conditions (P \textexclamdown{} .001), hypertension (P = .012), malignancy (P = .023), and diabetes (P = .029) were predictors for increased costs. CONCLUSION The cost of care in primary elective TJA increases with greater patient co-morbidity. Our data provide insight into the relative impact of specific medical conditions on cost of care and may be used in risk stratification in future reimbursement methodologies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9H7DYKPN\\penna_et_al_2019_impact_of_co-morbidities_on_the_cost_of_care_in_primary_elective_joint.pdf},
  journal = {The Journal of Arthroplasty},
  number = {5}
}

@article{Pepe2004,
  title = {Limitations of the Odds Ratio in Gauging the Performance of a Diagnostic, Prognostic, or Screening Marker},
  author = {Pepe, Margaret Sullivan and Janes, Holly and Longton, Gary and Leisenring, Wendy and Newcomb, Polly},
  year = {2004},
  volume = {159},
  pages = {882--890},
  issn = {00029262},
  doi = {10.1093/aje/kwh101},
  abstract = {A marker strongly associated with outcome (or disease) is often assumed to be effective for classifying persons according to their current or future outcome. However, for this assumption to be true, the associated odds ratio must be of a magnitude rarely seen in epidemiologic studies. In this paper, an illustration of the relation between odds ratios and receiver operating characteristic curves shows, for example, that a marker with an odds ratio of as high as 3 is in fact a very poor classification tool. If a marker identifies 10\% of controls as positive (false positives) and has an odds ratio of 3, then it will correctly identify only 25\% of cases as positive (true positives). The authors illustrate that a single measure of association such as an odds ratio does not meaningfully describe a marker's ability to classify subjects. Appropriate statistical methods for assessing and reporting the classification power of a marker are described. In addition, the serious pitfalls of using more traditional methods based on parameters in logistic regression models are illustrated.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2X54M98G\\pepe_et_al_2004_limitations_of_the_odds_ratio_in_gauging_the_performance_of_a_diagnostic,.pdf},
  isbn = {0002-9262 (Print){\r  }0002-9262 (Linking)},
  journal = {American Journal of Epidemiology},
  keywords = {Biological markers,Diagnostic test,Logistic regression,Odds ratio,ROC curve,Screening test},
  number = {9},
  pmid = {15105181}
}

@article{Perkins2004,
  title = {Common Comorbidity Scales Were Similar in Their Ability to Predict Health Care Costs and Mortality},
  author = {Perkins, Anthony J. and Kroenke, Kurt and Un{\"u}tzer, J{\"u}rgen and Katon, Wayne and Williams, John W. and Hope, Carol and Callahan, Christopher M.},
  year = {2004},
  volume = {57},
  pages = {1040--1048},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2004.03.002},
  abstract = {Objective To compare the ability of commonly used measures of medical comorbidity (ambulatory care groups [ACGs], Charlson comorbidity index, chronic disease score, number of prescribed medications, and number of chronic diseases) to predict mortality and health care costs over 1 year. Study Design and Setting A prospective cohort study of community-dwelling older adults (n=3,496) attending a large primary care practice. Results For predicting health care charges, the number of medications had the highest predictive validity (R 2 = 13.6\%) after adjusting for demographics. ACGs (R 2=16.4\%) and the number of medications (15.0\%) had the highest predictive validity for predicting ambulatory visits. ACGs and the Charlson comorbidity index (area under the receiver operator characteristic [ROC] curve=0.695-0.767) performed better than medication-based measures (area under the ROC curve=0.662-0.679) for predicting mortality. There is relatively little difference, however, in the predictive validity across these scales. Conclusion In an outpatient setting, a simple count of medications may be the most efficient comorbidity measure for predicting utilization and health-care charges over the ensuing year. In contrast, diagnosis-based measures have greater predictive validity for 1-year mortality. Current comorbidity measures, however, have only poor to moderate predictive validity for costs or mortality over 1 year. ?? 2004 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QVNC8HCU\\perkins_et_al_2004_common_comorbidity_scales_were_similar_in_their_ability_to_predict_health_care.pdf},
  isbn = {0895-4356 (Print)0895-4356 (Linking)},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Chronic disease,Comorbidity,Mortality,Utilization},
  number = {10},
  pmid = {15528055}
}

@article{Peters2008,
  title = {Multifarious Terminology: {{Multivariable}} or Multivariate? {{Univariable}} or Univariate?},
  author = {Peters, Tim J.},
  year = {2008},
  volume = {22},
  pages = {506},
  issn = {02695022},
  doi = {10.1111/j.1365-3016.2008.00966.x},
  abstract = {The author reflects on the multifarious terminology used in epidemiological reports including the word "multivariate," "multivariable," and "unvariate." It explains regression models of such terms including the single outcome of explanatory variables. It mentions that all article published within the journal that involves regression model also include univariate.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BF63JAYZ\\peters_2008_multifarious_terminology.pdf},
  isbn = {02695022},
  journal = {Paediatric and Perinatal Epidemiology},
  number = {6},
  pmid = {19000286}
}

@techreport{Petersson2017,
  title = {Etikpr\"ovning \textendash{} En \"Oversyn Av Reglerna Om Forskning Och H\"also- Och Sjukv\aa rd},
  author = {Petersson, Magdalena},
  year = {2017},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IEE2VAT9\\petersson_2017_etikprövning_–_en_översyn_av_reglerna_om_forskning_och_hälso-_och_sjukvård.pdf},
  isbn = {9789138247266}
}

@article{phd;MethodsExplainClinical2010,
  title = {Methods to Explain the Clinical Significance of Health Status Measures},
  author = {{PHD;} and THE CLINICAL SIGNIFICANCE CONSENSUS MEETING GROUP GORDON H. GUYATT, MD; DAVID OSOBA, MD; KATHLEEN W. WYRWICH, PHD; GEOFFREY R. NORMAN, MD; ALBERT W. WU},
  year = {2010},
  volume = {32},
  pages = {1--15},
  issn = {00256196},
  doi = {10.1097/01.mop.0000193271.09001.a3},
  isbn = {0000645419},
  journal = {Medicine \& Science in Sports \& Exercise},
  keywords = {\#nosource,applied sciences,biodynamics,extremity kinematics in,impact absorption,joint angles,reaction forces and lower,shod running,sports surfaces,surface effects on ground},
  number = {November 2000}
}

@generic{Phillips2004,
  title = {The Missed Lessons of Sir Austin Bradford Hill},
  author = {Phillips, Carl V and Goodman, Karen J},
  year = {2004},
  month = oct,
  volume = {1},
  pages = {3},
  publisher = {{BioMed Central}},
  issn = {17425573},
  doi = {10.1186/1742-5573-1-3},
  abstract = {Austin Bradford Hill's landmark 1965 paper contains several important lessons for the current conduct of epidemiology. Unfortunately, it is almost exclusively cited as the source of the "Bradford-Hill criteria" for inferring causation when association is observed, despite Hill's explicit statement that cause-effect decisions cannot be based on a set of rules. Overlooked are Hill's important lessons about how to make decisions based on epidemiologic evidence. He advised epidemiologists to avoid over-emphasizing statistical significance testing, given the observation that systematic error is often greater than random error. His compelling and intuitive examples point out the need to consider costs and benefits when making decisions about health-promoting interventions. These lessons, which offer ways to dramatically increase the contribution of health science to decision making, are as needed today as they were when Hill presented them.},
  isbn = {1742-5573 (Electronic)},
  journal = {Epidemiologic Perspectives and Innovations},
  keywords = {\#nosource,Epidemiology},
  number = {1},
  pmid = {15507128}
}

@article{Pioli2006,
  title = {Predictors of Mortality after Hip Fracture: {{Results}} from 1-Year Follow-Up},
  author = {Pioli, Giulio and Barone, Antonella and Giusti, Andrea and Oliveri, Mauro and Pizzonia, Monica and Razzano, Monica and Palummeri, Ernesto},
  year = {2006},
  volume = {18},
  pages = {381--387},
  issn = {15940667},
  doi = {3198 [pii]},
  abstract = {BACKGROUND AND AIMS: The study investigates one-year mortality risk associated with hip fracture in elderly people, and pre-fracture characteristics and events occurring during the acute phase which may represent significant predictors for acute and long-term mortality.: The study is a prospective cohort study of 252 patients aged 70 and older, consecutively admitted with hip fracture to the Division of Orthopedic Surgery of the Galliera Hospital of Genoa, Italy. At admission, each subject received a standardized diagnostic evaluation, including demographic variables, biochemical markers of nutritional status and basic medical, functional and cognitive assessment. Patients were followed by telephone interviews at three months, six months and one year after fracture. The relationship between mortality and the risk factors recorded was assessed using logistic regression models.: 248 patients were eligible. Cumulative mortality was 4.8\% during hospital stay, and 12.5\% at 3, 18.9\% at 6 and 24\% at 12 months. The risk factors significantly associated with mortality were: sex, Acute Physiology Score (APS), comorbidity, functional and cognitive status, and albumin levels. In multivariate models, albumin below 3 g/dL remained the only significant predictor of in-hospital mortality (OR 6,8, 95\% CI 1.56-29,7, p\textexclamdown 0.001); functional status and comorbidity were significant risk factors of mortality after 6 and 12 months.: These findings confirm the important role of serum albumin in assessing in-hospital health status and defining its role as a strong predictor of early and late mortality after hospital discharge. They also emphasize the effects of comorbidity and functional impairment on long-term mortality after hip fracture. Identifying these predictive factors may be helpful in improving case management during hospital stay and more accurate discharge planning.},
  isbn = {1594-0667},
  journal = {Aging clinical and experimental research},
  keywords = {\#nosource,80 and over,Aged,Cognition,Cohort Studies,Comorbidity,Elderly,Female,Follow-Up Studies,Health Status,Hip fracture,Hip Fractures,Hip Fractures: blood,Hip Fractures: mortality,Hip Fractures: physiopathology,Hip Fractures: psychology,Humans,Italy,Italy: epidemiology,Logistic Models,Male,Mortality,Multivariate Analysis,Outcome,Predictive Value of Tests,Prospective Studies,Risk factors,Risk Factors,Serum Albumin,Serum Albumin: analysis,Sex Factors},
  number = {5},
  pmid = {17167302}
}

@article{Pivec2012,
  title = {Hip Arthroplasty},
  author = {Pivec, Robert and Johnson, Aaron J. and Mears, Simon C. and Mont, Michael A.},
  year = {2012},
  volume = {380},
  pages = {1768--1777},
  issn = {01406736},
  doi = {10.1016/S0140-6736(12)60607-2},
  abstract = {Total hip arthroplasty is a cost-effective surgical procedure undertaken to relieve pain and restore function to the arthritic hip joint. More than 1 million arthroplasties are done every year worldwide, and this number is projected to double within the next two decades. Symptomatic osteoarthritis is the indication for surgery in more than 90\% of patients, and its incidence is increasing because of an ageing population and the obesity epidemic. Excellent functional outcomes are reported; however, careful patient selection is needed to achieve best possible results. The present economic situation in many developed countries will place increased pressure on containment of costs. Future demand for hip arthroplasty, especially in patients younger than 65 years, emphasises the need for objective outcome measures and joint registries that can track lifetime implant survivorship. New generations of bearing surfaces such as metal-on-metal, ceramic-on-ceramic, and metal-on-ceramic, and techniques such as resurfacing arthroplasty have the potential to improve outcomes and survivorship, but findings from prospective trials are needed to show efficacy. With the recall of some metal-on-metal bearings, new bearing surfaces have to be monitored carefully before they can be assumed to be better than traditional bearings.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9D3FIAP2\\pivec_et_al_2012_hip_arthroplasty.pdf},
  isbn = {0140-6736},
  journal = {The Lancet},
  number = {9855},
  pmid = {23021846}
}

@article{pl42011,
  title = {Restrcited Mean Survival Time: Calculation and Some Applicaitons in Trails and Prognostic Studies},
  author = {{pl4}},
  year = {2011},
  pages = {1--9},
  keywords = {\#nosource}
}

@article{Plumbley2003,
  title = {Algorithms for Nonnegative Independent Component Analysis},
  author = {Plumbley, M.D.},
  year = {2003},
  month = may,
  volume = {14},
  pages = {534--543},
  issn = {1045-9227},
  doi = {10.1109/TNN.2003.810616},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EXWLMWH7\\plumbley_2003_algorithms_for_nonnegative_independent_component_analysis.pdf},
  journal = {IEEE Transactions on Neural Networks},
  number = {3}
}

@article{Plutchak1991,
  title = {Envisioning Information},
  author = {Plutchak, T. Scott},
  year = {1991},
  volume = {79},
  pages = {346--348},
  issn = {0003-2999},
  doi = {10.1213/00000539-199103000-00040},
  abstract = {A remarkable range of examples for the idea of visual thinking, with beautifully printed pages. A real treat for all who reason and learn by means of images. - Rudolf Arnheim},
  isbn = {0961392118},
  journal = {Bulletin of the Medical Library Association},
  keywords = {\#nosource},
  number = {3},
  pmid = {3895920}
}

@article{Pohar2006,
  title = {Relative Survival Analysis in {{R}}},
  author = {Pohar, Maja and Stare, Janez},
  year = {2006},
  volume = {81},
  pages = {272--278},
  issn = {0169-2607},
  doi = {10.1016/j.cmpb.2006.01.004},
  abstract = {Relative survival techniques are used to compare the survival experience in a study cohort with the one expected should they follow the background population mortality rates. The techniques are especially useful when the cause-specific death information is not accurate or not available since they provide a measure of excess mortality in a group of patients with a certain disease. There are several approaches to modeling relative survival, but there is no widely used statistical package that would incorporate the relevant techniques. The existing software was mostly written by the authors of different methods, in different computer languages and with different requirements for the data input, which makes it almost impossible for a user to choose between available models. We describe our R package relsurv that provides functions for easy and flexible fitting of several relative survival regression models.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NMH25MI9\\pohar_stare_2006_relative_survival_analysis_in_r.pdf},
  journal = {Computer Methods and Programs in Biomedicine},
  keywords = {R software,Regression,Relative survival},
  number = {3}
}

@article{Pohar2007,
  title = {Making Relative Survival Analysis Relatively Easy},
  author = {Pohar, Maja and Stare, Janez},
  year = {2007},
  volume = {37},
  pages = {1741--1749},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2007.04.010},
  abstract = {In survival analysis we are interested in time from the beginning of an observation until certain event (death, relapse, etc.). We assume that the final event is well defined, so that we are never in doubt whether the final event has occurred or not. In practice this is not always true. If we are interested in cause-specific deaths, then it may sometimes be difficult or even impossible to establish the cause of death, or there may be different causes of death, making it impossible to assign death to just one cause. Suicides of terminal cancer patients are a typical example. In such cases, standard survival techniques cannot be used for estimation of mortality due to a certain cause. The cure to the problem are relative survival techniques which compare the survival experience in a study cohort to the one expected should they follow the background population mortality rates. This enables the estimation of the proportion of deaths due to a certain cause. In this paper, we briefly review some of the techniques to model relative survival, and outline a new fitting method for the additive model, which solves the problem of dependency of the parameter estimation on the assumption about the baseline excess hazard. We then direct the reader's attention to our R package relsurv that provides functions for easy and flexible fitting of all the commonly used relative survival regression models. The basic features of the package have been described in detail elsewhere, but here we additionally explain the usage of the new fitting method and the interface for using population mortality data freely available on the Internet. The combination of the package and the data sets provides a powerful informational tool in the hands of a skilled statistician/informatician.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TAZDNX9Y\\pohar_stare_2007_making_relative_survival_analysis_relatively_easy.pdf},
  journal = {Computers in Biology and Medicine},
  keywords = {Population tables,R software,Regression,Relative survival},
  number = {12}
}

@article{Pons2007,
  title = {Bootstrap of Means under Stratified Sampling},
  author = {Pons, Odile},
  year = {2007},
  volume = {1},
  pages = {381--391},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1935-7524},
  doi = {10.1214/07-EJS033},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2XXJLFIK\\pons_2007_bootstrap_of_means_under_stratified_sampling.pdf},
  journal = {Electronic Journal of Statistics},
  keywords = {bootstrap,Cluster sampling,second-order asymptotic},
  number = {0}
}

@article{pottegardPhysiciansPharmaciesOverview2011,
  title = {Physicians' and Pharmacies' Overview of Patients' Medication. {{An}} Analysis of Fidelity Coefficients},
  author = {Potteg\aa rd, Anton and Hallas, Jesper},
  year = {2011},
  volume = {67},
  pages = {919--924},
  publisher = {{Springer Verlag}},
  issn = {14321041},
  doi = {10.1007/s00228-011-1026-3},
  abstract = {Background It is essential that pharmacies and prescribers have an overview of each patient's medication in order to prevent drug interactions, unintentional co-prescribing, unnecessary polypharmacy and underprescribing. We have assessed this overview by measuring the 'fidelity coefficient', a measure of the extent to which a drug user has a preference for one prescriber or one pharmacy. Methods and setting Data for all prescriptions issued for the population in Southern Denmark (population 1.2 million) in 2009 was extracted from the Odense University Pharmacoepidemiological Database (OPED). Analysis of the extracted data was then limited to persons with at least ten prescriptions within the year, resulting in 8,246,064 prescriptions issued to 283,388 individuals. For each individual, we identified the most used prescriber and calculated the proportion of all prescriptions accounted for by that prescriber (FCpresc). The individual user's most frequented pharmacy was also identified and the FCpharm calculated in a similar fashion. Results The average FCPresc and average FCPharm were0.883 (standard deviation 0.158) and 0.927 (0.139), respectively. The estimated difference was 0.0446 (95\% confidence interval 0.0439-0.0453). Among the factors associated with a high FCpresc and high FCpharm were older age, male gender and a high volume of prescriptions. The major drug classes that were most often prescribed by a non-main prescriber were beta-lactams, antidepressants and opioids. Similarly, the major drug classes associated with use of non-main pharmacy were beta-lactams, antidepressants and inhaled beta-agonists. Conclusion Based on this analysis, both prescribers and pharmacies generally have an equal potential for maintaining an excellent overview of their patients' medication, but the pharmacies account for a slightly higher proportion of patients. \textcopyright{} Springer-Verlag 2011.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4VCZQIZU\\pottegård_hallas_2011_physicians'_and_pharmacies'_overview_of_patients'_medication.pdf},
  journal = {European Journal of Clinical Pharmacology},
  keywords = {Fidelity coefficient,Overview,Patient's medication,Pharmacy,Prescriber},
  number = {9}
}

@article{Poultsides2013,
  title = {In-{{Hospital Surgical Site Infections}} after {{Primary Hip}} and {{Knee Arthroplasty}} \textemdash{} {{Incidence}} and {{Risk Factors}}},
  author = {Poultsides, Lazaros A. and Ma, Yan and Della Valle, Alejandro Gonzalez and Chiu, Ya-Lin and Sculco, Thomas P. and Memtsoudis, Stavros G.},
  year = {2013},
  month = mar,
  volume = {28},
  pages = {385--389},
  issn = {08835403},
  doi = {10.1016/j.arth.2012.06.027},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {3}
}

@inproceedings{pozzoloCalibratingProbabilityUndersampling2015,
  title = {Calibrating Probability with Undersampling for Unbalanced Classification},
  author = {Pozzolo, Andrea Dal and Caelen, Olivier and Bontempi, Gianluca and Johnson, Reid A},
  year = {2015},
  pages = {159--166},
  doi = {10.1109/SSCI.2015.33},
  abstract = {Undersampling is a popular technique for unbalanced datasets to reduce the skew in class distributions. However, it is well-known that undersampling one class modifies the priors of the training set and consequently biases the posterior probabilities of a classifier [9]. In this paper, we study analytically and experimentally how undersampling affects the posterior probability of a machine learning model. We formalize the problem of undersampling and explore the relationship between conditional probability in the presence and absence of undersampling. Although the bias due to undersampling does not affect the ranking order returned by the posterior probability, it significantly impacts the classification accuracy and probability calibration. We use Bayes Minimum Risk theory to find the correct classification threshold and show how to adjust it after undersampling. Experiments on several real-world unbalanced datasets validate our results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8KE6PKPB\\pozzolo_et_al_2015_calibrating_probability_with_undersampling_for_unbalanced_classification.pdf},
  series = {2015 {{IEEE Symposium Series}} on {{Computational Intelligence}}}
}

@article{Pratt2018,
  title = {The Validity of the Rx-Risk Comorbidity Index Using Medicines Mapped to the Anatomical Therapeutic Chemical ({{ATC}}) Classification System},
  author = {Pratt, Nicole L. and Kerr, Mhairi and Barratt, John D. and {Kemp-Casey}, Anna and Ellett, Lisa M. Kalisch and Ramsay, Emmae and Roughead, Elizabeth Ellen},
  year = {2018},
  month = apr,
  volume = {8},
  publisher = {{BMJ Publishing Group}},
  issn = {20446055},
  doi = {10.1136/bmjopen-2017-021122},
  abstract = {Objectives To provide a map of Anatomical Therapeutic Chemical (ATC) Classification System codes to individual Rx-Risk comorbidities and to validate the Rx-Risk Comorbidity Index. Design The 46 comorbidities in the Rx-Risk Index were mapped to dispensing's indicative of each condition using ATC codes. Prescription dispensing claims in 2014 were used to calculate the Rx-Risk. A baseline logistic regression model was fitted using age and gender as covariates. Rx-Risk was added to the base model as an (1) unweighted score, (2) weighted score and as (3) individual comorbidity categories indicating the presence or absence of each condition. The Akaike information criterion and c-statistic were used to compare the models. Setting Models were developed in the Australian Government Department of Veterans' Affairs health claims data, and external validation was undertaken in a 10\% sample of the Australian Pharmaceutical Benefits Scheme Data. Participants Subjects aged 65 years or older. Outcome measures Death within 1 year (eg, 2015). Results Compared with the base model (c-statistic 0.738, 95\% CI 0.734 to 0.742), including Rx-Risk improved prediction of mortality; unweighted score 0.751, 95\% CI 0.747 to 0.754, weighted score 0.786, 95\% CI 0.782 to 0.789 and individual comorbidities 0.791, 95\% CI 0.788 to 0.795. External validation confirmed the utility of the weighted index (c-statistic=0.833). Conclusions The updated Rx-Risk Comorbidity Score was predictive of 1-year mortality and may be useful in practice to adjust for confounding in observational studies using medication claims data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\T5KC2GKS\\pratt_et_al_2018_the_validity_of_the_rx-risk_comorbidity_index_using_medicines_mapped_to_the.pdf},
  journal = {BMJ Open},
  keywords = {chronic disease burden,claims data,coder,comorbidity,model validation,mortality prediction,weighting},
  number = {4}
}

@article{Preen2006,
  title = {Length of Comorbidity Lookback Period Affected Regression Model Performance of Administrative Health Data},
  author = {Preen, David B. and Holman, C.D'Arcy J. and Spilsbury, Katrina and Semmens, James B. and Brameld, Kate J.},
  year = {2006},
  volume = {59},
  pages = {940--946},
  doi = {10.1016/j.jclinepi.2005.12.013},
  abstract = {BACKGROUND AND OBJECTIVE The impact of different comorbidity ascertainment lookback periods on modeling posthospitalization mortality and readmission was examined. METHODS Index cases comprised medical (n = 326,456) and procedural (n = 349,686) patients with a hospital admission from 1990\textendash 1996. Administrative hospital data were extracted for 102 comorbidities, ascertained at index admission and for 1-, 2-, 3-, and 5-year lookback periods. Deaths and readmissions were identified within 12 months and 30 days of separation, respectively. Hierarchically nested and nonnested Cox regressions as well as Receiver Operator Characteristic Area Under the Curve (ROC-AUC) were used to determine model-fit and predictive ability of lookback period models. RESULTS The 1-year lookback period provided the best model-fit for both patient groups when modeling mortality. A similar model-fit was seen at index admission for procedural but not medical patients. The superior readmission model employed 5 years of lookback for both patient groups. With one exception, all lookback period models were superior to those abstracting comorbidity from index admission only. Similar results were evident from ROC-AUC, although greater predictive ability was seen with modeling of mortality (0.847\textendash 0.923) compared with readmission (0.593\textendash 0.681). CONCLUSION The explanatory power of regression models, when adjusting for comorbidity, is influenced by length of lookback, outcome investigated and clinical subgroup. Shorter periods ({$\sim$}1 year) appear appropriate for modeling posthospitalization mortality, whereas longer lookback periods are superior for readmission outcomes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FGZ4QJSH\\preen_et_al_2006_length_of_comorbidity_lookback_period_affected_regression_model_performance_of.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {9}
}

@article{Price2019,
  title = {The {{Arthroplasty Candidacy Help Engine}} Tool to Select Candidates for Hip and Knee Replacement Surgery: Development and Economic Modelling},
  author = {Price, Andrew and Smith, James and Dakin, Helen and Kang, Sujin and Eibich, Peter and Cook, Jonathan and Gray, Alastair and Harris, Kristina and Middleton, Robert and Gibbons, Elizabeth and Benedetto, Elena and Smith, Stephanie and Dawson, Jill and Fitzpatrick, Raymond and Sayers, Adrian and Miller, Laura and Marques, Elsa and {Gooberman-Hill}, Rachael and Blom, Ashley and Judge, Andrew and Arden, Nigel and Murray, David and {Glyn-Jones}, Sion and Barker, Karen and Carr, Andrew and Beard, David},
  year = {2019},
  month = jun,
  volume = {23},
  pages = {1--216},
  issn = {1366-5278},
  doi = {10.3310/hta23320},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UGVJVAVL\\price_et_al_2019_the_arthroplasty_candidacy_help_engine_tool_to_select_candidates_for_hip_and.pdf},
  journal = {Health Technology Assessment},
  number = {32}
}

@article{Priebe2000,
  title = {Alternating Kernel and Mixture Density Estimates},
  author = {Priebe, Carey E. and Marchette, David J.},
  year = {2000},
  volume = {35},
  pages = {43--65},
  issn = {01679473},
  doi = {10.1016/S0167-9473(00)00003-7},
  abstract = {We describe and investigate a data-driven procedure for obtaining parsimonious mixture model estimates or, conversely, kernel estimates with data-driven local smoothing properties. The main idea is to obtain a semiparametric estimate by alternating between the parametric and nonparametric viewpoints. (C) 2000 Elsevier Science B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WQ28NIVC\\priebe_marchette_2000_alternating_kernel_and_mixture_density_estimates.pdf},
  isbn = {0167-9473},
  journal = {Computational Statistics and Data Analysis},
  keywords = {Kernel estimator,Mixture model,Semiparametric},
  number = {1}
}

@article{Protas2017,
  title = {Cervical Spine Aneurysmal Bone Cysts in the Pediatric Population: {{A}} Systematic Review of the Literature},
  author = {Protas, Matthew and Jones, Lydia W. and Sardi, Juan Pablo and Fisahn, Christian and Iwanaga, Joe and Oskouian, Rod J. and Tubbs, R. Shane},
  year = {2017},
  volume = {52},
  pages = {219--224},
  publisher = {{Karger Publishers}},
  doi = {10.1159/000475820},
  abstract = {Cervical spine aneurysmal bone cysts (ABCs) in pediatric patients have not been thoroughly studied. Using PubMed and Google Scholar, a systematic review of the literature was conducted for publications that included patients aged {$\leq$}15 years with a confirmed diagnosis of ABC in the cervical spine. Thirty-five studies with a total of 71 patients met the inclusion criteria. Nearly 80\% of patients presented with neck or shoulder pain. The axis was the level most frequently involved (34.28\%), followed by C5 (24.28\%). Posterior elements were most likely to be affected (88.46\%) while exclusive involvement of the body was uncommon. To our knowledge, this is the first systematic review of the literature regarding ABCs of the cervical spine in a pediatric population. Spinal ABCs are rarely found in the cervical region, and their treatment remains challenging due to their location, vascularization, and a high overall recurrence rate even with surgical resection.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\I92KC2EW\\protas_et_al_2017_cervical_spine_aneurysmal_bone_cysts_in_the_pediatric_population.pdf},
  journal = {Pediatric Neurosurgery},
  number = {4},
  pmid = {28605734}
}

@article{Protas2017,
  title = {Cervical Spine Aneurysmal Bone Cysts: {{A Meta}}-\-{{Analysis}} of 114 Cases and Comparison of Clinical Features between Pediatric and Adult Patients},
  author = {Protas, Matthew and Wingfield, Henry and Ishak, Basem and Li, Rong and Oskouian, Rod J and Loukas, Marios and Tubbs, R Shane},
  year = {2017},
  volume = {21},
  doi = {10.26632/ss.4.2017.1.1},
  abstract = {Aneurysmal bone cysts have an unclear etiology and are most common during childhood. To our knowledge, a comprehensive review comparing adult and childhood aneurysmal bone cysts has, to date, not been performed. Using standard search engines, a review of aneurysmal bone cysts was conducted. Many differences were found comparing adult and pediatric ABC patients. For example, females were much more commonly affected than males in children and tumors were commonly idiopathic however, they were found after cervical spine trauma in children. Pediatric patients are significantly more likely to be affected by ABC than adults.},
  journal = {THE SPINE SCHOLAR},
  keywords = {\#nosource},
  number = {1}
}

@article{Puig2015,
  title = {Fault Diagnosis Tools in Multivariate Statistical Process Fault Diagnosis Tools in Multivariate Statistical Process and Quality Control},
  author = {Puig, Santiago Vidal and Puig, Santiago Vidal},
  year = {2015},
  pages = {318},
  institution = {{UNIVERSIDAD POLIT\'ECNICA DE VALENCIA}},
  abstract = {La realizaci\'on de un diagn\'ostico preciso de los fallos, tanto si se trata de fallos de sensores como si se trata de fallos de procesos, ha llegado a ser algo de vital importancia en la monitorizaci\'on de procesos (reduce las paradas de planta, incrementa la seguridad de la operaci\'on en planta y reduce los costes de producci\'on). Se requieren diagn\'osticos r\'apidos y correctos si se quiere poder recuperar los procesos o productos antes de que la seguridad o la calidad de los mismos se pueda ver comprometida. En el estudio de las diferentes metodolog\'ias para el diagn\'ostico de fallos esta tesis distingue dos escenarios diferentes, m\'etodos para el control de estad\'istico multivariante de la calidad (MSQC) y m\'etodos para el control estad\'istico de procesos basados en el uso de variables latentes (Lb-MSPC). En la primera parte de esta tesis se introduce el estado del arte sobre el diagn\'ostico e identificaci\'on de fallos (FDI). La segunda parte de la tesis est\'a centrada en el estudio del diagn\'ostico de fallos en control estad\'istico multivariante de la calidad. Se describen los fundamentos de los m\'etodos m\'as extendidos para el diagn\'ostico en escenarios supervisados, sus requerimientos para su implementaci\'on sus puntos fuertes y d\'ebiles y sus posibles relaciones. Los resultados de diagn\'ostico de los m\'etodos es comparado usando diferentes \'indices sobre los datos procedentes de dos procesos reales y de diferentes simulaciones. En la tesis se proponen nuevas variantes que tratan de mejorar los resultados obtenidos en MSQC. La tercera parte de la tesis est\'a dedicada al diagn\'ostico de fallos en control estad\'istico multivariante de procesos basados en el uso de modelos de variables latentes (Lb-MSPC). Se describe los fundamentos de los m\'etodos mas extendidos en el diagn\'ostico de fallos en Lb-MSPC supervisado y se introduce una de nuestras propuestas, el fingerprint contribution plot (FCP). Finalmente la tesis presenta y compara los resultados de diagn\'ostico de los m\'etodos propuestos en vi Lb-MSPC. Los resultados son comparados sobre los datos de dos procesos usando una nueva estrategia basada en el uso de la sensitividad y especificidad promedia.},
  keywords = {\#nosource}
}

@article{Pulido2008,
  title = {Periprosthetic {{Joint Infection}}: {{The Incidence}}, {{Timing}}, and {{Predisposing Factors}}},
  shorttitle = {Periprosthetic {{Joint Infection}}},
  author = {Pulido, Luis and Ghanem, Elie and Joshi, Ashish and Purtill, James J. and Parvizi, Javad},
  year = {2008},
  month = jul,
  volume = {466},
  pages = {1710--1715},
  issn = {0009-921X, 1528-1132},
  doi = {10.1007/s11999-008-0209-4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2FVDEM6A\\Pulido et al_2008_Periprosthetic Joint Infection.pdf},
  journal = {Clinical Orthopaedics and Related Research},
  language = {en},
  number = {7}
}

@article{Putter2007,
  title = {Tutorial in Biostatistics: Competing Risks and Multi-State Models.},
  author = {Putter, H and Fiocco, M and Geskus, R B},
  year = {2007},
  volume = {26},
  pages = {2389--2430},
  issn = {0277-6715},
  doi = {10.1002/sim.2712},
  abstract = {Standard survival data measure the time span from some time origin until the occurrence of one type of event. If several types of events occur, a model describing progression to each of these competing risks is needed. Multi-state models generalize competing risks models by also describing transitions to intermediate events. Methods to analyze such models have been developed over the last two decades. Fortunately, most of the analyzes can be performed within the standard statistical packages, but may require some extra effort with respect to data preparation and programming. This tutorial aims to review statistical methods for the analysis of competing risks and multi-state models. Although some conceptual issues are covered, the emphasis is on practical issues like data preparation, estimation of the effect of covariates, and estimation of cumulative incidence functions and state and transition probabilities. Examples of analysis with standard software are shown.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WJBRLYJL\\putter_et_al_2007_tutorial_in_biostatistics.pdf},
  isbn = {2007090091480},
  journal = {Statistics in medicine},
  keywords = {Biometry,HIV Infections,Humans,Models,Netherlands,Risk Assessment,Statistical,Survival Analysis},
  number = {11},
  pmid = {17031868}
}

@article{Putter2007,
  title = {Tutorial in Biostatistics: {{Competing}} Risks Andmulti-State Models},
  author = {Putter, H and Fiocco, M and Geskus, R B},
  year = {2007},
  volume = {26},
  pages = {2389--2430},
  issn = {02776715},
  doi = {10.1002/sim},
  abstract = {Standard survival data measure the time span from some time origin until the occurrence of one type of event. If several types of events occur, a model describing progression to each of these competing risks is needed.Multi-state models generalize competing risksmodels by also describing transitions to intermediate events. Methods to analyze such models have been developed over the last two decades. Fortunately, most of the analyzes can be performed within the standard statistical packages, but may require some extra effort with respect to data preparation and programming. This tutorial aims to review statistical methods for the analysis of competing risks and multi-state models. Although some conceptual issues are covered, the emphasis is on practical issues like data preparation, estimation of the effect of covariates, and estimation of cumulative incidence functions and state and transition probabilities. Examples of analysis with standard software are shown. Copyright},
  isbn = {2007090091480},
  journal = {Statistics in medicine},
  keywords = {\#nosource,ces-d,conditional maximum likelihood,fixed effects,generalized linear mixed model,hausman test,linear mixed model,random effects,robust,variance},
  number = {October 2006},
  pmid = {19455509}
}

@article{Quail2011,
  title = {Comparing Comorbidity Measures for Predicting Mortality and Hospitalization in Three Population-Based Cohorts.},
  author = {Quail, Jacqueline M and Lix, Lisa M and Osman, Beliz Acan and Teare, Gary F},
  year = {2011},
  volume = {11},
  pages = {146},
  publisher = {{BioMed Central Ltd}},
  issn = {1472-6963},
  doi = {10.1186/1472-6963-11-146},
  abstract = {BACKGROUND: Multiple comorbidity measures have been developed for risk-adjustment in studies using administrative data, but it is unclear which measure is optimal for specific outcomes and if the measures are equally valid in different populations. This research examined the predictive performance of five comorbidity measures in three population-based cohorts.: Administrative data from the province of Saskatchewan, Canada, were used to create the cohorts. The general population cohort included all Saskatchewan residents 20+ years, the diabetes cohort included individuals 20+ years with a diabetes diagnosis in hospital and/or physician data, and the osteoporosis cohort included individuals 50+ years with diagnosed or treated osteoporosis. Five comorbidity measures based on health services utilization, number of different diagnoses, and prescription drugs over one year were defined. Predictive performance was assessed for death and hospitalization outcomes using measures of discrimination (c-statistic) and calibration (Brier score) for multiple logistic regression models.: The comorbidity measures with optimal performance were the same in the general population (n = 662,423), diabetes (n = 41,925), and osteoporosis (n = 28,068) cohorts. For mortality, the Elixhauser index resulted in the highest c-statistic and lowest Brier score, followed by the Charlson index. For hospitalization, the number of diagnoses had the best predictive performance. Consistent results were obtained when we restricted attention to the population 65+ years in each cohort.: The optimal comorbidity measure depends on the health outcome and not on the disease characteristics of the study population.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NHXYHG9G\\quail_et_al_2011_comparing_comorbidity_measures_for_predicting_mortality_and_hospitalization_in.pdf},
  isbn = {1472-6963 (Electronic){\r  }1472-6963 (Linking)},
  journal = {BMC health services research},
  keywords = {Benchmarking,Benchmarking: statistics \& numerical data,Comorbidity,Confidence Intervals,Female,Health Status Indicators,Hospital Mortality,Hospital Mortality: trends,Hospitalization,Hospitalization: statistics \& numerical data,Humans,Logistic Models,Male,Middle Aged,Odds Ratio,Prognosis,Registries,Risk Assessment,Saskatchewan,Sensitivity and Specificity},
  pmid = {21663672}
}

@article{Quan2005,
  title = {Coding Algorithms for Defining Comorbidities in {{ICD}}-9-{{CM}} and {{ICD}}-10 Administrative Data.},
  author = {Quan, Hude and Sundararajan, Vijaya and Halfon, Patricia and Fong, Andrew and Burnand, Bernard and Luthi, Jean-Christophe and Saunders, L Duncan and a Beck, Cynthia and Feasby, Thomas E and a Ghali, William},
  year = {2005},
  volume = {43},
  pages = {1130--1139},
  issn = {0025-7079},
  doi = {10.1097/01.mlr.0000182534.19832.83},
  abstract = {OBJECTIVES: Implementation of the International Statistical Classification of Disease and Related Health Problems, 10th Revision (ICD-10) coding system presents challenges for using administrative data. Recognizing this, we conducted a multistep process to develop ICD-10 coding algorithms to define Charlson and Elixhauser comorbidities in administrative data and assess the performance of the resulting algorithms. METHODS: ICD-10 coding algorithms were developed by "translation" of the ICD-9-CM codes constituting Deyo's (for Charlson comorbidities) and Elixhauser's coding algorithms and by physicians' assessment of the face-validity of selected ICD-10 codes. The process of carefully developing ICD-10 algorithms also produced modified and enhanced ICD-9-CM coding algorithms for the Charlson and Elixhauser comorbidities. We then used data on in-patients aged 18 years and older in ICD-9-CM and ICD-10 administrative hospital discharge data from a Canadian health region to assess the comorbidity frequencies and mortality prediction achieved by the original ICD-9-CM algorithms, the enhanced ICD-9-CM algorithms, and the new ICD-10 coding algorithms. RESULTS: Among 56,585 patients in the ICD-9-CM data and 58,805 patients in the ICD-10 data, frequencies of the 17 Charlson comorbidities and the 30 Elixhauser comorbidities remained generally similar across algorithms. The new ICD-10 and enhanced ICD-9-CM coding algorithms either matched or outperformed the original Deyo and Elixhauser ICD-9-CM coding algorithms in predicting in-hospital mortality. The C-statistic was 0.842 for Deyo's ICD-9-CM coding algorithm, 0.860 for the ICD-10 coding algorithm, and 0.859 for the enhanced ICD-9-CM coding algorithm, 0.868 for the original Elixhauser ICD-9-CM coding algorithm, 0.870 for the ICD-10 coding algorithm and 0.878 for the enhanced ICD-9-CM coding algorithm. CONCLUSIONS: These newly developed ICD-10 and ICD-9-CM comorbidity coding algorithms produce similar estimates of comorbidity prevalence in administrative data, and may outperform existing ICD-9-CM coding algorithms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HLX75W2Q\\Quan m. fl. - 2005 - Coding algorithms for defining comorbidities in IC.pdf},
  isbn = {0025-7079 (Print){\r  }0025-7079 (Linking)},
  journal = {Medical care},
  keywords = {\#nosource,1130,1139,43,administrative data,coder,comorbidity,department of community health,from the,icd-10,icd-9,med care 2005,outcome,risk adjustment,sciences,university of cal-},
  number = {11},
  pmid = {16224307}
}

@article{Quan2011,
  title = {Updating and Validating the Charlson Comorbidity Index and Score for Risk Adjustment in Hospital Discharge Abstracts Using Data from 6 Countries},
  author = {Quan, Hude and Li, Bing and Couris, Chantal M. and Fushimi, Kiyohide and Graham, Patrick and Hider, Phil and Januel, Jean Marie and Sundararajan, Vijaya},
  year = {2011},
  volume = {173},
  pages = {676--682},
  issn = {00029262},
  doi = {10.1093/aje/kwq433},
  abstract = {With advances in the effectiveness of treatment and disease management, the contribution of chronic comorbid diseases (comorbidities) found within the Charlson comorbidity index to mortality is likely to have changed since development of the index in 1984. The authors reevaluated the Charlson index and reassigned weights to each condition by identifying and following patients to observe mortality within 1 year after hospital discharge. They applied the updated index and weights to hospital discharge data from 6 countries and tested for their ability to predict in-hospital mortality. Compared with the original Charlson weights, weights generated from the Calgary, Alberta, Canada, data (2004) were 0 for 5 comorbidities, decreased for 3 comorbidities, increased for 4 comorbidities, and did not change for 5 comorbidities. The C statistics for discriminating in-hospital mortality between the new score generated from the 12 comorbidities and the Charlson score were 0.825 (new) and 0.808 (old), respectively, in Australian data (2008), 0.828 and 0.825 in Canadian data (2008), 0.878 and 0.882 in French data (2004), 0.727 and 0.723 in Japanese data (2008), 0.831 and 0.836 in New Zealand data (2008), and 0.869 and 0.876 in Swiss data (2008). The updated index of 12 comorbidities showed good-to-excellent discrimination in predicting in-hospital mortality in data from 6 countries and may be more appropriate for use with more recent administrative data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KN6R5ZQT\\quan_et_al_2011_updating_and_validating_the_charlson_comorbidity_index_and_score_for_risk.pdf},
  isbn = {1476-6256 (Electronic){\r  }0002-9262 (Linking)},
  journal = {American Journal of Epidemiology},
  keywords = {Comorbidity,International classification of diseases,Mortality,Quality of health care,Risk adjustment},
  number = {6},
  pmid = {21330339}
}

@article{Rabin2001,
  title = {{{EQ}}-{{SD}}: A Measure of Health Status from the {{EuroQol Group}}},
  author = {Rabin, Rosalind and Charro, Frank De},
  year = {2001},
  volume = {33},
  pages = {337--343},
  abstract = {Zimbabwe. The process o f shared development and local experimentation resulted in EQ-5D, a generic measure of health status that provides a simple descriptive profile and a single index value that can be used in the clinical and economic evaluation o f health care and in population health surveys. Currently, EQ-5D is being widely used in different countries by clinical researchers in a variety o f clinical areas. EQ-5D is also being used by eight out o f the first 10 o f the top 50 pharmaceutical companies listed in the annual report o f Pharma Business (November/ December 1999). Furthermore, EQ-5D is one o f the handful o f measures recommended for use in cost-effectiveness analyses by the Washington Panel on Cost Effectiveness in Health and Medicine. EQ-5D has now been translated into most major languages with the EuroQol Group closely monitoring the process.},
  journal = {Annals of Medicine},
  keywords = {\#nosource,application,EQ-5D,EuroQol Group,health status measurement,translation,valuation},
  number = {5}
}

@article{Rady2005,
  title = {An Easy Way to Calculate the Moments of Sample Correlation Coefficients},
  author = {Rady, El-Houssainy A and Fergany, Hala A and Edress, Adel M},
  year = {2005},
  volume = {54},
  pages = {21--28},
  journal = {Communications Series A1 Mathematics \& Statistics},
  keywords = {\#nosource},
  number = {1}
}

@article{Raj2019,
  title = {Machine Learning-Based Dynamic Mortality Prediction after Traumatic Brain Injury},
  author = {Raj, Rahul and Luostarinen, Teemu and Pursiainen, Eetu and Posti, Jussi P and Takala, Riikka S K},
  year = {2019},
  pages = {1--13},
  doi = {10.1038/s41598-019-53889-6},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9TVJ5HW8\\raj_et_al_2019_machine_learning-based_dynamic_mortality_prediction_after_traumatic_brain_injury.pdf},
  isbn = {4159801953889}
}

@article{Raju1997,
  title = {Methodology {{Review}}: {{Estimation}} of Population Validity and Cross-Validity, and the Use of Equal Weights in Prediction},
  author = {Raju, Nambury S and Bilgic, Reyhan and Edwards, Jack E and Fleer, Paul F},
  year = {1997},
  volume = {21},
  pages = {291--305},
  journal = {Applied Psychological Measurement},
  keywords = {\#nosource},
  number = {4}
}

@article{Raju1999,
  title = {Accuracy of Population Validity and Cross-Validity Estimation: {{An}} Empirical Comparison of Formula-Based, Traditional Empirical, and Equal Weights Procedures},
  author = {Raju, N S and Bilgic, R and Edwards, J E and Fleer, P F},
  year = {1999},
  volume = {23},
  pages = {99--115},
  issn = {0146-6216},
  doi = {10.1177/01466219922031220},
  abstract = {An empirical monte carlo study was performed using predictor and criterion data from 84,808 U.S. Air Force enlistees. 501 samples were drawn for each of seven sample size conditions: 25, 40, 60, 80, 100, 150, and 200. Using an eight-predictor model, 500 estimates for each of 9 validity and 11 cross-validity estimation procedures were generated for each sample size condition. These estimates were then compared to the actual squared population validity and cross-validity in terms of mean bias and mean squared bias. For the regression models determined using ordinary least squares, the Ezekiel procedure produced the most accurate estimates of squared population validity (followed by the Smith and the Wherry procedures), and Burket's formula resulted in the best estimates of squared population cross-validity. Other analyses compared the coefficients determined by traditional empirical cross-validation and equal weights; equal weights resulted in no loss of predictive accuracy and less shrinkage. Numerous issues for future basic research on validation and cross-validation are identified.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JFES37KU\\raju_et_al_1999_accuracy_of_population_validity_and_cross-validity_estimation.pdf},
  isbn = {0146-6216},
  journal = {Applied Psychological Measurement},
  number = {2}
}

@article{Raju2016,
  title = {Accuracy of Population Validity and Cross-Validity Estimation: {{An}} Empirical Comparison of Formula-Based, Traditional Empirical, and Equal Weights Procedures Defense Manpower Data Center},
  author = {Raju, Nambury S and Edwards, Jack E and Fleer, Paul F},
  year = {2016},
  volume = {23},
  pages = {99--115},
  abstract = {An empirical monte carlo study was performed using predictor and criterion data from 84,808 U.S. Air Force enlistees. 501 samples were drawn for each of seven sample size conditions: 25, 40, 60, 80, 100, 150, and 200. Using an eight-predictor model, 500 estimates for each of 9 validity and 11 cross-validity estimation procedures were generated for each sample size condition. These estimates were then compared to the actual squared population validity and cross-validity in terms of mean bias and mean squared bias. For the regression models determined using ordinary least squares, the Ezekiel procedure produced the most accurate estimates of squared population validity (followed by the Smith and the Wherry procedures), and Burket's formula resulted in the best estimates of squared population cross-validity. Other analyses compared the coefficients determined by traditional empirical cross-validation and equal weights; equal weights resulted in no loss of predictive accuracy and less shrinkage. Numerous issues for future basic research on validation and cross-validation are identified. Index terms: cross-validation, equal weights, mul-tiple regression, ordinary least squares, population cross-validity, population validity, unit weights. Raju, Bilgic, Edwards, \& Fleer (1997) reviewed the accuracy of currently available formula-based procedures for estimating squared population validity ({$\rho$} 2), squared population cross-validity ({$\rho$} 2 c), and the accuracy of the equal weights (EW) procedure. As Raju et al. noted, different stud-ies investigated different sets of formula-based estimation procedures, thus making it difficult to identify the most accurate procedure or procedures. This study empirically assessed the complete set of formula-based estimation procedures reviewed by Raju et al., as well as EW. The simulation studies reviewed by Raju et al. suggested that EW should be used when there is a low-to-moderate multiple correlation and low variability for predictor-criterion correlations. However, previous studies have not compared estimates of population validity and cross-validity derived using EW with formula-based estimates. Monte carlo procedures provide a means for obtaining population values against which the accuracy of the formula-based estimates {$\rho$} 2 an},
  keywords = {\#nosource},
  number = {2}
}

@article{Ramanathan1969,
  title = {Journal of the American Statistical},
  author = {{Ramanathan}},
  year = {1969},
  volume = {64},
  pages = {90--101},
  doi = {10.2307/2286841},
  isbn = {0262194759},
  journal = {journal of American Statistical Association},
  keywords = {\#nosource},
  number = {325}
}

@article{Ranstam2010,
  title = {Statistical Analysis of Arthroplasty Register Data.},
  author = {Ranstam, Jonas and Robertsson, Otto},
  year = {2010},
  volume = {81},
  pages = {10--14},
  issn = {1745-3674},
  doi = {10.3109/17453671003587168},
  abstract = {Data from arthroplasty registers are often analyzed using survival methods. Several methodological problems exist, for example relating to competing events, non-random censoring, non-proportional hazards and dependent observations. League tables and ranking of specific survival results leds to further methodological difficulties. Most of these problems are, however, well known and a number of methods for dealing successfully with the problems have been developed. These methods are usually accessible in commercially available statistical software packages. The statistical analysis and reporting of data from arthroplasty registers can thus be improved. Development of arthroplasty register guidelines for statistical analysis could play an important role in making these registers even more useful.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LBTBZLR2\\ranstam_robertsson_2010_statistical_analysis_of_arthroplasty_register_data.pdf},
  journal = {Acta orthopaedica},
  number = {1},
  pmid = {20175657}
}

@article{Ranstam2011,
  title = {Statistical Analysis of Arthroplasty Data. {{I}}. {{Introduction}} and Background},
  author = {Ranstam, Jonas and K{\"a}rrholm, Johan and Pulkkinen, Pekka and M{\"a}kel{\"a}, Keijo and Espehaug, Birgitte and Pedersen, Alma Becic and Mehnert, Frank and Furnes, Ove},
  year = {2011},
  volume = {82},
  pages = {253--257},
  issn = {17453674},
  doi = {10.3109/17453674.2011.588862},
  abstract = {It is envisaged that guidelines for statistical analysis and presentation of results will improve the quality and value of research. The Nordic Arthroplasty Register Association (NARA) has therefore developed guidelines for the statistical analysis of arthroplasty register data. The guidelines are divided into two parts, one with an introduction and a discussion of the background to the guidelines (, see pages x-y in this issue), and this one with a more technical statistical discussion on how specific problems can be handled. This second part contains (1) recommendations for the interpretation of methods used to calculate survival, (2) recommendations on howto deal with bilateral observations, and (3) a discussion of problems and pitfalls associated with analysis of factors that influence survival or comparisons between outcomes extracted from different hospitals.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CZPDEZK4\\ranstam_et_al_2011_statistical_analysis_of_arthroplasty_data.pdf},
  isbn = {9781441900838},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {21619499}
}

@article{Ranstam2011,
  title = {Statistical Analysis of Arthroplasty Data. {{II}}. {{Guidelines}}},
  author = {Ranstam, Jonas and K{\"a}rrholm, Johan and Pulkkinen, Pekka and M{\"a}kel{\"a}, Keijo and Espehaug, Birgitte and Pedersen, Alma Becic and Mehnert, Frank and Furnes, Ove},
  year = {2011},
  volume = {82},
  pages = {258--267},
  issn = {17453674},
  doi = {10.3109/17453674.2011.588863},
  abstract = {It is envisaged that guidelines for statistical analysis and presentation of results will improve the quality and value of research. The Nordic Arthroplasty Register Association (NARA) has therefore developed guidelines for the statistical analysis of arthroplasty register data. The guidelines are divided into two parts, one with an introduction and a discussion of the background to the guidelines (, see pages x-y in this issue), and this one with a more technical statistical discussion on how specific problems can be handled. This second part contains (1) recommendations for the interpretation of methods used to calculate survival, (2) recommendations on howto deal with bilateral observations, and (3) a discussion of problems and pitfalls associated with analysis of factors that influence survival or comparisons between outcomes extracted from different hospitals.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PXERW53U\\ranstam_et_al_2011_statistical_analysis_of_arthroplasty_data.pdf},
  isbn = {1745-3682; 1745-3674},
  journal = {Acta orthopaedica},
  number = {3},
  pmid = {21619500}
}

@article{Ranstam2012,
  title = {Repeated Measurements, Bilateral Observations and Pseudoreplicates, Why Does It Matter?},
  author = {Ranstam, J.},
  year = {2012},
  volume = {20},
  pages = {473--475},
  publisher = {{Elsevier Ltd}},
  issn = {10634584},
  doi = {10.1016/j.joca.2012.02.011},
  abstract = {A common requirement of statistical methods, critical to the interpretation of the data, is that the analyzed observations are independent. This is not always the case in experiments and clinical studies, a mistake which can be expected to lead to erroneous study results. The phenomenon is explained, its consequences described, and suggestions to avoid the problems presented. ?? 2012 Osteoarthritis Research Society International.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZJECXHS4\\ranstam_2012_repeated_measurements,_bilateral_observations_and_pseudoreplicates,_why_does_it.pdf},
  isbn = {1522-9653; 1063-4584},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Bilateral,Biostatistics,Independence,Precision,Pseudoreplicates,Study design,Variation},
  number = {6},
  pmid = {22406008}
}

@article{Rapiti2014,
  title = {Planning for the Future: {{Cancer}} Incidence Projections in {{Switzerland}} up to 2019},
  author = {Rapiti, Elisabetta and Guarnori, Sandrine and Pastoors, Bert and Miralbell, Raymond and Usel, Massimo},
  year = {2014},
  volume = {14},
  pages = {1--7},
  issn = {14712458},
  doi = {10.1186/1471-2458-14-102},
  abstract = {BACKGROUND: Projections of the national burden of cancer play a key role in planning cancer control programmes and investments. We present projections of cancer incidence rates and cases for the period up to 2015-2019 in Switzerland.: Projections were based on cancer incidence data estimated from cancer registries for the 1989-2009 periods and demographic projections of the Federal Statistical Office. Age-specific incidence rates were modelled as a function of age, period-birth cohort using NORDPRED.: Up to 2019 the incidence of all cancers combined is expected to decrease slightly for both sexes. Nevertheless, the overall number of cases is predicted to increase. The number of male cancer cases will increase by 30\%, from 20005 in 2005-2009 to 25910/year in 2015-2019. For females the number will increase by 20\%, from 16913 to 20359/year in 2015-2019. Changes in the population size and structure will be responsible for most of the increase. Among men, the largest increase is observed for melanoma (+54\%), thyroid (+45\%), non-Hodgkin lymphoma (+43\%), and prostate (+37\%). Prostate cancer will contribute with 8083 cases, colorectal cancer with 2908 and lung cancer with 2791. For women, cases of lung and oral cavity cancers will increase by +48\% and +38\%, respectively; those of thyroid by +45\% and non-Hodgkin lymphoma by +36\%. The sites with the most cancer predicted are breast (5870), colorectal and lung (over 2000 each), melanoma (1341) and corpus uteri (1040). The overall annual cancer burden predicted for 2015-19 is of 46269 new cases in Switzerland.: Substantial investments appear to be needed in Switzerland cancer services to meet and fill absolute increased demand driven by aging population.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\43QSWNV2\\rapiti_et_al_2014_planning_for_the_future.pdf},
  isbn = {1471-2458},
  journal = {BMC Public Health},
  keywords = {Adult,Age Factors,Aged,Cancer,Cost of Illness,Female,Forecasting,Health Planning,Humans,Incidence,Male,Middle Aged,Models,Neoplasms,Neoplasms: epidemiology,Population-based cancer registries,Projections,Statistical,Switzerland,Switzerland: epidemiology,Young Adult},
  number = {1},
  pmid = {24484472}
}

@article{Rapkin2004,
  title = {Toward a Theoretical Model of Quality of Life Appraisal: Implications for Findings from Studies of Response Shift},
  author = {Rapkin, B D and Schwartz, C E},
  year = {2004},
  volume = {2},
  pages = {1--12},
  doi = {10.1186/1477-7525-2-14},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7Q3DGC6B\\rapkin_schwartz_2004_toward_a_theoretical_model_of_quality_of_life_appraisal.pdf},
  journal = {Health and quality of life outcomes}
}

@article{Rasmussen2016,
  title = {Validity of the Prescriber Information in the Danish National Prescription Registry},
  author = {Rasmussen, Lotte and Valentin, Julie and Gesser, Katarina Margareta and Hallas, Jesper and Potteg\aa rd, Anton},
  year = {2016},
  month = oct,
  volume = {119},
  pages = {376--380},
  publisher = {{Blackwell Publishing Ltd}},
  issn = {17427843},
  doi = {10.1111/bcpt.12610},
  abstract = {The aim of this study was to measure the validity of the prescriber information recorded in the Danish National Prescription Registry (DNPR). The prescriber information recorded in the pharmacies' electronic dispensing system was considered to represent the prescriber information recorded in the DNPR. Further, the problem of validity of the prescriber information pertains only to non-electronic prescriptions, as these are manually entered into the dispensing system. The recorded prescriber information was thus validated against information from a total of 2000 non-electronic prescriptions at five Danish community pharmacies. The validity of the recorded prescriber information was measured at the level of the individual prescriber and the prescriber type, respectively. The proportion of non-electronic prescriptions with incorrect registrations was 22.4\% (95\% confidence interval (CI): 20.6\textendash 24.3) when considering individual prescriber identifiers and 17.8\% (95\% CI: 16.1\textendash 19.5) when considering prescriber type. When excluding prescriptions specifically registered as `missing prescriber identifier', the proportions decreased to 9.5\% (95\% CI: 8.2\textendash 11.0) and 4.1\% (95\% CI: 3.2\textendash 5.1), respectively. The positive predictive values for the classification of prescriber types were in the range of 94.0\textendash 99.2\%, while the sensitivity ranged between 64.6\% and 91.8\%. With a maximum of 14\% non-electronic prescriptions of all prescriptions in the DNPR in 2015, this corresponds to correct classification of prescriber types in the DNPR of at least 97.5\%. In conclusion, the prescriber information in the DNPR was found to be valid, especially in recent years. Researchers should be aware of the low sensitivity towards prescriptions from private practicing specialists.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KJASU5MZ\\rasmussen_et_al_2016_validity_of_the_prescriber_information_in_the_danish_national_prescription.pdf},
  journal = {Basic and Clinical Pharmacology and Toxicology},
  number = {4}
}

@article{Rasouli2014,
  title = {Perioperative Morbidity and Mortality Following Bilateral Total Hip Arthroplasty.},
  author = {Rasouli, Mohammad R and Maltenfort, Mitchell G and Ross, David and Hozack, William J and Memtsoudis, Stavros G and Parvizi, Javad},
  year = {2014},
  volume = {29},
  pages = {142--8},
  publisher = {{Elsevier Inc.}},
  issn = {1532-8406},
  doi = {10.1016/j.arth.2013.04.001},
  abstract = {There is concern about safety of bilateral total hip arthroplasty (THA).This study aims to compare in-hospital complication rates between unilateral, simultaneous and staged bilateral THAs. The Nationwide Inpatient Sample from 2002-2010 was used. Patients and complications were identified using ICD-9-CM codes. In multivariate analysis, bilateral THA had higher risk of systemic complications (Odds ratio (OR): 2.1, P\textexclamdown 0.001) compared to unilateral procedure, whereas no significant difference existed between simultaneous and staged bilateral THAs. The rate of local complications was higher in bilateral versus unilateral (4.96\% versus 4.54\%, P=0.009) and in staged versus simultaneous bilateral THAs (OR: 1.75, P=0.05). Bilateral THA increases risk of systemic complications compared to unilateral surgery and simultaneous bilateral THA appears to be safer than staging during one hospitalization.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\U5NF5M7A\\rasouli_et_al_2014_perioperative_morbidity_and_mortality_following_bilateral_total_hip_arthroplasty.pdf},
  journal = {The Journal of arthroplasty},
  keywords = {Arthroplasty,Databases,Factual,Female,Hip,Hip: adverse effects,Hip: statistics \& numer,Hip: trends,Humans,Male,Morbidity,Perioperative Period,Postoperative Complications,Postoperative Complications: epidemiology,Replacement,United States,United States: epidemiology},
  number = {1},
  pmid = {23664280}
}

@article{Rasouli2014a,
  title = {Risk {{Factors}} for {{Surgical Site Infection Following Total Joint Arthroplasty}}:},
  shorttitle = {Risk {{Factors}} for {{Surgical Site Infection Following Total Joint Arthroplasty}}},
  author = {Rasouli, Mohammad R and Restrepo, Camilo and Maltenfort, Mitchell G and Purtill, James J and Parvizi, Javad},
  year = {2014},
  month = sep,
  volume = {96},
  pages = {e158-1-5},
  issn = {0021-9355},
  doi = {10.2106/JBJS.M.01363},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J53S2ZR2\\Rasouli et al_2014_Risk Factors for Surgical Site Infection Following Total Joint Arthroplasty.pdf},
  journal = {The Journal of Bone and Joint Surgery-American Volume},
  language = {en},
  number = {18}
}

@article{Ravi2013,
  title = {The Relation between Total Joint Arthroplasty and Risk for Serious Cardiovascular Events in Patients with Moderate-Severe Osteoarthritis: Propensity Score Matched Landmark Analysis.},
  author = {Ravi, Bheeshma and Croxford, Ruth and Austin, Peter C and Lipscombe, Lorraine and Bierman, Arlene S and Harvey, Paula J and a Hawker, Gillian},
  year = {2013},
  volume = {347},
  pages = {f6187},
  issn = {1756-1833},
  doi = {10.1136/bmj.f6187},
  abstract = {OBJECTIVE: To examine whether total joint arthroplasty of the hip and knee reduces the risk for serious cardiovascular events in patients with moderate-severe osteoarthritis.: Propensity score matched landmark analysis.: Ontario, Canada.: 2200 adults with hip or knee osteoarthritis aged 55 or more at recruitment (1996-98) and followed prospectively until death or 2011.OUTCOME MEASURE: Rates of serious cardiovascular events for those who received a primary total joint arthroplasty compared with those did not within an exposure period of three years after baseline assessment.: The propensity score matched cohort consisted of 153 matched pairs of participants with moderate-severe arthritis. Over a median follow-up period of seven years after the landmark date (start of the study), matched participants who underwent a total joint arthroplasty during the exposure period were significantly less likely than those who did not to experience a cardiovascular event (hazards ratio 0.56, 95\% confidence interval 0.43 to 0.74, P\textexclamdown 0.001). Within seven years of the exposure period the absolute risk reduction was 12.4\% (95\% confidence interval 1.7\% to 23.1\%) and number needed to treat was 8 (95\% confidence interval 4 to 57 patients).: Using a propensity matched landmark analysis in a population cohort with advanced hip or knee osteoarthritis, this study found a cardioprotective benefit of primary elective total joint arthroplasty.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DE7GJXPB\\ravi_et_al_2013_the_relation_between_total_joint_arthroplasty_and_risk_for_serious.pdf},
  isbn = {1756-1833},
  journal = {BMJ (Clinical research ed.)},
  keywords = {80 and over,Aged,Arthroplasty,Cardiovascular Diseases,Cardiovascular Diseases: epidemiology,Case-Control Studies,Female,Follow-Up Studies,Hip,Hip: adverse effects,Hip: surgery,Humans,Knee,Knee: adverse effects,Knee: surgery,Male,Middle Aged,Ontario,Ontario: epidemiology,Osteoarthritis,Propensity Score,Prospective Studies,Replacement,Risk Factors,Treatment Outcome},
  number = {October},
  pmid = {24174640}
}

@article{Ravi2013,
  title = {Exclusion of Patients with Sequential Primary Total Joint Arthroplasties from Arthroplasty Outcome Studies Biases Outcome Estimates: {{A}} Retrospective Cohort Study},
  author = {Ravi, B. and Croxford, R. and Hawker, G.},
  year = {2013},
  volume = {21},
  pages = {1841--1848},
  publisher = {{Elsevier Ltd}},
  issn = {10634584},
  doi = {10.1016/j.joca.2013.08.020},
  abstract = {Objective: Total joint arthroplasty (TJA) outcome studies have largely focused on recipients of a single primary TJA, which may bias outcome estimates. Design: This retrospective cohort study utilized health administrative databases from Ontario, Canada, to assemble a cohort that received a first primary elective hip or knee TJA for osteoarthritis (OA) between 2002 and 2009 (index TJA). Characteristics of TJA recipients at their index TJA were compared for those who did vs did not go on to receive one or more subsequent primary, elective hip/knee TJAs (multiple TJAs - yes/no) over a 2-year follow-up period. Cox proportional hazards, censored on death, was used to examine the relationship of receipt of multiple TJAs (yes/no) on rates of surgical complications for the index TJA, controlling for confounders. Results: Among 97,374 eligible patients, 19,856 (20.4\%) received a second primary elective TJA procedure within 2years. In bivariate analyses, recipients of multiple primary TJAs were significantly more likely than single TJA recipients to be female, younger, with fewer co-morbidities (P\textexclamdown 0.0001), and to experience surgical complications with the index surgery, including early revision (P\textexclamdown 0.0001). Controlling for patient differences, receipt of \textquestiondown 1 primary TJAs over 2years was independently and significantly associated with lower odds of having experienced a surgical complication following the index arthroplasty (adjusted HR 0.65, 95\%CI 0.59-0.72). Conclusions: One in five patients receiving their first elective primary hip or knee TJA received a second hip/knee TJA within 2years. Our results indicate that exclusion of this large subsample of TJA recipients from TJA outcomes studies over-estimates surgical risks and may underestimate patient-reported benefits. ?? 2013 Osteoarthritis Research Society International.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3ST2GZW9\\ravi_et_al_2013_exclusion_of_patients_with_sequential_primary_total_joint_arthroplasties_from.pdf},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Arthroplasty,Bias,Joint revision,Osteoarthritis,Post-operative complications},
  number = {12},
  pmid = {24012621}
}

@article{Rawshani2014,
  title = {The Incidence of Diabetes among 0-34 Year Olds in {{Sweden}}: {{New}} Data and Better Methods},
  author = {Rawshani, Araz and {Landin-Olsson}, Mona and Svensson, Ann Marie and Nystr{\"o}m, Lennarth and Arnqvist, Hans J. and Bolinder, Jan and Gudbj{\"o}rnsdottir, Soffia},
  year = {2014},
  volume = {57},
  pages = {1375--1381},
  issn = {14320428},
  doi = {10.1007/s00125-014-3225-9},
  abstract = {AIMS/HYPOTHESIS: We reassessed the validity of previously reported incidence rates for type 1 diabetes in 0-34 year olds in Sweden. We estimated new incidence rates through three nationwide registe ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DQTQB6X9\\rawshani_et_al_2014_the_incidence_of_diabetes_among_0-34_year_olds_in_sweden.pdf},
  isbn = {0012501432259},
  journal = {Diabetologia},
  keywords = {Epidemiology,Incidence,Spring harvest theory,Type 1 diabetes},
  number = {7},
  pmid = {24710965}
}

@article{rdmcleodl.dInterpretingPatientreportedOutcome2012,
  title = {Interpreting Patient-Reported Outcome Results: {{US FDA}} Guidance and Emerging Methods},
  author = {R D McLeod, L. D, C. D. Martin, S. A, Fehnel, S. E \& Hays, Coon},
  year = {2012},
  volume = {11},
  pages = {163--169},
  issn = {1473-7167},
  doi = {10.1586/erp.11.12.Interpreting},
  journal = {Pharmacoeconomics \& Outcomes Research - Expert Reviews},
  keywords = {\#nosource,a,become more critical of,in clinical trials,in recent years,individual change,instruments used to measure,minimal important differences,patient-reported outcomes,pros,reliable change index,responder,specifically,the agency now requires,the us fda has},
  number = {2}
}

@article{Redfors2015,
  title = {Mortality in Takotsubo Syndrome Is Similar to Mortality in Myocardial Infarction - {{A}} Report from the {{SWEDEHEART}}},
  author = {Redfors, Bj{\"o}rn and Vedad, Ramtin and Anger\aa s, Oskar and R\aa munddal, Truls and Petursson, Petur and Haraldsson, Inger and Ali, Anwar and Dworeck, Christian and Odenstedt, Jacob and Ioaness, Dan and Libungan, Berglin and Shao, Yangzhen and Albertsson, Per and Stone, Gregg W. and Omerovic, Elmir},
  year = {2015},
  volume = {185},
  pages = {282--289},
  publisher = {{Elsevier Ireland Ltd}},
  issn = {18741754},
  doi = {10.1016/j.ijcard.2015.03.162},
  abstract = {Background Takotsubo syndrome is an acute cardiovascular condition that predominantly affects women. In this study, we compared patients with takotsubo syndrome and those with acute myocardial infarction with respect to patient characteristics, angiographic findings, and short- and long-term mortality. Methods From the Swedish Coronary Angiography and Angioplasty Registry (SCAAR) and the Register of Information and Knowledge about Swedish Heart Intensive Care Admissions (RIKS-HIA), we obtained and merged data on patients undergoing coronary angiography in V\"astra G\"otaland County in western Sweden between January 2005 and May 2013. Short- and long-term mortality in patients with takotsubo (n = 302) and patients with ST-elevation myocardial infarction (STEMI, n = 6595) and non-ST-elevation myocardial infarction (NSTEMI, n = 8207) were compared by modeling unadjusted and propensity score-adjusted logistic and Cox proportional-hazards regression. Results The proportion of the patients diagnosed with takotsubo increased from 0.16\% in 2005 to 2.2\% in 2012 (P \textexclamdown{} 0.05); 14\% of these patients also had significant coronary artery disease. Cardiogenic shock developed more frequently in patients with takotsubo than NSTEMI (adjusted OR 3.08, 95\% CI 1.80-5.28, P \textexclamdown{} 0.001). Thirty-day mortality was 4.1\% and was comparable to STEMI and NSTEMI. The long-term risk of dying from takotsubo (median follow-up 25 months) was also comparable to NSTEMI (adjusted HR 1.01, 95\% CI 0.70-1.46, P = 0.955) STEMI (adjusted HR 0.83, 95\% CI 0.57-1.20, P = 0.328). Conclusions The proportion of acute coronary syndromes attributed to takotsubo syndrome in Western Sweden has increased over the last decade. The prognosis of takotsubo syndrome is poor, with similar early and late mortality as STEMI and NSTEMI.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QVE6IH8H\\redfors_et_al_2015_mortality_in_takotsubo_syndrome_is_similar_to_mortality_in_myocardial.pdf},
  journal = {International Journal of Cardiology},
  keywords = {Non-ST-elevation myocardial infarction,Percutaneous coronary intervention,ST-elevation myocardial infarction,Swedish Coronary Angiography and Angioplasty Regis,Takotsubo syndrome,Unstable angina pectoris},
  pmid = {25818540}
}

@article{Redmond2017,
  title = {What Factors Predict Conversion to {{THA}} after Arthroscopy?},
  author = {Redmond, John M. and Gupta, Asheesh and Dunne, Kevin and Humayun, Ammar and Yuen, Leslie C. and Domb, Benjamin G.},
  year = {2017},
  volume = {475},
  pages = {1--8},
  publisher = {{Springer US}},
  issn = {15281132},
  doi = {10.1007/s11999-017-5437-z},
  abstract = {BACKGROUND Failure of hip preservation to alleviate symptoms potentially subjects the patient to reoperation or conversion surgery to THA, adding recovery time, risk, and cost. A risk calculator using an algorithm that can predict the likelihood that a patient who undergoes arthroscopic hip surgery will undergo THA within 2 years would be helpful, but to our knowledge, no such tool exists. QUESTIONS (1) Are there preoperative and intraoperative variables at the time of hip arthroscopy associated with subsequent conversion to THA? (2) Can these variables be used to develop a predictive tool for conversion to THA? MATERIALS AND METHODS All patients undergoing arthroscopy from January 2009 through December 2011 were registered in our longitudinal database. Inclusion criteria for the study group were patients undergoing hip arthroscopy for a labral tear, who eventually had conversion surgery to THA. Patients were compared with a control group of patients who underwent hip arthroscopy for a labral tear but who did not undergo conversion surgery to THA during the same study period. Of the 893 who underwent surgery during that time, 792 (88.7\%) were available for followup at a minimum of 2 years (mean, 31.1 {$\pm$} 8.1 years) and so were considered in this analysis. Multivariate regression analyses of 41 preoperative and intraoperative variables were performed. Using the results of the multivariate regression, we developed a simplified calculator that may be helpful in counseling a patient regarding the risk of conversion to THA after hip arthroscopy. RESULTS Variables simultaneously associated with conversion to THA in this model were older age (rate ratio, 1.06; 95\% CI, 1.03-1.08; p \textexclamdown{} 0.0001), lower preoperative modified Harris hip score (rate ratio [RR], 0.98; 95\% CI, 0.96-0.99; p = 0.0003), decreased femoral anteversion (RR, 0.97; 95\% CI, 0.94-0.99; p = 0.0111), revision surgery (RR, 2.4; 95\% CI, 1.15-5.01; p = 0.0193), femoral Outerbridge Grades II to IV (Grade II: RR, 2.23 [95\% CI, 1.11-4.46], p = 0.023; Grade III: RR, 2.17, [95\% CI, 1.11-4.23], p = 0.024; Grade IV: RR, 2.96 [95\% CI, 1.34-6.52], p = 0.007), performance of acetabuloplasty (RR, 1.83; 95\% CI, 1.03-3.24; p = 0.038), and lack of performance of femoral osteoplasty (RR, 0.62; 95\% CI, 0.36-1.06; p = 0.081). Using the results of the multivariate regression, we developed a simplified calculator that may be helpful in counseling a patient regarding the risk of conversion surgery to THA after hip arthroscopy. CONCLUSION Multiple risk factors have been identified as possible risk factors for conversion to THA after hip arthroscopy. A weighted calculator based on our data is presented here and may be useful for predicting failure after hip arthroscopy for labral treatment. Determining the best candidates for hip preservation remains challenging; careful attention to long-term followup and identifying characteristics associated with successful outcomes should be the focus of further study. LEVEL OF EVIDENCE Level III, therapeutic study.},
  journal = {Clinical Orthopaedics and Related Research},
  keywords = {\#nosource},
  number = {10},
  pmid = {28688017}
}

@article{Reeve2008,
  title = {Reducing Bias in Cancer Research: Application of Propensity Score Matching},
  author = {Reeve, B B and Smith, A W and Arora, N K and Hays, R D},
  year = {2008},
  volume = {29},
  pages = {69--80},
  doi = {hcfr-29-04-069 [pii]},
  abstract = {In cancer observational studies, differences between groups on confounding variables may have a significant effect on results when examining health outcomes. This study demonstrates the utility of propensity score matching to balance a non-cancer and cancer cohort of older adults on multiple relevant covariates. This approach matches cases to controls on a single indicator, the propensity score, rather than multiple variables. Results indicated that propensity score matching is an efficient and useful way to create a matched case-control study out of a large cohort study, and allows confidence in the strength of the observed outcomes of the study.},
  isbn = {0195-8631 (Print){\r  }0195-8631 (Linking)},
  journal = {Health care financing review},
  keywords = {*Epidemiologic Research Design,*Quality of Life,\#nosource,80 and over,Aged,Chronic Disease/*epidemiology,Cohort Studies,Comorbidity,Cost of Illness,Database Management Systems,Female,Humans,Male,Managed Care Programs/*standards,Medicare/*standards,Neoplasms/*epidemiology,Observation,Outcome Assessment (Health Care)/*methods,SEER Program,Socioeconomic Factors,Survivors/*statistics \& numerical data,United States/epidemiology},
  number = {4},
  pmid = {18773615}
}

@book{Regeringskansliet2018,
  title = {R\"att Att Forska {{L\aa ngsiktig}} Reglering Av Forskningsdatabaser},
  author = {{Regeringskansliet}},
  year = {2018},
  isbn = {978-91-38-24800-3},
  keywords = {\#nosource}
}

@article{Renaud2010,
  title = {A Robust Coefficient of Determination for Regression},
  author = {Renaud, Olivier and {Victoria-Feser}, Maria Pia},
  year = {2010},
  volume = {140},
  pages = {1852--1862},
  publisher = {{Elsevier}},
  issn = {03783758},
  doi = {10.1016/j.jspi.2010.01.008},
  abstract = {To assess the quality of the fit in a multiple linear regression, the coefficient of determination or R2 is a very simple tool, yet the most used by practitioners. Indeed, it is reported in most statistical analyzes, and although it is not recommended as a final model selection tool, it provides an indication of the suitability of the chosen explanatory variables in predicting the response. In the classical setting, it is well known that the least-squares fit and coefficient of determination can be arbitrary and/or misleading in the presence of a single outlier. In many applied settings, the assumption of normality of the errors and the absence of outliers are difficult to establish. In these cases, robust procedures for estimation and inference in linear regression are available and provide a suitable alternative. In this paper we present a companion robust coefficient of determination that has several desirable properties not shared by others. It is robust to deviations from the specified regression model (like the presence of outliers), it is efficient if the errors are normally distributed, it does not make any assumption on the distribution of the explanatory variables (and therefore no assumption on the unconditional distribution of the responses). We also show that it is a consistent estimator of the population coefficient of determination. A simulation study and two real datasets support the appropriateness of this estimator, compared with classical (least-squares) and several previously proposed robust R2, even for small sample sizes. \textcopyright{} 2010 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SUDKASP9\\renaud_victoria-feser_2010_a_robust_coefficient_of_determination_for_regression.pdf},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Consistency,Correlation,Efficiency,Outliers,R-squared},
  number = {7}
}

@article{Revicki2007,
  title = {Interpreting and Reporting Results Based on Patient-Reported Outcomes.},
  author = {a Revicki, Dennis and a Erickson, Pennifer and a Sloan, Jeff and Dueck, Amylou and Guess, Harry and Santanello, Nancy C},
  year = {2007},
  volume = {10 Suppl 2},
  pages = {S116-24},
  issn = {1524-4733},
  doi = {10.1111/j.1524-4733.2007.00274.x},
  abstract = {This article deals with the incorporation of patient-reported outcomes (PROs) into clinical trials and focuses on issues associated with the interpretation and reporting of PRO data. The primary focus and context of this information relates to the evidentiary support and reporting for a labeling or advertising claim of a PRO benefit for a new or approved pharmaceutical product. This manuscript focuses on issues associated with assessing clinical significance and common pitfalls to avoid in presenting results related to PROs. Specifically, the questions addressed by this manuscript involve: What are the best methods to assess clinical significance for PROs? How should investigators present PRO data most effectively in a Food and Drug Administration (FDA) application? In labeling or in a scientific publication? Guidelines for interpreting clinical significance of PROs and for comprehensively reporting on the methods, measures and results of clinical trials that incorporate PROs are important for clinicians, regulatory agencies, and most of all to patients. Clear specifications for considering a finding on a PRO measure, as clinically meaningful, need to be determined by instrument developers and psychometricians; they need to be reported for all clinical trials involving PRO end points. Clinical trial reports need to be comprehensive, clear, and sufficient to enable any reader to understand the methods, PRO measures, statistical analysis, and results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NBAKKQAN\\revicki_et_al_2007_interpreting_and_reporting_results_based_on_patient-reported_outcomes.pdf},
  isbn = {1098-3015},
  journal = {Value in health : the journal of the International Society for Pharmacoeconomics and Outcomes Research},
  keywords = {Clinical Trials as Topic,Clinical Trials as Topic: statistics \& numerical d,Data Collection,Data Collection: methods,Data Collection: statistics \& numerical data,Data Interpretation,Endpoint Determination,Humans,Patient Satisfaction,Patient Satisfaction: statistics \& numerical data,Psychometrics,Psychometrics: methods,Statistical,Treatment Outcome},
  pmid = {17995470}
}

@book{reviewsSystematicReviews2009,
  title = {Systematic Reviews},
  author = {for {reviews}, Centre and {dissemination}},
  year = {2009},
  isbn = {978-1-900640-47-3},
  keywords = {\#nosource}
}

@book{Rice2001,
  title = {Mathematical Statistics and Data Analysis},
  author = {Rice, John A.},
  year = {2001},
  volume = {72},
  issn = {00255572},
  doi = {10.2307/3619963},
  abstract = {This is the first text in a generation to re-examine the purpose of the mathematical statistics course. The book's approach interweaves traditional topics with data analysis and reflects the use of the computer with close ties to the practice of statistic},
  isbn = {1-111-79371-9},
  keywords = {\#nosource}
}

@article{Rider1932,
  title = {On the {{Distribution}} of the Correlation Coefficient in Small Samples},
  author = {Rider, Paul R.},
  year = {1932},
  volume = {24},
  pages = {382--403},
  abstract = {IT was the original purpose of this study to attempt to discover the effect upon the distribution in random samples, particularly in small samples, of the product-moment coefficient of correlation, r, when the samples are drawn from a non-normal instead of a normal population. In Part I the results of sampling from certain populations which differ greatly from the normal are given, also the results of sampling from a normal population having a high degree of correlation. As the sampling was done experimentally, it was necessary to deal with discrete populations. This opened up the question of the effect of grouping upon the distribution of r, a question which is investigated in Part II.},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {3}
}

@article{Ridgeway2005,
  title = {Infection of the Surgical Site after Arthroplasty of the Hip},
  author = {Ridgeway, S. and Wilson, J. and Charlet, A. and Kafatos, G. and Pearson, A. and Coello, R.},
  year = {2005},
  month = jun,
  volume = {87-B},
  pages = {844--850},
  issn = {0301-620X, 2044-5377},
  doi = {10.1302/0301-620X.87B6.15121},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5TMKUY8X\\Ridgeway et al_2005_Infection of the surgical site after arthroplasty of the hip.pdf},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  language = {en},
  number = {6}
}

@article{Riley2019,
  title = {A Guide to Systematic Review and Meta-Analysis of Prognostic Factor Studies},
  author = {Riley, Richard D. and Moons, Karel G. M. and Snell, Kym I. E. and Ensor, Joie and Hooft, Lotty and Altman, Douglas G. and Hayden, Jill and Collins, Gary S. and Debray, Thomas P. A.},
  year = {2019},
  month = jan,
  volume = {364},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.k4597},
  abstract = {{$<$}p{$>$}Prognostic factors are associated with the risk of future health outcomes in individuals with a particular health condition or some clinical start point (eg, a particular diagnosis). Research to identify genuine prognostic factors is important because these factors can help improve risk stratification, treatment, and lifestyle decisions, and the design of randomised trials. Although thousands of prognostic factor studies are published each year, often they are of variable quality and the findings are inconsistent. Systematic reviews and meta-analyses are therefore needed that summarise the evidence about the prognostic value of particular factors. In this article, the key steps involved in this review process are described.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WPMKBA57\\Riley m. fl. - 2019 - A guide to systematic review and meta-analysis of .pdf;C\:\\Users\\erik_\\Zotero\\storage\\PKC7S5EU\\bmj.html},
  journal = {BMJ},
  keywords = {acta review},
  language = {en},
  pmid = {30700442}
}

@article{Riley2020,
  title = {Calculating the Sample Size Required for Developing a Clinical Prediction Model},
  author = {Riley, Richard D. and Ensor, Joie and Snell, Kym I. E. and Harrell, Frank E. and Martin, Glen P. and Reitsma, Johannes B. and Moons, Karel G. M. and Collins, Gary and van Smeden, Maarten},
  year = {2020},
  month = mar,
  volume = {368},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m441},
  abstract = {{$<$}p{$>$}Clinical prediction models aim to predict outcomes in individuals, to inform diagnosis or prognosis in healthcare. Hundreds of prediction models are published in the medical literature each year, yet many are developed using a dataset that is too small for the total number of participants or outcome events. This leads to inaccurate predictions and consequently incorrect healthcare decisions for some individuals. In this article, the authors provide guidance on how to calculate the sample size required to develop a clinical prediction model.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com.ezproxy.ub.gu.se/group/rights-licensing/permissions},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TV94YFVT\\riley_et_al_2020_calculating_the_sample_size_required_for_developing_a_clinical_prediction_model.pdf;C\:\\Users\\erik_\\Zotero\\storage\\BMKFU8SM\\bmj.html},
  journal = {BMJ},
  keywords = {coverletter},
  language = {en},
  pmid = {32188600}
}

@book{Ripley2002,
  title = {Modern Applied Statistics with {{S}}},
  author = {Ripley, Brian and Venables, W N},
  year = {2002},
  publisher = {{Springer, New York}},
  keywords = {\#nosource}
}

@article{Ripollone2018,
  title = {Implications of the Propensity Score Matching Paradox in Pharmacoepidemiology},
  author = {Ripollone, John E and Huybrechts, Krista F and Rothman, Kenneth J and Ferguson, Ryan E and Franklin, Jessica M},
  year = {2018},
  month = sep,
  volume = {187},
  pages = {1951--1961},
  issn = {0002-9262},
  doi = {10.1093/aje/kwy078},
  abstract = {Recent work has demonstrated that propensity score matching may lead to increased covariate imbalance, even with the corresponding decrease in propensity score distance between matched units. The extent to which this paradoxical phenomenon might harm causal inference in real epidemiologic studies has not been explored. We evaluated the effect of this phenomenon using insurance claims data from the Pharmaceutical Assistance Contract for the Elderly (1999-2002) and Medicaid Analytic eXtract (2000-2007) databases in the United States. For each data set, we created several 1:1 propensity-score-matched data sets by manipulating the size of the covariate set used to generate propensity scores, the index exposure prevalence in the prematched data set, and the matching algorithm. We matched all index units, then progressively pruned matched sets in order of decreasing propensity score distance, calculating covariate imbalance after each pruning. Although covariate imbalance sometimes increased after progressive pruning of matched sets, the application of commonly used propensity score calipers for defining an acceptable match stopped pruning near the lowest region of the imbalance trend and resulted in an improvement over the imbalance in the prematched data set. Thus, propensity score matching does not appear to induce increased covariate imbalance when standard propensity score calipers are applied in these types of pharmacoepidemiologic studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\D6CQ99YG\\ripollone_et_al_2018_implications_of_the_propensity_score_matching_paradox_in_pharmacoepidemiology.pdf},
  journal = {American Journal of Epidemiology},
  number = {9},
  pmid = {29750409}
}

@article{Rizopoulos2010,
  title = {{{JM}}: {{An R}} Package for the Joint Modelling of Longitudinal and Time-to-Event Data},
  author = {Rizopoulos, Dimitris},
  year = {2010},
  volume = {35},
  pages = {1--33},
  publisher = {{University of California at Los Angeles}},
  issn = {15487660},
  doi = {10.18637/jss.v035.i09},
  abstract = {In longitudinal studies measurements are often collected on different types of outcomes for each subject. These may include several longitudinally measured responses (such as blood values relevant to the medical condition under study) and the time at which an event of particular interest occurs (e.g., death, development of a disease or dropout from the study). These outcomes are often separately analyzed; however, in many instances, a joint modeling approach is either required or may produce a better insight into the mechanisms that underlie the phenomenon under study. In this paper we present the R package JM that fits joint models for longitudinal and time-to-event data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EMNR28AI\\rizopoulos_2010_jm.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Attrition,Dropout,Longitudinal data,Shared parameter models,Survival data,Time-dependent covariates},
  number = {9}
}

@article{Robinson2017,
  title = {Paediatric Fracture Clinic Re-Design: {{Incorporating}} a Virtual Fracture Clinic},
  author = {Robinson, Paul M. and Sim, Francis and Latimer, Mark and Mitchell, Piers D.},
  year = {2017},
  pages = {6--10},
  publisher = {{Elsevier Ltd}},
  issn = {00201383},
  doi = {10.1016/j.injury.2017.08.006},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WM4Z7RZ8\\robinson_et_al_2017_paediatric_fracture_clinic_re-design.pdf},
  journal = {Injury}
}

@article{Roche2005,
  title = {Effect of Comorbidities and Postoperative Complications on Mortality after Hip Fracture in Elderly People: Prospective Observational Cohort Study},
  author = {Roche, J J W},
  year = {2005},
  volume = {331},
  pages = {1374--0},
  issn = {0959-8138},
  doi = {10.1136/bmj.38643.663843.55},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E3FWJ6WJ\\roche_2005_effect_of_comorbidities_and_postoperative_complications_on_mortality_after_hip.pdf},
  isbn = {1468-5833 (Electronic){\r  }0959-535X (Linking)},
  journal = {Bmj},
  number = {7529},
  pmid = {16299013}
}

@article{rodgersThirteenWaysLook1988,
  title = {Thirteen Ways to Look at the Correlation Coefficient},
  author = {Rodgers, Joseph Lee and Wander, W. Alan Nice and Rodgers, Joseph Lee and Nicewander, W. Alan},
  year = {1988},
  volume = {42},
  pages = {59--66},
  issn = {15372731},
  doi = {10.1080/00031305.1988.10475524},
  abstract = {In 1885, Sir Francis Galton first defined the term "regression" and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
  isbn = {00031305},
  journal = {American Statistician},
  keywords = {\#nosource},
  number = {1},
  pmid = {2685263}
}

@bill{Roffman2016,
  title = {Charlson Comorbidities Index},
  author = {Roffman, Caroline E. and Buchanan, John and Allison, Garry T.},
  year = {2016},
  month = jul,
  volume = {62},
  pages = {171},
  publisher = {{Elsevier}},
  issn = {18369561},
  doi = {10.1016/j.jphys.2016.05.008},
  abstract = {Description: The Charlson Comorbidity Index (CCI) was developed and validated as a measure of 1-year mortality risk and burden of disease. 1\textendash 4 To account for age being an independent predictor of mortality, a Combined Age-CCI (CA-CCI) score can be generated. 1\textendash 3 The CCI has been extensively used in clinical research to address the confounding influence of comorbidities, predict outcomes, standardise comorbidities abstracted from medical records or administrative databases and for self report of comorbidities. 1,3,5\textendash 9 In clinical practice, the CCI reduces comorbid-ities into a single numeric score that may assist health professionals with stratifying patients into subgroups based on disease severity, developing targeted models of care and resource allocation. 3,8},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WQCSZ29A\\roffman_et_al_2016_charlson_comorbidities_index.pdf},
  isbn = {1836-9553},
  journal = {Journal of Physiotherapy},
  number = {3},
  pmid = {27298055}
}

@article{Rogmark2016,
  title = {Hip Arthroplasty for the Treatment of Displaced Fractures of the Femoral Neck in Elderly Patients},
  author = {Rogmark, C. and Leonardsson, O.},
  year = {2016},
  volume = {98-B},
  journal = {Bone \& Joint Journal},
  keywords = {\#nosource},
  number = {3}
}

@article{Rohrer2018,
  title = {Thinking Clearly about Correlations and Causation: {{Graphical}} Causal Models for Observational Data},
  author = {Rohrer, Julia M.},
  year = {2018},
  pages = {251524591774562},
  issn = {2515-2459},
  doi = {10.1177/2515245917745629},
  abstract = {Correlation does not imply causation; but often, observational data are the only option, even though the research question at hand involves causality. This article discusses causal inference based on observational data, introducing readers to graphical causal models that can provide a powerful tool for thinking more clearly about the interrelations between variables. Topics covered include the rationale behind the statistical control of third variables, common procedures for statistical control, and what can go wrong during their implementation. Certain types of third variables\textemdash colliders and mediators\textemdash should not be controlled for because that can actually move the estimate of an association away from the value of the causal effect of interest. More subtle variations of such harmful control include using unrepresentative samples, which can undermine the validity of causal conclusions, and statistically controlling for mediators. Drawing valid causal inferences on the basis of observational data is not a me...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\K2S6DRSR\\rohrer_2018_thinking_clearly_about_correlations_and_causation.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  keywords = {12,17,9,directed acyclic graphs,face a dilemma,psychologists in many fields,received 8,revision accepted 11,whereas}
}

@article{Rolfson2011,
  title = {Use of Patient-Reported Outcomes in the Context of Different Levels of Data* Why Patient-Reported Outcome Measures ({{PROMs}}) Data Are Needed},
  author = {Rolfson, Ola and Rothwell, Alastair and Sedrakyan, Art and Chenok, Kate Eresian and Bohm, Eric and Bozic, Kevin J and Garellick, G{\"o}ran},
  year = {2011},
  volume = {93},
  pages = {66--71},
  doi = {10.2106/JBJS.K.01021},
  abstract = {There is increasing interest in measuring patient-reported outcomes as part of routine medical practice, partic-ularly in fields like total joint replacement surgery, where pain relief, satisfaction, function, and health-related quality of life, as perceived by the patient, are primary outcomes. We review some well-known outcome instruments, measurement issues, and early experiences with large-scale collection of patient-reported outcome measures in joint registries. The patient-reported outcome measures are reviewed in the context of multidimensional outcome assessment that includes the traditional clinical outcome parameters as well as disease-specific and general patient-reported outcome measures.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DRNN3B8E\\rolfson_et_al_2011_use_of_patient-reported_outcomes_in_the_context_of_different_levels_of_data.pdf},
  journal = {The journal of bone and joint surgery},
  keywords = {The Journal of Bone and Joint Surgery},
  number = {Suppl 3(E)}
}

@article{Rolfson2011,
  title = {Patient-Reported Outcomes in the {{Swedish Hip Arthroplasty Register}}: {{Results}} of a Nationwide Prospective Observational Study},
  author = {Rolfson, O. and K{\"a}rrholm, J and Dahlberg, L. E. and Garellick, G. and Karrholm, J. and Dahlberg, L. E. and Garellick, G.},
  year = {2011},
  volume = {93-B},
  pages = {867--875},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.93B7.25737},
  abstract = {We present the development and results of a nationwide, prospective, observational follow-up programme including patient-reported outcome measures (PROMs) for the Swedish Hip Arthroplasty Register. The programme started in 2002 and has gradually expanded to include all units performing total hip replacement in Sweden. The self-administered PROMs protocol comprises the EQ-5D instrument, the Charnley class categorisation and visual analogue scales for pain and satisfaction. These current analyses include 34 960 total hip replacements with complete pre- and one-year post-operative questionnaires. Patients eligible for total hip replacement generally report low health-related quality of life and suffer from pain. One year post-operatively the mean EQ-5D index increased to above the level of an age- and gender-matched population, with a considerable reduction of pain (p \textexclamdown 0.001). Females, younger patients and those with Charnley category C reported a lower EQ-5D index pre-operatively than males, older patients and Charnley category A or B, respectively (all p \textexclamdown 0.001). In a multivariable regression analysis Charnley category C, male gender and higher age were associated with less improvement in health-related quality of life (p \textexclamdown 0.001). Nationwide implementation of a PROMs programme requires a structured organisation and effective data capture. Patients' response rates to the Registry are good. The continuous collection of PROMs permits local and national improvement work and allows for further health-economic evaluation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Z2V2U8Q5\\rolfson_et_al_2011_patient-reported_outcomes_in_the_swedish_hip_arthroplasty_register.pdf},
  isbn = {0301-620X},
  journal = {The Bone \& Joint Journal},
  number = {7},
  pmid = {21705555}
}

@article{Rolfson2016,
  title = {Patient-Reported Outcome Measures in Arthroplasty Registries: {{Report}} of the {{Patient}}-{{Reported Outcome Measures Working Group}} of the {{International Society}} of {{Arthroplasty RegistriesPart II}}. {{Recommendations}} for Selection, Administration, and Analysis},
  author = {Rolfson, Ola and Bohm, Eric and Franklin, Patricia and Lyman, Stephen and Denissen, Geke and Dawson, Jill and Dunn, Jennifer and Chenok, Kate Eresian and Dunbar, Michael and Overgaard, S\o ren and Garellick, G{\"o}ran and L{\"u}bbeke, Anne},
  year = {2016},
  volume = {87},
  pages = {9--23},
  issn = {17453682},
  doi = {10.1080/17453674.2016.1181816},
  abstract = {- The International Society of Arthroplasty Registries (ISAR) Patient-Reported Outcome Measures (PROMs) Working Group have evaluated and recommended best practices in the selection, administration, and interpretation of PROMs for hip and knee arthroplasty registries. The 2 generic PROMs in common use are the Short Form health surveys (SF-36 or SF-12) and EuroQol 5-dimension (EQ-5D). The Working Group recommends that registries should choose specific PROMs that have been appropriately developed with good measurement properties for arthroplasty patients. The Working Group recommend the use of a 1-item pain question ("During the past 4 weeks, how would you describe the pain you usually have in your [right/left] [hip/knee]?"; response: none, very mild, mild, moderate, or severe) and a single-item satisfaction outcome ("How satisfied are you with your [right/left] [hip/knee] replacement?"; response: very unsatisfied, dissatisfied, neutral, satisfied, or very satisfied). Survey logistics include patient instructions, paper- and electronic-based data collection, reminders for follow-up, centralized as opposed to hospital-based follow-up, sample size, patient- or joint-specific evaluation, collection intervals, frequency of response, missing values, and factors in establishing a PROMs registry program. The Working Group recommends including age, sex, diagnosis at joint, general health status preoperatively, and joint pain and function score in case-mix adjustment models. Interpretation and statistical analysis should consider the absolute level of pain, function, and general health status as well as improvement, missing data, approaches to analysis and case-mix adjustment, minimal clinically important difference, and minimal detectable change. The Working Group recommends data collection immediately before and 1 year after surgery, a threshold of 60\% for acceptable frequency of response, documentation of non-responders, and documentation of incomplete or missing data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UGFU6B68\\rolfson_et_al_2016_patient-reported_outcome_measures_in_arthroplasty_registries.pdf},
  journal = {Acta Orthopaedica},
  number = {May},
  pmid = {27228230}
}

@article{Rolfson2018,
  title = {Svenska H\"oftprotesregistret},
  author = {Rolfson, Ola},
  year = {2018},
  pages = {24--27},
  journal = {Svenska Geriatrisk Tidskrift},
  keywords = {\#nosource}
}

@article{Romano1993,
  title = {Presentation Adapting a Clinical Comorbidity Index for Use with {{ICD}}-9-{{CM}} Administrative Data: {{Differing}} Perspectives},
  author = {Romano, Patrick S. and Roos, Leslie L. and Jollis, James G.},
  year = {1993},
  month = oct,
  volume = {46},
  pages = {1075--1079},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(93)90103-8},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VK7DPQS5\\romano_et_al_1993_presentation_adapting_a_clinical_comorbidity_index_for_use_with_icd-9-cm.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {10}
}

@article{Rose2019,
  title = {Limitations of P-Values and r-Squared for Stepwise Regression Building: {{A}} Fairness Demonstration in Health Policy Risk Adjustment},
  author = {Rose, Sherri and McGuire, Thomas G.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {152--156},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00031305.2018.1518269},
  abstract = {ABSTRACTStepwise regression building procedures are commonly used applied statistical tools, despite their well-known drawbacks. While many of their limitations have been widely discussed in the literature, other aspects of the use of individual statistical fit measures, especially in high-dimensional stepwise regression settings, have not. Giving primacy to individual fit, as is done with p-values and R2, when group fit may be the larger concern, can lead to misguided decision making. One of the most consequential uses of stepwise regression is in health care, where these tools allocate hundreds of billions of dollars to health plans enrolling individuals with different predicted health care costs. The main goal of this ``risk adjustment'' system is to convey incentives to health plans such that they provide health care services fairly, a component of which is not to discriminate in access or care for persons or groups likely to be expensive. We address some specific limitations of p-values and R2 for high...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F2LGG8CD\\rose_mcguire_2019_limitations_of_p-values_and_r-squared_for_stepwise_regression_building.pdf},
  journal = {The American Statistician},
  number = {sup1}
}

@article{Rosenbaum1983,
  title = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
  author = {Rosenbaum, P. R and Rubin, D. B},
  year = {1983},
  volume = {70},
  pages = {41--55},
  journal = {\{B\}iometrika},
  keywords = {\#nosource},
  number = {1}
}

@book{Rosenbaum2010,
  title = {Design of Observational Studies},
  author = {Rosenbaum, Paul R},
  year = {2010},
  isbn = {978-1-4419-0319-8},
  keywords = {\#nosource}
}

@article{Rosenbaum2015,
  title = {Two r Packages for Sensitivity Analysis in Observational Studies},
  author = {Rosenbaum, Paul},
  year = {2015},
  volume = {1},
  pages = {1--17},
  journal = {Observational Studies},
  keywords = {\#nosource,m -test,observational study,permutational t -test,randomization inference,sensitivity analysis}
}

@article{Rosengren2014,
  title = {The Annual Number of Hip Fractures in {{Sweden}} Will Double from Year 2002 to 2050},
  author = {Rosengren, Bj{\"o}rn E and Karlsson, Magnus K},
  year = {2014},
  volume = {85},
  pages = {234--237},
  issn = {1745-3674},
  doi = {10.3109/17453674.2014.916491},
  abstract = {BACKGROUND AND PURPOSE: The incidence and annual number of hip fractures have increased worldwide during the past 50 years, and projections have indicated a further increase. During the last decade, however, a down-turn in the incidence of hip fracture has been seen in the western world. We predicted the development of hip fractures in Sweden until the year 2050. METHODS: We reviewed surgical records for the period 2002-2012 in the city of Malm\"o, Sweden, and identified patients aged 50 years or more with a hip fracture. We estimated incidence rates by using official population figures as denominator and applied the rates to population projections each year until 2050. We also made projections based on our previously published nationwide Swedish hip fracture rates for the period 1987-2002. Since the projections are based on estimates, no confidence limits are given. RESULTS: During the period 2002-2012, there were 7,385 hip fractures in Malm\"o. Based on these data, we predicted that there would be approximately 30,000 hip fractures in Sweden in the year 2050. Use of nationwide rates for 2002 in the predictive model gave similar results, which correspond to an increase in the number of hip fractures by a factor of 1.9 (1.7 for women and 2.3 for men) compared to 2002. INTERPRETATION: The annual number of hip fractures will almost double during the first half of the century. Time trends in hip fractures and also changes in population size and age distribution should be continuously monitored, as such changes will influence the number of hip fractures in the future. Our results indicate that we must optimize preventive measures for hip fractures and prepare for major demands in resources.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LG2YWSAH\\rosengren_karlsson_2014_the_annual_number_of_hip_fractures_in_sweden_will_double_from_year_2002_to_2050.pdf},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {24786906}
}

@article{Rosengren2017,
  title = {Recent Hip Fracture Trends in {{Sweden}} and {{Denmark}} with Age-Period-Cohort Effects},
  author = {Rosengren, B. E. and Bj??rk, J. and Cooper, C. and Abrahamsen, B.},
  year = {2017},
  volume = {28},
  pages = {139--149},
  publisher = {{Osteoporosis International}},
  issn = {14332965},
  doi = {10.1007/s00198-016-3768-3},
  abstract = {This study used nationwide hip fracture data from Denmark and Sweden during 1987-2010 to examine effects of (birth) cohort and period. We found that time trends, cohort, and period effects were different in the two countries. Results also indicated that hip fracture rates may increase in the not so far future. INTRODUCTION The reasons for the downturn in hip fracture rates remain largely unclear but circumstances earlier in life seem important. METHODS We ascertained hip fractures in the populations {$\geq$}50 years in Denmark and Sweden in national discharge registers. Country- and sex-specific age-period-cohort (APC) effects during 1987-2010 were evaluated by log-likelihood estimates in Poisson regression models presented as incidence rate ratios (IRR). RESULTS There were 399,596 hip fractures in SE and 248,773 in DK. Age-standardized hip fracture rate was stable in SE men but decreased in SE women and in DK. Combined period + cohort effects were generally stronger in SE than DK and in women than men. IRR per period ranged from 1.05 to 1.30 in SE and 0.95 to 1.21 in DK. IRR per birth cohort ranged from 1.07 to 3.13 in SE and 0.77 to 1.67 in DK. Relative period effects decreased with successive period in SE and described a convex curve in DK. Relative cohort effects increased with successive birth cohort in both countries but with lower risks for DK women and men and SE women born around the 1930s (age 75-86 years today and responsible for most hip fractures) partly explaining the recent downturn. Men and women born thereafter however seem to have a higher hip fracture risk, and we expect a reversal of the present decline in rates, with increasing hip fracture rates in both Denmark and Sweden during the upcoming decade. CONCLUSIONS Time trends, cohort, and period effects were different in SE and DK. This may reflect differences in general health as evident in known differences in life expectancy, healthcare organization, and prevention such as use of anti-osteoporosis drugs. Analyses indicate that hip fracture rates may increase in the not so far future.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5JMNVTZK\\rosengren_et_al_2017_recent_hip_fracture_trends_in_sweden_and_denmark_with_age-period-cohort_effects.pdf},
  isbn = {0019801637},
  journal = {Osteoporosis International},
  keywords = {Age-period-cohort,Hip fracture,Men,Trends,Women},
  number = {1},
  pmid = {27647528}
}

@article{rossgentlemanLexicalScopeStatistical2000,
  title = {Lexical Scope and Statistical Computin},
  author = {Ross Gentleman, RobertIhaka},
  year = {2000},
  volume = {9},
  pages = {582--599},
  doi = {10.1198/1061860032238},
  abstract = {A simple method for providing mathematical annotation of plots produced with the R environment is described. Although the implementation is specific to R, a similar method could be used in any environment which uses an expression-based command interface and provides a basic quoting mechanism},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4DWBNX6D\\ross_gentleman_2000_lexical_scope_and_statistical_computin.pdf},
  isbn = {106186006X},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {equations,labels,typesetting},
  number = {3}
}

@article{Rothman2016,
  title = {Lessons Learned during 48 Years of Orthopedic Practice},
  author = {Rothman, Richard H.},
  year = {2016},
  volume = {31},
  pages = {2377--2379},
  publisher = {{Elsevier Ltd}},
  issn = {08835403},
  doi = {10.1016/j.arth.2016.05.036},
  abstract = {Among the many advantages of an organized and thoughtful civilization is the capacity to improve through reflection on past experiences. George Santayana, the famous Hispanic American philosopher, underlined the importance of his historical analysis of behavior with a frequently quoted observation: " Those who cannot remember the past are condemned to repeat it " [1]. At this juncture of my career, having enjoyed 48 years of academic orthopedic practice, I frequently reflect on the most important lessons that I have learned from my colleagues and my own personal experience. Had I learned only one lesson per year that would amount to 48 rules of behavior, an overwhelming compendium. I have learned even more than this of course, but I can distill from all of them the most important 5 as follows:},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CCKRZMB9\\rothman_2016_lessons_learned_during_48_years_of_orthopedic_practice.pdf},
  journal = {The Journal of Arthroplasty},
  number = {11}
}

@article{Roy2016,
  title = {Introduction to Data Science , r and Data Visualization},
  author = {Roy, Joseph and Gstat, Ph D},
  year = {2016},
  keywords = {\#nosource},
  number = {October}
}

@article{Royston2002,
  title = {Flexible Parametric Proportional-Hazards and Proportional-Odds Models for Censored Survival Data, with Application to Prognostic Modelling and Estimation of Treatment Effects},
  author = {Royston, Patrick and Parmar, Mahesh K.B.},
  year = {2002},
  volume = {21},
  pages = {2175--2197},
  issn = {02776715},
  doi = {10.1002/sim.1203},
  abstract = {Modelling of censored survival data is almost always done by Cox proportional-hazards regression. However, use of parametric models for such data may have some advantages. For example, non-proportional hazards, a potential difficulty with Cox models, may sometimes be handled in a simple way, and visualization of the hazard function is much easier. Extensions of the Weibull and log-logistic models are proposed in which natural cubic splines are used to smooth the baseline log cumulative hazard and log cumulative odds of failure functions. Further extensions to allow non-proportional effects of some or all of the covariates are introduced. A hypothesis test of the appropriateness of the scale chosen for covariate effects (such as of treatment) is proposed. The new models are applied to two data sets in cancer. The results throw interesting light on the behaviour of both the hazard function and the hazard ratio over time. The tools described here may be a step towards providing greater insight into the natural history of the disease and into possible underlying causes of clinical events. We illustrate these aspects by using the two examples in cancer. Copyright \textcopyright{} 2002 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NVEVKT7W\\royston_parmar_2002_flexible_parametric_proportional-hazards_and_proportional-odds_models_for.pdf},
  journal = {Statistics in Medicine},
  keywords = {Parametric models,Proportional hazards,Proportional odds,Splines,Survival analysis},
  number = {15}
}

@article{Royston2006,
  title = {Dichotomizing Continuous Predictors in Multiple Regression: A Bad Idea},
  author = {Royston, Patrick and Altman, Douglas G and Sauerbrei, Willi},
  year = {2006},
  volume = {25},
  pages = {127--141},
  doi = {10.1002/sim.2331},
  abstract = {SUMMARY In medical research, continuous variables are often converted into categorical variables by grouping values into two or more categories. We consider in detail issues pertaining to creating just two groups, a common approach in clinical research. We argue that the simplicity achieved is gained at a cost; dichotomization may create rather than avoid problems, notably a considerable loss of power and residual confounding. In addition, the use of a data-derived 'optimal' cutpoint leads to serious bias. We illustrate the impact of dichotomization of continuous predictor variables using as a detailed case study a randomized trial in primary biliary cirrhosis. Dichotomization of continuous data is unnecessary for statistical analysis and in particular should not be applied to explanatory variables in regression models.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NL9J7YD9\\royston_et_al_2006_dichotomizing_continuous_predictors_in_multiple_regression.pdf},
  journal = {STATISTICS IN MEDICINE Statist. Med}
}

@article{Royston2009,
  title = {Prognosis and Prognostic Research: {{Developing}} a Prognostic Model},
  author = {Royston, Patrick and Moons, Karel G M and Altman, Douglas G and Vergouwe, Yvonne},
  year = {2009},
  month = mar,
  volume = {338},
  abstract = {In the second article in their series, Patrick Royston and colleagues describe different approaches to building clinical prognostic modelsThe first article in this series reviewed why prognosis is important and how it is practised in different medical settings.1 We also highlighted the difference between multivariable models used in aetiological research and those used in prognostic research and outlined the design characteristics for studies developing a prognostic model. In this article we focus on developing a multivariable prognostic model. We illustrate the statistical issues using a logistic regression model to predict the risk of a specific event. The principles largely apply to all multivariable regression methods, including models for continuous outcomes and for time to event outcomes.Summary pointsModels with multiple variables can be developed to give accurate and discriminating predictions In clinical practice simpler models are more practicable There is no consensus on the ideal method for developing a modelMethods to develop simple, interpretable models are described and comparedThe goal is to construct an accurate and discriminating prediction model from multiple variables. Models may be a complicated function of the predictors, as in weather forecasting, but in clinical applications considerations of practicality and face validity usually suggest a simple, interpretable model (as in box 1).Box 1 Example of a prognostic modelRisk score from a logistic regression model to predict the risk of postoperative nausea or vomiting (PONV) within the first 24 hours after surgery2:Risk score= -2.28+(1.27\texttimes female sex)+(0.65\texttimes history of PONV or motion sickness)+(0.72\texttimes non-smoking)+(0.78\texttimes postoperative opioid use)where all variables are coded 0 for no or 1 for yes.The value -2.28 is called the intercept and the other numbers are the estimated regression coefficients for the predictors, which indicate their mutually adjusted relative contribution to the outcome risk. The regression coefficients are log(odds ratios) for a change of 1 unit in \ldots},
  journal = {BMJ: British Medical Journal},
  keywords = {\#nosource}
}

@article{Royston2011,
  title = {The Use of Restricted Mean Survival Time to Estimate the Treatment Effect in Randomized Clinical Trials When the Proportional Hazards Assumption Is in Doubt},
  author = {Royston, Patrick and Parmar, Mahesh K B},
  year = {2011},
  volume = {30},
  pages = {2409--2421},
  issn = {02776715},
  doi = {10.1002/sim.4274},
  abstract = {In most randomized clinical trials (RCTs) with a right-censored time-to-event outcome, the hazard ratio is taken as an appropriate measure of the effectiveness of a new treatment compared with a standard-of-care or control treatment. However, it has long been known that the hazard ratio is valid only under the proportional hazards (PH) assumption. This assumption is formally checked only rarely. Some recent trials, particularly the IPASS trial in lung cancer and the ICON7 trial in ovarian cancer, have alerted researchers to the possibility of gross non-PH, raising the critical question of how such data should be analyzed. Here, we propose the use of the restricted mean survival time at a prespecified, fixed time point as a useful general measure to report the difference between two survival curves. We describe different methods of estimating it and we illustrate its application to three RCTs in cancer. The examples are graded from a trial in kidney cancer in which there is no evidence of non-PH, to IPASS, where the opposite is clearly the case. We propose a simple, general scheme for the analysis of data from such RCTs. Key elements of our approach are Andersen's method of 'pseudo-observations,' which is based on the Kaplan-Meier estimate of the survival function, and Royston and Parmar's class of flexible parametric survival models, which may be used for analyzing data in the presence or in the absence of PH of the treatment effect.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LU4DTRF3\\royston_parmar_2011_the_use_of_restricted_mean_survival_time_to_estimate_the_treatment_effect_in.pdf},
  journal = {Statistics in Medicine},
  keywords = {Flexible parametric survival models,Hazard ratio,Non-proportional hazards,Randomized controlled trials,Restricted mean survival time,Time-to-event data},
  number = {19}
}

@article{Royston2013,
  title = {Restricted Mean Survival Time: {{An}} Alternative to the Hazard Ratio for the Design and Analysis of Randomized Trials with a Time-to-Event Outcome},
  author = {Royston, Patrick and Parmar, Mahesh K.B.},
  year = {2013},
  volume = {13},
  issn = {14712288},
  doi = {10.1186/1471-2288-13-152},
  abstract = {BACKGROUND: Designs and analyses of clinical trials with a time-to-event outcome almost invariably rely on the hazard ratio to estimate the treatment effect and implicitly, therefore, on the proportional hazards assumption. However, the results of some recent trials indicate that there is no guarantee that the assumption will hold. Here, we describe the use of the restricted mean survival time as a possible alternative tool in the design and analysis of these trials.: The restricted mean is a measure of average survival from time 0 to a specified time point, and may be estimated as the area under the survival curve up to that point. We consider the design of such trials according to a wide range of possible survival distributions in the control and research arm(s). The distributions are conveniently defined as piecewise exponential distributions and can be specified through piecewise constant hazards and time-fixed or time-dependent hazard ratios. Such designs can embody proportional or non-proportional hazards of the treatment effect.: We demonstrate the use of restricted mean survival time and a test of the difference in restricted means as an alternative measure of treatment effect. We support the approach through the results of simulation studies and in real examples from several cancer trials. We illustrate the required sample size under proportional and non-proportional hazards, also the significance level and power of the proposed test. Values are compared with those from the standard approach which utilizes the logrank test.: We conclude that the hazard ratio cannot be recommended as a general measure of the treatment effect in a randomized controlled trial, nor is it always appropriate when designing a trial. Restricted mean survival time may provide a practical way forward and deserves greater attention.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RDJVMGMM\\royston_parmar_2013_restricted_mean_survival_time.pdf},
  journal = {BMC Medical Research Methodology},
  keywords = {Hazard ratio,Logrank test,Non-proportional hazards,Piecewise exponential distribution,Randomized controlled trials,Restricted mean survival time,Time-to-event data},
  number = {1}
}

@article{Ruben1966,
  title = {Some New Results on the Coefficient of the Sample Correlation Distribution},
  author = {Ruben, Harold},
  year = {1966},
  volume = {28},
  pages = {513--525},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
  keywords = {\#nosource},
  number = {3}
}

@article{Runge2017,
  title = {The Limit Imbalanced Logistic Regression by Binary Predictors and Its Fast Lasso Computation},
  author = {Runge, Vincent},
  year = {2017},
  abstract = {In this work, we introduce a modified (rescaled) likelihood for imbalanced logistic regression. This new approach makes easier the use of exponential priors and the computation of lasso regularization path. Precisely, we study a limiting behavior for which class imbalance is artificially increased by replication of the majority class observations. If some strong overlap conditions are satisfied, the maximum likelihood estimate converges towards a finite value close to the initial one (intercept excluded) as shown by simulations with binary predictors. This solution corresponds to the extremum of a strictly concave function that we refer to as "rescaled" likelihood. In this context, the use of exponential priors has a clear interpretation as a shift on the predictor means for the minority class. Thanks to the simple binary structure, some random designs give analytic path estimators for the lasso regularization problem. An effective approximate path algorithm by piecewise logarithmic functions based on matrix inversions is also presented. This work was motivated by its potential application to spontaneous reports databases in a pharmacovigilance context.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R577L69E\\runge_2017_the_limit_imbalanced_logistic_regression_by_binary_predictors_and_its_fast.pdf},
  keywords = {49M29,62F12,62F15,62P10,limit class imbalance,path estimator,pharamacovigilance model,piecewise logarithmic approxi-mate path,rescaled likelihood,secondary 34E05,spontaneous reports database,square exact solution MS classification : Primary}
}

@article{Rysinska2018,
  title = {Aseptic Loosening after Total Hip Arthroplasty and the Risk of Cardiovascular Disease: {{A}} Nested Case-Control Study},
  author = {Rysinska, Agata and Sk{\"o}ldenberg, Olof and Garland, Anne and Rolfson, Ola and Aspberg, Sara and Eisler, Thomas and Garellick, G{\"o}ran and Stark, Andreas and Hailer, Nils and Gordon, Max},
  year = {2018},
  issn = {19326203},
  doi = {10.1371/journal.pone.0204391},
  abstract = {BACKGROUND Patients with surgically treated osteoarthritis of the hip have an increased risk of cardiovascular morbidity and mortality many years after the operation compared with controls. Our hypothesis is that this increased risk after total hip arthroplasty (THA) is mediated by development of periprosthetic osteolysis leading to aseptic loosening of the implant. METHODS We conducted a nation-wide, nested, case-control study consisting of patients receiving a cemented THA due to osteoarthritis between the years 1992 and 2005. Our study population included a total of 14,430 subjects identified in the Swedish hip arthroplasty register and linked to the Swedish National Patient Register. The case group consisted of patients (n = 2,886) who underwent reoperation of the treated hip due to osteolysis or aseptic loosening at any time within five years after the index surgery. Each case was matched with four controls (n = 11,544) who had not undergone reoperation. The main outcomes were cardiovascular events i.e. myocardial infarction, heart failure and cerebral infarction according to ICD-codes and time to the first cardiovascular event during the exposure period. Outcomes were subgrouped into cardiac and cerebral events. We used regression models to calculate the incidence rates and adjusted our results for confounders. FINDINGS Overall, 5.1\% of patients had cardiac events, with slightly more overall cardiovascular events occurring in the control group (8.1\% vs. 6.7\%, odds ratio 0.8, 95\% confidence interval (CI) 0.7 to 1.0). After adjusting for confounders, the case group had an increased relative risk of 1.3 (95\% confidence interval (CI) 1.1 to 1.3) for total number of cardiovascular events. Similar effect sizes were observed for time to first event. INTERPRETATION Patients with osteoarthritis who received THA and subsequently underwent a revision operation due to loosening had a higher relative risk of developing cardiovascular events than controls. Thus there is an association which could be explained by a common inflammatory disease pathway that requires further experimental research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HDCGQIL2\\rysinska_et_al_2018_aseptic_loosening_after_total_hip_arthroplasty_and_the_risk_of_cardiovascular.pdf},
  journal = {PLoS ONE},
  pmid = {30427844}
}

@article{Saha-Chaudhuri2013,
  title = {Non-Parametric Estimation of a Time-Dependent Predictive Accuracy Curve.},
  author = {{Saha-Chaudhuri}, P and Heagerty, P J},
  year = {2013},
  month = jan,
  volume = {14},
  pages = {42--59},
  publisher = {{Oxford University Press}},
  issn = {1468-4357},
  doi = {10.1093/biostatistics/kxs021},
  abstract = {A major biomedical goal associated with evaluating a candidate biomarker or developing a predictive model score for event-time outcomes is to accurately distinguish between incident cases from the controls surviving beyond t throughout the entire study period. Extensions of standard binary classification measures like time-dependent sensitivity, specificity, and receiver operating characteristic (ROC) curves have been developed in this context (Heagerty, P. J., and others, 2000. Time-dependent ROC curves for censored survival data and a diagnostic marker. Biometrics 56, 337-344). We propose a direct, non-parametric method to estimate the time-dependent Area under the curve (AUC) which we refer to as the weighted mean rank (WMR) estimator. The proposed estimator performs well relative to the semi-parametric AUC curve estimator of Heagerty and Zheng (2005. Survival model predictive accuracy and ROC curves. Biometrics 61, 92-105). We establish the asymptotic properties of the proposed estimator and show that the accuracy of markers can be compared very simply using the difference in the WMR statistics. Estimators of pointwise standard errors are provided.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\E6PXG3K6\\saha-chaudhuri_heagerty_2013_non-parametric_estimation_of_a_time-dependent_predictive_accuracy_curve.pdf},
  journal = {Biostatistics (Oxford, England)},
  number = {1},
  pmid = {22734044}
}

@article{Saito2017,
  title = {Precrec: Fast and Accurate Precision\textendash Recall and {{ROC}} Curve Calculations in {{R}}},
  author = {Saito, Takaya and Rehmsmeier, Marc},
  year = {2017},
  month = jan,
  volume = {33},
  pages = {145--147},
  publisher = {{Oxford University Press}},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btw570},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MK35UMQL\\saito_rehmsmeier_2017_precrec.pdf},
  journal = {Bioinformatics},
  number = {1}
}

@article{Saklad1941,
  title = {Grading of Patients for Surgical Procedures},
  author = {Saklad, M},
  year = {1941},
  volume = {2},
  pages = {281--284},
  journal = {Anesthesiology},
  keywords = {\#nosource}
}

@book{Salsburg2001,
  title = {The Lady Tasting Tea},
  author = {Salsburg, David},
  year = {2001},
  isbn = {0-7167-4106-7},
  keywords = {\#nosource}
}

@article{Sandin2008,
  title = {Analyzing and Modeling the Relative Survival Rate of Patients Diagnosed with Malignant Melanoma},
  author = {Sandin, Fredrik},
  year = {2008},
  keywords = {\#nosource}
}

@article{Sauerbrei1999,
  title = {The Use of Resampling Methods to Simplify Regression Models in Medical Statistics},
  author = {Sauerbrei, Willi},
  year = {1999},
  month = aug,
  volume = {48},
  pages = {313--329},
  publisher = {{John Wiley \& Sons, Ltd (10.1111)}},
  issn = {0035-9254},
  doi = {10.1111/1467-9876.00155},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\C9XNXGAV\\sauerbrei_1999_the_use_of_resampling_methods_to_simplify_regression_models_in_medical.pdf},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  keywords = {Backward elimination,Bootstrap,Cross‐validation,Model complexity,Prediction,Selection bias,Selection level},
  number = {3}
}

@article{Sauerbrei2007,
  title = {Selection of Important Variables and Determination of Functional Form for Continuous Predictors in Multivariable Model Building},
  author = {Sauerbrei, Willi and Royston, Patrick and Binder, Harald},
  year = {2007},
  pages = {5512--5528},
  doi = {10.1002/sim},
  keywords = {\#nosource,fractional polynomials,functional form,regression models,splines,variable selection},
  number = {October}
}

@article{Sayed-Noor2019,
  title = {Body Mass Index Is Associated with Risk of Reoperation and Revision after Primary Total Hip Arthroplasty: A Study of the {{Swedish Hip Arthroplasty Register}} Including 83,146 Patients},
  shorttitle = {Body Mass Index Is Associated with Risk of Reoperation and Revision after Primary Total Hip Arthroplasty},
  author = {{Sayed-Noor}, Arkan S and Mukka, Sebastian and Mohaddes, Maziar and K{\"a}rrholm, Johan and Rolfson, Ola},
  year = {2019},
  month = may,
  volume = {90},
  pages = {220--225},
  issn = {1745-3674, 1745-3682},
  doi = {10.1080/17453674.2019.1594015},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TUH9MXT9\\Sayed-Noor m. fl. - 2019 - Body mass index is associated with risk of reopera.pdf},
  journal = {Acta Orthopaedica},
  language = {en},
  number = {3}
}

@article{Sayers2016,
  title = {Probabilistic Record Linkage},
  author = {Sayers, Adrian and {Ben-Shlomo}, Yoav and Blom, Ashley W and Steele, Fiona},
  year = {2016},
  month = jun,
  volume = {45},
  pages = {954--964},
  publisher = {{Oxford University Press}},
  issn = {0300-5771},
  doi = {10.1093/ije/dyv322},
  abstract = {Studies involving the use of probabilistic record linkage are becoming increasingly common. However, the methods underpinning probabilistic record linkage are not widely taught or understood, and therefore these studies can appear to be a `black box' research tool. In this article, we aim to describe the process of probabilistic record linkage through a simple exemplar. We first introduce the concept of deterministic linkage and contrast this with probabilistic linkage. We illustrate each step of the process using a simple exemplar and describe the data structure required to perform a probabilistic linkage. We describe the process of calculating and interpreting matched weights and how to convert matched weights into posterior probabilities of a match using Bayes theorem. We conclude this article with a brief discussion of some of the computational demands of record linkage, how you might assess the quality of your linkage algorithm, and how epidemiologists can maximize the value of their record-linked research using robust record linkage methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VLRXINUF\\sayers_et_al_2016_probabilistic_record_linkage.pdf},
  journal = {International Journal of Epidemiology},
  keywords = {Bias,Data linkage,Epidemiological methods,Medical record linkage,Record linkage},
  number = {3}
}

@article{Sayers2018,
  title = {Are Competing Risks Models Appropriate to Describe Implant Failure?},
  author = {Sayers, Adrian and Evans, Jonathan T. and Whitehouse, Michael R. and Blom, Ashley W.},
  year = {2018},
  volume = {89},
  pages = {256--258},
  issn = {17453682},
  doi = {10.1080/17453674.2018.1444876},
  abstract = {\textcopyright{} 2018 The Author(s). Published by Taylor \& Francis on behalf of the Nordic Orthopedic Federation. Background and purpose \textemdash{} The use of competing risks models is widely advocated in the arthroplasty literature due to a perceived bias in comparison of simple Kaplan\textendash Meier estimates. Proponents of competing risk models in the arthroplasty literature appear to be unaware of the subtle but important differences in interpretation of net and crude failure estimated by competing risk and Kaplan\textendash Meier methods respectively. Methods \textemdash{} Using a simple simulation we illustrate the differences between competing risks and Kaplan\textendash Meier methods. Results \textemdash{} Competing risk and Kaplan\textendash Meier methods estimate different survival quantities, i.e., crude and net failure respectively. Estimates of crude failure estimated using competing risk methods will be less than net failure as estimated using Kaplan\textendash Meier methods. Interpretation \textemdash{} Kaplan\textendash Meier methods are appropriate for describing implant failure, whereas crude survival estimated using competing risk methods estimates the risk of surgical revision as it depends on both implant failure and mortality. Both competing risk models and Kaplan\textendash Meier methods are useful in arthroplasty, and both provide unbiased estimates of crude and net failure in the absence of any confounding or selection respectively. Surgeons and researchers should carefully consider whether the use of competing risks is always justified. Lower estimates of failure from competing risk models may be misleading to surgeons who are attempting to select the best implants with the lowest failure rates for their patients.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UIZ6PY8P\\sayers_et_al_2018_are_competing_risks_models_appropriate_to_describe_implant_failure.pdf},
  journal = {Acta Orthopaedica},
  number = {3},
  pmid = {29521152}
}

@techreport{SBU2003,
  title = {Str\aa lbehandling Vid Cancer: {{En}} Systematisk Litteratur\"oversikt},
  author = {{SBU}},
  year = {2003},
  keywords = {\#nosource}
}

@book{SBU2016,
  title = {V\"ardering Av Effektivitet i Klinisk Vardag {{Statistiska}} Strategier F\"or Att Hantera Skillnader i Behandlingseffektivitet Mellan Randomiserade Kliniska Pr\"ovningar Och Praktik},
  author = {{SBU}},
  year = {2016},
  isbn = {978-91-85413-99-7},
  keywords = {\#nosource}
}

@article{Scarlat2018,
  title = {Quality of Publications in ``{{International Orthopaedics}}'' and Projects for the near Future},
  author = {Scarlat, Marius M.},
  year = {2018},
  pages = {1--2},
  issn = {0341-2695},
  doi = {10.1007/s00264-018-4244-9},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B736XLPP\\scarlat_2018_quality_of_publications_in_“international_orthopaedics”_and_projects_for_the.pdf},
  journal = {International Orthopaedics}
}

@article{Schall2012,
  title = {The Empirical Coverage of Confidence Intervals: {{Point}} Estimates and Confidence Intervals for Confidence Levels},
  author = {Schall, Robert},
  year = {2012},
  volume = {54},
  pages = {537--551},
  issn = {03233847},
  doi = {10.1002/bimj.201100134},
  abstract = {Many confidence intervals calculated in practice are potentially not exact, either because the requirements for the interval estimator to be exact are known to be violated, or because the (exact) distribution of the data is unknown. If a confidence interval is approximate, the crucial question is how well its true coverage probability approximates its intended coverage probability. In this paper we propose to use the bootstrap to calculate an empirical estimate for the (true) coverage probability of a confidence interval. In the first instance, the empirical coverage can be used to assess whether a given type of confidence interval is adequate for the data at hand. More generally, when planning the statistical analysis of future trials based on existing data pools, the empirical coverage can be used to study the coverage properties of confidence intervals as a function of type of data, sample size, and analysis scale, and thus inform the statistical analysis plan for the future trial. In this sense, the paper proposes an alternative to the problematic pretest of the data for normality, followed by selection of the analysis method based on the results of the pretest. We apply the methodology to a data pool of bioequivalence studies, and in the selection of covariance patterns for repeated measures data. \textcopyright{} 2012 Wiley-VCH Verlag GmbH \& Co. KGaA, Weinheim.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GNNLBKQX\\schall_2012_the_empirical_coverage_of_confidence_intervals.pdf},
  isbn = {2751444202},
  journal = {Biometrical Journal},
  keywords = {Bootstrap,Confidence interval,Coverage probability,Normality tests},
  number = {4}
}

@article{Schemper1996,
  title = {A Note on Quantifying Follow-up in Studies of Failure Time},
  author = {Schemper, Michael and Smith, Terry L},
  year = {1996},
  volume = {17},
  pages = {343--346},
  doi = {8889347},
  journal = {Controlled clinical trials},
  keywords = {\#nosource}
}

@article{Schijven2010,
  title = {Transatlantic Comparison of the Competence of Surgeons at the Start of Their Professional Career},
  author = {Schijven, M. P. and Reznick, R. K. and {ten Cate}, O. Th. J. and Grantcharov, T. P. and Regehr, G. and Satterthwaite, L. and Thijssen, A. S. and MacRae, H. M.},
  year = {2010},
  month = mar,
  volume = {97},
  pages = {443--449},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {00071323},
  doi = {10.1002/bjs.6858},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZIW9R2RV\\schijven_et_al_2010_transatlantic_comparison_of_the_competence_of_surgeons_at_the_start_of_their.pdf},
  journal = {British Journal of Surgery},
  number = {3}
}

@article{Schilcher2011,
  title = {Bisphosphonate Use and Atypical Fractures of the Femoral Shaft},
  author = {Schilcher, J{\"o}rg and Micha{\"e}lsson, Karl and Aspenberg, Per},
  year = {2011},
  month = may,
  volume = {364},
  pages = {1728--1737},
  publisher = {{Massachusetts Medical Society}},
  doi = {10.1056/NEJMoa1010650},
  abstract = {Background Studies show conflicting results regarding the possible excess risk of atypical fractures of the femoral shaft associated with bisphosphonate use. Methods In Sweden, 12,777 women 55 year...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Q42FZGGE\\schilcher_et_al_2011_bisphosphonate_use_and_atypical_fractures_of_the_femoral_shaft.pdf},
  journal = {New England Journal of Medicine},
  number = {18}
}

@article{Schmidt2008,
  ids = {Yalcin2014},
  title = {When to Use the Odds Ratio or the Relative Risk?},
  author = {Schmidt, Carsten Oliver and Kohlmann, Thomas},
  year = {2008},
  volume = {53},
  pages = {165--167},
  doi = {10.1007/s000},
  isbn = {0003800870019},
  journal = {International Journal of Public Health},
  keywords = {\#nosource},
  number = {Februry}
}

@inproceedings{Schmidt2009,
  title = {Bayesian Non-Negative Matrix Factorization},
  author = {Schmidt, Mikkel N. and Winther, Ole and Hansen, Lars Kai},
  year = {2009},
  pages = {540--547},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-00599-2_68},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\YXIZQFPP\\schmidt_et_al_2009_bayesian_non-negative_matrix_factorization.pdf}
}

@generic{Schmidt2014,
  title = {The Danish Civil Registration System as a Tool in Epidemiology},
  author = {Schmidt, Morten and Pedersen, Lars and S\o rensen, Henrik Toft},
  year = {2014},
  volume = {29},
  pages = {541--549},
  issn = {15737284},
  doi = {10.1007/s10654-014-9930-3},
  abstract = {The methodological advances in epidemiology have facilitated the use of the Danish Civil Registration System (CRS) in ways not previously described systematically. We reviewed the CRS and its use as a research tool in epidemiology. We obtained information from the Danish Law on Civil Registration and the Central Office of Civil Registration, and used existing literature to provide illustrative examples of its use. The CRS is an administrative register established on April 2, 1968. It contains individual-level information on all persons residing in Denmark (and Greenland as of May 1, 1972). By January 2014, the CRS had cumulatively registered 9.5 million individuals and more than 400 million person-years of follow-up. A unique ten-digit Civil Personal Register number assigned to all persons in the CRS allows for technically easy, cost-effective, and unambiguous individual-level record linkage of Danish registers. Daily updated information on migration and vital status allows for nationwide cohort studies with virtually complete long-term follow-up on emigration and death. The CRS facilitates sampling of general population comparison cohorts, controls in case-control studies, family cohorts, and target groups in population surveys. The data in the CRS are virtually complete, have high accuracy, and can be retrieved for research purposes while protecting the anonymity of Danish residents. In conclusion, the CRS is a key tool for epidemiological research in Denmark. \textcopyright{} Springer Science+Business Media 2014.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6EUZP7Z7\\schmidt_et_al_2014_the_danish_civil_registration_system_as_a_tool_in_epidemiology.pdf},
  journal = {European Journal of Epidemiology},
  number = {8}
}

@book{Schmoor2013,
  title = {Competing Risks and Multistate Models},
  author = {Schmoor, Claudia and Schumacher, Martin and Finke, J{\"u}rgen and Beyersmann, Jan},
  year = {2013},
  volume = {19},
  issn = {10780432},
  doi = {10.1158/1078-0432.CCR-12-1619},
  abstract = {Instructional Book for using R for programming},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4P66X4GD\\schmoor_et_al_2013_competing_risks_and_multistate_models.pdf},
  isbn = {978-0-387-78170-9},
  pmid = {22057480}
}

@article{Schneeweiss2006,
  title = {Sensitivity Analysis and External Adjustment for Unmeasured Confounders in Epidemiologic Database Studies of Therapeutics},
  author = {Schneeweiss, Sebastian},
  year = {2006},
  volume = {15},
  pages = {291--303},
  issn = {10538569},
  doi = {10.1002/pds.1200},
  abstract = {Background: Large health care utilization databases are frequently used to analyze unintended effects of prescription drugs and biologics. Confounders that require detailed information on clinical parameters, lifestyle, or over-the-counter medications are often not measured in such datasets, causing residual confounding bias. Objective: This paper provides a systematic approach to sensitivity analyses to investigate the impact of residual confounding in pharmacoepidemiologic studies that use health care utilization databases. Methods: Four basic approaches to sensitivity analysis were identified: (1) sensitivity analyses based on an array of informed assumptions; (2) analyses to identify the strength of residual confounding that would be necessary to explain an observed drug-outcome association; (3) external adjustment of a drug-outcome association given additional information on single binary confounders from survey data using algebraic solutions; (4) external adjustment considering the joint distribution of multiple confounders of any distribution from external sources of information using propensity score calibration. Conclusion: Sensitivity analyses and external adjustments can improve our understanding of the effects of drugs and biologics in epidemiologic database studies. With the availability of easy-to-apply techniques, sensitivity analyses should be used more frequently, substituting qualitative discussions of residual confounding. Copyright \textcopyright 2006 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3LU8TNNT\\schneeweiss_2006_sensitivity_analysis_and_external_adjustment_for_unmeasured_confounders_in.pdf},
  isbn = {1053-8569 (Print)1053-8569 (Linking)},
  journal = {Pharmacoepidemiology and Drug Safety},
  keywords = {Bias,Claims databases,Confounding,Epidemiologic methods,Pharmacoepidemiology,Sensitivity analysis},
  number = {5},
  pmid = {16447304}
}

@article{Schoenfeld1980,
  title = {Chi-Squared Goodness-of-Fit Tests for the Proportional Hazards Regression Model},
  author = {Schoenfeld, David},
  year = {1980},
  month = jan,
  volume = {67},
  pages = {145--153},
  publisher = {{Oxford University Press}},
  issn = {0006-3444},
  doi = {10.1093/biomet/67.1.145},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B9HRTDFR\\schoenfeld_1980_chi-squared_goodness-of-fit_tests_for_the_proportional_hazards_regression_model.pdf},
  journal = {Biometrik},
  number = {1}
}

@article{Schoenfeld1982,
  title = {Partial Residuals for the Proportionnal Hazards Regression Model},
  author = {Schoenfeld, David},
  year = {1982},
  volume = {69},
  pages = {239--241},
  issn = {00063444},
  abstract = {Residuals are defined for the proportional hazards regression model introduced by Cox (1972). These residuals can be plotted against time to test the proportional hazards assumption. Histograms of these residuals can be used to examine fit and detect outlying covariate values},
  journal = {Biometrika},
  keywords = {\#nosource,Regression,Time},
  number = {1}
}

@article{Schoenfeld1982,
  title = {Partial Residuals for the Proportional Hazards Regression Model},
  author = {Schoenfeld, David},
  year = {1982},
  volume = {69},
  pages = {239--241},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {1}
}

@article{schonbrodtWhatSampleSize2013,
  title = {At What Sample Size Do Correlations Stabilize?},
  author = {Sch{\"o}nbrodt, Felix D. and Perugini, Marco},
  year = {2013},
  month = oct,
  volume = {47},
  pages = {609--612},
  issn = {00926566},
  doi = {10.1016/j.jrp.2013.05.009},
  abstract = {Sample correlations converge to the population value with increasing sample size, but the estimates are often inaccurate in small samples. In this report we use Monte-Carlo simulations to determine the critical sample size from which on the magnitude of a correlation can be expected to be stable. The necessary sample size to achieve stable estimates for correlations depends on the effect size, the width of the corridor of stability (i.e., a corridor around the true value where deviations are tolerated), and the requested confidence that the trajectory does not leave this corridor any more. Results indicate that in typical scenarios the sample size should approach 250 for stable estimates.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DSIYDJ2A\\schönbrodt_perugini_2013_at_what_sample_size_do_correlations_stabilize.pdf},
  isbn = {00926566},
  journal = {Journal of Research in Personality},
  keywords = {Accuracy,Correlation,Sample size,Simulation},
  number = {5}
}

@article{Schulman2008,
  title = {How to Interpret Your Dot: {{Decoding}} the Message of Clinical Performance Indicators},
  author = {Schulman, J. and Spiegelhalter, D. J. and Parry, G.},
  year = {2008},
  volume = {28},
  pages = {588--596},
  issn = {07438346},
  doi = {10.1038/jp.2008.67},
  abstract = {Comparative performance reports continue to proliferate, so it is increasingly important that healthcare workers can interpret the graphically displayed results correctly. This article acquaints readers with key concepts for thinking clearly and critically about such displays: (1) articulating the question a display answers, along with reflecting on questions the display might appear to, but does not, answer; (2) establishing that provider comparisons are made fairly, ever mindful of methodological assumptions and limitations; (3) accounting for systematic differences among performers that are unexplained by specified predictors, that is, random effect methods that yield 'shrunken' estimates; (4) understanding funnel plots used to summarize complex analyses and how one may vary the interrogative focus so that 'outlier' values most likely signal extraordinary performance. Finally, these concepts are given broader context in a view of the ultimate aim of the evaluative enterprise.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PVZKMKS5\\schulman_et_al_2008_how_to_interpret_your_dot.pdf},
  isbn = {1476-5543 (Electronic) 0743-8346 (Linking)},
  journal = {Journal of Perinatology},
  keywords = {benchmarking,quality measurement,risk adjustment},
  number = {9},
  pmid = {18633418}
}

@article{Schuster2016,
  title = {Propensity Score Model Overfitting Led to Inflated Variance of Estimated Odds Ratios},
  author = {Schuster, Tibor and Lowe, Wilfrid Kouokam and Platt, Robert W.},
  year = {2016},
  month = dec,
  volume = {80},
  pages = {97--106},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/J.JCLINEPI.2016.05.017},
  abstract = {OBJECTIVE Simulation studies suggest that the ratio of the number of events to the number of estimated parameters in a logistic regression model should be not less than 10 or 20 to 1 to achieve reliable effect estimates. Applications of propensity score approaches for confounding control in practice, however, do often not consider these recommendations. STUDY DESIGN AND SETTING We conducted extensive Monte Carlo and plasmode simulation studies to investigate the impact of propensity score model overfitting on the performance in estimating conditional and marginal odds ratios using different established propensity score inference approaches. We assessed estimate accuracy and precision as well as associated type I error and type II error rates in testing the null hypothesis of no exposure effect. RESULTS For all inference approaches considered, our simulation study revealed considerably inflated standard errors of effect estimates when using overfitted propensity score models. Overfitting did not considerably affect type I error rates for most inference approaches. However, because of residual confounding, estimation performance and type I error probabilities were unsatisfactory when using propensity score quintile adjustment. CONCLUSION Overfitting of propensity score models should be avoided to obtain reliable estimates of treatment or exposure effects in individual studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IDMX2565\\schuster_et_al_2016_propensity_score_model_overfitting_led_to_inflated_variance_of_estimated_odds.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@article{Schwartsmann2015,
  title = {Correlation between Patient Age at Total Hip Replacement Surgery and Lifeexpectancy},
  author = {Schwartsmann, Carlos Roberto and {de Freitas Spinelli}, Leandro and Boschin, Leonardo Carbonera and Y{\'e}pez, Anthony Kerbes and Crestani, Marcus Vinicius and Silva, Marcelo Faria and Schwartsmann1, Carlos Roberto and {de Freitas Spinelli}, Leandro and Boschin, Leonardo Carbonera and Y{\'e}pez, Anthony Kerbes and Crestani, Marcus Vinicius and Silva, Marcelo Faria},
  year = {2015},
  month = dec,
  volume = {23},
  pages = {323--325},
  publisher = {{Sociedade Brasileira de Ortopedia e Traumatologia}},
  issn = {1413-7852},
  doi = {10.1590/1413-785220152306148609},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DA45VUEZ\\schwartsmann_et_al_2015_correlation_between_patient_age_at_total_hip_replacement_surgery_and.pdf},
  journal = {Acta Ortop\'edica Brasileira},
  number = {6}
}

@article{Scrucca2010,
  title = {Regression Modeling of Competing Risk Using {{R}}: {{An}} in Depth Guide for Clinicians},
  author = {Scrucca, L. and Santucci, A. and Aversa, F.},
  year = {2010},
  volume = {45},
  pages = {1388--1395},
  publisher = {{Nature Publishing Group}},
  issn = {02683369},
  doi = {10.1038/bmt.2009.359},
  abstract = {We describe how to conduct a regression analysis for competing risks data. The use of an add-on package for the R statistical software is described, which allows for the estimation of the semiparametric proportional hazards model for the subdistribution of a competing risk analysis as proposed by Fine and Gray. \textcopyright{} 2010 Macmillan Publishers Limited All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3XJZTAX5\\scrucca_et_al_2010_regression_modeling_of_competing_risk_using_r.pdf},
  journal = {Bone Marrow Transplantation},
  keywords = {HSCT recipients,instructions for use,model selection,R statistical software,regression model for competing risk analysis,sample data base},
  number = {9}
}

@article{seanEffectCorrelationCoefficient2005,
  title = {The Effect of Correlation Coefficient among Multiple Input Vectors on the Efficiency Mean in Data Envelopment Analysis},
  author = {Sean, R. Farzipoor and Memariani, A. and Lotfi, F. Hosseinzadeh},
  year = {2005},
  volume = {162},
  pages = {503--521},
  issn = {00963003},
  doi = {10.1016/j.amc.2003.12.117},
  abstract = {In some of the papers on data envelopment analysis (DEA), there have been explained that if correlation coefficient between each pair of input (output) vectors is strong and positive, one of the input (output) vector could be omitted. The objective of this paper is to determine correlation coefficient threshold that beyond which omission of one or more input vectors have no statistically significant effect on the efficiency mean. The threshold identification in terms of some of the DEA models including CCR, CCRCSW, BCC and BCCCSW are performed. To analyze the data, analysis of variance (ANOVA) is used. \textcopyright{} 2004 Published by Elsevier Inc.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GX9LCU93\\sean_et_al_2005_the_effect_of_correlation_coefficient_among_multiple_input_vectors_on_the.pdf},
  isbn = {0096-3003},
  journal = {Applied Mathematics and Computation},
  keywords = {Analysis of variance,Correlation coefficient,Data envelopment analysis},
  number = {2}
}

@article{Sebaaly2015,
  title = {Aneurysmal Bone Cyst of the Cervical Spine in Children},
  author = {Sebaaly, Amer and Ghostine, Bachir and Kreichati, Gaby and Mallet, Jean F. and Glorion, Christophe and Moussa, Ronald and Kharrat, Khalil and Ghanem, Ismat},
  year = {2015},
  volume = {35},
  pages = {693--702},
  doi = {10.1097/BPO.0000000000000365},
  journal = {Journal of Pediatric Orthopaedics},
  keywords = {\#nosource},
  number = {7}
}

@article{Seber1963,
  title = {The Non-Central Chi-Squared and Beta Distributions},
  author = {Seber, G A F},
  year = {1963},
  volume = {50},
  pages = {542--544},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {3}
}

@article{Sekhon2008,
  title = {Multivariate and Propensity Score Matching the Matching Package for r},
  author = {Sekhon, Jasjeet S},
  year = {2008},
  volume = {10},
  abstract = {Matching is an R package which provides functions for multivariate and propensity score matching and for finding optimal covariate balance based on a genetic search algorithm. A variety of univariate and multivariate metrics to determine if balance actually has been obtained are provided. The underlying matching algorithm is written in C++, makes extensive use of system BLAS and scales efficiently with dataset size. The genetic algorithm which finds optimal balance is parallelized and can make use of multiple CPUs or a cluster of computers. A large number of options are provided which control exactly how the matching is conducted and how balance is evaluated.},
  journal = {Journal of Statistical Software},
  keywords = {\#nosource,causal,genetic optimization,multivariate matching,propensity score matching},
  number = {2}
}

@article{Sen2019,
  title = {Efficient Posterior Sampling for High-Dimensional Imbalanced Logistic Regression},
  author = {Sen, Deborshee and Sachs, Matthias and Lu, Jianfeng and Dunson, David},
  year = {2019},
  month = may,
  file = {C\:\\Users\\erik_\\Zotero\\storage\\I5AUGVCU\\sen_et_al_2019_efficient_posterior_sampling_for_high-dimensional_imbalanced_logistic_regression.pdf}
}

@article{Serden2003,
  title = {Have {{DRG}}-Based Prospective Payment Systems Influenced the Number of Secondary Diagnoses in Health Care Administrative Data?},
  author = {Serd{\'e}n, Lisbeth and Lindqvist, Rikard and Ros{\'e}n, M\aa ns},
  year = {2003},
  volume = {65},
  pages = {101--107},
  issn = {01688510},
  doi = {10.1016/S0168-8510(02)00208-7},
  abstract = {Diagnosis-related groups (DRGs) are secondary patient classification systems based on primary classified medical data, in which single events of care are grouped into larger, economically and medically consistent groups. The main primary classified medical data are diagnoses and surgery codes. In Sweden, the number of secondary diagnoses per case increased during the 1990s. In the early 1990s some county councils introduced DRG systems. The present study investigated whether the introduction of such systems had influenced the number of secondary diagnoses. The nation-wide Hospital Discharge Register from 1988 to 2000 was used for the analyses. All regional hospitals were included, giving a database of 5,355,000 discharges. The hospitals were divided into those that had introduced prospective payment systems during the study period and those that had not. Among all regional hospitals, there was an increase in the number of coded secondary diagnoses, but also in the number of secondary diagnoses per case. Hospitals with prospective payment systems had a larger increase, starting after the system was introduced. Regional hospitals without prospect payment systems had a more constant increase, starting later and coinciding with the introduction of their DRG-based management systems. It is concluded that introduction of DRG-based systems, irrespective of use, focuses on recording diagnoses and therefore increases the number of diagnoses. Other reasons may also have contributed to the increase. It was found that the changes in the speciality mix, during the study period, have impact on the increase of secondary diagnoses. \textcopyright{} 2003 Elsevier Science Ireland Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AGDIIN38\\serdén_et_al_2003_have_drg-based_prospective_payment_systems_influenced_the_number_of_secondary.pdf},
  isbn = {0168-8510},
  journal = {Health Policy},
  keywords = {Coding practice,DRG,Prospective payment system,Reimbursement,Secondary diagnoses},
  number = {2},
  pmid = {12849909}
}

@article{Shah2019,
  title = {Total Hip Arthroplasty in {{Parkinson}}'s Disease Patients: A Propensity Score-Matched Analysis with Minimum 2-Year Surveillance},
  author = {Shah, Neil V and Solow, Maximillian and Lavian, Joshua D and Bloom, Lee R and Grieco, Preston W and Stroud, Sarah G and Abraham, Roby and Naziri, Qais and Paulino, Carl B and Maheshwari, Aditya V and Diebo, Bassel G},
  year = {2019},
  month = jul,
  pages = {112070001986224},
  publisher = {{SAGE PublicationsSage UK: London, England}},
  issn = {1120-7000},
  doi = {10.1177/1120700019862247},
  abstract = {Introduction:Parkinson's disease (PD) patients experience chronic pain related to osteoarthritis at comparable rates to the general population. While total hip arthroplasty (THA) effectively improv...},
  journal = {HIP International},
  keywords = {\#nosource,Long-term outcomes,Parkinson’s disease,postoperative outcomes,propensity-score match,total hip arthroplasty}
}

@article{Shan2014,
  title = {Total Hip Replacement: {{A}} Systematic Review and Meta-Analysis on Mid-Term Quality of Life},
  author = {Shan, L. and Shan, B. and Graham, D. and Saxena, A.},
  year = {2014},
  volume = {22},
  pages = {389--406},
  publisher = {{Elsevier Ltd}},
  issn = {10634584},
  doi = {10.1016/j.joca.2013.12.006},
  abstract = {Objective: Total hip replacement (THR) is one of the most successful and frequently performed operations worldwide. Health-related quality of life (HRQOL) is a key outcome measure of surgery. We investigated mid-term HRQOL after THR in patients with osteoarthritis (OA). Design: A systematic review of clinical studies published after January 2000 was performed using strict eligibility criteria. Quality appraisal and data tabulation were performed using pre-determined forms. Data were synthesised by narrative review and random-effects meta-analysis using standardised response means. Tau2 and I2 values and Funnel plots were analysed. Results: 20 studies were included. Mid-term post-operative HRQOL is superior compared to pre-operative status on qualitative and quantitative analysis. Pooled response means of total Harris Hip Score (HHS) (P\textexclamdown 0.00001) and combined pain (P=0.00001) and physical function (P\textexclamdown 0.00001) domains of Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC) and HHS improved markedly up to 7 years. Medical Outcomes Survey Short Form 36 shows physical functioning (PF) (P\textexclamdown 0.00001), bodily pain (BP) (P\textexclamdown 0.00001), role physical (P=0.001), role emotional (P=0.04), and social functioning (SF) (P=0.03) were improved up to 7 years. General health (GH) (P=0.29), mental health (MH) (P=0.43), and vitality (P=0.17) was similar. HRQOL is at least as good as reference populations in the first few years and subsequently plateaus or declines. Patient satisfaction and functional status was favourable. There was significant heterogeneity amongst all studies, but publication bias was low in pooled analysis. Conclusion: THR confers significant mid-term HRQOL benefits across a broad range of health domains. Further studies based on consistent guidelines provided in this review are required. \textcopyright{} 2013 Osteoarthritis Research Society International.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZW67KJSC\\shan_et_al_2014_total_hip_replacement.pdf},
  isbn = {1063-4584},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Mid-term,Orthopaedic surgery,Osteoarthritis,Quality of life,Total hip arthroplasty,Total hip replacement},
  number = {3},
  pmid = {24389057}
}

@book{Shao2003,
  title = {Mathematical Statistics},
  author = {Shao, Jun},
  year = {2003},
  issn = {01621459},
  doi = {10.1007/b97553},
  abstract = {This graduate textbook covers topics in statistical theory essential for graduate students preparing for work on a Ph.D. degree in statistics. This new edition has been revised and updated and in this fourth printing, errors have been ironed out. The first chapter provides a quick overview of concepts and results in measure-theoretic probability theory that are useful in statistics. The second chapter introduces some fundamental concepts in statistical decision theory and inference. Subsequent chapters contain detailed studies on some important topics: unbiased estimation, parametric estimation, nonparametric estimation, hypothesis testing, and confidence sets. A large number of exercises in each chapter provide not only practice problems for students, but also many additional results.},
  isbn = {978-0-387-95382-3},
  keywords = {\#nosource},
  pmid = {10911016}
}

@article{Shao2015,
  title = {Takotsubo Syndrome and {{McConnell}}'s Phenomenon},
  author = {Shao, Yangzhen and Redfors, Bj{\"o}rn and Ali, Anwar and Bossone, Eduardo and Lyon, Alexander and Omerovic, Elmir},
  year = {2015},
  volume = {197},
  pages = {349--350},
  publisher = {{Elsevier B.V.}},
  issn = {18741754},
  doi = {10.1016/j.ijcard.2015.06.025},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HHD5K6EV\\shao_et_al_2015_takotsubo_syndrome_and_mcconnell's_phenomenon.pdf},
  journal = {International Journal of Cardiology}
}

@article{Sharabiani2012,
  title = {Systematic Review of Comorbidity Indices for Administrative Data},
  author = {Sharabiani, Mansour T. A. and Aylin, Paul and Bottle, Alex},
  year = {2012},
  month = dec,
  volume = {50},
  pages = {1109--1118},
  issn = {0025-7079},
  doi = {10.1097/MLR.0b013e31825f64d0},
  abstract = {BACKGROUND: Adjustment for comorbidities is common in performance benchmarking and risk prediction. Despite the exponential upsurge in the number of articles citing or comparing Charlson, Elixhauser, and their variants, no systematic review has been conducted on studies comparing comorbidity measures in use with administrative data. We present a systematic review of these multiple comparison studies and introduce a new meta-analytical approach to identify the best performing comorbidity measures/indices for short-term (inpatient + \textexclamdown/= 30 d) and long-term (outpatient+\textquestiondown 30 d) mortality. METHODS: Articles up to March 18, 2011 were searched based on our predefined terms. The bibliography of the chosen articles and the relevant reviews were also searched and reviewed. Multiple comparisons between comorbidity measures/indices were split into all possible pairs. We used the hypergeometric test and confidence intervals for proportions to identify the comparators with significantly superior/inferior performance for short-term and long-term mortality. In addition, useful information such as the influence of lookback periods was extracted and reported. RESULTS: Out of 1312 retrieved articles, 54 articles were eligible. The Deyo variant of Charlson was the most commonly referred comparator followed by the Elixhauser measure. Compared with baseline variables such as age and sex, comorbidity adjustment methods seem to better predict long-term than short-term mortality and Elixhauser seems to be the best predictor for this outcome. For short-term mortality, however, recalibration giving empirical weights seems more important than the choice of comorbidity measure. CONCLUSIONS: The performance of a given comorbidity measure depends on the patient group and outcome. In general, the Elixhauser index seems the best so far, particularly for mortality beyond 30 days, although several newer, more inclusive measures are promising. FAU - Sharabiani, Mansour T A},
  journal = {Medical Care},
  keywords = {\#nosource,1109,1118,50,administrative data,casemix,co-,comorbidity,med care 2012,meta-analysis,mortality,n risk prediction and,review,risk adjustment modeling,systematic},
  number = {12}
}

@article{Sheehan2016,
  title = {Patient and System Factors of Mortality after Hip Fracture: A Scoping Review},
  author = {Sheehan, K. J. and Sobolev, B. and Chudyk, A. and Stephens, T. and Guy, P.},
  year = {2016},
  volume = {17},
  pages = {166},
  publisher = {{BMC Musculoskeletal Disorders}},
  issn = {1471-2474},
  doi = {10.1186/s12891-016-1018-7},
  abstract = {Several patient and health system factors were associated with the risk of death among patients with hip fracture. However, without knowledge of underlying mechanisms interventions to improve survival post hip fracture can only be designed on the basis of the found statistical associations. We used the framework developed by Arksey and O'Malley and Levac et al. for synthesis of factors and mechanisms of mortality post low energy hip fracture in adults over the age of 50 years, published in English, between September 1, 2009 and October 1, 2014 and indexed in MEDLINE. Proposed mechanisms for reported associations were extracted from the discussion sections. We synthesized the evidence from 56 articles that reported on 35 patient and 9 system factors of mortality post hip fracture. For 21 factors we found proposed biological mechanisms for their association with mortality which included complications, comorbidity, cardiorespiratory function, immune function, bone remodeling and glycemic control. The majority of patient and system factors of mortality post hip fracture were reported by only one or two articles and with no proposed mechanisms for their effects on mortality. Where reported, underlying mechanisms are often based on a single article and should be confirmed with further study. Therefore, one cannot be certain whether intervening on such factors may produce expected results.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FA9SCRGH\\sheehan_et_al_2016_patient_and_system_factors_of_mortality_after_hip_fracture.pdf},
  journal = {BMC Musculoskeletal Disorders},
  keywords = {excess mortality persists for,factors have been,hip fracture,Hip fracture,mortality,Mortality,Patient fact,patient factors,scoping review,Scoping review,several patient and system,system factors,what is previously known,years post hip fracture},
  number = {1}
}

@article{Sherman2016,
  title = {Real-{{World Evidence}} \textemdash{} {{What Is It}} and {{What Can It Tell Us}}?},
  author = {Sherman, Rachel E. and Anderson, Steven A. and Dal Pan, Gerald J. and Gray, Gerry W. and Gross, Thomas and Hunter, Nina L. and LaVange, Lisa and {Marinac-Dabic}, Danica and Marks, Peter W. and Robb, Melissa A. and Shuren, Jeffrey and Temple, Robert and Woodcock, Janet and Yue, Lilly Q. and Califf, Robert M.},
  year = {2016},
  month = dec,
  volume = {375},
  pages = {2293--2297},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMsb1609216},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2R95AMYX\\Sherman m. fl. - 2016 - Real-World Evidence — What Is It and What Can It T.pdf},
  journal = {New England Journal of Medicine},
  keywords = {coder},
  language = {en},
  number = {23}
}

@article{Shieh2008,
  title = {Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient},
  author = {Shieh, Gwowen},
  year = {2008},
  volume = {11},
  pages = {387--407},
  journal = {Organizational Research Methods},
  keywords = {\#nosource,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
  number = {2}
}

@article{Shieh2009,
  title = {Exact Analysis of Squared Cross-Validity Coefficient in Predictive Regression Models},
  author = {Shieh, Gwowen},
  year = {2009},
  volume = {44},
  pages = {82--105},
  issn = {0027-3171},
  doi = {10.1080/00273170802620097},
  abstract = {In regression analysis, the notion of population validity is of theoretical interest for describing the usefulness of the underlying regression model, whereas the presumably more important concept of population cross-validity represents the predictive effectiveness for the regression equation in future research. It appears that the inference procedures of the squared multiple correlation coefficient have been extensively developed. In contrast, a full range of statistical methods for the analysis of the squared cross-validity coefficient is considerably far from complete. This article considers a distinct expression for the definition of the squared cross-validity coefficient as the direct connection and monotone transformation to the squared multiple correlation coefficient. Therefore, all the currently available exact methods for interval estimation, power calculation, and sample size determination of the squared multiple correlation coefficient are naturally modified and extended to the analysis of the squared cross-validity coefficient. The adequacies of the existing approximate procedures and the suggested exact method are evaluated through a Monte Carlo study. Furthermore, practical applications in areas of psychology and management are presented to illustrate the essential features of the proposed methodologies. The first empirical example uses 6 control variables related to driver characteristics and traffic congestion and their relation to stress in bus drivers, and the second example relates skills, cognitive performance, and personality to team performance measures. The results in this article can facilitate the recommended practice of cross-validation in psychological and other areas of social science research. (Contains 2 figures and 8 tables.)},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IWCTXGMR\\shieh_2009_exact_analysis_of_squared_cross-validity_coefficient_in_predictive_regression.pdf},
  isbn = {0027-3171},
  journal = {Multivariate Behavioral Research},
  number = {1},
  pmid = {263268700004}
}

@article{Shieh2010,
  title = {Estimation of the Simple Correlation Coefficient.},
  author = {Shieh, Gwowen},
  year = {2010},
  volume = {42},
  pages = {906--917},
  issn = {1554-351X},
  doi = {10.3758/BRM.42.4.906},
  abstract = {This article investigates some unfamiliar properties of the Pearson product-moment correlation coefficient for the estimation of simple correlation coefficient. Although Pearson's r is biased, except for limited situations, and the minimum variance unbiased estimator has been proposed in the literature, researchers routinely employ the sample correlation coefficient in their practical applications, because of its simplicity and popularity. In order to support such practice, this study examines the mean squared errors of r and several prominent formulas. The results reveal specific situations in which the sample correlation coefficient performs better than the unbiased and nearly unbiased estimators, facilitating recommendation of r as an effect size index for the strength of linear association between two variables. In addition, related issues of estimating the squared simple correlation coefficient are also considered.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JZB87G67\\shieh_2010_estimation_of_the_simple_correlation_coefficient.pdf},
  isbn = {1554-3528 (Electronic){\r  }1554-351X (Linking)},
  journal = {Behavior research methods},
  number = {4},
  pmid = {21139158}
}

@article{Shih2015,
  title = {Functional Status Outperforms Comorbidities in Predicting Acute Care Readmissions in Medically Complex Patients},
  author = {Shih, Shirley L. and Gerrard, Paul and Goldstein, Richard and Mix, Jacqueline and Ryan, Colleen M. and Niewczyk, Paulette and Kazis, Lewis and Hefner, Jaye and Ackerly, D. Clay and Zafonte, Ross and Schneider, Jeffrey C.},
  year = {2015},
  volume = {30},
  pages = {1688--1695},
  issn = {15251497},
  doi = {10.1007/s11606-015-3350-2},
  abstract = {OBJECTIVE: To examine functional status versus medical comorbidities as predictors of acute care readmissions in medically complex patients. DESIGN: Retrospective database study. SETTING: U.S. inpatient rehabilitation facilities. PARTICIPANTS: Subjects included 120,957 patients in the Uniform Data System for Medical Rehabilitation admitted to inpatient rehabilitation facilities under the medically complex impairment group code between 2002 and 2011. INTERVENTIONS: A Basic Model based on gender and functional status was developed using logistic regression to predict the odds of 3-, 7-, and 30-day readmission from inpatient rehabilitation facilities to acute care hospitals. Functional status was measured by the FIM((R)) motor score. The Basic Model was compared to six other predictive models-three Basic Plus Models that added a comorbidity measure to the Basic Model and three Gender-Comorbidity Models that included only gender and a comorbidity measure. The three comorbidity measures used were the Elixhauser index, Deyo-Charlson index, and Medicare comorbidity tier system. The c-statistic was the primary measure of model performance. MAIN OUTCOME MEASURES: We investigated 3-, 7-, and 30-day readmission to acute care hospitals from inpatient rehabilitation facilities. RESULTS: Basic Model c-statistics predicting 3-, 7-, and 30-day readmissions were 0.69, 0.64, and 0.65, respectively. The best-performing Basic Plus Model (Basic+Elixhauser) c-statistics were only 0.02 better than the Basic Model, and the best-performing Gender-Comorbidity Model (Gender+Elixhauser) c-statistics were more than 0.07 worse than the Basic Model. CONCLUSIONS: Readmission models based on functional status consistently outperform models based on medical comorbidities. There is opportunity to improve current national readmission risk models to more accurately predict readmissions by incorporating functional data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4JTTUZCA\\shih_et_al_2015_functional_status_outperforms_comorbidities_in_predicting_acute_care.pdf},
  isbn = {0884-8734},
  journal = {Journal of General Internal Medicine},
  keywords = {care transitions,functional status,outcomes,risk assessment,statistical modeling},
  number = {11},
  pmid = {25956826}
}

@article{Shmueli2011,
  title = {To Explain or to Predict?},
  author = {Shmueli, Galit},
  year = {2011},
  volume = {25},
  pages = {289--310},
  issn = {0883-4237},
  doi = {10.1214/10-STS330},
  abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LDN268LU\\shmueli_2011_to_explain_or_to_predict.pdf},
  isbn = {0883-4237},
  journal = {Statistical Science},
  keywords = {and phrases,causality,data mining,eling,explanatory modeling,Explanatory modeling,modeling,predictive,predictive mod-,predictive modeli,predictive power,scientific,scientific research,statistical strategy},
  number = {3},
  pmid = {25246403}
}

@article{Shohat2019,
  title = {Hip and {{Knee Section}}, {{What}} Is the {{Definition}} of a {{Periprosthetic Joint Infection}} ({{PJI}}) of the {{Knee}} and the {{Hip}}? {{Can}} the {{Same Criteria}} Be {{Used}} for {{Both Joints}}?: {{Proceedings}} of {{International Consensus}} on {{Orthopedic Infections}}},
  shorttitle = {Hip and {{Knee Section}}, {{What}} Is the {{Definition}} of a {{Periprosthetic Joint Infection}} ({{PJI}}) of the {{Knee}} and the {{Hip}}?},
  author = {Shohat, Noam and Bauer, Thomas and Buttaro, Martin and Budhiparama, Nicolaas and Cashman, James and Della Valle, Craig J. and Drago, Lorenzo and Gehrke, Thorsten and Marcelino Gomes, Luiz S. and Goswami, Karan and Hailer, Nils P. and Han, Seung Beom and Higuera, Carlos A. and Inaba, Yutaka and Jenny, Jean-Yves and {Kjaersgaard-Andersen}, Per and Lee, Mel and Llin{\'a}s, Adolfo and Malizos, Konstantinos and Mont, Michael A. and Jones, Rhidian Morgan and Parvizi, Javad and Peel, Trisha and {Rivero-Boschert}, Salvador and Segreti, John and Soriano, Alex and Sousa, Ricardo and Spangehl, Mark and Tan, Timothy L. and Tikhilov, Rashid and Tuncay, Ibrahim and Winkler, Heinz and Witso, Eivind and {Wouthuyzen-Bakker}, Marjan and Young, Simon and Zhang, Xianlong and Zhou, Yixin and Zimmerli, Werner},
  year = {2019},
  month = feb,
  volume = {34},
  pages = {S325-S327},
  issn = {08835403},
  doi = {10.1016/j.arth.2018.09.045},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {2}
}

@article{Simmonds2014,
  title = {Understanding {{NHS}} Hospital Admissions in England: Linkage of Hospital Episode Statistics to the Hertfordshire Cohort Study},
  author = {Simmonds, Shirley J. and Syddall, Holly E. and Walsh, Bronagh and Evandrou, Maria and Dennison, Elaine M. and Cooper, Cyrus and Sayer, Avan Aihie},
  year = {2014},
  month = sep,
  volume = {43},
  pages = {653--660},
  issn = {1468-2834},
  doi = {10.1093/ageing/afu020},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TT64AN2C\\simmonds_et_al_2014_understanding_nhs_hospital_admissions_in_england.pdf},
  journal = {Age and Ageing},
  number = {5}
}

@article{Simoncelli1992,
  title = {Shiftable Multiscale Transforms},
  author = {Simoncelli, E.P. and Freeman, W.T. and Adelson, E.H. and Heeger, D.J.},
  year = {1992},
  month = mar,
  volume = {38},
  pages = {587--607},
  issn = {0018-9448},
  doi = {10.1109/18.119725},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F33Y2NDZ\\simoncelli_et_al_1992_shiftable_multiscale_transforms.pdf},
  journal = {IEEE Transactions on Information Theory},
  number = {2}
}

@article{Sinha2013,
  title = {Studies Using {{English}} Administrative Data ({{Hospital Episode Statistics}}) to Assess Health-Care Outcomes\textemdash Systematic Review and Recommendations for Reporting},
  author = {Sinha, Sidhartha and Peach, George and Poloniecki, Jan D. and Thompson, Matt M. and Holt, Peter J.},
  year = {2013},
  month = feb,
  volume = {23},
  pages = {86--92},
  issn = {1464-360X},
  doi = {10.1093/eurpub/cks046},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7I2PUBVT\\sinha_et_al_2013_studies_using_english_administrative_data_(hospital_episode_statistics)_to.pdf},
  journal = {European Journal of Public Health},
  number = {1}
}

@article{Siontis2011,
  title = {Predicting Death: {{An}} Empirical Evaluation of Predictive Tools for Mortality},
  author = {Siontis, GM and Tzoulaki, I and JA, Ioannidis},
  year = {2011},
  month = oct,
  volume = {171},
  pages = {1721--1726},
  issn = {0003-9926},
  abstract = {Background The ability to predict death is crucial in medicine, and many relevant prognostic tools have been developed for application in diverse settings. We aimed to evaluate the discriminating performance of predictive tools for death and the variability in this performance across different clinical conditions and studies.Methods We used Medline to identify studies published in 2009 that assessed the accuracy (based on the area under the receiver operating characteristic curve [AUC]) of validated tools for predicting all-cause mortality. For tools where accuracy was reported in 4 or more assessments, we calculated summary accuracy measures. Characteristics of studies of the predictive tools were evaluated to determine if they were associated with the reported accuracy of the tool.Results A total of 94 eligible studies provided data on 240 assessments of 118 predictive tools. The AUC ranged from 0.43 to 0.98 (median [interquartile range], 0.77 [0.71-0.83]), with only 23 of the assessments reporting excellent discrimination (10\%) (AUC, \textquestiondown 0.90). For 10 tools, accuracy was reported in 4 or more assessments; only 1 tool had a summary AUC exceeding 0.80. Established tools showed large heterogeneity in their performance across different cohorts (I2 range, 68\%-95\%). Reported AUC was higher for tools published in journals with lower impact factor (P = .01), with larger sample size (P = .01), and for those that aimed to predict mortality among the highest-risk patients (P = .002) and among children (P \textexclamdown{} .001).Conclusions Most tools designed to predict mortality have only modest accuracy, and there is large variability across various diseases and populations. Most proposed tools do not have documented clinical utility.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8SECZ24K\\siontis_et_al_2011_predicting_death.pdf},
  journal = {Archives of Internal Medicine},
  number = {19}
}

@article{Siontis2015,
  title = {External Validation of New Risk Prediction Models Is Infrequent and Reveals Worse Prognostic Discrimination},
  author = {Siontis, George C M and Tzoulaki, Ioanna and Castaldi, Peter J. and Ioannidis, John P A},
  year = {2015},
  volume = {68},
  pages = {25--34},
  publisher = {{Elsevier Inc}},
  issn = {18785921},
  doi = {10.1016/j.jclinepi.2014.09.007},
  abstract = {Objectives To evaluate how often newly developed risk prediction models undergo external validation and how well they perform in such validations. Study Design and Setting We reviewed derivation studies of newly proposed risk models and their subsequent external validations. Study characteristics, outcome(s), and models' discriminatory performance [area under the curve, (AUC)] in derivation and validation studies were extracted. We estimated the probability of having a validation, change in discriminatory performance with more stringent external validation by overlapping or different authors compared to the derivation estimates. Results We evaluated 127 new prediction models. Of those, for 32 models (25\%), at least an external validation study was identified; in 22 models (17\%), the validation had been done by entirely different authors. The probability of having an external validation by different authors within 5 years was 16\%. AUC estimates significantly decreased during external validation vs. the derivation study [median AUC change: -0.05 (P \textexclamdown{} 0.001) overall; -0.04 (P = 0.009) for validation by overlapping authors; -0.05 (P \textexclamdown{} 0.001) for validation by different authors]. On external validation, AUC decreased by at least 0.03 in 19 models and never increased by at least 0.03 (P \textexclamdown{} 0.001). Conclusion External independent validation of predictive models in different studies is uncommon. Predictive performance may worsen substantially on external validation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\K5UVW3EU\\siontis_et_al_2015_external_validation_of_new_risk_prediction_models_is_infrequent_and_reveals.pdf},
  isbn = {0895-4356},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Area under the receiver operating characteristics,Derivation study,Discrimination,External validation,Prognostic models,Risk prediction model},
  number = {1},
  pmid = {25441703}
}

@article{sjolanderEstimationCausalEffect2018,
  title = {Estimation of Causal Effect Measures with the {{R}} -Package {{stdReg}}},
  author = {Sj{\"o}lander, Arvid},
  year = {2018},
  volume = {0123456789},
  publisher = {{Springer Netherlands}},
  issn = {1573-7284},
  doi = {10.1007/s10654-018-0375-y},
  abstract = {\textexclamdown h3 class="a-plus-plus"\textquestiondown Abstract\textexclamdown/h3\textquestiondown{} \textexclamdown p class="a-plus-plus"\textquestiondown Measures of causal effects play a central role in epidemiology. A wide range of measures exist, which are designed to give relevant answers to substantive epidemiological research questions. However, due to mathematical convenience and software limitations most studies only report odds ratios for binary outcomes and hazard ratios for time-to-event outcomes. In this paper we show how logistic regression models and Cox proportional hazards regression models can be used to estimate a wide range of causal effect measures, with the \textexclamdown span class="a-plus-plus emphasis fontcategory-non-proportional"\textquestiondown R\textexclamdown/span\textquestiondown -package \textexclamdown span class="a-plus-plus emphasis fontcategory-non-proportional"\textquestiondown stdReg\textexclamdown/span\textquestiondown. For illustration we focus on the attributable fraction, the number needed to treat and the relative excess risk due to interaction. We use two publicly available data sets, so that the reader can easily replicate and elaborate on the analyses. The first dataset includes information on 487 births among 188 women, and the second dataset includes information on 2982 women diagnosed with primary breast cancer.\textexclamdown/p\textquestiondown},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IF64NBC3\\sjölander_2018_estimation_of_causal_effect_measures_with_the_r_-package_stdreg.pdf},
  isbn = {0123456789},
  journal = {European Journal of Epidemiology},
  keywords = {á relative excess risk,Attributable fraction,attributable fraction á causal,Causal effect,Cox proportion,due to interaction,effect á cox proportional,hazards regression á logistic,number needed to treat,regression á}
}

@article{sjolanderIgnoringMatchingVariables2013,
  title = {Ignoring the Matching Variables in Cohort Studies - {{When}} Is It Valid and Why?},
  author = {Sj{\"o}lander, Arvid and Greenland, Sander},
  year = {2013},
  volume = {32},
  pages = {4696--4708},
  issn = {10970258},
  doi = {10.1002/sim.5879},
  abstract = {In observational studies of the effect of an exposure on an outcome, the exposure-outcome association is usually confounded by other causes of the outcome (potential confounders). One common method to increase efficiency is to match the study on potential confounders. Matched case-control studies are relatively common and well covered by the literature. Matched cohort studies are less common but do sometimes occur. It is often argued that it is valid to ignore the matching variables, in the analysis of matched cohort data. In this paper, we provide analyses delineating the scope and limits of this argument. We discuss why the argument does not carry over to effect estimation in matched case-control studies, although it does carry over to null-hypothesis testing. We also show how the argument does not extend to matched cohort studies when one adjusts for additional confounders in the analysis. Ignoring the matching variables can sometimes reduce variance, even though this is not guaranteed. We investigate the trade-off between bias and variance in deciding whether adjustment for matching factors is advisable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\I4V5ZTQW\\sjölander_greenland_2013_ignoring_the_matching_variables_in_cohort_studies_-_when_is_it_valid_and_why.pdf},
  isbn = {1097-0258 (Electronic){\r  }0277-6715 (Linking)},
  journal = {Statistics in Medicine},
  keywords = {Case-control studies,Cohort studies,Confounding,Matching,Stratification},
  number = {27},
  pmid = {23761197}
}

@article{sjolanderPropensityScoresMstructures2009,
  title = {Propensity Scores and {{M}}-Structures},
  author = {Sj{\"o}lander, Arvid},
  year = {2009},
  month = apr,
  volume = {28},
  pages = {1416--1420},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/sim.3532},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LUFTL2L8\\sjölander_2009_propensity_scores_and_m-structures.pdf},
  journal = {Statistics in Medicine},
  keywords = {DAG,M‐structure,propensity score},
  number = {9}
}

@article{sjolanderRegressionStandardizationPackage2016,
  title = {Regression Standardization with the {{R}} Package {{stdReg}}},
  author = {Sj{\"o}lander, Arvid},
  year = {2016},
  month = jun,
  volume = {31},
  pages = {563--574},
  publisher = {{Springer Netherlands}},
  issn = {0393-2990},
  doi = {10.1007/s10654-016-0157-3},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4NZUXCV2\\sjölander_2016_regression_standardization_with_the_r_package_stdreg.pdf},
  journal = {European Journal of Epidemiology},
  number = {6}
}

@techreport{Sjostrom1968,
  title = {Klassifikation Av Sjukdomar m m 1968: {{Systematisk}} F\"orteckning. [{{ICD8}}]},
  author = {Sj{\"o}str{\"o}m, \AA ke and Westerholm, Barbro},
  year = {1968},
  institution = {{Medecinalstyrelsen}},
  city = {Stockholm},
  keywords = {\#nosource}
}

@article{Skidmore2011,
  title = {Choosing the Best Correction Formula for the Pearson r 2 Effect Size},
  author = {Skidmore, Susan Troncoso and Thompson, Bruce},
  year = {2011},
  volume = {79},
  pages = {257--278},
  issn = {0022-0973},
  doi = {10.1080/00220973.2010.484437},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\NH42J945\\skidmore_thompson_2011_choosing_the_best_correction_formula_for_the_pearson_r_2_effect_size.pdf},
  journal = {The Journal of Experimental Education},
  number = {3}
}

@techreport{SKL2018,
  title = {{{REKOMMENDATIONER TILL NATIONELLA KVALITETSREGISTER INF\"OR DATASKYDDSF\"ORORDNINGEN}}},
  author = {{SKL}},
  year = {2018},
  abstract = {Denna orientering syftar till att uppm\"arksamma i f\"orsta hand centralt personuppgiftsansvariga myndigheter f\"or Nationella Kvalitetsregister (CPUA-myndigheter) p\aa{} konsekvenser f\"or Nationella Kvalitetsregister n\"ar EU:s nya dataskyddsf\"orordning tr\"ader i kraft den 25 maj detta \aa r. Orienteringen riktar sig \"aven till v\aa rdgivare som rapporterar patientuppgifter till kvalitetsregister samt regionala registercentrum och cancercentrum (registercentrumorganisationen, RCO), vilka har till uppgift att st\"odja och utveckla kvalitetsregister. N\"armast ber\"orda f\"or n\"odv\"andiga anpassnings\aa tg\"arder \"ar styrgrupper f\"or Nationella Kvalitetsregister, registerh\aa llare, registeransvariga hos v\aa rdgivare och dataskyddsombud hos CPUA-myndigheten (normalt landstings-eller regionstyrelser). RCO b\"or ta en ledande roll f\"or att genomf\"ora rekommenderade \aa tg\"arder i samverkan med ber\"orda v\aa rdgivare och CPUA-myndigheter. N\"ar dataskyddsf\"orordningen tr\"ader i kraft g\"aller den som lag i Sverige och \"ovriga EU:s medlemsl\"ander. Vid samma tidpunkt upph\"or personuppgiftslagen och det nuvarande dataskyddsdirektivet. F\"orordningen kommer att inneb\"ara en hel del f\"or\"andringar f\"or de som behandlar personuppgifter, t.ex. kvalitetsregister, och st\"arkta r\"attigheter f\"or den enskilde n\"ar det g\"aller den personliga integriteten. Det finns inga \"overg\aa ngsregler utan dataskyddsf\"orordningen kommer att g\"alla fr.o.m. den 25 maj. Den som behandlar personuppgifter men inte f\"oljer eller inte kan visa f\"oljsamhet till f\"orordningens best\"ammelser riskerar h\"oga vitessanktioner. Nationella och regionala kvalitetsregister regleras idag i 7 kap. patientdatalagen (2008:355; PDL). En s\"arskild utredning, Socialdataskyddsutredningen (SOU 2017:66), har granskat patientdatalagen med anledning av dataskyddsf\"orordningen. Utredningen har bed\"omt att PDL \"ar i stort sett f\"orenlig med f\"orordningen och f\"oreslagit endast mindre justeringar i lagen. Nuvarande reglering om kvalitetsregister i PDL kommer s\aa ledes att g\"alla efter den 25 maj med undantag f\"or vissa redaktionella \"andringar och en begr\"ansning som behandlas nedan. Regeringen har i skrivande stund \"annu inte presenterat en proposition med lag\"andringar i PDL. FATTA BESLUT OM CPUA F\"or att veta best\"amt vem som \"ar personuppgiftsansvarig f\"or ett Nationellt Kvalitetsregister och att det \"ar en myndighet rekommenderas styrgrupper att som f\"orsta \aa tg\"ard inf\"or en anpassning av verksamheten till dataskyddsf\"orordningen kontrollera huvudmannaskapet f\"or sitt eller sina Nationella Kvalitetsregister.},
  keywords = {\#nosource}
}

@article{Sloan2003,
  title = {Construction and Characteristics of the {{RxRisk}}-{{V}}: A {{VA}}-Adapted Pharmacy-Based Case-Mix Instrument.},
  author = {Sloan, Kevin L and Sales, Anne E and Liu, Chuan-Fen and Fishman, Paul and Nichol, Paul and Suzuki, Norman T and Sharp, Nancy D},
  year = {2003},
  month = jun,
  volume = {41},
  pages = {761--74},
  issn = {0025-7079},
  doi = {10.1097/01.MLR.0000064641.84967.B7},
  abstract = {BACKGROUND Assessment of disease burden is the key to many aspects of health care management. Patient diagnoses are commonly used for case-mix assessment. However, issues pertaining to diagnostic data availability and reliability make pharmacy-based strategies attractive. Our goal was to provide a reliable and valid pharmacy-based case-mix classification system for chronic diseases found in the Veterans Health Administration (VHA) population. OBJECTIVE To detail the development and category definitions of a VA-adapted version of the RxRisk (formerly the Chronic Disease Score); to describe category prevalence and reliability; to check category criterion validity against ICD-9 diagnoses; and to assess category-specific regression coefficients in concurrent and prospective cost models. RESEARCH DESIGN Clinical and pharmacological review followed by cohort analysis of diagnostic, pharmacy, and utilization databases. SUBJECTS 126,075 veteran users of VHA services in Washington, Oregon, Idaho, and Alaska. METHODS We used Kappa statistics to evaluate RxRisk category reliability and criterion validity, and multivariate regression to estimate concurrent and prospective cost models. RESULTS The RxRisk-V classified 70.5\% of the VHA Northwest Network 1998 users into an average of 2.61 categories. Of the 45 classes, 33 classes had good-excellent 1-year reliability and 25 classes had good-excellent criterion validity against ICD-9 diagnoses. The RxRisk-V accounts for a distinct proportion of the variance in concurrent (R2 = 0.18) and prospective cost (R2 = 0.10) models. CONCLUSIONS The RxRisk-V provides a reliable and valid method for administrators to describe and understand better chronic disease burden of their treated populations. Tailoring to the VHA permits assessment of disease burden specific to this population.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\T8RNRMDX\\Sloan m. fl. - 2003 - Construction and characteristics of the RxRisk-V .pdf},
  journal = {Medical care},
  keywords = {\#nosource,coder},
  number = {6},
  pmid = {12773842}
}

@article{Sloan2007,
  title = {Analysis and Interpretation of Results Based on Patient-Reported Outcomes.},
  author = {a Sloan, Jeff and Dueck, Amylou C and a Erickson, Pennifer and Guess, Harry and a Revicki, Dennis and Santanello, Nancy C},
  year = {2007},
  volume = {10 Suppl 2},
  pages = {S106-S115},
  issn = {1524-4733},
  doi = {10.1111/j.1524-4733.2007.00273.x},
  abstract = {This article is part of a series of manuscripts dealing with the incorporation of patient-reported outcomes (PROs) into clinical trials. The issues dealt with in this manuscript concern the common pitfalls to avoid in statistical analysis and interpretation of PROs. Specifically, the questions addressed by this manuscript involve the analysis pitfalls with PRO data in clinical trials and how can they be avoided (e.g.,missing data, multiplicity, null results etc.). The manuscript provides key literature for existing resources and proposes new guidelines.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2SUZD2IU\\sloan_et_al_2007_analysis_and_interpretation_of_results_based_on_patient-reported_outcomes.pdf},
  journal = {Value in health : the journal of the International Society for Pharmacoeconomics and Outcomes Research},
  keywords = {clinical significance,ence,minimally important differ-,missing data,patient-reported outcomes,statistical},
  pmid = {17995469}
}

@article{Slobogean2015,
  title = {Bigger Data, Bigger Problems},
  author = {Slobogean, Gerard P. and Giannoudis, Peter V. and Frihagen, Frede and Forte, Mary L. and Morshed, Saam and Bhandari, Mohit},
  year = {2015},
  month = dec,
  volume = {29},
  pages = {S43-S46},
  issn = {15312291},
  doi = {10.1097/BOT.0000000000000463},
  abstract = {Clinical studies frequently lack the ability to reliably answer their research questions because of inadequate sample sizes. Underpowered studies are subject to multiple sources of bias, may not represent the larger population, and are regularly unable to detect differences between treatment groups. Most importantly, an underpowered study can lead to incorrect conclusions. Big data can be used to address many of these concerns, enabling researchers to answer questions with increased certainty and less likelihood of bias. Big datasets, such as The National Hip Fracture Database in the United Kingdom and the Swedish Hip Arthroplasty Registry, collect valuable clinical information that can be used by researchers to guide patient care and inform policy makers, chief executives, commissioners, and clinical staff. The range of research questions that can be examined is directly related to the quality and complexity of the data, which is positively associated with the cost of the data. However, technological advancements have unlocked new possibilities for efficient data capture and widespread opportunities to merge massive datasets, particularly in the setting of national registries and administrative data.},
  isbn = {1531-2291 (Electronic){\r  }0890-5339 (Linking)},
  journal = {Journal of Orthopaedic Trauma},
  keywords = {\#nosource,Administrative data,Big data,National hip fracture database,Registry,Swedish hip registry},
  pmid = {26584266}
}

@article{Slobogean2017,
  title = {Femoral Neck Shortening in Adult Patients under the Age of 55 Years Is Associated with Worse Functional Outcomes : {{Analysis}} of the Prospective Multi-Center Study of Hip Fracture Outcomes in {{China}}},
  author = {Slobogean, Gerard P and Stockton, David J and Zeng, Bing-fang and Wang, Dong and Ma, Baotong and Pollak, Andrew N},
  year = {2017},
  volume = {48},
  pages = {1837--1842},
  publisher = {{Elsevier Ltd}},
  issn = {0020-1383},
  doi = {10.1016/j.injury.2017.06.013},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2L6XRKHG\\slobogean_et_al_2017_femoral_neck_shortening_in_adult_patients_under_the_age_of_55_years_is.pdf},
  journal = {Injury},
  keywords = {young femoral neck fracture},
  number = {8}
}

@book{smallExpansionsAsymptoticsStatistics2010,
  title = {Expansions and Asymptotics for Statistics},
  author = {Small, Christopher G},
  year = {2010},
  doi = {10.15713/ins.mmj.3},
  isbn = {978-90-04-31008-7},
  keywords = {\#nosource},
  number = {c},
  pmid = {29982528}
}

@article{Smith2012,
  title = {Risk of Cancer in First Seven Years after Metal-on-Metal Hip Replacement Compared with Other Bearings and General Population: {{Linkage}} Study between the {{National Joint Registry}} of {{England}} and {{Wales}} and Hospital Episode Statistics},
  author = {Smith, Alison J. and Dieppe, Paul and Porter, Martyn and Blom, Ashley W.},
  year = {2012},
  month = aug,
  volume = {344},
  issn = {17561833},
  doi = {10.1136/bmj.e2383},
  abstract = {Objective: To determine whether use of metal-on-metal bearing surfaces is associated with an increased risk of a diagnosis of cancer in the early years after total hip replacement and specifically with an increase in malignant melanoma and haematological, prostate, and renal tract cancers. Design: Linkage study with multivariable competing risks flexible parametric survival model to examine the incidence of new diagnoses of cancer in patients with metal-on-metal hip replacement compared with those with alternative bearings and to compare the observed incidence of diagnoses in patients undergoing hip replacement with that predicted by national incidence rates in the general population. Setting: National Joint Registry of England and Wales (NJR) linked to NHS hospital episode statistics data. Participants: 40 576 patients with hip replacement with metal-on-metal bearing surfaces and 248 995 with alternative bearings. Main outcome measures: Incidence of all cancers and incidence of malignant melanoma and prostate, renal tract, and haematological cancers. Results: The incidence of new diagnoses of cancer was low after hip replacement (1.25\% at one year, 95\% confidence interval 1.21\% to 1.30\%) and lower than that predicted from the age and sex matched normal population (1.65\%, 1.60\% to 1.70\%). Compared with alternative bearings, there was no evidence that metal-on-metal bearing surfaces were associated with an increased risk of any cancer diagnosis in the seven years after surgery (mean follow-up of three years, 23\% (n=67 361) of patients observed for five years or more). Similarly, there was no increase in the risk of malignant melanoma or haematological, prostate, and renal tract cancers. The adjusted five year incidence of all cancers for men aged 60 was 4.8\% (4.4\% to 5.3\%) with resurfacing, 6.2\% (5.7\% to 6.7\%) with stemmed metal-on-metal, and 6.7\% (6.5\% to 7.0\%) for other bearing surfaces. Equivalent rates for women aged 60 were lower: 3.1\% (2.8\% to 3.4\%) with resurfacing, 4.0\% (3.7\% to 4.3\%) with stemmed metal-on-metal, and 4.4\% (4.2\% to 4.5\%) with other bearings. Conclusions: These data are reassuring, but the findings are observational with short follow-up. The use of hospital episode statistics data might underestimate cancer diagnoses, and there is the possibility of confounding by indication. Furthermore, as some cancers have a long latency period it is important that we study the longer term outcomes and continue to investigate the effects of exposure to orthopaedic metals.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\M3X5SQHQ\\smith_et_al_2012_risk_of_cancer_in_first_seven_years_after_metal-on-metal_hip_replacement.pdf},
  journal = {BMJ (Online)}
}

@article{Smith2014,
  title = {Pre-Operative Indicators for Mortality Following Hip Fracture Surgery: A Systematic Review and Meta-Analysis},
  author = {Smith, Toby and Pelpola, Kelum and Ball, Martin and Ong, Alice and Myint, Phyo Kyaw},
  year = {2014},
  month = jun,
  volume = {43},
  pages = {464--471},
  issn = {0002-0729},
  doi = {10.1093/ageing/afu065},
  abstract = {OBJECTIVE: hip fracture is a common and serious condition associated with high mortality. This study aimed to identify pre-operative characteristics which are associated with an increased risk of mortality after hip fracture surgery.: systematic search of published and unpublished literature databases, including EMBASE, MEDLINE, AMED, CINAHL, PubMed and the Cochrane Library, was undertaken to identify all clinical studies on pre-operative predictors of mortality after surgery in hip fracture with at least 3-month follow-up. Data pertaining to the study objectives was extracted by two reviewers independently. Where study homogeneity was evidence, a meta-analysis of pooled relative risk and 95\% confidence intervals was performed for mortality against pre-admission characteristics.: fifty-three studies including 544,733 participants were included. Thirteen characteristics were identified as possible pre-operative indicators for mortality. Following meta-analysis, the four key characteristics associated with the risk of mortality up to 12 months were abnormal ECG (RR: 2.00; 95\% CI: 1.45, 2.76), cognitive impairment (RR: 1.91; 95\% CI: 1.35, 2.70), age \textquestiondown 85 years (RR: 0.42; 95\% CI: 0.20, 0.90) and pre-fracture mobility (RR: 0.13; 95\% CI: 0.05, 0.34). Other statistically significant pre-fracture predictors of increased mortality were male gender, being resident in a care institution, intra-capsular fracture type, high ASA grade and high Charlson comorbidity score on admission.: this review has identified the characteristics of patients with a high risk of mortality after a hip fracture surgery beyond the peri-operative period who may benefit from comprehensive assessment and appropriate management.REGISTRATION NUMBER: CRD42012002107.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DSEIV4V6\\smith_et_al_2014_pre-operative_indicators_for_mortality_following_hip_fracture_surgery.pdf},
  isbn = {0002-0729},
  journal = {Age and Ageing},
  number = {4},
  pmid = {24895018}
}

@article{Smith2015,
  title = {Multiple Temporalities of Knowing in Academic Research},
  author = {Smith, S.},
  year = {2015},
  pages = {0539018414566421-},
  issn = {0539-0184},
  doi = {10.1177/0539018414566421},
  abstract = {Based on ethnographic research at five Czech universities from 2011 to 2013, this article explores how academics make sense of and claims to three qualitatively distinct temporal regimes in which their activities as knowledge producers are inscribed: disciplinary time, career time and project time. This conceptual framework, a modification of Shinn's distinction between disciplinary, transitory and transversal knowledge-production regimes, seeks to replace images of competition and succession between regimes with images of their recombination and intersection. It enables an interpretation of the empirical findings beyond the indigenous complaint that excessive speed is compromising the quality of knowledge production. The relationship between projects, careers and disciplines emerges from the study as problematic rather than synergistic. In this respect the paper does not contradict the claim by critical theorists that we are witnessing the disintegration of what used to be a functional relationship between the multiple temporalities of academic knowledge production based on standardized career scripts, nor the related claim that this may reflect a deeper crisis of modernity as a predictive regime for the production of futures. It proposes, however, that transversal projects can still be mediators of disciplinary respiration' insofar as their timeframes are available for variable calibration commensurate with the increasingly heteronomous ways of knowing and knowledge routines that academic researchers practise.},
  isbn = {0539018414566},
  journal = {Social Science Information},
  keywords = {\#nosource,academic research,career,czech,discipline,knowledge production regime,project,temporality,transversal,university}
}

@article{Smith2018,
  title = {Journal of {{Open Source Software}} ({{JOSS}}): Design and First-Year Review},
  author = {Smith, Arfon M. and Niemeyer, Kyle E. and Katz, Daniel S. and Barba, Lorena A. and Githinji, George and Gymrek, Melissa and Huff, Kathryn D. and Madan, Christopher R. and Mayes, Abigail Cabunoc and Moerman, Kevin M. and Prins, Pjotr and Ram, Karthik and Rokem, Ariel and Teal, Tracy K. and Guimera, Roman Valls and Vanderplas, Jacob T.},
  year = {2018},
  month = feb,
  volume = {4},
  pages = {e147},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.147},
  abstract = {This article describes the motivation, design, and progress of the Journal of Open Source Software (JOSS). JOSS is a free and open-access journal that publishes articles describing research software. It has the dual goals of improving the quality of the software submitted and providing a mechanism for research software developers to receive credit. While designed to work within the current merit system of science, JOSS addresses the dearth of rewards for key contributions to science made in the form of software. JOSS publishes articles that encapsulate scholarship contained in the software itself, and its rigorous peer review targets the software components: functionality, documentation, tests, continuous integration, and the license. A JOSS article contains an abstract describing the purpose and functionality of the software, references, and a link to the software archive. The article is the entry point of a JOSS submission, which encompasses the full set of software artifacts. Submission and review proceed in the open, on GitHub. Editors, reviewers, and authors work collaboratively and openly. Unlike other journals, JOSS does not reject articles requiring major revision; while not yet accepted, articles remain visible and under review until the authors make adequate changes (or withdraw, if unable to meet requirements). Once an article is accepted, JOSS gives it a digital object identifier (DOI), deposits its metadata in Crossref, and the article can begin collecting citations on indexers like Google Scholar and other services. Authors retain copyright of their JOSS article, releasing it under a Creative Commons Attribution 4.0 International License. In its first year, starting in May 2016, JOSS published 111 articles, with more than 40 additional articles under review. JOSS is a sponsored project of the nonprofit organization NumFOCUS and is an affiliate of the Open Source Initiative (OSI).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GMQLX3JX\\smith_et_al_2018_journal_of_open_source_software_(joss).pdf},
  journal = {PeerJ Computer Science}
}

@article{Smith2018,
  title = {Evaluating the Implementation and Use of the Regional Cancer Plan in {{Western Sweden}} through Concept Mapping.},
  author = {Smith, Frida and Gunnarsdottir, Katrin Asta and Genell, Anna and McLinden, Daniel and Vaughn, Lisa and Garelius, Hege and {Nilsson-Ehle}, Herman and Lonqvist, Ulf and {Bjork-Eriksson}, Thomas},
  year = {2018},
  pages = {1--9},
  issn = {1464-3677 (Electronic)},
  doi = {10.1093/intqhc/mzy241},
  abstract = {Quality problem or issue: Within healthcare, policy documents are often used to strategically standardize, streamline or change how general health issues are managed for a specific patient group or treatment. Despite significant effort in developing policy and strategic planning documents, these may not have the intended impact and their value has long been questioned by practitioners. Choice of solution: To identify barriers and affordances for the implementation and use of a strategic plan for cancer care in the Western Sweden Healthcare Region, we used Concept Mapping; a participatory mixed method approach to inquiry consisting of both qualitative and quantitative tasks intended to elicit and integrate the diverse perspectives of multiple stakeholders. Implementation: The study was carried out between April and October 2017 and consisted of several sequential data collection steps: idea generation, sorting and rating ideas for importance and feasibility. Stakeholders from different levels and professions in cancercare participated, but the number varied in the separate steps of data collection: idea generation (n = 112), sorting (n = 16) and rating (n = 38). Evaluation: A concept map visualized seven areas that stakeholders throughout the cancer-care process considered necessary to address in order to enable the implementation of the plan. Skills provision was considered the most important cluster but also rated as least feasible. A consistent theme emerged that information, or lack thereof, might be a barrier for the plan being put into action to a greater extent in the cancer-care units. Nine actionable ideas rated highly on both importance and feasibility were presented as a go-zone. Lessons learned: Our results suggest that efforts might be better spent on ensuring information about and accessibility to strategic documents throughout the organization, rather than frequently updating them or producing new ones. Having sufficient skills provision seems to be the prerequisite for successful implementation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3Z8E5JY4\\smith_et_al_2018_evaluating_the_implementation_and_use_of_the_regional_cancer_plan_in_western.pdf},
  journal = {International journal for quality in health care : journal of the International Society for Quality in Health Care},
  pmid = {30576515}
}

@article{Smittenaar2016,
  title = {Cancer Incidence and Mortality Projections in the {{UK}} until 2035.},
  author = {Smittenaar, C R and Petersen, K A and Stewart, K and Moitt, N},
  year = {2016},
  volume = {115},
  pages = {1147--1155},
  publisher = {{Nature Publishing Group}},
  issn = {1532-1827},
  doi = {10.1038/bjc.2016.304},
  abstract = {BACKGROUND Cancer incidence and mortality projections are important for understanding the evolving landscape for cancer risk factors as well as anticipating future burden on the health service. METHODS We used an age-period-cohort model with natural cubic splines to estimate cancer cases and deaths from 2015 to 2035 based on 1979-2014 UK data. This was converted to rates using ONS population projections. Modified data sets were generated for breast and prostate cancers. RESULTS Cancer incidence rates are projected to decrease by 0.03\% in males and increase by 0.11\% in females yearly between 2015 and 2035; thyroid, liver, oral and kidney cancer are among the fastest accelerating cancers. 243 690 female and 270 261 male cancer cases are projected for 2035. Breast and prostate cancers are projected to be the most common cancers among females and males, respectively in 2035. Most cancers' mortality rate is decreasing; there are notable increases for liver, oral and anal cancer. For 2035, there are 95 961 female deaths projected and 116 585 male deaths projected. CONCLUSIONS These findings stress the need to continue efforts to address cancer risk factors. Furthermore, the increased burden of the number of cancer cases and deaths as a result of the growing and ageing population should be taken into consideration by healthcare planners.British Journal of Cancer advance online publication 11 October 2016; doi:10.1038/bjc.2016.304 www.bjcancer.com.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LD4V9RPU\\smittenaar_et_al_2016_cancer_incidence_and_mortality_projections_in_the_uk_until_2035.pdf},
  journal = {British journal of cancer},
  keywords = {cancer incidence and mortality,incidence,mortality,projections,projections in,uk},
  number = {9},
  pmid = {27727232}
}

@article{Sneeuw2002,
  title = {The Role of Health Care Providers and Significant Others in Evaluating the Quality of Life of Patients with Chronic Disease},
  author = {Sneeuw, Kommer C A and Sprangers, Mirjam A G and Aaronson, Neil K},
  year = {2002},
  volume = {55},
  pages = {1130--1143},
  issn = {08954356},
  doi = {10.1016/S0895-4356(02)00479-1},
  abstract = {Health-related quality of life (HRQL) studies sometimes rely, in part, on proxy information obtained from patients' significant others (spouse or close companion) or health care providers. This review: (1) provides a quantitative analysis of the results that have been reported in recent studies as-sessing the level of agreement between patient and proxy HRQL ratings, and (2) addresses a number of key methodological issues surrounding the use of proxy raters in HRQL research. This review concentrates on 23 studies, published between 1991\textendash 2000, that describe patient-proxy agreement for a number of well-known multidimensional HRQL instruments. In general, moderate to high levels of patient-proxy agreement were reported. Lower levels of agreement were found predominantly in studies employing a small sample size (approximately 50 patient-proxy pairs or less). In larger studies comparing patients and their significant others, median correlations were between 0.60\textendash 0.70 for physical HRQL domains and about 0.50 for psychosocial domains. Mixed results were reported in studies comparing patients and their health care providers, but most of these studies employed a relatively small sample size. Proxy raters tended to report more HRQL problems than patients themselves, but the magnitude of ob-served differences was modest (median standardized differences of about 0.20). Based on the current evidence, we conclude that judgements made by significant others and health care providers about several aspects of patients' HRQL are reasonably accurate. Substantial discrepancies between patient and proxy ratings occur in a minority of cases. We recommend that future studies focus on: (a) the reliability and validity of proxy ratings ac-cording to common psychometric methods, and (b) the balance between information bias due to proxy ratings and potential selection bias due to ex-clusion of important patient subgroups from HRQL studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5LGAEQ6G\\sneeuw_et_al_2002_the_role_of_health_care_providers_and_significant_others_in_evaluating_the.pdf},
  isbn = {0895-4356{\r  }0895-4356 (Linking)},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Agreement,Assessment,Proxy,Quality of life,Reliability,Validity},
  pmid = {12507678}
}

@article{Snell2017,
  title = {Meta-Analysis of Prediction Model Performance across Multiple Studies: {{Which}} Scale Helps Ensure between-Study Normality for the {{C}}-Statistic and Calibration Measures?:},
  shorttitle = {Meta-Analysis of Prediction Model Performance across Multiple Studies},
  author = {Snell, Kym IE and Ensor, Joie and Debray, Thomas PA and Moons, Karel GM and Riley, Richard D.},
  year = {2017},
  month = may,
  publisher = {{SAGE PublicationsSage UK: London, England}},
  doi = {10.1177/0962280217705678},
  abstract = {If individual participant data are available from multiple studies or clusters, then a prediction model can be externally validated multiple times. This allows ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4KT3CZKB\\Snell m. fl. - 2017 - Meta-analysis of prediction model performance acro.pdf;C\:\\Users\\erik_\\Zotero\\storage\\9VJFT79F\\0962280217705678.html},
  journal = {Statistical Methods in Medical Research},
  keywords = {acta review},
  language = {en}
}

@book{Socialstyrelsen1987,
  title = {Klassifikation Av Sjukdomar 1987: {{Systematisk}} F\"orteckning},
  author = {{Socialstyrelsen}},
  year = {1987},
  publisher = {{Liber Information}},
  city = {Stockholm},
  isbn = {91-38-09347-2},
  keywords = {\#nosource}
}

@article{Soderman2000,
  title = {Are the Findings in the Swedish National Total Hip Arthroplasty Register Valid? {{A}} Comparison between the Swedish National Total Hip Arthroplasty Register, the National Discharge Register, and the National Death Register.},
  author = {S{\"o}derman, P and Malchau, H and Herberts, P and Johnell, O},
  year = {2000},
  month = oct,
  volume = {15},
  pages = {884--9},
  issn = {0883-5403},
  abstract = {The Swedish National Total Hip Arthroplasty (THA) Register was initiated in 1979, and it is one of the oldest quality registers in the world. The register covers all hospitals in Sweden, and today it contains \textquestiondown{} 205,000 hip arthroplasties. The failure endpoint definition in the register is revision. There is no information about quality of life and mortality. The aim of this study was to validate the results presented by the Swedish THA register by comparison with the Discharge register (the Swedish National Board of Health and Welfare) and to study mortality after hip arthroplasties. All hip arthroplasties from the Discharge register, performed in 1986 and thereafter, were compared with the Swedish THA register. Epidemiologic parameters, including mortality, were documented from the Swedish Death register. The mortality for primary THAs for men was 1\% higher and for women 6\% higher when compared with an age-matched and sex-matched cohort. For revision, the numbers were 7\% and 9\% higher. The risk for death compared with an age-matched and sex-matched population was lower for patients with osteoarthrosis treated with hip arthroplasty. The results with revision as failure endpoint showed that the Swedish THA register is reliable. The register includes \textquestiondown 95\% of the primary and revision THAs performed in Sweden between 1986 and 1995.},
  journal = {The Journal of arthroplasty},
  keywords = {\#nosource},
  number = {7},
  pmid = {11061449}
}

@article{Soderman2001,
  title = {Outcome after Total Hip Arthroplasty: {{Part II}}. {{Disease}}-Specific Follow-up and the Swedish National Total Hip Arthroplasty Register.},
  author = {S{\"o}derman, P and Malchau, H and Herberts, P and Z{\"u}gner, R and Regn{\'e}r, H and Garellick, G},
  year = {2001},
  month = apr,
  volume = {72},
  pages = {113--9},
  issn = {0001-6470},
  doi = {10.1080/000164701317323345},
  abstract = {The Swedish National Total Hip Arthroplasty Register records primary hip replacements, revisions and surgical technique/environmental factors. The end-point for failure is revision. A prosthesis still in place, however, does not mean success. Clinical and radiographic outcomes should describe in more detail the efficacy of hip replacement surgery instead of the relatively blunt outcome measure that the register can provide. We performed a clinical outcome analysis on patients with primary total hip replacement thus testing the adequacy of the end-point for failure in the Swedish register. 1,113 randomly selected patients who had had total hip replacement surgery between 1986 and 1995 answered a disease-specific self-administered questionnaire (WOMAC). A cohort of 344 patients was studied, using the Harris Hip Score and a conventional radiographic examination as outcome measures. We found clinical failure rates of 13\% and 20\% for all implants after 10 years, using 60 points or revision as the definition of failure in the Harris Hip Score and WOMAC, respectively. The result, according to the register during the same period, was a 7\% revision rate. The clinical failure rate depended on the type of evaluation tool, definition of failure and demographics, which made it difficult to decide whether there was a need for revision. With the exception of pain measured by the Harris Hip Score, the results showed no significant correlation between clinical failure and radiographic failure. Hence, with the knowledge that there is a difference between the revision rate according to the register and clinical outcome, the strict definition of failure in the register is useful as an end-point for primary hip replacement surgery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F7SY5MWL\\söderman_et_al_2001_outcome_after_total_hip_arthroplasty.pdf},
  journal = {Acta orthopaedica Scandinavica},
  number = {2},
  pmid = {11372940}
}

@article{Solka1998,
  title = {Mixture Structure Analysis Using the {{Akaike Information Criterion}} and the Bootstrap},
  author = {Solka, Jeffrey L and Wegman, Edward J and Priebe, Carey E and Poston, Wendy L and Rogers, George W},
  year = {1998},
  volume = {8},
  pages = {177--188},
  abstract = {Given i.i.d. observations x 1 Y x 2 Y x 3 Y F F F Y x n drawn from a mixture of normal terms, one is often interested in determining the number of terms in the mixture and their de\textregistered ning parameters. Although the problem of determining the number of terms is intractable under the most general assumptions, there is hope of elucidating the mixture structure given appropriate caveats on the underlying mixture. This paper examines a new approach to this problem based on the use of Akaike Information Criterion (AIC) based pruning of data driven mixture models which are obtained from resampled data sets. Results of the application of this pro-cedure to arti\textregistered cially generated data sets and a real world data set are provided.},
  journal = {Statistics and Computing},
  keywords = {\#nosource,AIC,bootstrap,cluster analysis,mixture models}
}

@article{solknerFrailtyModelsSurvival1996,
  title = {Frailty Models in Survival Analysis},
  author = {S{\"o}lkner, Johanna},
  year = {1996},
  volume = {4},
  pages = {235--239},
  journal = {Journal of computing and information technology},
  keywords = {\#nosource}
}

@book{Solla2000,
  title = {Advances in Neural Information Processing Systems 12 : Proceedings of the 1999 Conference},
  author = {Solla, Sara A. and M{\"u}ller, Klaus-Robert. and Leen, Todd K. and Denver, Colorado) Neural Information Processing Systems (Conference) (13th : 1999 :},
  year = {2000},
  publisher = {{MIT Press}},
  abstract = {"This volume contains the papers presented at the thirteenth annual Neural Information Processing Systems (NIPS) conference, held in Colorado from November 29 through December 4, 1999"\textendash Preface.},
  isbn = {0-262-19450-3},
  keywords = {\#nosource}
}

@article{Soper1913,
  title = {On the Peobable Error of the Correlation Coefficient to a Second Approximation},
  author = {Soper, H. E.},
  year = {1913},
  volume = {9},
  pages = {91--115},
  issn = {00063444},
  doi = {10.1093/biomet/9.1-2.91},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Z8D9BTQP\\soper_1913_on_the_peobable_error_of_the_correlation_coefficient_to_a_second_approximation.pdf},
  journal = {Biometrika},
  number = {1-2}
}

@article{Sousa2008,
  title = {Connecting Knowledge to Management: {{The}} Case of Academic Research},
  author = {Sousa, Celio and Hendriks, Paul},
  year = {2008},
  volume = {15},
  pages = {811--830},
  issn = {13505084},
  doi = {10.1177/1350508408091004},
  abstract = {Drawing on in-depth interviews with research managers, this paper argues that academic research management is ideologically close to knowledge management. The research followed a grounded theory approach. This method appears particularly suited for this inquiry, due to the absence of a dominant theoretical framework, the consequent need for extra theorizing, and the appeal to develop a theoretical account that relies on the most privileged sources of this knowledge, namely research managers. The data analysis shows that competing conceptualizations of knowledge and associated management models provide the playground for academic research management. Owing to the impact of cultural and behavioural aspects in the dynamics of knowledge creation, shaping collectively crafted courses of action\textemdash rather than managing them\textemdash aptly represents the essence of academic research management.},
  isbn = {1350-5084},
  journal = {Organization},
  keywords = {\#nosource,academic research management • grounded theory app},
  number = {6}
}

@article{Southern2004,
  title = {Comparison of the Elixhauser and Charlson/Deyo Methods of Comorbidity Measurement in Administrative Data},
  author = {Southern, Danielle A. and Quan, Hude and Ghali, William A.},
  year = {2004},
  volume = {42},
  pages = {355--360},
  issn = {00257079},
  doi = {10.1097/01.mlr.0000118861.56848.ee},
  abstract = {Background: Comorbidity risk adjustment methods have been used widely with administrative data, and the Charlson/Deyo method is perhaps the most commonly used in the literature. However, a new method defined by Elixhauser et al. has been introduced recently and could be superior, although it has not been validated widely. Objectives: We compared the Charlson/Deyo and Elixhauser methods using Canadian administrative data on patients with myocardial infarction (MI). Research Design: We conducted a historical cohort study. Subjects: We used administrative hospital discharge data from a large Canadian city for all cases with acute MI coded as most responsible diagnosis between January 1, 1995, and March 31, 2001. Measures: We used each of the 2 methods to define comorbidity variables based on the International Classification of Diseases, 9th Revision, Clinical Modification codes present in each case record. We then compared 2 models predicting in-hospital mortality based on presence or absence of the variables defined by each of the methods. Frequency tables were produced and c-statistics and changes in -2 log likelihood (-2LogL) were calculated. We also visually assessed model performance by plotting observed and expected percentages of death for increasing risk categories defined by the 2 models. Results: The Elixhauser model outperformed the Charlson/Deyo model in predicting mortality, with higher c-statistic values (0.793 vs. 0.704). Superior performance of the Elixhauser method is confirmed when plotting the expected and observed risks of death across groupings of increasing risk, in which the Elixhauser method yields a wider range of predicted and observed probabilities of death across groupings (2.5\%-33\%) than does the Charlson/Deyo method (5\%-25\%). Conclusions: The Elixhauser comorbidity measurement method performs better than the widely used Charlson/Deyo method in the Canadian acute MI cases studied.},
  isbn = {0025-7079 (Print){\r  }0025-7079 (Linking)},
  journal = {Medical Care},
  keywords = {\#nosource,355-360,42,although it has not,been validated widely,charlson,Charlson,comorbidity index,Comorbidity index,could be superior,deyo and elixhauser meth-,elixhauser,Elixhauser,icd-9-cm,ICD-9-CM,med care 2004,objectives,we compared the charlson},
  number = {4},
  pmid = {15076812}
}

@article{Spencer2012,
  title = {Hospital Episode Statistics: {{Improving}} the Quality and Value of Hospital Data: {{A}} National Internet e-Survey of Hospital Consultants},
  author = {Spencer, Stephen Andrew and Davies, Mark Price},
  year = {2012},
  volume = {2},
  issn = {20446055},
  doi = {10.1136/bmjopen-2012-001651},
  abstract = {Hypothesis: Senior hospital clinicians are poorly engaged with clinical coding and hospital episode statistics (HES). Aims: {$\RHD$}To understand the current level of clinical engagement with collection of national data and clinical coding. {$\RHD$}To gain the views of frontline staff on proposed improvements to hospital statistics. {$\RHD$}To gain an indication of likely clinical engagement in change. {$\RHD$}To understand the clinical priority for improvement. Design: Internet e-survey accessible from Academy of Royal Medical College Website. Setting: National Health Service (NHS) Trusts. Participants: 1081 NHS hospital consultants and two general practitioners who volunteered to take part. Results: 3.4\% of the sample regularly access HES data; 21\% are regularly involved in clinical coding and 6.2\% meet coding staff at least monthly. 95\% would like to access HES data and there was a strong support for using this data for appraisal, revalidation and improving the quality of patient care. In terms of improvements, 91.9\% would be prepared to code diagnosis in outpatients given the right tools. The highest priority for improvement is clinical validation of diagnostic data. Conclusions: Clinical engagement with coding and access to HES data is poor. However, there is professional support for improvement. Clinical requirements should be considered in all future developments of national data collection to provide the quality and scope of data that is required to deliver the information revolution.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UFFD5KXG\\spencer_davies_2012_hospital_episode_statistics.pdf},
  journal = {BMJ Open},
  number = {6}
}

@article{Sperrin2020,
  title = {Prediction Models for Diagnosis and Prognosis in {{Covid}}-19},
  author = {Sperrin, Matthew and Grant, Stuart W. and Peek, Niels},
  year = {2020},
  month = apr,
  volume = {369},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m1464},
  abstract = {{$<$}p{$>$}All models are wrong but data sharing and better reporting could improve this{$<$}/p{$>$}},
  chapter = {Editorial},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com.ezproxy.ub.gu.se/group/rights-licensing/permissions},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3MBZEQMV\\sperrin_et_al_2020_prediction_models_for_diagnosis_and_prognosis_in_covid-19.pdf;C\:\\Users\\erik_\\Zotero\\storage\\TPTPL39F\\bmj.html},
  journal = {BMJ},
  keywords = {coverletter},
  language = {en},
  pmid = {32291266}
}

@article{Spiegelhalter1986,
  title = {Probabilistic Prediction in Patient Management and Clinical Trials},
  author = {Spiegelhalter, D. J.},
  year = {1986},
  month = sep,
  volume = {5},
  pages = {421--433},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {02776715},
  doi = {10.1002/sim.4780050506},
  journal = {Statistics in Medicine},
  keywords = {\#nosource,Bayesian inference,Clinical trials,Logistic regression,Prediction,Shrinkage,Subjective probability},
  number = {5}
}

@article{Spiegelhalter2005,
  title = {Funnel Plots for Comparing Institutional Performance},
  author = {Spiegelhalter, David J.},
  year = {2005},
  volume = {24},
  pages = {1185--1202},
  issn = {02776715},
  doi = {10.1002/sim.1970},
  abstract = {'Funnel plots' are recommended as a graphical aid for institutional comparisons, in which an estimate of an underlying quantity is plotted against an interpretable measure of its precision. 'Control limits' form a funnel around the target outcome, in a close analogy to standard Shewhart control charts. Examples are given for comparing proportions and changes in rates, assessing association between outcome and volume of cases, and dealing with over-dispersion due to unmeasured risk factors. We conclude that funnel plots are flexible, attractively simple, and avoid spurious ranking of institutions into 'league tables'.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KBHNXP26\\spiegelhalter_2005_funnel_plots_for_comparing_institutional_performance.pdf},
  isbn = {0277-6715 (Print)},
  journal = {Statistics in Medicine},
  keywords = {Control charts,Institutional profiling,Outliers,Over-dispersion,Ranking},
  number = {8},
  pmid = {15568194}
}

@article{Sprague2018,
  title = {Factors Associated with Health-Related Quality of Life, Hip Function, and Health Utility after Operative Management of Femoral Neck Fractures},
  author = {Sprague, S. and Bhandari, M. and Heetveld, M. J. and Liew, S. and Scott, T. and Bzovsky, S. and {Heels-Ansdell}, D. and Zhou, Q. and Swiontkowski, M. and Schemitsch, E. H.},
  year = {2018},
  volume = {100-B},
  pages = {361--369},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.100B3.BJJ-2017-0853.R1},
  abstract = {Aims The primary aim of this prognostic study was to identify baseline factors associated with physical health-related quality of life (HRQL) in patients after a femoral neck fracture. The secondary aims were to identify baseline factors associated with mental HRQL, hip function, and health utility. Patients and Methods Patients who were enrolled in the Fixation using Alternative Implants for the Treatment of Hip Fractures (FAITH) trial completed the 12-item Short Form Health Survey (SF-12), Western Ontario and McMaster Universities Arthritis Index, and EuroQol 5-Dimension at regular intervals for 24 months. We conducted multilevel mixed models to identify factors potentially associated with HRQL. Results The following were associated with lower physical HRQL: older age (-1.42 for every ten-year increase, 95\% confidence interval (CI) -2.17 to -0.67, p \textexclamdown{} 0.001); female gender (-1.52, 95\% CI -3.00 to -0.05, p = 0.04); higher body mass index (-0.69 for every five-point increase, 95\% CI -1.36 to -0.02, p = 0.04); American Society of Anesthesiologists class III ( versus class I) (-3.19, 95\% CI -5.73 to -0.66, p = 0.01); and sustaining a displaced fracture (-2.18, 95\% CI -3.88 to -0.49, p = 0.01). Additional factors were associated with mental HRQL, hip function, and health utility. Conclusion We identified several baseline factors associated with lower HRQL, hip function, and utility after a femoral neck fracture. These findings may be used by clinicians to inform treatment and outcomes. Cite this article: Bone Joint J 2018;100-B:361-9.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QFCGC7XK\\sprague_et_al_2018_factors_associated_with_health-related_quality_of_life,_hip_function,_and.pdf},
  journal = {The Bone \& Joint Journal},
  number = {3},
  pmid = {29589490}
}

@article{Sprangers1999,
  title = {Integrating Response Shift into Health-Related Quality of Life Research: {{A}} Theoretical Model},
  author = {Sprangers, M A G and Schwartz, C E},
  year = {1999},
  volume = {48},
  pages = {1507--1515},
  journal = {Social Science and Medicine},
  keywords = {\#nosource,change,quality of life,response shift,self-report,theory},
  number = {1999}
}

@article{Springate2014,
  title = {{{ClinicalCodes}}: {{An}} Online Clinical Codes Repository to Improve the Validity and Reproducibility of Research Using Electronic Medical Records},
  author = {Springate, David A. and Kontopantelis, Evangelos and Ashcroft, Darren M. and Olier, Ivan and Parisi, Rosa and Chamapiwa, Edmore and Reeves, David},
  year = {2014},
  volume = {9},
  pages = {6--11},
  issn = {19326203},
  doi = {10.1371/journal.pone.0099825},
  abstract = {Lists of clinical codes are the foundation for research undertaken using electronic medical records (EMRs). If clinical code lists are not available, reviewers are unable to determine the validity of research, full study replication is impossible, researchers are unable to make effective comparisons between studies, and the construction of new code lists is subject to much duplication of effort. Despite this, the publication of clinical codes is rarely if ever a requirement for obtaining grants, validating protocols, or publishing research. In a representative sample of 450 EMR primary research articles indexed on PubMed, we found that only 19 (5.1\%) were accompanied by a full set of published clinical codes and 32 (8.6\%) stated that code lists were available on request. To help address these problems, we have built an online repository where researchers using EMRs can upload and download lists of clinical codes. The repository will enable clinical researchers to better validate EMR studies, build on previous code lists and compare disease definitions across studies. It will also assist health informaticians in replicating database studies, tracking changes in disease definitions or clinical coding practice through time and sharing clinical code information across platforms and data sources as research objects.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7IIKLI7L\\springate_et_al_2014_clinicalcodes.pdf},
  isbn = {1932-6203},
  journal = {PLoS ONE},
  number = {6},
  pmid = {24941260}
}

@article{Springate2017,
  title = {{{rEHR}}: {{An R}} Package for Manipulating and Analysing {{Electronic Health Record}} Data},
  shorttitle = {{{rEHR}}},
  author = {Springate, David A. and Parisi, Rosa and Olier, Ivan and Reeves, David and Kontopantelis, Evangelos},
  editor = {Harezlak, Jaroslaw},
  year = {2017},
  month = feb,
  volume = {12},
  pages = {e0171784},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0171784},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JJBCMYWT\\Springate m. fl. - 2017 - rEHR An R package for manipulating and analysing .pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {2}
}

@article{Spurk2015,
  title = {Fostering Networking Behavior, Career Planning and Optimism, and Subjective Career Success: {{An}} Intervention Study},
  author = {Spurk, Daniel and Kauffeld, Simone and Barthauer, Luisa and Heinemann, Nora S R},
  year = {2015},
  volume = {87},
  pages = {134--144},
  publisher = {{Elsevier Inc.}},
  issn = {00018791},
  doi = {10.1016/j.jvb.2014.12.007},
  abstract = {The present study evaluated personal resource-oriented interventions supporting the career development of young academics, working at German universities within the STEM fields. The study sought to foster subjective career success by improving networking behavior, career planning, and career optimism. The study involved a quasi-experimental pre-post intervention with two intervention and two control groups (N= 81 research associates). Participants of the first intervention group received networking training; participants of the second intervention group received the same networking training plus individual career coaching. Participants of both intervention groups were female. Participants of the control groups (i.e., male vs. female group) did not participate in any intervention. As expected, path analyses, based on mean differences from pre-test to post-test, revealed an increase in career planning and career optimism within the networking plus career coaching intervention group, that was indirectly positively related to changes in subjective career success. Contrary to our expectations, the networking group training alone and in combination with the career coaching showed no effectiveness in fostering networking behavior. Results are discussed in the context of career counseling and intervention effectiveness studies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8NPVPK3R\\spurk_et_al_2015_fostering_networking_behavior,_career_planning_and_optimism,_and_subjective.pdf},
  isbn = {0001-8791},
  journal = {Journal of Vocational Behavior},
  keywords = {Career intervention effectiveness,Career optimism,Career planning,Career success,Networking}
}

@book{Staaf2016,
  title = {F\"orvaltningsr\"att: En Introduktion F\"or Professionsutbildningar},
  author = {Staaf, Annika and Zanderin, Lars and Staaf, Annika},
  year = {2016},
  keywords = {\#nosource}
}

@book{staffIEEESignalProcessing2002,
  title = {{{IEEE}} Signal Processing Society Workshop - Neural Networks for Signal Processing 2002.},
  author = {Staff, IEEE Signal Processing Society},
  year = {2002},
  publisher = {{I E E E}},
  isbn = {0-7803-7616-1},
  keywords = {\#nosource}
}

@article{Stafford2012,
  title = {Total Hip Replacement for the Treatment of Acute Femoral Neck Fractures: Results from the {{National Joint Registry}} of {{England}} and {{Wales}} at 3-5 Years after Surgery},
  author = {Stafford, GH and Charman, SC and Borroff, MJ and Newell, C and Tucker, JK},
  year = {2012},
  month = apr,
  volume = {94},
  pages = {193--198},
  issn = {0035-8843},
  doi = {10.1308/003588412X13171221589720},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\935FW68U\\stafford_et_al_2012_total_hip_replacement_for_the_treatment_of_acute_femoral_neck_fractures.pdf},
  journal = {The Annals of The Royal College of Surgeons of England},
  number = {3}
}

@article{Stanfill2010,
  title = {A Systematic Literature Review of Automated Clinical Coding and Classification Systems},
  author = {Stanfill, Mary H and Williams, Margaret and Fenton, Susan H and Jenders, Robert A and Hersh, William R},
  year = {2010},
  month = nov,
  volume = {17},
  pages = {646--651},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/jamia.2009.001024},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\G33HC9DY\\Stanfill m. fl. - 2010 - A systematic literature review of automated clinic.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {6}
}

@article{Stanghellini2019,
  title = {On Marginal and Conditional Parameters in Logistic Regression Models},
  author = {Stanghellini, Elena and Doretti, Marco},
  year = {2019},
  month = sep,
  volume = {106},
  pages = {732--739},
  publisher = {{Oxford Academic}},
  issn = {0006-3444},
  doi = {10.1093/biomet/asz019},
  abstract = {Summary.  We derive the exact formula linking the parameters of marginal and conditional logistic regression models with binary mediators when no conditional in},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XIHPF7NQ\\Stanghellini och Doretti - 2019 - On marginal and conditional parameters in logistic.pdf;C\:\\Users\\erik_\\Zotero\\storage\\565YI58K\\5488514.html},
  journal = {Biometrika},
  language = {en},
  number = {3}
}

@article{Stare2005,
  title = {Goodness of Fit of Relative Survival Models},
  author = {Stare, Janez and Pohar, Maja and Henderson, Robin},
  year = {2005},
  volume = {24},
  pages = {3911--3925},
  issn = {02776715},
  doi = {10.1002/sim.2414},
  abstract = {Additive regression models are preferred over multiplicative models in the analysis of relative survival data. Such preferences are mainly grounded in practical experience with mostly cancer registries data, where the basic assumption of the additivity of hazards is more likely to be met. Also, the interpretation of coefficients is more meaningful in additive than in multiplicative models. Nonetheless, the question of goodness of fit of the assumed model must still be addressed, and while there is an abundance of methods to check the goodness of fit of multiplicative models, the respective arsenal for additive models is almost empty. We propose here a variety of procedures for testing the null hypothesis of a good fit. These are based on partial residuals defined similarly to Schoenfeld residuals familiar for Cox model diagnostics. The tests have appropriate sizes under the null hypothesis, and good power under different alternatives. We investigate their performance through simulations and apply the methods to data from a study into survival of colon cancer patients.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LHD3FEMH\\stare_et_al_2005_goodness_of_fit_of_relative_survival_models.pdf},
  journal = {Statistics in Medicine},
  keywords = {Goodness of fit,Model diagnostics,Relative survival regression},
  number = {24},
  pmid = {16320279}
}

@article{Stare2016,
  title = {Odds Ratio, Hazard Ratio and Relative Risk},
  author = {Stare, Janez and {Maucort-Boulch}, Delphine},
  year = {2016},
  volume = {13},
  pages = {59--67},
  issn = {0151-9638},
  abstract = {Odds ratio (OR) is a statistic commonly encountered in professional or scientific medical literature. Most readers perceive it as relative risk (RR), although most of them do not know why that would be true. But since such perception is mostly correct, there is nothing (or almost nothing) wrong with that. It is nevertheless useful to be reminded now and then what is the relation between the relative risk and the odds ratio, and when by equating the two statistics we are sometimes forcing OR to be something it is not. Another statistic, which is often also perceived as a relative risk, is the hazard ratio (HR). We encounter it, for example, when we fit the Cox model to survival data. Under proportional hazards it is probably " natural " to think in the following way: if the probability of death in one group is at every time point k-times as high as the probability of death in another group, then the relative risk must be k, regardless of where in time we are. This could be hardly further from the truth and in this paper we try to dispense with this blunder.},
  isbn = {0151-9638},
  journal = {Metodoloski zvezki},
  keywords = {\#nosource},
  number = {1},
  pmid = {14724550}
}

@article{Stattin2018,
  title = {Public Online Reporting from a Nationwide Population-Based Clinical Prostate Cancer Register},
  author = {Stattin, P{\"a}r and Sandin, Fredrik and Loeb, Stacy and Robinson, David and Lissbrant, Ingela Franck and Lambe, Mats},
  year = {2018},
  volume = {122},
  pages = {8--10},
  issn = {14644096},
  doi = {10.1111/bju.14213},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V96WNAWQ\\stattin_et_al_2018_public_online_reporting_from_a_nationwide_population-based_clinical_prostate.pdf},
  journal = {BJU International},
  number = {1}
}

@article{Stawicki2015,
  title = {Comorbidity Polypharmacy Score and Its Clinical Utility: {{A}} Pragmatic Practitioner's Perspective},
  author = {Stawicki, Stanislaw P and Kalra, Sarathi and Jones, Christian and Justiniano, Carla F and Papadimos, Thomas J and Galwankar, Sagar C and Pappada, Scott M and Feeney, John J and Evans, David C},
  year = {2015},
  volume = {8},
  pages = {224--231},
  publisher = {{Medknow Publications \& Media Pvt Ltd}},
  issn = {0974-2700},
  doi = {10.4103/0974-2700.161658},
  abstract = {Modern medical management of comorbid conditions has resulted in escalating use of multiple medications and the emergence of the twin phenomena of multimorbidity and polypharmacy. Current understanding of how the polypharmacy in conjunction with multimorbidity influences trauma outcomes is limited, although it is known that trauma patients are at increased risk for medication-related adverse events. The comorbidity-polypharmacy score (CPS) is a simple clinical tool that quantifies the overall severity of comorbidities using the polypharmacy as a surrogate for the "intensity" of treatment necessary to adequately control chronic medical conditions. Easy to calculate, CPS is derived by counting all known pre-injury comorbid conditions and medications. CPS has been independently associated with mortality, increased risk for complications, lower functional outcomes, readmissions, and longer hospital stays. In addition, CPS may help identify older trauma patients at risk of post-emergency department undertriage. The goal of this article was to review and refine the rationale for CPS and to provide an evidence-based outline of its potential clinical applications.},
  journal = {Journal of emergencies, trauma, and shock},
  keywords = {\#nosource},
  number = {4}
}

@article{Stefanski2002,
  title = {The Calculus of {{M}}-Estimation},
  author = {Stefanski, Leonard A. and Boos, Dennis D.},
  year = {2002},
  volume = {56},
  pages = {29--38},
  issn = {00031305},
  doi = {10.1198/000313002753631330},
  abstract = {Since the seminal papers by Huber in the 1960s, M-estimation methods (also known as estimating equation methods) have been increasingly important for asymptotic analysis and approximate inference. This article illustrates the breadth and generality of the M-estimation approach, thereby facilitating its use in practice and in the classroom as a unifying approach to the study of large-sample inference.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\T2QXAH7X\\stefanski_boos_2002_the_calculus_of_m-estimation.pdf},
  journal = {American Statistician},
  keywords = {Asymptotic variance,Central limit theorem,Estimating equations,Large-sample inference,M-estimator,Maple},
  number = {1}
}

@article{Steiger1992,
  title = {R2: {{A}} Computer Program for Interval Estimation, Power {{Calculations}}, Sample Size Estimation, and Hypothesis Testing in Multiple Regression},
  author = {Steiger, James H. and Fouladi, Rachel T.},
  year = {1992},
  month = dec,
  volume = {24},
  pages = {581--582},
  issn = {0743-3808},
  doi = {10.3758/BF03203611},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\B8UEZT4Z\\steiger_fouladi_1992_r2.pdf},
  journal = {Behavior Research Methods, Instruments, \& Computers},
  number = {4}
}

@article{steliarova-foucherQualityComparabilityMethods2006,
  title = {Quality, Comparability and Methods of Analysis of Data on Childhood Cancer in {{Europe}} (1978\textendash 1997): {{Report}} from the {{Automated Childhood Cancer Information System}} Project},
  author = {{Steliarova-Foucher}, E. and Kaatsch, P. and Lacour, B. and {Pompe-Kirn}, V. and Eser, S. and Miranda, A. and Danzon, A. and Ratiu, A. and Parkin, D.M.},
  year = {2006},
  month = sep,
  volume = {42},
  pages = {1915--1951},
  issn = {09598049},
  doi = {10.1016/j.ejca.2006.05.007},
  abstract = {In collaboration with 62 population-based cancer registries contributing to the Automated Childhood Cancer Information System (ACCIS), we built a database to study incidence and survival of children and adolescents with cancer in Europe. We describe the methods and evaluate the quality and internal comparability of the database, by geographical region, period of registration, type of registry and other characteristics. Data on 88,465 childhood and 15,369 adolescent tumours registered during 1978-1997 were available. Geographical differences in incidence are caused partly by differences in definition of eligible cases. The observed increase in incidence rates cannot be explained by biases due to the selection of datasets for analyses, and only partially by the registration of non-malignant or multiple primary tumours. Part of the observed differences in survival between the regions may be due to variable completeness of follow-up, but most is probably explained by resource availability and organisation of care. Further standardisation of data and collection of additional variables are required so that this study may continue to yield valuable results with reliable interpretation. ?? 2006 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8FHTKLU8\\steliarova-foucher_et_al_2006_quality,_comparability_and_methods_of_analysis_of_data_on_childhood_cancer_in.pdf},
  isbn = {0959-8049 (Print)0959-8049 (Linking)},
  journal = {European Journal of Cancer},
  keywords = {Childhood cancer,Data quality,Epidemiology,Europe,Incidence,Registry,Survival},
  number = {13},
  pmid = {16919762}
}

@article{Stengel2017,
  title = {Recruitment Rates in Orthopaedic Trauma Trials: {{Zen}} or the Art of Riding Dead Horses},
  author = {Stengel, Dirk and Mauffrey, Cyril and Civil, Ian and Gray, A.C. and Roberts, C. and Pape, Hans-Christoph and Evans, C. and Kool, Bridget and Mauffrey, O.J. and Giannoudis, Peter},
  year = {2017},
  volume = {48},
  pages = {1719--1721},
  issn = {00201383},
  doi = {10.1016/j.injury.2017.07.028},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JPQ9HXG9\\stengel_et_al_2017_recruitment_rates_in_orthopaedic_trauma_trials.pdf},
  journal = {Injury},
  number = {8}
}

@generic{Stensrud2019,
  title = {Limitations of Hazard Ratios in Clinical Trials},
  author = {Stensrud, Mats J. and Aalen, John M. and Aalen, Odd O. and Valberg, Morten},
  year = {2019},
  month = may,
  volume = {40},
  pages = {1378--1383},
  publisher = {{Oxford University Press}},
  issn = {15229645},
  doi = {10.1093/eurheartj/ehy770},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8F3NVZVR\\stensrud_et_al_2019_limitations_of_hazard_ratios_in_clinical_trials.pdf},
  journal = {European Heart Journal},
  number = {17}
}

@article{Steyerberg2001,
  title = {Internal Validation of Predictive Models},
  author = {Steyerberg, Ewout W and Harrell, Frank E. and Borsboom, Gerard J.J.M and Eijkemans, M.J.C and Vergouwe, Yvonne and Habbema, J.Dik F},
  year = {2001},
  month = aug,
  volume = {54},
  pages = {774--781},
  publisher = {{Pergamon}},
  issn = {08954356},
  doi = {10.1016/S0895-4356(01)00341-9},
  abstract = {The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10\% of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GKW6C6JW\\steyerberg_et_al_2001_internal_validation_of_predictive_models.pdf},
  isbn = {0895-4356 (Print)},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Bootstrapping,Internal validation,Logistic regression analysis,Predictive models},
  number = {8},
  pmid = {11470385}
}

@article{Steyerberg2004,
  title = {Validation and Updating of Predictive Logistic Regression Models: A Study on Sample Size and Shrinkage},
  author = {Steyerberg, Ewout W. and Borsboom, Gerard J. J. M. and {van Houwelingen}, Hans C. and Eijkemans, Marinus J. C. and Habbema, J. Dik F.},
  year = {2004},
  month = aug,
  volume = {23},
  pages = {2567--2586},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0277-6715},
  doi = {10.1002/sim.1844},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\MJDEGJNF\\steyerberg_et_al_2004_validation_and_updating_of_predictive_logistic_regression_models.pdf},
  journal = {Statistics in Medicine},
  keywords = {logistic regression,shrinkage,updating,validation},
  number = {16}
}

@article{Steyerberg2010,
  title = {Assessing the Performance of Prediction Models: A Framework for Traditional and Novel Measures.},
  author = {Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
  year = {2010},
  month = jan,
  volume = {21},
  pages = {128--38},
  issn = {1531-5487},
  doi = {10.1097/EDE.0b013e3181c30fb2},
  abstract = {The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration.Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision-analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions.We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation).We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Z52P48S4\\steyerberg_et_al_2010_assessing_the_performance_of_prediction_models.pdf},
  journal = {Epidemiology (Cambridge, Mass.)},
  number = {1},
  pmid = {20010215}
}

@article{Steyerberg2014,
  title = {Towards Better Clinical Prediction Models: {{Seven}} Steps for Development and an {{ABCD}} for Validation},
  author = {Steyerberg, Ewout W. and Vergouwe, Yvonne},
  year = {2014},
  volume = {35},
  pages = {1925--1931},
  issn = {15229645},
  doi = {10.1093/eurheartj/ehu207},
  abstract = {Clinical prediction models provide risk estimates for the presence of disease (diagnosis) or an event in the future course of disease (prognosis) for individual patients. Although publications that present and evaluate such models are becoming more frequent, the methodology is often suboptimal. We propose that seven steps should be considered in developing prediction models: (i) consideration of the research question and initial data inspection; (ii) coding of predictors; (iii) model specification; (iv) model estimation; (v) evaluation of model performance; (vi) internal validation; and (vii) model presentation. The validity of a prediction model is ideally assessed in fully independent data, where we propose four key measures to evaluate model performance: calibration-in-the-large, or the model intercept (A); calibration slope (B); discrimination, with a concordance statistic (C); and clinical usefulness, with decision-curve analysis (D). As an application, we develop and validate prediction models for 30-day mortality in patients with an acute myocardial infarction. This illustrates the usefulness of the proposed framework to strengthen the methodological rigour and quality for prediction models in cardiovascular research.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZJAMLXPB\\steyerberg_vergouwe_2014_towards_better_clinical_prediction_models.pdf},
  isbn = {1522-9645 (Electronic){\r  }0195-668X (Linking)},
  journal = {European Heart Journal},
  keywords = {Calibration,Clinical usefulness,Discrimination,Missing values,Non-linearity,Prediction model,Shrinkage},
  number = {29},
  pmid = {24898551}
}

@article{Steyerberg2016,
  title = {Prediction Models Need Appropriate Internal, Internal\textendash External, and External Validation},
  author = {Steyerberg, Ewout W. and Harrell, Frank E.},
  year = {2016},
  month = jan,
  volume = {69},
  pages = {245--247},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2015.04.005},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4KJEF2H6\\Steyerberg och Harrell - 2016 - Prediction models need appropriate internal, inter.pdf},
  journal = {Journal of Clinical Epidemiology},
  keywords = {acta review},
  language = {en}
}

@article{Steyerberg2018,
  title = {Poor Performance of Clinical Prediction Models: The Harm of Commonly Applied Methods},
  author = {Steyerberg, Ewout W. and Uno, Hajime and Ioannidis, John P.A. and {van Calster}, Ben and Ukaegbu, Chinedu and Dhingra, Tara and Syngal, Sapna and Kastrinos, Fay},
  year = {2018},
  month = jun,
  volume = {98},
  pages = {133--143},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/J.JCLINEPI.2017.11.013},
  abstract = {OBJECTIVE To evaluate limitations of common statistical modeling approaches in deriving clinical prediction models and explore alternative strategies. STUDY DESIGN AND SETTING A previously published model predicted the likelihood of having a mutation in germline DNA mismatch repair genes at the time of diagnosis of colorectal cancer. This model was based on a cohort where 38 mutations were found among 870 participants, with validation in an independent cohort with 35 mutations. The modeling strategy included stepwise selection of predictors from a pool of over 37 candidate predictors and dichotomization of continuous predictors. We simulated this strategy in small subsets of a large contemporary cohort (2,051 mutations among 19,866 participants) and made comparisons to other modeling approaches. All models were evaluated according to bias and discriminative ability (concordance index, c) in independent data. RESULTS We found over 50\% bias for five of six originally selected predictors, unstable model specification, and poor performance at validation (median c = 0.74). A small validation sample hampered stable assessment of performance. Model prespecification based on external knowledge and using continuous predictors led to better performance (c = 0.836 and c = 0.852 with 38 and 2,051 events respectively). CONCLUSION Prediction models perform poorly if based on small numbers of events and developed with common but suboptimal statistical approaches. Alternative modeling strategies to best exploit available predictive information need wider implementation, with collaborative research to increase sample sizes.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7BU4F9YV\\steyerberg_et_al_2018_poor_performance_of_clinical_prediction_models.pdf},
  journal = {Journal of Clinical Epidemiology}
}

@book{Steyerberg2019,
  title = {Clinical Prediction Models. {{Statistics}} for Biology and Health. 2nd Edition},
  author = {Steyerberg, E W},
  year = {2019},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3PGWZSAI\\2019-Clinical_Prediction_Models._Statistics_for_Biology_and_Health._2nd_edition.pdf},
  isbn = {978-0-387-77243-1},
  keywords = {\#nosource}
}

@book{Stockholm2017,
  title = {Personuppgiftsbehandling F\"or Forsknings\"andam\aa l},
  author = {Stockholm, Forskningsdatautredningen},
  year = {2017},
  isbn = {978-91-38-24625-2},
  keywords = {\#nosource}
}

@article{Stommel2009,
  title = {Accuracy and Usefulness of {{BMI}} Measures Based on Self-Reported Weight and Height: {{Findings}} from the {{NHANES}} \& {{NHIS}} 2001-2006},
  author = {Stommel, Manfred and Schoenborn, Charlotte A.},
  year = {2009},
  month = nov,
  volume = {9},
  pages = {1--10},
  publisher = {{BioMed Central}},
  issn = {14712458},
  doi = {10.1186/1471-2458-9-421},
  abstract = {Background: The Body Mass Index (BMI) based on self-reported height and weight (self-reported BMI) in epidemiologic studies is subject to measurement error. However, because of the ease and efficiency in gathering height and weight information through interviews, it remains important to assess the extent of error present in self-reported BMI measures and to explore possible adjustment factors as well as valid uses of such self-reported measures. Methods: Using the combined 2001-2006 data from the continuous National Health and Nutrition Examination Survey, discrepancies between BMI measures based on self-reported and physical height and weight measures are estimated and socio-demographic predictors of such discrepancies are identified. Employing adjustments derived from the socio-demographic predictors, the self-reported measures of height and weight in the 2001-2006 National Health Interview Survey are used for population estimates of overweight \& obesity as well as the prediction of health risks associated with large BMI values. The analysis relies on two-way frequency tables as well as linear and logistic regression models. All point and variance estimates take into account the complex survey design of the studies involved. Results: Self-reported BMI values tend to overestimate measured BMI values at the low end of the BMI scale (\textexclamdown{} 22) and underestimate BMI values at the high end, particularly at values \textquestiondown{} 28. The discrepancies also vary systematically with age (younger and older respondents underestimate their BMI more than respondents aged 42-55), gender and the ethnic/racial background of the respondents. BMI scores, adjusted for socio-demographic characteristics of the respondents, tend to narrow, but do not eliminate misclassification of obese people as merely overweight, but health risk estimates associated with variations in BMI values are virtually the same, whether based on self-report or measured BMI values. Conclusion: BMI values based on self-reported height and weight, if corrected for biases associated with socio-demographic characteristics of the survey respondents, can be used to estimate health risks associated with variations in BMI, particularly when using parametric prediction models. \textcopyright{} 2009 Stommel and Schoenborn; licensee BioMed Central Ltd.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ELC745IJ\\stommel_schoenborn_2009_accuracy_and_usefulness_of_bmi_measures_based_on_self-reported_weight_and_height.pdf},
  journal = {BMC Public Health},
  keywords = {Biostatistics,Environmental Health,Epidemiology,general,Medicine/Public Health,Public Health,Vaccine},
  number = {1}
}

@article{Stone2002,
  title = {Spatiotemporal Independent Component Analysis of Event-Related {{fMRI}} Data Using Skewed Probability Density Functions},
  author = {Stone, J.V and Porrill, J and Porter, N.R and Wilkinson, I.D},
  year = {2002},
  month = feb,
  volume = {15},
  pages = {407--421},
  issn = {10538119},
  doi = {10.1006/nimg.2001.0986},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DABJTTW5\\stone_et_al_2002_spatiotemporal_independent_component_analysis_of_event-related_fmri_data_using.pdf},
  journal = {NeuroImage},
  number = {2}
}

@book{strombergAllmanForvaltningsratt2010,
  title = {Allm\"an F\"orvaltningsr\"att},
  author = {Str{\"o}mberg, H\aa kan and Lundell, Bengt},
  year = {2010},
  keywords = {\#nosource}
}

@article{Stroup2000,
  title = {Meta-Analysis of {{Observational Studies}} in {{Epidemiology}}: {{A Proposal}} for {{Reporting}}},
  shorttitle = {Meta-Analysis of {{Observational Studies}} in {{Epidemiology}}},
  author = {Stroup, Donna F. and Berlin, Jesse A. and Morton, Sally C. and Olkin, Ingram and Williamson, G. David and Rennie, Drummond and Moher, David and Becker, Betsy J. and Sipe, Theresa Ann and Thacker, Stephen B. and in Epidemiology (MOOSE)
Group, for the Meta-analysis Of Observational Studies},
  year = {2000},
  month = apr,
  volume = {283},
  pages = {2008--2012},
  publisher = {{American Medical Association}},
  issn = {0098-7484},
  doi = {10.1001/jama.283.15.2008},
  abstract = {ObjectiveBecause of the pressure for timely, informed decisions in public health and clinical practice and the explosion of information in the scientific literature, research results must be synthesized. Meta-analyses are increasingly used to address this problem, and they often evaluate observational studies. A workshop was held in Atlanta, Ga, in April 1997, to examine the reporting of meta-analyses of observational studies and to make recommendations to aid authors, reviewers, editors, and readers.ParticipantsTwenty-seven participants were selected by a steering committee, based on expertise in clinical practice, trials, statistics, epidemiology, social sciences, and biomedical editing. Deliberations of the workshop were open to other interested scientists. Funding for this activity was provided by the Centers for Disease Control and Prevention.EvidenceWe conducted a systematic review of the published literature on the conduct and reporting of meta-analyses in observational studies using MEDLINE, Educational Research Information Center (ERIC), PsycLIT, and the Current Index to Statistics. We also examined reference lists of the 32 studies retrieved and contacted experts in the field. Participants were assigned to small-group discussions on the subjects of bias, searching and abstracting, heterogeneity, study categorization, and statistical methods.Consensus ProcessFrom the material presented at the workshop, the authors developed a checklist summarizing recommendations for reporting meta-analyses of observational studies. The checklist and supporting evidence were circulated to all conference attendees and additional experts. All suggestions for revisions were addressed.ConclusionsThe proposed checklist contains specifications for reporting of meta-analyses of observational studies in epidemiology, including background, search strategy, methods, results, discussion, and conclusion. Use of the checklist should improve the usefulness of meta-analyses for authors, reviewers, editors, readers, and decision makers. An evaluation plan is suggested and research areas are explored.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QHZBBYYP\\Stroup m. fl. - 2000 - Meta-analysis of Observational Studies in Epidemio.pdf;C\:\\Users\\erik_\\Zotero\\storage\\PGQEPPD3\\192614.html},
  journal = {JAMA},
  keywords = {acta review},
  language = {en},
  number = {15}
}

@article{Stuart2010,
  title = {Matching Methods for Causal Inference: {{A}} Review and a Look Forward.},
  author = {Stuart, Elizabeth A},
  year = {2010},
  month = feb,
  volume = {25},
  pages = {1--21},
  publisher = {{NIH Public Access}},
  issn = {0883-4237},
  doi = {10.1214/09-STS313},
  abstract = {When estimating causal effects using observational data, it is desirable to replicate a randomized experiment as closely as possible by obtaining treated and control groups with similar covariate distributions. This goal can often be achieved by choosing well-matched samples of the original treated and control groups, thereby reducing bias due to the covariates. Since the 1970's, work on matching methods has examined how to best choose treated and control subjects for comparison. Matching methods are gaining popularity in fields such as economics, epidemiology, medicine, and political science. However, until now the literature and related advice has been scattered across disciplines. Researchers who are interested in using matching methods-or developing methods related to matching-do not have a single place to turn to learn about past and current research. This paper provides a structure for thinking about matching methods and guidance on their use, coalescing the existing research (both old and new) and providing a summary of where the literature on matching methods is now and where it should be headed.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PDQ8LQCS\\stuart_2010_matching_methods_for_causal_inference.pdf},
  journal = {Statistical science : a review journal of the Institute of Mathematical Statistics},
  number = {1},
  pmid = {20871802}
}

@article{Stute1994,
  title = {The Jackknife Estimate of a Kaplan-Meier Integral},
  author = {Stute, Winfried and Wang, Jane Ling},
  year = {1994},
  volume = {81},
  pages = {602--606},
  issn = {00063444},
  doi = {10.1093/biomet/81.3.602},
  abstract = {SUMMARY: We derive an explicit formula for the jackknife estimate of a Kaplan-Meier integral. From this the asymptotic analysis of the jackknifed Kaplan-Meier process becomes straightforward. In a small simulation study it is demonstrated that jackknifing may lead to a considerable reduction of the bias. \textcopyright{} 1994 Biometrika Trust.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BDCSHEBH\\stute_wang_1994_the_jackknife_estimate_of_a_kaplan-meier_integral.pdf},
  journal = {Biometrika},
  keywords = {Bias reduction,Jackknife,Kaplan-Meier integral},
  number = {3}
}

@article{Stute1995,
  title = {The Central Limit Theorem under Random Censorship},
  author = {Stute, Winfried},
  year = {1995},
  volume = {23},
  pages = {422--439},
  journal = {The Annals of Statistics},
  keywords = {\#nosource},
  number = {2}
}

@article{Stute1996,
  title = {The Jackknife Estimate of Variance of a Kaplan-Meier},
  author = {Stute, Winfried},
  year = {1996},
  volume = {24},
  pages = {2679--2704},
  journal = {The Annals of Statistics},
  keywords = {\#nosource},
  number = {6}
}

@article{Sultan2016,
  title = {Development and Validation of Risk Prediction Model for Venous Thromboembolism in Postpartum Women: Multinational Cohort Study},
  author = {Sultan, Alyshah Abdul and West, Joe and Grainge, Matthew J and Riley, Richard D and Tata, Laila J and Stephansson, Olof and Fleming, Kate M and {Nelson-Piercy}, Catherine and Ludvigsson, Jonas F},
  year = {2016},
  pages = {i6253},
  issn = {1756-1833},
  doi = {10.1136/bmj.i6253},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\L6HGAHY6\\sultan_et_al_2016_development_and_validation_of_risk_prediction_model_for_venous_thromboembolism.pdf},
  isbn = {0959-535x},
  journal = {Bmj},
  pmid = {27919934}
}

@article{Sundararajan2004,
  title = {New {{ICD}}-10 Version of the {{Charlson}} Comorbidity Index Predicted in-Hospital Mortality.},
  author = {Sundararajan, Vijaya and Henderson, Toni and Perry, Catherine and Muggivan, Amanda and Quan, Hude and Ghali, William A},
  year = {2004},
  month = dec,
  volume = {57},
  pages = {1288--94},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2004.03.012},
  abstract = {BACKGROUND AND OBJECTIVE The ICD-9-CM adaptation of the Charlson comorbidity score has been a valuable resource for health services researchers. With the transition into ICD-10 coding worldwide, an ICD-10 version of the Deyo adaptation was developed and validated using population-based hospital data from Victoria, Australia. METHODS The algorithm was translated from ICD-9-CM into ICD-10-AM (Australian modification) in a multistep process. After a mapping algorithm was used to develop an initial translation, these codes were manually examined by the coding experts and a general physician for face validity. Because the ICD-10 system is country specific, our goal was to keep many of the translated code at the three-digit level for generalizability of the new index. RESULTS There appears to be little difference in the distribution of the Charlson Index score between the two versions. A strong association between increasing index scores and mortality exists: the area under the ROC curve is 0.865 for the last year using the ICD-9-CM version and remains high, at 0.855, for the ICD-10 version. CONCLUSION This work represents the first rigorous adaptation of the Charlson comorbidity index for use with ICD-10 data. In comparison with a well-established ICD-9-CM coding algorithm, it yields closely similar prevalence and prognosis information by comorbidity category.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7VTMHTCZ\\sundararajan_et_al_2004_new_icd-10_version_of_the_charlson_comorbidity_index_predicted_in-hospital.pdf},
  journal = {Journal of clinical epidemiology},
  keywords = {Administrative data,Charlson,Comorbidity,ICD-10},
  number = {12},
  pmid = {15617955}
}

@article{Sundararajan2016,
  title = {Cross-National Comparative Performance of Three Versions of the {{ICD}}-10 Charlson Index Linked References Are Available on {{JSTOR}} for This Article : {{Cross}}-National Comparative Performance of Three Versions of the {{ICD}}-10 Charlson Index},
  author = {Sundararajan, Vijaya and Quan, Hude and Halfon, Patricia and Fushimi, Kiyohide and Luthi, Christophe and Burnand, Bernard and Ghali, William A and Methodology, International and Care, Source Medical and Dec, No and Sundararajan, Vijaya and Quart, Hude and Halfon, Patricia},
  year = {2016},
  volume = {45},
  pages = {1210--1215},
  journal = {Medical Care},
  keywords = {\#nosource},
  number = {12}
}

@article{Sutradhar2018,
  title = {Relative Rates Not Relative Risks: {{Addressing}} a Widespread Misinterpretation of Hazard Ratios},
  author = {Sutradhar, Rinku and Austin, Peter C.},
  year = {2018},
  volume = {28},
  pages = {54--57},
  publisher = {{Elsevier Inc}},
  issn = {18732585},
  doi = {10.1016/j.annepidem.2017.10.014},
  abstract = {The use of the Cox proportional hazards model is ubiquitous in modern medical research. Despite the widespread implementation of this model, the terminology and interpretation that is used to describe the estimate hazard ratio (HR) has become loose and, unfortunately, often incorrect. Although some journals offer guidelines that advise against reporting HRs as relative risks, these guidelines are frequently overlooked. Perhaps due to a lack of understanding, authors continue to interpret the resultant HR as a relative risk-such an interpretation is inappropriate and can be misleading. The HR should be described as a relative rate, not as a relative risk. This article demonstrates that although the direction of the HR can be used to explain the direction of the relative risk, the magnitude of the HR alone cannot be used to explain the magnitude of the relative risk. This article clarifies the relationship between HRs and relative risks in a way that may be better suited for the applied clinical researcher. We also provide a convenient table illustrating the magnitude of relative risk under various values of the HR; the table demonstrates that for a given constant HR, the magnitude of the relative risk can vary substantially. As a take-home message, authors should refrain from using the magnitude of the HR to describe the magnitude of the relative risk. Authors should be strongly encouraged to ascribe accurate interpretations to the statistics derived from fitted Cox proportional hazards regression models.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2Z3KYMCH\\sutradhar_austin_2018_relative_rates_not_relative_risks.pdf},
  journal = {Annals of Epidemiology},
  keywords = {Cox proportional hazards regression model,Hazard ratio,Instantaneous rate,Relative rate,Relative risk},
  number = {1},
  pmid = {29239842}
}

@article{Swales1996,
  title = {Academic Writing for Graduate Students: {{Essential}} Tasks and Skills},
  author = {Swales, John M. and Feak, Christine B.},
  year = {1996},
  volume = {47},
  pages = {443},
  issn = {0010096X},
  doi = {10.2307/358319},
  abstract = {The second edition of this successful guide to writing for graduate-and undergraduate-students has been modified to include updates and replacements of older data sets; an increased range of disciplines with tasks such as nursing, marketing, and art history; discussions of discourse analysis; a broader discussion of e-mail use that includes current e-mail practices. Like its predecessor, this edition of Academic Writing for Graduate Students" explains understanding the intended audience, the purpose of the paper, and academic genres." includes the use of task-based methodology, analytic group discussion, and genre consciousness-raising." shows how to write summaries and critiques." features "language focus" sections that address linguistic elements as they affect the wider rhetorical objectives." helps students position themselves as junior scholars in their academic communities.The Commentary has also been revised and is available.},
  isbn = {0472088564},
  journal = {College Composition and Communication},
  keywords = {\#nosource},
  number = {3},
  pmid = {22748837}
}

@article{Swaminathan2016,
  title = {Mission Possible: {{Successful}} Careers in Adult Cardiothoracic {{Anesthesiology}}\textemdash{{What I}} Wish {{I}} Had Known in the First 5 Years after Fellowship},
  author = {Swaminathan, Madhav and Glas, Kathryn E. and Heller, Lori and Augoustides, John G.T. and Culp, William C. and Sniecinski, Roman M.},
  year = {2016},
  volume = {31},
  pages = {321--328},
  publisher = {{Elsevier}},
  issn = {10530770},
  doi = {10.1053/j.jvca.2016.10.013},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CTXSLM5V\\swaminathan_et_al_2016_mission_possible.pdf},
  journal = {Journal of Cardiothoracic and Vascular Anesthesia},
  keywords = {academic pillar,academic practice,administration,American Society of Anesthesiology,American Society of Echocardiography,cardiothoracic anesthesiology,career tracks,choices,dissemination,early career,education,fellowship,goals,graduate medical education,involvement,journey,masters degree,material,mentors,milieu,momentum,planning,presentation,private practice,publication,research,service,Society of Academic Anesthesiology Associations,Society of Cardiovascular Anesthesiologists,value},
  number = {1}
}

@book{Szende2007,
  title = {{{EQ}}-{{5D}} Value Sets: {{Inventory}}, Comparative Review and User Guide: {{Inventory}}, Comparative Review and User Guide (Google {{eBook}})},
  author = {Szende, Agota},
  year = {2007},
  doi = {10.1007/1-4020-5511-0},
  abstract = {This book provides an essential guide to the use of the EuroQol Group 's value sets for working with EQ-5D data. The EQ-5D is a widely used generic health state descriptive system and facilitates the valuation of health and health gain through its pre-existing value sets. This book brings together a comprehensive inventory of these value sets and their characteristics and offers guidance on how to choose which value set for what purpose.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EISTDIGY\\szende_2007_eq-5d_value_sets.pdf},
  isbn = {1-4020-5511-0}
}

@article{Szepannek2018,
  title = {{{clustMixType}}: {{User}}-Friendly Clustering of Mixed-Type Data in r},
  author = {Szepannek, Gero},
  year = {2018},
  volume = {10},
  pages = {200--208},
  abstract = {Clustering algorithms are designed to identify groups in data where the traditional emphasis has been on numeric data. In consequence, many existing algorithms are devoted to this kind of data even though a combination of numeric and categorical data is more common in most business applications. Recently, new algorithms for clustering mixed-type data have been proposed based on Huang's k-prototypes algorithm. This paper describes the R package clustMixType which provides an implementation of k-prototypes in R.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WQRZV4N3\\szepannek_2018_clustmixtype.pdf},
  journal = {The R Journal},
  number = {2}
}

@article{Tahta2016,
  title = {Is {{ACE}}-27 a Reliable Method for Predicting Mortality of Hip Fractures Treated with Hemiarthroplasty in the Elderly?},
  author = {Tahta, Mesut and Bulut, Tugrul and Ozturk, Tahir and Sener, Muhittin and Gunal, Izge},
  year = {2016},
  volume = {31},
  pages = {260--265},
  issn = {21492042},
  doi = {10.5222/MMJ.2016.260},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EN8JLXWK\\tahta_et_al_2016_is_ace-27_a_reliable_method_for_predicting_mortality_of_hip_fractures_treated.pdf},
  journal = {Medeniyet Medical Journal},
  keywords = {elderly,hip fracture mortality,risk prediction},
  number = {4}
}

@article{talbackCancerPatientSurvival2004,
  title = {Cancer Patient Survival in {{Sweden}} at the Beginning of the Third Millennium - {{Predictions}} Using Period Analysis},
  author = {Talb{\"a}ck, Mats and Ros{\'e}n, M\aa ns and Stenbeck, Magnus and Dickman, Paul W.},
  year = {2004},
  volume = {15},
  pages = {967--976},
  issn = {09575243},
  doi = {10.1007/s10522-004-2475-1},
  abstract = {Estimates of cancer patient survival made using traditional, cohort-based, methods can be heavily influenced by the survival experience of patients diagnosed many years in the past and may not be particularly relevant to recently diagnosed patients. Period-based survival analysis has been shown to provide better predictions of survival for recently diagnosed patients and earlier detection of temporal trends in patient survival than cohort analysis. We aim to provide predictions of the long-term survival of recently diagnosed cancer patients using period analysis. The period estimates are compared with the latest available cohort-based estimates. Our results, based on period analysis for the years 2000-2002, suggest an improvement in survival for many forms of cancer during recent years. For all sites combined the 5-, 10-, 15-, and 20-year relative survival ratios were 62\%, 53\%, 48\%, and 47\% for males and 67\%, 62\%, 60\%, and 59\%, for females. These estimates were 3-14\% units higher than those obtained using the latest available cohorts with the respective lengths of follow-up. The interval-specific relative survival stabilised for males at 97\% after 8 years of follow-up and for females at 98\% after 7 years for both period and cohort analyses.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XQCD9WUN\\talbäck_et_al_2004_cancer_patient_survival_in_sweden_at_the_beginning_of_the_third_millennium_-.pdf},
  journal = {Cancer Causes and Control},
  keywords = {cancer registries,period analysis,predictions,survival analysis},
  number = {9},
  pmid = {15577299}
}

@article{Taljaard2016,
  title = {Substantial Risks Associated with Few Clusters in Cluster Randomized and Stepped Wedge Designs},
  author = {Taljaard, M. and Teerenstra, S. and Ivers, N. M. and Fergusson, D. A.},
  year = {2016},
  issn = {1740-7745},
  doi = {10.1177/1740774516634316},
  journal = {Clinical Trials},
  keywords = {\#nosource,cluster cross-over trial,cluster randomized trial,evaluating health policy and,for,is a preferred method,sample size calculation,stepped wedge trial,systems interventions,the cluster randomized trial}
}

@article{Talsnes2013,
  title = {Perioperative Mortality in Hip Fracture Patients Treated with Cemented and Uncemented Hemiprosthesis: {{A}} Register Study of 11,210 Patients},
  author = {Talsnes, Ove and Vinje, Tarjei and Gjertsen, Jan Erik and Dahl, Ola E. and Enges\ae ter, Lars B. and Baste, Valborg and Pripp, Are Hugo and Reiker\aa s, Olav},
  year = {2013},
  volume = {37},
  pages = {1135--1140},
  issn = {03412695},
  doi = {10.1007/s00264-013-1851-3},
  abstract = {PURPOSE: Adverse events associated with the use of bone cement for fixation of prostheses is a known complication. Due to inconclusive results in studies of hip fracture patients treated with cemented and uncemented hemiprostheses, this study was initiated. METHODS: Our study is based on data reported to the Norwegian Hip Fracture Register on 11,210 cervical hip fractures treated with hemiprostheses (8,674 cemented and 2,536 uncemented). RESULTS: Significantly increased mortality within the first day of surgery was found in the cemented group (relative risk 2.9, 95 \% confidence interval 1.6-5.1, p=0.001). The finding was robust giving the same results after adjusting for independent risk factors such as age, sex, cognitive impairment and comorbidity [American Society of Anesthesiologists (ASA) score]. For the first post-operative day the number needed to harm was 116 (one death for every 116 cemented prosthesis). However, in the most comorbid group (ASA worse than 3), the number needed to harm was only 33. CONCLUSIONS: We found increased mortality for the cemented hemiprosthesis the first post-operative day compared to uncemented procedures. This increased risk is closely related to patient comorbidity estimated by the patient's ASA score.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CQJIYU9Y\\talsnes_et_al_2013_perioperative_mortality_in_hip_fracture_patients_treated_with_cemented_and.pdf},
  isbn = {0026401318513},
  journal = {International Orthopaedics},
  number = {6},
  pmid = {23508867}
}

@article{Tam2016,
  title = {Specific Allergen Immunotherapy for the Treatment of Atopic Eczema.},
  author = {Tam, Herman and Calderon, Moises A and Manikam, Logan and Nankervis, Helen and Nunez, Ignacio Garcia and Williams, Hywel C and Durham, Stephen and Boyle, Robert J},
  year = {2016},
  volume = {2},
  pages = {CD008774},
  issn = {1469-493X (Electronic)},
  doi = {10.1002/14651858.CD008774.pub2},
  abstract = {BACKGROUND: Specific allergen immunotherapy (SIT) is a treatment that may improve disease severity in people with atopic eczema (AE) by inducing immune tolerance to the relevant allergen. A high quality systematic review has not previously assessed the efficacy and safety of this treatment. OBJECTIVES: To assess the effects of specific allergen immunotherapy (SIT), including subcutaneous, sublingual, intradermal, and oral routes, compared with placebo or a standard treatment in people with atopic eczema. SEARCH METHODS: We searched the following databases up to July 2015: the Cochrane Skin Group Specialised Register, CENTRAL in the Cochrane Library (Issue 7, 2015), MEDLINE (from 1946), EMBASE (from 1974), LILACS (from 1982), Web of Science (from 2005), the Global Resource of EczemA Trials (GREAT database), and five trials databases. We searched abstracts from recent European and North American allergy meetings and checked the references of included studies and review articles for further references to relevant trials. SELECTION CRITERIA: Randomised controlled trials (RCTs) of specific allergen immunotherapy that used standardised allergen extracts in people with AE. DATA COLLECTION AND ANALYSIS: Two authors independently undertook study selection, data extraction (including adverse effects), assessment of risk of bias, and analyses. We used standard methodological procedures expected by Cochrane. MAIN RESULTS: We identified 12 RCTs for inclusion in this review; the total number of participants was 733. The interventions included SIT in children and adults allergic to either house dust mite (10 trials), grass pollen, or other inhalant allergens (two trials). They were administered subcutaneously (six trials), sublingually (four trials), orally, or intradermally (two trials). Overall, the risk of bias was moderate, with high loss to follow up and lack of blinding as the main methodological concern.Our primary outcomes were 'Participant- or parent-reported global assessment of disease severity at the end of treatment'; 'Participant- or parent-reported specific symptoms of eczema, by subjective measures'; and 'Adverse events, such as acute episodes of asthma or anaphylaxis'. SCORing Atopic Dermatitis (SCORAD) is a means of measuring the effect of atopic dermatitis by area (A); intensity (B); and subjective measures (C), such as itch and sleeplessness, which we used.For 'Participant- or parent-reported global assessment of disease severity at the end of treatment', one trial (20 participants) found improvement in 7/9 participants (78\%) treated with the SIT compared with 3/11 (27\%) treated with the placebo (risk ratio (RR) 2.85, 95\% confidence interval (CI) 1.02 to 7.96; P = 0.04). Another study (24 participants) found no difference: global disease severity improved in 8/13 participants (62\%) treated with the SIT compared with 9/11 (81\%) treated with the placebo (RR 0.75, 95\% CI 0.45 to 1.26; P = 0.38). We did not perform meta-analysis because of high heterogeneity between these two studies. The quality of the evidence was low.For 'Participant- or parent-reported specific symptoms of eczema, by subjective measures', two trials (184 participants) did not find that the SIT improved SCORAD part C (mean difference (MD) -0.74, 95\% CI -1.98 to 0.50) or sleep disturbance (MD -0.49, 95\% CI -1.03 to 0.06) more than placebo. For SCORAD part C itch severity, these two trials (184 participants) did not find that the SIT improved itch (MD -0.24, 95\% CI -1.00 to 0.52). One other non-blinded study (60 participants) found that the SIT reduced itch compared with no treatment (MD -4.20, 95\% CI -3.69 to -4.71) and reduced the participants' overall symptoms (P \textexclamdown{} 0.01), but we could not pool these three studies due to high heterogeneity. The quality of the evidence was very low.Seven trials reported systemic adverse reactions: 18/282 participants (6.4\%) treated with the SIT had a systemic reaction compared with 15/210 (7.1\%) with no treatment (RR 0.78, 95\% CI 0.41 to 1.49; the quality of the evidence was moderate). The same seven trials reported local adverse reactions: 90/280 participants (32.1\%) treated with the SIT had a local reaction compared with 44/204 (21.6\%) in the no treatment group (RR 1.27, 95\% CI 0.89 to 1.81). As these had the same study limitations, we deemed the quality of the evidence to also be moderate.Of our secondary outcomes, there was a significant improvement in 'Investigator- or physician-rated global assessment of disease severity at the end of treatment' (six trials, 262 participants; RR 1.48, 95\% CI 1.16 to 1.88). None of the studies reported our secondary outcome 'Parent- or participant-rated eczema severity assessed using a published scale', but two studies (n = 184), which have been mentioned above, used SCORAD part C, which we included as our primary outcome 'Participant- or parent-reported specific symptoms of eczema, by subjective measures'.Our findings were generally inconclusive because of the small number of studies. We were unable to determine by subgroup analyses a particular type of allergen or a particular age or level of disease severity where allergen immunotherapy was more successful. We were also unable to determine whether sublingual immunotherapy was associated with more local adverse reactions compared with subcutaneous immunotherapy. AUTHORS' CONCLUSIONS: Overall, the quality of the evidence was low. The low quality was mainly due to the differing results between studies, lack of blinding in some studies, and relatively few studies reporting participant-centred outcome measures. We found limited evidence that SIT may be an effective treatment for people with AE. The treatments used in these trials were not associated with an increased risk of local or systemic reactions. Future studies should use high quality allergen formulations with a proven track record in other allergic conditions and should include participant-reported outcome measures.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZN29N277\\tam_et_al_2016_specific_allergen_immunotherapy_for_the_treatment_of_atopic_eczema.pdf},
  journal = {The Cochrane database of systematic reviews},
  keywords = {Adult,Allergens,Animals,Atopic,Child,Dermatitis,Dermatophagoides farinae,Dermatophagoides pteronyssinus,Desensitization,Humans,Immunologic,methods,Randomized Controlled Trials as Topic,therapeutic use,therapy},
  number = {2},
  pmid = {26871981}
}

@article{Tan2018,
  title = {Development and Evaluation of a Preoperative Risk Calculator for Periprosthetic Joint Infection Following Total Joint Arthroplasty},
  author = {Tan, Timothy L. and Maltenfort, Mitchell G. and Chen, Antonia F. and Shahi, AliSina and Higuera, Carlos A. and Siqueira, Marcelo and Parvizi, Javad},
  year = {2018},
  issn = {0021-9355},
  doi = {10.2106/JBJS.16.01435},
  abstract = {BACKGROUND Preoperative identification of patients at risk for periprosthetic joint infection (PJI) following total hip arthroplasty (THA) or total knee arthroplasty (TKA) is important for patient optimization and targeted prevention. The purpose of this study was to create a preoperative PJI risk calculator for assessing a patient's individual risk of developing (1) any PJI, (2) PJI caused by Staphylococcus aureus, and (3) PJI caused by antibiotic-resistant organisms. METHODS A retrospective review was performed of 27,717 patients (12,086 TKAs and 31,167 THAs), including 1,035 with confirmed PJI, who were treated at a single institution from 2000 to 2014. A total of 42 risk factors, including patient characteristics and surgical variables, were evaluated with a multivariate analysis in which coefficients were scaled to produce integer scores. External validation was performed with use of data on 29,252 patients who had undergone total joint arthroplasty (TJA) at an independent institution. RESULTS Of the 42 risk factors studied, 25 were found not to be significant risk factors for PJI. The most influential of the remaining 17 included a previous open surgical procedure, drug abuse, a revision procedure, and human immunodeficiency virus (HIV)/acquired immunodeficiency syndrome (AIDS). The areas under the curves were 0.83 and 0.84 for any PJI, 0.86 and 0.83 for antibiotic-resistant PJI, and 0.86 and 0.73 for S. aureus PJI in the internal and external validation models, respectively. The rates of PJI were 0.56\% and 0.61\% in the lowest decile of risk scores and 15.85\% and 20.63\% in the highest decile. CONCLUSIONS In this large-cohort study, we were able to identify and validate risk factors and their relative weights for predicting PJI. Factors such as prior surgical procedures and high-risk comorbidities should be considered when determining whether TJA is indicated and when counseling patients. LEVEL OF EVIDENCE Prognostic Level IV. See Instructions for Authors for a complete description of levels of evidence.},
  journal = {The Journal of Bone and Joint Surgery},
  keywords = {\#nosource},
  pmid = {29715226}
}

@article{Tarity2006,
  title = {Ninety-Day Mortality after Hip Arthroplasty: {{A}} Comparison between Unilateral and Simultaneous Bilateral Procedures},
  author = {Tarity, T. David and Herz, Amy L. and Parvizi, Javad and Rothman, Richard H.},
  year = {2006},
  month = sep,
  volume = {21},
  pages = {60--64},
  publisher = {{Churchill Livingstone}},
  issn = {0883-5403},
  doi = {10.1016/J.ARTH.2006.05.016},
  abstract = {This study compares the 90-day mortality of unilateral total hip arthroplasty (THA) with simultaneous bilateral THA. Patient demographics, cause of death, and risk factors for mortality after THA were investigated. A total of 6258 patients (6791 hips) received primary THA using uncemented prostheses from 1995 to 2002. There were 5725 (91\%) patients who received unilateral THA, whereas 533 (9\%) patients underwent simultaneous bilateral THA. Of 6258 patients, 10 (0.16\%) died within 90 days of THA, none of whom underwent simultaneous bilateral THA (0\%, 0/533). Simultaneous bilateral uncemented THA performed in a select group of patients carries no greater perioperative mortality rate than unilateral THA.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FNV4PJN4\\tarity_et_al_2006_ninety-day_mortality_after_hip_arthroplasty.pdf},
  journal = {The Journal of Arthroplasty},
  number = {6}
}

@article{Taylor2018,
  title = {Forecasting at Scale Forecasting at Scale {{ABSTRACT}}},
  author = {Taylor, Sean J and Letham, Benjamin and Taylor, Sean J and Letham, Benjamin},
  year = {2018},
  volume = {72},
  pages = {37--45},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1380080},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IJDC9T4U\\taylor_et_al_2018_forecasting_at_scale_forecasting_at_scale_abstract.pdf},
  journal = {The American Statistician},
  keywords = {nonlinear regression,Nonlinear regression,statistical practice,Statistical practice,time,Time ser},
  number = {1}
}

@article{Tenenbaum2017,
  title = {Orthopaedic Injuries among Electric Bicycle Users},
  author = {Tenenbaum, Shay and Weltsch, Daniel and Bariteau, Jason T. and Givon, Adi and Peleg, Kobi and Thein, Ran},
  year = {2017},
  issn = {00201383},
  doi = {10.1016/j.injury.2017.08.020},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3VUUJITI\\tenenbaum_et_al_2017_orthopaedic_injuries_among_electric_bicycle_users.pdf},
  journal = {Injury}
}

@article{Tennant2004,
  title = {Application of {{Rasch}} Analysis in the Development and Application of Quality of Life Instruments},
  author = {Tennant, Alan and McKenna, Stephen P. and Hagell, Peter},
  year = {2004},
  volume = {7},
  pages = {S22-S26},
  publisher = {{International Society for Pharmacoeconomics and Outcomes Research (ISPOR)}},
  issn = {10983015},
  doi = {10.1111/j.1524-4733.2004.7s106.x},
  abstract = {This paper discusses recent advances that have been made in the field of psychometrics, specifically, the application of Rasch analysis to the instrument development process. It emphasizes the importance of assessing the fundamental scaling properties of an instrument prior to consideration of traditional psychometric indicators. The paper introduces Rasch analysis and shows how it has been applied in the development of needs-based measures in order to ensure that they provide unidimensional measurement. By ensuring that scales are based on the same measurement model and that they fit the Rasch model it is possible for QoL scores to be compared across diseases by means of cocalibration and item banking.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F8JHY3QF\\tennant_et_al_2004_application_of_rasch_analysis_in_the_development_and_application_of_quality_of.pdf},
  journal = {Value in Health},
  keywords = {Classical test theory,Differential item functioning,Needs-based quality of life,Rasch analysis,Undimensionality},
  number = {SUPPL. 1},
  pmid = {15367240}
}

@article{Tepper1993,
  title = {Factors Associated with Hip Osteoarthritis: {{Data}} from the First National Health and Nutrition Examination Survey ({{NHANES}}-1)},
  author = {Tepper, Sherri and Hochberg, Marc C.},
  year = {1993},
  month = may,
  volume = {137},
  pages = {1081--1088},
  publisher = {{Narnia}},
  doi = {10.1093/oxfordjournals.aje.a116611},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8HUGJCSM\\tepper_hochberg_1993_factors_associated_with_hip_osteoarthritis.pdf},
  journal = {American Journal of Epidemiology},
  number = {10}
}

@article{Teschl2012,
  title = {Ordinary Differential Equations and Dynamical Systems},
  author = {Teschl, Gerald and Cox, David},
  year = {2012},
  volume = {XXX},
  isbn = {978-0-8218-8328-0},
  journal = {Society},
  keywords = {\#nosource}
}

@article{Thabane2013,
  title = {A Tutorial on Sensitivity Analyses in Clinical Trials: {{The}} What, Why, When and How},
  author = {Thabane, Lehana and Mbuagbaw, Lawrence and Zhang, Shiyuan and Samaan, Zainab and Marcucci, Maura and Ye, Chenglin and Thabane, Marroon and Giangregorio, Lora and Dennis, Brittany and Kosa, Daisy and Debono, Victoria Borg and Dillenburg, Rejane and Fruci, Vincent and Bawor, Monica and Lee, Juneyoung and Wells, George and Goldsmith, Charles H.},
  year = {2013},
  volume = {13},
  issn = {14712288},
  doi = {10.1186/1471-2288-13-92},
  abstract = {BACKGROUND: Sensitivity analyses play a crucial role in assessing the robustness of the findings or conclusions based on primary analyses of data in clinical trials. They are a critical way to assess the impact, effect or influence of key assumptions or variations\textendash such as different methods of analysis, definitions of outcomes, protocol deviations, missing data, and outliers\textendash on the overall conclusions of a study.The current paper is the second in a series of tutorial-type manuscripts intended to discuss and clarify aspects related to key methodological issues in the design and analysis of clinical trials.: In this paper we will provide a detailed exploration of the key aspects of sensitivity analyses including: 1) what sensitivity analyses are, why they are needed, and how often they are used in practice; 2) the different types of sensitivity analyses that one can do, with examples from the literature; 3) some frequently asked questions about sensitivity analyses; and 4) some suggestions on how to report the results of sensitivity analyses in clinical trials.: When reporting on a clinical trial, we recommend including planned or posthoc sensitivity analyses, the corresponding rationale and results along with the discussion of the consequences of these analyses on the overall findings of the study.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JPGIP3CF\\thabane_et_al_2013_a_tutorial_on_sensitivity_analyses_in_clinical_trials.pdf},
  isbn = {1471-2288},
  journal = {BMC Medical Research Methodology},
  keywords = {Clinical trials,Robustness,Sensitivity analysis},
  number = {1},
  pmid = {23855337}
}

@book{Therneau2000,
  title = {Modeling Survival Data : Extending the {{Cox}} Model},
  author = {Therneau, Terry M. and Grambsch, Patricia M.},
  year = {2000},
  publisher = {{Springer}},
  abstract = {1. Introduction \textendash{} 2. Estimating the Survival and Hazard Functions \textendash{} 3. The Cox Model \textendash{} 4. Residuals \textendash{} 5. Functional Form \textendash{} 6. Testing Proportional Hazards \textendash{} 7. Influence \textendash{} 8. Multiple Events per Subject \textendash{} 9. Frailty Models \textendash{} 10. Expected Survival \textendash{} A. Introduction to SAS and S-Plus \textendash{} B. SAS Macros \textendash{} C. S Functions.},
  isbn = {978-0-387-98784-2},
  keywords = {\#nosource}
}

@book{Therneau2016,
  title = {Survival Analysis},
  author = {Therneau, Terry},
  year = {2016},
  issn = {1441966455},
  doi = {10.1007/978-1-4419-6646-9},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PI9GXZDI\\therneau_2016_survival_analysis.pdf},
  isbn = {0-471-25218-2},
  keywords = {Imports graphics,Matrix,methods,splines,stats,utils LazyData Yes LazyLoad Yes ByteCompile Yes}
}

@techreport{Therneau2018,
  title = {Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model},
  author = {Therneau, Terry and Crowson, C and Atkinson, Elizabeth},
  year = {2018},
  keywords = {\#nosource,cox}
}

@article{Thomas2014,
  title = {Tutorial: {{Survival}} Estimation for Cox Regression Models with Time-Varying Coefficients Using {{SAS}} and r},
  author = {Thomas, Laine and Reyes, Eric},
  year = {2014},
  volume = {61},
  pages = {1--23},
  issn = {1548-7660},
  doi = {http://dx.doi.org/10.18637/jss.v061.c01},
  abstract = {Survival estimates are an essential compliment to multivariable regression models for time-to-event data, both for prediction and illustration of covariate effects. They are easily obtained under the Cox proportional-hazards model. In populations defined by an initial, acute event, like myocardial infarction, or in studies with long-term follow-up, the proportional-hazards assumption of constant hazard ratios is frequently violated.{\r  }alternative is to fit an interaction between covariates and a prespecified function of time, implemented as a time-dependent covariate. This effectively creates a time-varying coefficient that is easily estimated in software such as SAS and R. However, the usual{\r  }statements for survival estimation are not directly applicable. Unique data manipulation and syntax is required, but is not well documented for either software.{\r  }paper offers a tutorial in survival estimation for the time-varying coefficient model, implemented in SAS and R. We provide a macro coxtvc to facilitate estimation in SAS{\r  }the current functionality is more limited. The macro is validated in simulated data{\r  }illustrated in an application.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\THQ9FN2F\\thomas_reyes_2014_tutorial.pdf},
  journal = {Journal of Statistical Software},
  keywords = {cox proportional-hazards,model,r,sas,survival estimation,time-dependent covariates,time-varying coefficients},
  number = {October}
}

@article{Thomazeau2014,
  title = {Pain Management and Pain Characteristics in Obese and Normal Weight Patients before Joint Replacement},
  author = {Thomazeau, Jos{\'e}phine and Perin, Juliette and Nizard, Remy and Bouhassira, Didier and Collin, Elisabeth and Nguyen, Eliane and Perrot, Serge and Bergmann, Jean Fran{\c c}ois and {Lloret-Linares}, C{\'e}lia},
  year = {2014},
  volume = {20},
  pages = {611--616},
  issn = {13652753},
  doi = {10.1111/jep.12176},
  abstract = {RATIONALE, AIMS AND OBJECTIVES: The objective was to compare the extent of pain interference and pain medication among persons who were classified as obese [body mass index (BMI) {$\geq$}30 kg m(-2) ] and normal weighted (BMI {$\leq$}25 kg m(-2) ), before a hip or knee replacement surgery.: Patients candidate for an orthopaedic surgery were successively enrolled, over a 6-month period, and classified in either the normal weight (BMI {$\leq$}25 kg m(-2) ) or the obese (BMI {$\geq$}30 kg m(-2) ) categories. Data were collected using self-administered questionnaires with items concerning pain characteristics, pain medication and pain interference. Two standardized questionnaires were associated: the Brief Pain Inventory (BPI) and the Hospital Anxiety and Depression scale (HAD).: Fifty-two obese patients (candidates for 24 hip replacements and 28 knee replacements) and 51 non-obese (23 hip replacements and 28 knee replacements) were enrolled. Obese patients suffered from a higher rate of acute pain episodes than non-obese patients (65 versus 44\%, P \textexclamdown{} 0.05). Pain interference on walking distance, sleep and relations with others was higher in obese patients. HAD score showed no significant difference between groups. The use of strong opioids and of non-steroidal anti-inflammatory drugs (NSAIDs) was significantly more important in obese patients (13 versus 0\% and 31 versus 14\%).: Obese patients suffer more significantly of unrelieved chronic pain, which lowers considerably their quality of life. Pain relief is more difficult to obtain, as it requires stronger pain medication and NSAIDs.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DHFP5V2M\\thomazeau_et_al_2014_pain_management_and_pain_characteristics_in_obese_and_normal_weight_patients.pdf},
  isbn = {1356-1294},
  journal = {Journal of Evaluation in Clinical Practice},
  keywords = {Analgesics,Clinical safety,Evaluation,Obesity,Orthopedics,Pain},
  number = {5},
  pmid = {24828954}
}

@article{Thompson2015,
  title = {A New {{Elixhauser}}-Based Comorbidity Summary Measure to Predict in-Hospital Mortality},
  author = {Thompson, Nicolas R. and Fan, Youran and Dalton, Jarrod E. and Jehi, Lara and Rosenbaum, Benjamin P. and Vadera, Sumeet and Griffith, Sandra D.},
  year = {2015},
  volume = {53},
  pages = {374--379},
  issn = {1537-1948},
  doi = {10.1097/MLR.0000000000000326},
  abstract = {BACKGROUND: Recently, van Walraven developed a weighted summary score (VW) based on the 30 comorbidities from the Elixhauser comorbidity system. One of the 30 comorbidities, cardiac arrhythmia, is currently excluded as a comorbidity indicator in administrative datasets such as the Nationwide Inpatient Sample (NIS), prompting us to examine the validity of the VW score and its use in the NIS. METHODS: Using data from the 2009 Maryland State Inpatient Database, we derived weighted summary scores to predict in-hospital mortality based on the full (30) and reduced (29) set of comorbidities and compared model performance of these and other comorbidity summaries in 2009 NIS data. RESULTS: Weights of our derived scores were not sensitive to the exclusion of cardiac arrhythmia. When applied to NIS data, models containing derived summary scores performed nearly identically (c statistics for 30 and 29 variable-derived summary scores: 0.804 and 0.802, respectively) to the model using all 29 comorbidity indicators (c=0.809), and slightly better than the VW score (c=0.793). Each of these models performed substantially better than those based on a simple count of Elixhauser comorbidities (c=0.745) or a categorized count (0, 1, 2, or \textquestiondown/= 3 comorbidities; c=0.737). CONCLUSIONS: The VW score and our derived scores are valid in the NIS and are statistically superior to summaries using simple comorbidity counts. Researchers wishing to summarize the Elixhauser comorbidities with a single value should use the VW score or those derived in this study.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7EQA7SWW\\thompson_et_al_2015_a_new_elixhauser-based_comorbidity_summary_measure_to_predict_in-hospital.pdf},
  isbn = {0025-7079},
  journal = {Medical Care},
  keywords = {*Comorbidity,*Health Status Indicators,*Hospital Mortality,comorbidity adjustment,comorbidity summary measures,Elixhauser comorbidity system,Humans,Inpatients,Maryland,Nationwide Inpatient Sample},
  number = {4},
  pmid = {25769057}
}

@article{Thorn2016,
  title = {Validation of the Hospital Episode Statistics Outpatient Dataset in England},
  author = {Thorn, Joanna C. and Turner, Emma and Hounsome, Luke and Walsh, Eleanor and Donovan, Jenny L. and Verne, Julia and Neal, David E. and Hamdy, Freddie C. and Martin, Richard M. and Noble, Sian M.},
  year = {2016},
  month = feb,
  volume = {34},
  pages = {161--168},
  publisher = {{Springer International Publishing}},
  issn = {11792027},
  doi = {10.1007/s40273-015-0326-3},
  abstract = {Objectives: The Hospital Episode Statistics (HES) dataset is a source of administrative `big data' with potential for costing purposes in economic evaluations alongside clinical trials. This study assesses the validity of coverage in the HES outpatient dataset. Methods: Men who died of, or with, prostate cancer were selected from a prostate-cancer screening trial (CAP, Cluster randomised triAl of PSA testing for Prostate cancer). Details of visits that took place after 1/4/2003 to hospital outpatient departments for conditions related to prostate cancer were extracted from medical records (MR); these appointments were sought in the HES outpatient dataset based on date. The matching procedure was repeated for periods before and after 1/4/2008, when the HES outpatient dataset was accredited as a national statistic. Results: 4922 outpatient appointments were extracted from MR for 370 men. 4088 appointments recorded in MR were identified in the HES outpatient dataset (83.1 \%; 95 \% confidence interval [CI] 82.0\textendash 84.1). For appointments occurring prior to 1/4/2008, 2195/2755 (79.7 \%; 95 \% CI 78.2\textendash 81.2) matches were observed, while 1893/2167 (87.4 \%; 95 \% CI 86.0\textendash 88.9) appointments occurring after 1/4/2008 were identified (p for difference \textexclamdown 0.001). 215/370 men (58.1 \%) had at least one appointment in the MR review that was unmatched in HES, 155 men (41.9 \%) had all their appointments identified, and 20 men (5.4 \%) had no appointments identified in HES. Conclusions: The HES outpatient dataset appears reasonably valid for research, particularly following accreditation. The dataset may be a suitable alternative to collecting MR data from hospital notes within a trial, although caution should be exercised with data collected prior to accreditation.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4HZKT589\\thorn_et_al_2016_validation_of_the_hospital_episode_statistics_outpatient_dataset_in_england.pdf},
  journal = {PharmacoEconomics},
  number = {2}
}

@book{Thrun2004,
  title = {Advances in Neural Information Processing Systems 16 : Proceedings of the 2003 Conference},
  author = {Thrun, Sebastian and Saul, Lawrence K. and Scholkopf, Bernhard.},
  year = {2004},
  publisher = {{MIT Press}},
  isbn = {0-262-20152-6},
  keywords = {\#nosource}
}

@generic{Thygesen2011,
  title = {Danish Population-Based Registers for Public Health and Health-Related Welfare Research: {{Introduction}} to the Supplement},
  author = {Thygesen, Lau Caspar and Ersb\o ll, Annette Kj\ae r},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {8--10},
  issn = {14034948},
  doi = {10.1177/1403494811409654},
  journal = {Scandinavian Journal of Public Health},
  keywords = {\#nosource},
  number = {7}
}

@article{Tian2005,
  title = {On the {{Cox}} Model with Time-Varying Regression Coefficients},
  author = {Tian, Lu and Zucker, David and Wei, L. J.},
  year = {2005},
  volume = {100},
  pages = {172--183},
  issn = {01621459},
  doi = {10.1198/016214504000000845},
  abstract = {In the analysis of censored failure time observations, the standard Cox proportional hazards model assumes that the regression coefficients are time invariant. Often, these parameters vary over time, and the temporal covariate effects on the failure time are of great interest. In this article, following previous work of Cai and Sun, we propose a simple estimation procedure for the Cox model with time-varying coefficients based on a kernel-weighted partial likelihood approach. We construct pointwise and simultaneous confidence intervals for the regression parameters over a properly chosen time interval via a simple resampling technique. We derive a prediction method for future patients' survival with any specific set of covariates. Building on the estimates for the time-varying coefficients, we also consider the mixed case and present an estimation procedure for time-independent parameters in the model. Furthermore. we show how to use an integrated function of the estimate for a specific regression coefficient to examine the adequacy of proportional hazards assumption for the corresponding covariate graphically and numerically. All of the proposals are illustrated extensively with a well-known study from the Mayo Clinic.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F3FGU3GE\\tian_et_al_2005_on_the_cox_model_with_time-varying_regression_coefficients.pdf},
  isbn = {0162-1459},
  journal = {Journal of the American Statistical Association},
  keywords = {Confidence band,Kernel estimation,Martingale,Model checking and selection,Partial likelihood,Prediction,Survival analysis},
  number = {469}
}

@article{Tian2014,
  title = {Predicting the Restricted Mean Event Time with the Subject's Baseline Covariates in Survival Analysis},
  author = {Tian, L. and Zhao, L. and Wei, L. J.},
  year = {2014},
  month = apr,
  volume = {15},
  pages = {222--233},
  publisher = {{Narnia}},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxt050},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ELZ8M84X\\tian_et_al_2014_predicting_the_restricted_mean_event_time_with_the_subject's_baseline.pdf},
  journal = {Biostatistics},
  number = {2}
}

@article{Tiwari2010,
  title = {Within-Cluster Resampling for Analysis of Family Data: {{Ready}} for Prime-Time?},
  author = {Tiwari, Hemant K and Patki, Amit and Allison, David B. and Patki, Amit and Tiwari, Hemant K},
  year = {2010},
  volume = {3},
  pages = {169--176},
  issn = {1938-7997},
  doi = {10.1126/scisignal.2001449.Engineering},
  abstract = {Hoffman et al. [1] proposed an elegant resampling method for analyzing clustered binary data. The focus of their paper was to perform association tests on clustered binary data using within-cluster-resampling (WCR) method. Follmann et al. [2] extended Hoffman et al.'s procedure more generally with applicability to angular data, combining of p-values, testing of vectors of parameters, and Bayesian inference. Follmann et al. [2] termed their procedure multiple outputation because all "excess" data within each cluster is thrown out multiple times. Herein, we refer to this procedure as WCR-MO. For any statistical test to be useful for a particular design, it must be robust, have adequate power, and be easy to implement and flexible. WCR-MO can be easily extended to continuous data and is a computationally intensive but simple and highly flexible method. Considering family as a cluster, one can apply WCR to familial data in genetic studies. Using simulations, we evaluated WCR-MO's robustness for analysis of a continuous trait in terms of type I error rates in genetic research. WCR-MO performed well at the 5\% {$\alpha$}-level. However, it provided inflated type I error rates for {$\alpha$}-levels less than 5\% implying the procedure is liberal and may not be ready for application to genetic studies where {$\alpha$} levels used are typically much less than 0.05.},
  isbn = {8585348585},
  journal = {Statistics and Its Interface},
  keywords = {\#nosource},
  number = {2},
  pmid = {20664749}
}

@book{Tobergte2013,
  title = {Statistics for Biology and Health},
  author = {Tobergte, David R. and Curtis, Shirley},
  year = {2013},
  volume = {53},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\SVI28G5G\\tobergte_curtis_2013_statistics_for_biology_and_health.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {icle},
  pmid = {25246403}
}

@book{Tobergte2013,
  title = {The Concise Encyclopedia of Statistics},
  author = {Tobergte, David R. and Curtis, Shirley},
  year = {2013},
  volume = {53},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {applicability for this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F2XKC73E\\tobergte_curtis_2013_the_concise_encyclopedia_of_statistics.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {icle},
  pmid = {25246403}
}

@article{Toson2015,
  title = {The {{ICD}}-10 {{Charlson Comorbidity Index}} Predicted Mortality but Not Resource Utilization Following Hip Fracture.},
  author = {Toson, Barbara and Harvey, Lara A and Close, Jacqueline C T},
  year = {2015},
  month = jan,
  volume = {68},
  pages = {44--51},
  publisher = {{Elsevier}},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2014.09.017},
  abstract = {OBJECTIVES To evaluate the performance of the Charlson Comorbidity Index (CCI) in the prediction of mortality, 30-day readmission, and length of stay (LOS) in a hip fracture population using algorithms designed for use in International Classification of Diseases, 10th Revision (ICD-10)\textendash coded administrative data sets. STUDY DESIGN AND SETTING Hospitalization and death data for 47,698 New South Wales residents aged 65 years and over, admitted for hip fracture, were linked. Comorbidities were ascertained using ICD-10 coding algorithms developed by Sundararajan (2004) and Quan (2005). Regression models were fitted, and area under the receiver operating curve (AUC) and Akaike information criterion were assessed. RESULTS Both algorithms had acceptable discrimination in predicting in-hospital (AUC, 0.72-0.76), 30-day (0.72-0.75), and 1-year mortality (0.69-0.75) but poor ability to predict 30-day readmission (0.54-0.57) or LOS (adjusted R(2), 0.007-0.045). The Quan algorithm provided better model fit than the Sundararajan algorithm. Models incorporating comorbidities as individual variables performed better than the Charlson weighted or updated Quan weighted score. Including a 1-year lookback period increased predictive ability for 1-year mortality only. CONCLUSION The CCI is a valid tool for predicting mortality but not resource utilization after hip fracture. We recommend the use of the Quan algorithm rather than Sundararajan algorithm and to model individual conditions rather than categorized weighted scores.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\CBMNGDGU\\toson_et_al_2015_the_icd-10_charlson_comorbidity_index_predicted_mortality_but_not_resource.pdf},
  journal = {Journal of clinical epidemiology},
  keywords = {Charlson Comorbidity Index,Comorbidity,Hip fracture,ICD-10,Mortality,Risk adjustment},
  number = {1},
  pmid = {25447352}
}

@article{Touraine2016,
  title = {Predictions in an Illness-Death Model},
  author = {Touraine, C{\'e}lia and Helmer, Catherine and Joly, Pierre},
  year = {2016},
  month = aug,
  volume = {25},
  pages = {1452--1470},
  publisher = {{SAGE PublicationsSage UK: London, England}},
  issn = {0962-2802},
  doi = {10.1177/0962280213489234},
  abstract = {Multi-state models allow subjects to move among a finite number of states during a follow-up period. Most often, the objects of study are the transition intensities. The impact of covariates on them can also be studied by specifying regression models. Thus, estimation in multi-state models is usually focused on the transition intensities (or the cumulative transition intensities) and on the regression parameters. However, from a clinical or epidemiological point of view, other quantities could provide additional information and may be more relevant to answer practical questions. For example, given a set of covariates for a subject, it may be of interest to estimate the probability to experience a future event or the expected time without any event. To address these kinds of issues, we need to estimate quantities such as transition probabilities, cumulative probabilities and life expectancies. The purpose of this paper is to review a large number of these quantities in an illness-death model which is perha...},
  journal = {Statistical Methods in Medical Research},
  keywords = {\#nosource,Illness-death model,interval-censored data,life expectancies,lifetime risk,predictions,transition probabilities},
  number = {4}
}

@article{Troelsen2019,
  title = {The Problem Is Not Necessarily the Data, It Is the Interpretation},
  author = {Troelsen, Anders and Haddad, Fares S.},
  year = {2019},
  month = oct,
  volume = {101-B},
  pages = {1177--1178},
  publisher = {{The British Editorial Society of Bone \& Joint Surgery London}},
  issn = {2049-4394},
  doi = {10.1302/0301-620X.100B10.BJJ-2019-0983},
  journal = {The Bone \& Joint Journal},
  keywords = {\#nosource},
  number = {10}
}

@article{Trust1908,
  title = {Probable Error of a Correlation Coefficient},
  author = {Trust, Biometrika and {Student}},
  year = {1908},
  volume = {6},
  pages = {302--310},
  issn = {00063444},
  doi = {10.1093/biomet/6.2-3.302},
  abstract = {His question was answered by Messrs Yule and Hooker and Professor Edgeworth, all of whom considered that Mr Hooker was probably safe in taking'HO as his limit of significance for a sample of 21. They did not, however, answer Dr Shaw's question in any more ...},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KGUQDUHB\\trust_student_1908_probable_error_of_a_correlation_coefficient.pdf},
  journal = {Biometrika},
  number = {2-3},
  pmid = {2331474}
}

@article{Trust2016,
  title = {Biometrika {{Trust CORRELATION COEFFICIENT IN RANDOM SAMPLES OF ANY SIZE DRAWN FROM NON}}-{{NORMAL UNIVERSES}}},
  author = {Trust, Biometrika},
  year = {2016},
  volume = {38},
  pages = {219--247},
  keywords = {\#nosource},
  number = {1}
}

@article{Tsagozis2015,
  title = {Current Strategies for the Treatment of Aneurysmal Bone Cysts.},
  author = {Tsagozis, Panagiotis and Brosj{\"o}, Otte},
  year = {2015},
  month = dec,
  volume = {7},
  pages = {6182},
  publisher = {{PAGEPress}},
  doi = {10.4081/or.2015.6182},
  abstract = {Aneurysmal bone cysts are benign bone tumors that usually present in childhood and early adulthood. They usually manifest as expansile osteolytic lesions with a varying potential to be locally aggressive. Since their first description in 1942, a variety of treatment methods has been proposed. Traditionally, these tumors were treated with open surgery. Either intralesional surgical procedures or en bloc excisions have been described. Furthermore, a variety of chemical or physical adjuvants has been utilized in order to reduce the risk for local recurrence after excision. Currently, there is a shift to more minimally invasive procedures in order to avoid the complications of open surgical excision. Good results have been reported during percutaneous surgery, or the use of embolization. Recently, sclerotherapy has emerged as a promising treatment, showing effective consolidation of the lesions and functional results that appear to be superior to the ones of open surgery. Lastly, non-invasive treatment, such as pharmaceutical intervention with denosumab or bisphosphonates has been reported to be effective in the management of the disease. Radiotherapy has also been shown to confer good local control, either alone or in conjunction to other treatment modalities, but is associated with serious adverse effects. Here, we review the current literature on the methods of treatment of aneurysmal bone cysts. The indication for each type of treatment along reported outcome of the intervention, as well as potential complications are systematically presented. Our review aims to increase awareness of the different treatment modalities and facilitate decision-making regarding each individual patient.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IRCCJC4J\\tsagozis_brosjö_2015_current_strategies_for_the_treatment_of_aneurysmal_bone_cysts.pdf},
  journal = {Orthopedic reviews},
  number = {4},
  pmid = {26793296}
}

@article{Tu2008,
  title = {Simpson's Paradox, Lord's Paradox, and Suppression Effects Are the Same Phenomenon \textendash{} the Reversal Paradox},
  author = {Tu, Yu-Kang and Gunnell, David and Gilthorpe, Mark},
  year = {2008},
  issn = {00283754},
  doi = {10.1186/1742-7622-5-2},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S3L698F8\\tu_et_al_2008_simpson's_paradox,_lord's_paradox,_and_suppression_effects_are_the_same.pdf},
  isbn = {9783540793960},
  journal = {BioMed Central},
  pmid = {18394806}
}

@book{Tufte2006,
  title = {Beautiful Evidenc},
  author = {Tufte, Edward},
  year = {2006},
  keywords = {\#nosource}
}

@article{Turkiewicz2014,
  title = {Current and Future Impact of Osteoarthritis on Health Care: A Population-Based Study with Projections to Year 2032},
  author = {Turkiewicz, A and Petersson, I F and Bj{\"o}rk, J and Hawker, G and Dahlberg, L E and Lohmander, L S and Englund, M},
  year = {2014},
  volume = {22},
  pages = {1826--1832},
  issn = {1063-4584},
  doi = {10.1016/j.joca.2014.07.015},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Z7USQKMA\\turkiewicz_et_al_2014_current_and_future_impact_of_osteoarthritis_on_health_care.pdf},
  journal = {Osteoarthritis and Cartilage},
  keywords = {Epidemiology,Knee osteoarthritis,Osteoarthritis},
  number = {11}
}

@article{Universitetsbibliotek2016,
  title = {From the {{SAGE}} Social Science Collections . {{All}} Rights},
  author = {Universitetsbibliotek, Uppsala and Bremen, Staatsuniversitaets Bibliothek and Universitetsbibliotek, Uppsala},
  year = {2016},
  issn = {1059-6011},
  doi = {0803973233},
  isbn = {0893-3200},
  keywords = {\#nosource},
  pmid = {803973233}
}

@article{Uno2011,
  title = {On the C-Statistics for Evaluating Overall Adequacy of Risk Prediction Procedures with Censored Survival Data},
  author = {Uno, Hajime and Cai, Tianxi and Pencina, Michael J. and D'Agostino, Ralph B. and Wei, L. J.},
  year = {2011},
  volume = {257},
  pages = {n/a-n/a},
  publisher = {{John Wiley \& Sons, Ltd.}},
  issn = {02776715},
  doi = {10.1002/sim.4154},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IPKPL6DY\\uno_et_al_2011_on_the_c-statistics_for_evaluating_overall_adequacy_of_risk_prediction.pdf},
  isbn = {6176321972},
  journal = {Statistics in Medicine},
  keywords = {auc,AUC,correlated residuals,cox,Cox's proportional hazards model,familial data,framingham risk score,Framingham risk score,genetic research,multiple outputation,roc,ROC,s proportional hazards model,type i error,wcr},
  number = {10},
  pmid = {1000000221}
}

@article{Uno2014,
  title = {Moving beyond the Hazard Ratio in Quantifying the Between-Group Difference in Survival Analysis},
  author = {Uno, Hajime and Claggett, Brian and Tian, Lu and Inoue, Eisuke and Gallo, Paul and Miyata, Toshio and Schrag, Deborah and Takeuchi, Masahiro and Uyama, Yoshiaki and Zhao, Lihui and Skali, Hicham and Solomon, Scott and Jacobus, Susanna and Hughes, Michael and Packer, Milton and Wei, Lee-Jen},
  year = {2014},
  month = aug,
  volume = {32},
  pages = {2380--2385},
  issn = {0732-183X},
  doi = {10.1200/JCO.2014.55.2208},
  abstract = {In a longitudinal clinical study to compare two groups, the primary end point is often the time to a specific event (eg, disease progression, death). The hazard ratio estimate is routinely used to empirically quantify the between-group difference under the assumption that the ratio of the two hazard functions is approximately constant over time. When this assumption is plausible, such a ratio estimate may capture the relative difference between two survival curves. However, the clinical meaning of such a ratio estimate is difficult, if not impossible, to interpret when the underlying proportional hazards assumption is violated (ie, the hazard ratio is not constant over time). Although this issue has been studied extensively and various alternatives to the hazard ratio estimator have been discussed in the statistical literature, such crucial information does not seem to have reached the broader community of health science researchers. In this article, we summarize several critical concerns regarding this conventional practice and discuss various well-known alternatives for quantifying the underlying differences between groups with respect to a time-to-event end point. The data from three recent cancer clinical trials, which reflect a variety of scenarios, are used throughout to illustrate our discussions. When there is not sufficient information about the profile of the between-group difference at the design stage of the study, we encourage practitioners to consider a prespecified, clinically meaningful, model-free measure for quantifying the difference and to use robust estimation procedures to draw primary inferences.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\JT7TQE8Y\\uno_et_al_2014_moving_beyond_the_hazard_ratio_in_quantifying_the_between-group_difference_in.pdf},
  journal = {Journal of Clinical Oncology},
  number = {22},
  pmid = {24982461}
}

@article{Uno2015,
  title = {Alternatives to Hazard Ratios for Comparing the Efficacy or Safety of Therapies in Noninferiority Studies},
  author = {Uno, Hajime and Wittes, Janet and Fu, Haoda and Solomon, Scott D. and Claggett, Brian and Tian, Lu and Cai, Tianxi and Pfeffer, Marc A. and Evans, Scott R. and Wei, Lee Jen},
  year = {2015},
  volume = {163},
  pages = {127--134},
  issn = {15393704},
  doi = {10.7326/M14-1741},
  abstract = {A noninferiority study is often used to investigate whether a treatment's efficacy or safety profile is acceptable compared with an alternative therapy regarding the time to a clinical event. The empirical quantification of the treatment difference for such a study is routinely based on the hazard ratio (HR) estimate. The HR, which is not a relative risk, may be difficult to interpret clinically, especially when the underlying proportional hazards assumption is violated. The precision of the HR estimate depends primarily on the number of observed events but not directly on exposure times or sample size of the study population. If the event rate is low, the study may require an impractically large number of events to ensure that the prespecified noninferiority criterion for the HR is attainable. This article discusses deficiencies in the current approach for the design and analysis of a noninferiority study. Alternative procedures are provided, which do not depend on any model assumption, to compare 2 treatments. For a noninferiority safety study, the patients' exposure times are more clinically important than the observed number of events. If the patients' exposure times are long enough to evaluate safety reliably, then these alternative procedures can effectively provide clinically interpretable evidence on safety, even with relatively few observed events. These procedures are illustrated with data from 2 studies. One explores the cardiovascular safety of a pain medicine; the second examines the cardiovascular safety of a new treatment for diabetes. These alternative strategies to evaluate safety or efficacy of an intervention lead to more meaningful interpretations of the analysis results than the conventional strategy that uses the HR estimate.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\87JGKZ5Q\\uno_et_al_2015_alternatives_to_hazard_ratios_for_comparing_the_efficacy_or_safety_of_therapies.pdf},
  journal = {Annals of Internal Medicine},
  number = {2}
}

@article{uriz-otanoFactorsAssociatedInstitutionalization2016,
  title = {Factors Associated to Institutionalization and Mortality over Three Years, in Elderly People with a Hip Fracture - {{An}} Observational Study},
  author = {{Uriz-Otano}, Francisco and {Pla-Vidal}, Jorge and {Tiberio-L{\'o}pez}, Gregorio and Malafarina, Vincenzo},
  year = {2016},
  volume = {89},
  pages = {9--15},
  issn = {18734111},
  doi = {10.1016/j.maturitas.2016.04.005},
  abstract = {Objective: To identify the factors associated to institutionalization and mortality in elderly patients with hip fractures (HF). Design: Thirty-six months observational study. Setting: A post-acute rehabilitation ward. Participants: subjects living in the community or in nursing-home, above the age of 65, with HF. Measurements: The following were registered: comorbidity, intra-hospital complications, Barthel index, walking ability and Mini Mental State Examination, as well as blood samples upon admission and discharge. Destination upon discharge was recorded as well as mortality during hospital stay and over the three-year follow up. Results: a total of 430 subjects were included in the study. Twenty-three patients (5.3\%) died during their stay in hospital and 152 (35.3\%) during follow up after discharge. Forty-five patients (10.5\%) were institutionalized upon discharge. In adjusted analysis, the factors that predict intra-hospital mortality are higher comorbidity (OR, 1.46; 95\%CI, 1.06-2.01), and the number of complications (OR, 1.71; 95\%CI, 1.16-2.64). Factors that predict mortality in the long term are age (HR 1.04; 95\%CI, 1.01-1.06), comorbidity (HR 1.19, 95\% CI, 1.09-1.30), the number of complications (HR 1.17, 95\%CI, 1.05-1.31). The factors that predicted new institutionalization were age (OR 1.04, 95\%CI, 0.98-1.09), living alone (OR 3.95, 95\%CI, 1.38-11.3), and length of hospital stay (OR 1.02 95\%CI, 1.00-1.03). Conclusions: Mortality 3 years after a hip fracture and institutionalization are associated to age, the loss of autonomy in walking, a worse cognitive status and living alone before the fracture. Identification of and, when possible, intervention upon these factors can improve care of elderly people with hip fractures.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\QXHPBKHZ\\uriz-otano_et_al_2016_factors_associated_to_institutionalization_and_mortality_over_three_years,_in.pdf},
  journal = {Maturitas},
  keywords = {Functional status,Hip fracture,Institutionalization,Mortality,Nursing home},
  pmid = {27180154}
}

@statute{utbildningsutskottetsbetankandeBehandlingAvPersonuppgifter2018,
  title = {Behandling Av Personuppgifter F\"or Forsknings\"andam\aa l Inneh\aa llsf\"orteckning},
  author = {{Utbildningsutskottets\textsubscript{b}et\"ankande}},
  year = {2018},
  keywords = {\#nosource},
  number = {V19}
}

@article{Valderas2009,
  title = {Defining Comorbidity: Implications for Understanding Health and Health Services},
  author = {Valderas, Jose M. and Starfield, B. and Sibbald, Bonnie and Salisbury, Chris and Rloand, M.},
  year = {2009},
  volume = {7},
  pages = {357--363},
  issn = {1544-1709},
  doi = {10.1370/afm.983.Martin},
  abstract = {Comorbidity is associated with worse health outcomes, more complex clinical management, and increased health care costs. There is no agreement, however, on the meaning of the term, and related constructs, such as multimorbidity, morbidity burden, and patient complexity, are not well conceptualized. In this article, we review defi nitions of comorbidity and their relationship to related constructs. We show that the value of a given construct lies in its ability to explain a particular phenomenon of interest within the domains of (1) clinical care, (2) epidemiology, or (3) health services planning and fi nancing. Mechanisms that may underlie the coexistence of 2 or more conditions in a patient (direct causation, associated risk factors, heterogeneity, independence) are examined, and the implications for clinical care considered. We conclude that the more precise use of constructs, as proposed in this article, would lead to improved research into the phenomenon of ill health in clinical care, epidemiology, and health services},
  isbn = {1544-1709},
  journal = {Annals Of Family Medicine},
  keywords = {\#nosource},
  pmid = {19597174}
}

@article{VanCalster2020,
  title = {Regression Shrinkage Methods for Clinical Prediction Models Do Not Guarantee Improved Performance: {{Simulation}} Study},
  shorttitle = {Regression Shrinkage Methods for Clinical Prediction Models Do Not Guarantee Improved Performance},
  author = {Van Calster, Ben and {van Smeden}, Maarten and De Cock, Bavo and Steyerberg, Ewout W},
  year = {2020},
  month = may,
  pages = {0962280220921415},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0962-2802},
  doi = {10.1177/0962280220921415},
  abstract = {When developing risk prediction models on datasets with limited sample size, shrinkage methods are recommended. Earlier studies showed that shrinkage results in better predictive performance on average. This simulation study aimed to investigate the variability of regression shrinkage on predictive performance for a binary outcome. We compared standard maximum likelihood with the following shrinkage methods: uniform shrinkage (likelihood-based and bootstrap-based), penalized maximum likelihood (ridge) methods, LASSO logistic regression, adaptive LASSO, and Firth's correction. In the simulation study, we varied the number of predictors and their strength, the correlation between predictors, the event rate of the outcome, and the events per variable. In terms of results, we focused on the calibration slope. The slope indicates whether risk predictions are too extreme (slope\,{$<$}\,1) or not extreme enough (slope\,{$>$}\,1). The results can be summarized into three main findings. First, shrinkage improved calibration slopes on average. Second, the between-sample variability of calibration slopes was often increased relative to maximum likelihood. In contrast to other shrinkage approaches, Firth's correction had a small shrinkage effect but showed low variability. Third, the correlation between the estimated shrinkage and the optimal shrinkage to remove overfitting was typically negative, with Firth's correction as the exception. We conclude that, despite improved performance on average, shrinkage often worked poorly in individual datasets, in particular when it was most needed. The results imply that shrinkage methods do not solve problems associated with small sample size or low number of events per variable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PQNGJJGS\\Van Calster m. fl. - 2020 - Regression shrinkage methods for clinical predicti.pdf},
  journal = {Statistical Methods in Medical Research},
  language = {en}
}

@article{vandenbrinkGenderPracticesConstruction2012,
  title = {Gender Practices in the Construction of Academic Excellence: {{Sheep}} with Five Legs},
  author = {{van den Brink}, Marieke and Benschop, Yvonne},
  year = {2012},
  volume = {19},
  pages = {507--524},
  issn = {13505084},
  doi = {10.1177/1350508411414293},
  abstract = {Academic excellence is allegedly a universal and gender neutral standard of merit. This article examines exactly what is constructed as academic excellence at the micro-level, how evaluators operationalize this construct in the criteria they apply in academic evaluation, and how gender inequalities are imbued in the construction and evaluation of excellence. We challenge the view that the academic world is governed by the normative principle of meritocracy in its allocation of rewards and resources. Based on an empirical study of professorial appointments in the Netherlands, we argue that academic excellence is an evasive social construct that is inherently gendered. We show how gender is practiced in the evaluation of professorial candidates, resulting in disadvantages for women and privileges for men that accumulate to produce substantial inequalities in the construction of excellence.},
  isbn = {1350508411},
  journal = {Organization},
  keywords = {\#nosource,construction of excellence,gender practices,inequality,meritocracy,recruitment and selection,women in academia},
  number = {4}
}

@article{Vandenbroucke2007,
  title = {Strengthening the Reporting of Observational Studies in Epidemiology ({{STROBE}}): {{Explanation}} and Elaboration},
  author = {Vandenbroucke, Jan P. and Elm, Erik Von and Altman, Douglas G. and G\o tzsche, Peter C. and Mulrow, Cynthia D. and Pocock, Stuart J. and Poole, Charles and Schlesselman, James J. and Egger, Matthias},
  year = {2007},
  volume = {18},
  pages = {805--835},
  issn = {10443983},
  doi = {10.1097/EDE.0b013e3181577511},
  abstract = {Much medical research is observational. The reporting of observational studies is often of insufficient quality. Poor reporting hampers the assessment of the strengths and weaknesses of a study and the generalizability of its results. Taking into account empirical evidence and theoretical considerations, a group of methodologists, researchers, and editors developed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) recommendations to improve the quality of reporting of observational studies. The STROBE Statement consists of a checklist of 22 items, which relate to the title, abstract, introduction, methods, results and discussion sections of articles. Eighteen items are common to cohort studies, case-control studies and cross-sectional studies and four are specific to each of the three study designs. The STROBE Statement provides guidance to authors about how to improve the reporting of observational studies and facilitates critical appraisal and interpretation of studies by reviewers, journal editors and readers.This explanatory and elaboration document is intended to enhance the use, understanding, and dissemination of the STROBE Statement. The meaning and rationale for each checklist item are presented. For each item, one or several published examples and, where possible, references to relevant empirical studies and methodological literature are provided. Examples of useful flow diagrams are also included. The STROBE Statement, this document, and the associated web site (http://www.strobe-statement.org) should be helpful resources to improve reporting of observational research.},
  isbn = {1044-3983},
  journal = {Epidemiology},
  keywords = {\#nosource},
  number = {6},
  pmid = {18049195}
}

@article{Vansteelandt2014,
  title = {On Regression Adjustment for the Propensity Score: {{S}}. {{VANSTEELANDT AND R}}. {{M}}. {{DANIEL}}},
  shorttitle = {On Regression Adjustment for the Propensity Score},
  author = {Vansteelandt, S. and Daniel, R.M.},
  year = {2014},
  month = oct,
  volume = {33},
  pages = {4053--4072},
  issn = {02776715},
  doi = {10.1002/sim.6207},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3AD3PC7U\\Vansteelandt och Daniel - 2014 - On regression adjustment for the propensity score.pdf},
  journal = {Statistics in Medicine},
  keywords = {simonsson},
  language = {en},
  number = {23}
}

@article{vanwayenburgAgeMenopauseBody2000,
  title = {Age at Menopause, Body Mass Index, and the Risk of Colorectal Cancer Mortality in the Dutch Diagnostisch Onderzoek Mammacarcinoom ({{DOM}}) Cohort},
  author = {{van Wayenburg}, Caroline A M and {van der Schouw}, Yvonne T and {van Noord}, Paulus A H and Peeters, Petra H M},
  year = {2000},
  volume = {11},
  issn = {1044-3983},
  abstract = {We investigated whether age at menopause is associated with subsequent mortality from colorectal cancer along with the possible modification of this association by body mass index. Our data are from the Diagnostisch Onderzoek Mammacarcinoom cohort of 10,671 postmenopausal women in the Netherlands, enrolled between 1974 and 1977, with a median follow-up of 18 years. During this follow-up, 95 women died of colorectal cancer. Women 49 years of age or older at menopause showed a lower risk of colorectal cancer mortality compared with women younger than 49 at menopause. This protective effect, however, was found only among nonoverweight women ({$\leq$}24 kg/m2), for whom the hazard ratio was 0.46 (95\% confidence interval = 0.21\textendash 1.03). In larger women, the hazard ratio was 1.17 (95\% confidence interval = 0.68\textendash 2.00).},
  journal = {Epidemiology},
  keywords = {\#nosource,age at menopause,body mass index,cohort study,colorectal neoplasms,endogenous female hormones,mortality},
  number = {3}
}

@book{vardanalysLapptackeMedOtillracklig2017,
  title = {Lappt\"acke Med Otillr\"acklig T\"ackning {{Slututv\"ardering}} Av Satsningen P\aa{} Nationella Kvalitetsregister},
  author = {{V\aa rdanalys}},
  year = {2017},
  isbn = {978-91-87213-71-7},
  keywords = {\#nosource}
}

@article{Varma2006,
  title = {Bias in Error Estimation When Using Cross-Validation for Model Selection},
  author = {Varma, Sudhir and Simon, Richard},
  year = {2006},
  volume = {7},
  pages = {1--8},
  issn = {14712105},
  doi = {10.1186/1471-2105-7-91},
  abstract = {BACKGROUND: Cross-validation (CV) is an effective method for estimating the prediction error of a classifier. Some recent articles have proposed methods for optimizing classifiers by choosing classifier parameter values that minimize the CV error estimate. We have evaluated the validity of using the CV error estimate of the optimized classifier as an estimate of the true error expected on independent data. RESULTS: We used CV to optimize the classification parameters for two kinds of classifiers; Shrunken Centroids and Support Vector Machines (SVM). Random training datasets were created, with no difference in the distribution of the features between the two classes. Using these "null" datasets, we selected classifier parameter values that minimized the CV error estimate. 10-fold CV was used for Shrunken Centroids while Leave-One-Out-CV (LOOCV) was used for the SVM. Independent test data was created to estimate the true error. With "null" and "non null" (with differential expression between the classes) data, we also tested a nested CV procedure, where an inner CV loop is used to perform the tuning of the parameters while an outer CV is used to compute an estimate of the error. The CV error estimate for the classifier with the optimal parameters was found to be a substantially biased estimate of the true error that the classifier would incur on independent data. Even though there is no real difference between the two classes for the "null" datasets, the CV error estimate for the Shrunken Centroid with the optimal parameters was less than 30\{\%\} on 18.5\{\%\} of simulated training data-sets. For SVM with optimal parameters the estimated error rate was less than 30\{\%\} on 38\{\%\} of "null" data-sets. Performance of the optimized classifiers on the independent test set was no better than chance. The nested CV procedure reduces the bias considerably and gives an estimate of the error that is very close to that obtained on the independent testing set for both Shrunken Centroids and SVM classifiers for "null" and "non-null" data distributions. CONCLUSION: We show that using CV to compute an error estimate for a classifier that has itself been tuned using CV gives a significantly biased estimate of the true error. Proper use of CV for estimating true error of a classifier developed using a well defined algorithm requires that all steps of the algorithm, including classifier parameter tuning, be repeated in each CV loop. A nested CV procedure provides an almost unbiased estimate of the true error.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TBJ9B7XQ\\varma_simon_2006_bias_in_error_estimation_when_using_cross-validation_for_model_selection.pdf},
  isbn = {1471-2105},
  journal = {BMC Bioinformatics},
  number = {9},
  pmid = {16504092}
}

@article{Vaupel1979,
  title = {The Impact of Heterogeneity i Nindividual Frailty on the Dynamics of Mortality},
  author = {Vaupel, James W and Manton, Kenneth G and Stallard, Eric},
  year = {1979},
  volume = {16},
  pages = {439--454},
  journal = {Demography},
  keywords = {\#nosource},
  number = {3}
}

@article{Vennix2015,
  title = {Laparoscopic Peritoneal Lavage or Sigmoidectomy for Perforated Diverticulitis with Purulent Peritonitis: A Multicentre, Parallel-Group, Randomised, Open-Label Trial},
  author = {Vennix, Sandra and Musters, Gijsbert D and Mulder, Irene M and Swank, Hilko A and Consten, Esther C and Belgers, Eric H and {van Geloven}, Anna A and Gerhards, Michael F and Govaert, Marc J and {van Grevenstein}, Wilhelmina M and Hoofwijk, Anton G and Kruyt, Philip M and Nienhuijs, Simon W and Boermeester, Marja A and Vermeulen, Jefrey and {van Dieren}, Susan and Lange, Johan F and Bemelman, Willem A and Hop, W C and Opmeer, B C and Reitsma, J B and Scholte, R A and Waltmann, E W H and Legemate, D A and Bartelsman, J F and Meijer, D W and {de Brouwer}, M and {van Dalen}, J and Durbridge, M and Geerdink, M and Ilbrink, G J and Mehmedovic, S and Middelhoek, P and Saverio, Salomone Di and Boom, M J and Consten, E C J and {van der Bilt}, J D W and {van Olden}, G D J and Stam, M A W and Verweij, M S and Busch, O R C and Buskens, C J and {El-Massoudi}, Y and Kluit, A B and {van Rossem}, C C and Schijven, M P and Tanis, P J and Unlu, C and Gerhards, M F and Karsten, T M and {de Nes}, L C and Rijna, H and {van Wagensveld}, B A and Koffeman, G I and Steller, E P and Tuynman, J B and Bruin, S C and {van der Peet}, D L and {Blanken-Peeters}, C F J M and Cense, H A and Jutte, E and Crolla, R M P H and {van der Schelling}, G P and {van Zeeland}, M and {de Graaf}, E J R and Groenendijk, R P R and Karsten, T M and Vermaas, M and Schouten, O and {de Vries}, M R and Prins, H A and Lips, D J and Bosker, R J I and {van der Hoeven}, J A B and Diks, J and Plaisier, P W and Kruyt, P M and Sietses, C and Stommel, M W J and Nienhuijs, S W and {de Hingh}, I H J T and Luyer, M D P and {van Montfort}, G and Ponten, E H and Smulders, J F and {van Duyn}, E B and Klaase, J M and Swank, D J and Ottow, R T and Stockmann, H B A C and Vermeulen, J and Vuylsteke, R J C L M and Belgers, H J and Fransen, S and {von Meijenfeldt}, E M and Sosef, M N and {van Geloven}, A A W and Hendriks, E R and {ter Horst}, B and Leeuwenburgh, M M N and {van Ruler}, O and Vogten, J M and Vriens, E J C and Westerterp, M and Eijsbouts, Q A J and Bentohami, A and Bijlsma, T S and {de Korte}, N and Nio, D and Govaert, M J P M and Joosten, J J A and Tollenaar, R A E M and Stassen, L P S and Wiezer, M J and Hazebroek, E J and Smits, A B and {van Westreenen}, H L and Lange, J F and Brandt, A and Nijboer, W N and Toorenvliet, B R and Weidema, W F and Coene, P P L O and Mannaerts, G H H and den Hartog, D and {de Vos}, R J and Zengerink, J F and Hoofwijk, A G M and Hulsew{\'e}, K W E and Melenhorst, J and Stoot, J H M B and Steup, W H and Huijstee, P J and Merkus, J W S and Wever, J J and Maring, J K and Heisterkamp, J and {van Grevenstein}, W M U and Vriens, M R and Besselink, M G H and Rinkes, I H M Borel and Witkamp, A J and Slooter, G D and Konsten, J L M and Engel, A F and Pierik, E G J M and Frakking, T G and {van Geldere}, D and Patijn, G A and D'Hoore, A J L and {de Buck van Overstraeten}, A and Miserez, M and Terrasson, I and Wolthuis, A and Blasiis, M G De},
  year = {2015},
  month = sep,
  volume = {386},
  pages = {1269--1277},
  publisher = {{Elsevier}},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(15)61168-0},
  abstract = {BACKGROUND Case series suggest that laparoscopic peritoneal lavage might be a promising alternative to sigmoidectomy in patients with perforated diverticulitis. We aimed to assess the superiority of laparoscopic lavage compared with sigmoidectomy in patients with purulent perforated diverticulitis, with respect to overall long-term morbidity and mortality. METHODS We did a multicentre, parallel-group, randomised, open-label trial in 34 teaching hospitals and eight academic hospitals in Belgium, Italy, and the Netherlands (the Ladies trial). The Ladies trial is split into two groups: the LOLA group comparing laparoscopic lavage with sigmoidectomy and the DIVA group comparing Hartmann's procedure with sigmoidectomy plus primary anastomosis. The DIVA section of this trial is still underway but here we report the results of the LOLA section. Patients with purulent perforated diverticulitis were enrolled for LOLA, excluding patients with faecal peritonitis, aged older than 85 years, with high-dose steroid use ({$\geq$}20 mg daily), and haemodynamic instability. Patients were randomly assigned (2:1:1; stratified by age [\textexclamdown 60 years vs {$\geq$}60 years]) using secure online computer randomisation to laparoscopic lavage, Hartmann's procedure, or primary anastomosis in a parallel design after diagnostic laparoscopy. Patients were analysed according to a modified intention-to-treat principle and were followed up after the index operation at least once in the outpatient setting and after sigmoidoscopy and stoma reversal, according to local protocols. The primary endpoint was a composite endpoint of major morbidity and mortality within 12 months. This trial is registered with ClinicalTrials.gov, number NCT01317485. FINDINGS Between July 1, 2010, and Feb 22, 2013, 90 patients were randomly assigned in the LOLA section of the Ladies trial when the study was terminated by the data and safety monitoring board because of an increased event rate in the lavage group. Two patients were excluded for protocol violations. The primary endpoint occurred in 30 (67\%) of 45 patients in the lavage group and 25 (60\%) of 42 patients in the sigmoidectomy group (odds ratio 1{$\cdot$}28, 95\% CI 0{$\cdot$}54\textendash 3{$\cdot$}03, p=0{$\cdot$}58). By 12 months, four patients had died after lavage and six patients had died after sigmoidectomy (p=0{$\cdot$}43). INTERPRETATION Laparoscopic lavage is not superior to sigmoidectomy for the treatment of purulent perforated diverticulitis. FUNDING Netherlands Organisation for Health Research and Development.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8KTBJ8DG\\vennix_et_al_2015_laparoscopic_peritoneal_lavage_or_sigmoidectomy_for_perforated_diverticulitis.pdf},
  journal = {The Lancet},
  number = {10000}
}

@article{Verdecchia2002,
  title = {Estimation and Projections of Cancer Prevalence from Cancer Registry Data},
  author = {Verdecchia, Arduino and Angelis, Giovanni De and Capocaccia, Riccardo},
  year = {2002},
  month = nov,
  volume = {21},
  pages = {3511--3526},
  issn = {0277-6715},
  doi = {10.1002/sim.1304},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\AA7GLWLY\\verdecchia_et_al_2002_estimation_and_projections_of_cancer_prevalence_from_cancer_registry_data.pdf},
  journal = {Statistics in Medicine},
  number = {22}
}

@article{Vergara2014,
  title = {Factors Related to Functional Prognosis in Elderly Patients after Accidental Hip Fractures: A Prospective Cohort Study},
  author = {Vergara, Itziar and Vrotsou, Kalliopi and Orive, Miren and Gonzalez, Nerea and Garcia, Susana and Quintana, Jose M},
  year = {2014},
  month = dec,
  volume = {14},
  pages = {124},
  issn = {1471-2318},
  doi = {10.1186/1471-2318-14-124},
  abstract = {BACKGROUND A restriction in functional capacity occurs in all hip fractures and a variety of factors have been shown to influence patient functional outcome. This study sought to provide new and comprehensive insights into the role of factors influencing functional recovery six months after an accidental hip fracture. METHODS A prospective cohort study was conducted of patients aged 65 years or more who attended the Emergency Room (ER) for a hip fracture due to a fall. The following were studied as independent factors: socio-demographic data (age, sex, instruction level, living condition, received help), comorbidities, characteristics of the fracture, treatment performed, destination at discharge, health-related quality of life (12-Item Short Form Health Survey) and hip function (Short Western Ontario and McMaster Universities Osteoarthritis Index). As main outcome functional status was measured (Barthel Index and Lawton Instrumental Activities of Daily Living Scale). Data were collected during the first week after fracture occurrence and after 6 months of follow-up. Patients were considered to have deteriorated if there was worsening in their functional status as measured by Barthel Index and Lawton IADL scores. Factors associated with the outcome were studied via logistic regression analysis. RESULTS Six months after the fall, deterioration in function was notable, with mean reductions of 23.7 (25.2) and 1.6 (2.2) in the Barthel Index and Lawton IADL Scale scores respectively. Patients whose status deteriorated were older, had a higher degree of comorbidity and were less educated than those who remained stable or improved. The multivariate model assessing the simultaneous impact of various factors on the functional prognosis showed that older patients, living with a relative or receiving some kind of social support and those with limited hip function before the fall had the highest odds of having losses in function. CONCLUSION In our setting, the functional prognosis of patients is determined by clinical and social factors, already present before the occurrence of the fracture. This could make it necessary to perform comprehensive assessments for patients with hip fractures in order to identify those with a poor functional prognosis to tackle their specific needs and improve their recovery.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\44K8SF42\\vergara_et_al_2014_factors_related_to_functional_prognosis_in_elderly_patients_after_accidental.pdf},
  isbn = {1471-2318},
  journal = {BMC Geriatrics},
  number = {1},
  pmid = {25425462}
}

@article{Vergouwe2005,
  title = {Substantial Effective Sample Sizes Were Required for External Validation Studies of Predictive Logistic Regression Models},
  author = {Vergouwe, Yvonne and Steyerberg, Ewout W. and Eijkemans, Marinus J.C. and Habbema, J. Dik F.},
  year = {2005},
  month = may,
  volume = {58},
  pages = {475--483},
  publisher = {{Pergamon}},
  issn = {0895-4356},
  doi = {10.1016/J.JCLINEPI.2004.06.017},
  abstract = {BACKGROUND AND OBJECTIVES The performance of a prediction model is usually worse in external validation data compared to the development data. We aimed to determine at which effective sample sizes (i.e., number of events) relevant differences in model performance can be detected with adequate power. METHODS We used a logistic regression model to predict the probability that residual masses of patients treated for metastatic testicular cancer contained only benign tissue. We performed standard power calculations and Monte Carlo simulations to estimate the numbers of events that are required to detect several types of model invalidity with 80\% power at the 5\% significance level. RESULTS A validation sample with 111 events was required to detect that a model predicted too high probabilities, when predictions were on average 1.5 times too high on the odds scale. A decrease in discriminative ability of the model, indicated by a decrease in the c-statistic from 0.83 to 0.73, required 81 to 106 events, depending on the specific scenario. CONCLUSION We suggest a minimum of 100 events and 100 nonevents for external validation samples. Specific hypotheses may, however, require substantially higher effective sample sizes to obtain adequate power.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2TMCPNF2\\vergouwe_et_al_2005_substantial_effective_sample_sizes_were_required_for_external_validation.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {5}
}

@article{Viechtbauer2010,
  title = {Conducting Meta-Analyses in r with the Metafor Package},
  author = {Viechtbauer, Wolfgang},
  year = {2010},
  volume = {36},
  issn = {1548-7660},
  doi = {10.18637/jss.v036.i03},
  abstract = {The metafor package provides functions for conducting meta-analyses in R. The package includes functions for fitting the meta-analytic fixed- and random-effects models and allows for the inclusion of moderators variables (study-level covariates) in these models. Meta-regression analyses with continuous and categorical moderators can be conducted in this way. Functions for the Mantel-Haenszel and Peto's one-step method for meta-analyses of 2 x 2 table data are also available. Finally, the package provides various plot functions (for example, for forest, funnel, and radial plots) and functions for assessing the model fit, for obtaining case diagnostics, and for tests of publication bias.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZE4I6H9L\\viechtbauer_2010_conducting_meta-analyses_in_r_with_the_metafor_package.pdf},
  isbn = {1548-7660},
  journal = {Journal of Statistical Software},
  keywords = {meta-analysis,meta-regression,mixed-effects model,moderator analysis,r},
  number = {3},
  pmid = {18291371}
}

@article{Viera2008,
  title = {Odds {{Ratios}} and {{Risk Ratios}}: {{What}}'s the {{Difference}} and {{Why Does It Matter}}?:},
  shorttitle = {Odds {{Ratios}} and {{Risk Ratios}}},
  author = {Viera, Anthony J.},
  year = {2008},
  month = jul,
  volume = {101},
  pages = {730--734},
  issn = {0038-4348},
  doi = {10.1097/SMJ.0b013e31817a7ee4},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\LW4QCAG6\\Viera - 2008 - Odds Ratios and Risk Ratios What’s the Difference.pdf},
  journal = {Southern Medical Journal},
  language = {en},
  number = {7}
}

@article{Visuri2002,
  ids = {Visuri2009},
  title = {Survivorship of Hip Prosthesis in Primary Arthrosis: Influence of Bilaterality and Interoperative Time in 45,000 Hip Prostheses from the {{Finnish}} Endoprosthesis Register},
  author = {Visuri, Tuomo and Turula, Kaj B. and Pulkkinen, Pekka and Nevalainen, Juha},
  year = {2002},
  volume = {73},
  pages = {287--290},
  issn = {0001-6470},
  doi = {10.1080/000164702320155266},
  abstract = {We studied the influence of bilaterality and interoperative time on survivorship of the hip prosthesis. The material consisted of 45,000 (3,153 bilateral) total hip arthroplasties and 38,000 patients operated on for primary osteoarthrosis, using data from the Finnish Endoprosthesis Register between 1980 and 1999. Cox regression analysis showed that male sex, young age, uncemented prosthesis and time of surgery (first 10-year period) were significant risk factors for aseptic loosening. We found no difference between the survivorship of the first bilateral and that of unilaterals, but second bilaterals survived better than the unilaterals. Bilateral prostheses survived better when the second prosthesis was implanted during the first postoperative year. The risk of loosening of a bilateral prosthesis increased when the second prosthesis was implanted a few years later. Survivorship of bilateral prosthesesin a 1-stage bilateral operation was about the same as in those operated on within the first postoperative year. Better survivorship of the second bilateral can cause bias in per hip survivorship analyses. In bilateral cases, the second hip should be operated on as soon as possible or be considered for a 1-stage bilateral procedure.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\W3FENS5C\\visuri_et_al_2002_survivorship_of_hip_prosthesis_in_primary_arthrosis.pdf},
  isbn = {0001-6470 (Print)},
  journal = {Acta Orthopaedica Scandinavica},
  keywords = {*Hip Prosthesis,Aged,Female,Finland,Humans,Male,Osteoarthritis/surgery,Prosthesis Failure,Registries,Regression Analysis,Risk Factors,Time Factors},
  number = {3},
  pmid = {12143974}
}

@article{Vittinghoff2007,
  title = {Relaxing the Rule of Ten Events per Variable in Logistic and Cox Regression},
  author = {Vittinghoff, Eric and McCulloch, Charles E.},
  year = {2007},
  volume = {165},
  pages = {710--718},
  issn = {00029262},
  doi = {10.1093/aje/kwk052},
  abstract = {The rule of thumb that logistic and Cox models should be used with a minimum of 10 outcome events per predictor variable (EPV), based on two simulation studies, may be too conservative. The authors conducted a large simulation study of other influences on confidence interval coverage, type I error, relative bias, and other model performance measures. They found a range of circumstances in which coverage and bias were within acceptable levels despite less than 10 EPV, as well as other factors that were as influential as or more influential than EPV. They conclude that this rule can be relaxed, in particular for sensitivity analyses undertaken to demonstrate adequate control of confounding.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6UGSNR39\\vittinghoff_mcculloch_2007_relaxing_the_rule_of_ten_events_per_variable_in_logistic_and_cox_regression.pdf},
  isbn = {0002-9262 (Print)0002-9262 (Linking)},
  journal = {American Journal of Epidemiology},
  keywords = {Bias (epidemiology),Coverage probability,Event history analysis,Model adequacy,Type I error,Variable selection},
  number = {6},
  pmid = {17182981}
}

@article{Vogl2014,
  title = {The Impact of Preoperative Patient Characteristics on Health States after Total Hip Replacement and Related Satisfaction Thresholds: A Cohort Study},
  author = {Vogl, Matthias and Wilkesmann, Rainer and Lausmann, Christian and Hunger, Matthias and Pl{\"o}tz, Werner},
  year = {2014},
  volume = {12},
  doi = {10.1186/s12955-014-0108-1},
  abstract = {Background: The aim of the study was to analyze the effect of preoperative patient characteristics on health outcomes 6 months after total hip replacement (THR), to support patient's decision making in daily practice with predicted health states and satisfaction thresholds. By giving incremental effects for different patient subgroups, we support comparative effectiveness research (CER) on osteoarthritis interventions. Methods: In 2012, 321 patients participated in health state evaluation before and 6 months after THR. Health-related quality of life (HRQoL) was measured with the EQ-5D questionnaire. Hip-specific pain, function, and mobility were measured with the WOMAC in a prospective observation of a cohort. The predictive capability of preoperative patient characteristics \textendash{} classified according to socio-demographic factors, medical factors, and health state variables \textendash{} for changes in health outcomes is tested by correlation analysis and multivariate linear regressions. Related satisfaction thresholds were calculated with the patient acceptable symptom state (PASS) concept. Results: The mean WOMAC and EQ-5D scores before operation were 52 and 60 respectively (0 worst, 100 best). At the 6-month follow-up, scores improved by 35 and 19 units. On average, patients reported satisfaction with the operation if postoperative (change) WOMAC scores were higher than 85 (32) and postoperative (change) EQ-5D scores were higher than 79 (14). Conclusions: Changes in WOMAC and EQ-5D scores can mainly be explained by preoperative scores. The lower the preoperative WOMAC or EQ-5D scores, the higher the change in the scores. Very good or very poor preoperative scores lower the probability of patient satisfaction with THR. Shared decision making using a personalized risk assessment approach provides predicted health states and satisfaction thresholds.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GQDKIAU9\\vogl_et_al_2014_the_impact_of_preoperative_patient_characteristics_on_health_states_after_total.pdf},
  journal = {Health and quality of life outcomes},
  keywords = {EQ-5D,Health-related quality of life,Patient acceptable symptom state,Satisfaction,Total hip replacement,WOMAC},
  number = {108}
}

@article{Vogl2014,
  title = {The Impact of Preoperative Patient Characteristics on the Cost-Effectiveness of Total Hip Replacement: A Cohort Study},
  author = {Vogl, Matthias and Wilkesmann, Rainer and Lausmann, Christian and Pl{\"o}tz, Werner},
  year = {2014},
  volume = {14},
  abstract = {Background: To facilitate the discussion on the increasing number of total hip replacements (THR) and their effectiveness, we apply a joint evaluation of hospital case costs and health outcomes at the patient level to enable comparative effectiveness research (CER) based on the preoperative health state. Methods: In 2012, 292 patients from a German orthopedic hospital participated in health state evaluation before and 6 months after THR, where health-related quality of life (HRQoL) and disease specific pain and dysfunction were analyzed using EQ-5D and WOMAC scores. Costs were measured with a patient-based DRG costing scheme in a prospective observation of a cohort. Costs per quality-adjusted life year (QALY) were calculated based on the preoperative WOMAC score, as preoperative health states were found to be the best predictors of QALY gains in multivariate linear regressions. Results: Mean inpatient costs of THR were 6,310 Euros for primary replacement and 7,730 Euros for inpatient lifetime costs including revisions. QALYs gained using the U.K. population preference-weighted index were 5.95. Lifetime costs per QALY were 1,300 Euros. Conclusions: The WOMAC score and the EQ-5D score before operation were the most important predictors of QALY gains. The poorer the WOMAC score or the EQ-5D score before operation, the higher the patient benefit. Costs per QALY were far below common thresholds in all preoperative utility score groups and with all underlying calculation methodologies.},
  journal = {BMC Health Services Research},
  keywords = {\#nosource,Cost-effectiveness,Cost-utility,Costs,EQ-5D,Health-related quality of life,Hip Background,QALY,Total hip replacement,WOMAC},
  number = {342}
}

@article{Vogl2015,
  title = {Comparison of Pre-and Post-Operative Health-Related Quality of Life and Length of Stay after Primary Total Hip Replacement in Matched {{English}} and {{German}} Patient Cohorts},
  author = {Vogl, Matthias and Leidl, Reiner and Pl{\"o}tz, Werner and Gutacker, Nils},
  year = {2015},
  volume = {24},
  pages = {513--520},
  doi = {10.1007/s11136-014-0782-9},
  abstract = {Purpose We compare pre-and post-operative health-related quality of life (HRQoL) and length of stay after total hip replacement (THR) in matched German and English patient cohorts to test for differences in admission thresholds, clinical effectiveness and resource utilisation between the healthcare systems. Methods German data (n = 271) were collected in a large orthopaedic hospital in Munich, Germany; English data (n = 26,254) were collected as part of the national patient-reported outcome measures programme. HRQoL was measured using the EuroQoL-5D instrument. Propen-sity score matching was used to construct two patient cohorts that are comparable in terms of preoperative patient characteristics. Results Before matching, patients in England showed lower preoperative EQ-5D scores (0.35 vs 0.52, p  0.001) and experienced a larger improvement in HRQoL (0.43 vs 0.33, p  0.001) than German patients. Patients in the German cohort were more likely to report no or only moderate problems with mobility and pain preoperatively than their English counterparts. After matching, improve-ments in HRQoL were comparable (0.32 vs 0.33, p = 0.638); post-operative scores were slightly higher in the German cohort (0.82 vs 0.85, p = 0.585). Length of stay was substantially lower in England than in Germany (4.5 vs 9.0 days, p  0.001). Conclusions Our results highlight differences in preop-erative health status between countries, which may arise due to different admission thresholds and access to surgery. In terms of quality of life, THR surgery is equally effective in both countries when performed on similar patients, but hospital stay is shorter in England.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\XZXHMU6E\\vogl_et_al_2015_comparison_of_pre-and_post-operative_health-related_quality_of_life_and_length.pdf},
  journal = {Quality of Life Research},
  keywords = {England Á,Germany,Health-related quality of life Á EQ-5D Á,Introduction,Total hip replacement Á}
}

@article{Vollmer2020,
  title = {Machine Learning and Artificial Intelligence Research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics, and Effectiveness},
  shorttitle = {Machine Learning and Artificial Intelligence Research for Patient Benefit},
  author = {Vollmer, Sebastian and Mateen, Bilal A. and Bohner, Gergo and Kir{\'a}ly, Franz J. and Ghani, Rayid and Jonsson, Pall and Cumbers, Sarah and Jonas, Adrian and McAllister, Katherine S. L. and Myles, Puja and Grainger, David and Birse, Mark and Branson, Richard and Moons, Karel G. M. and Collins, Gary S. and Ioannidis, John P. A. and Holmes, Chris and Hemingway, Harry},
  year = {2020},
  month = mar,
  volume = {368},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.l6927},
  abstract = {{$<$}p{$>$}Machine learning, artificial intelligence, and other modern statistical methods are providing new opportunities to operationalise previously untapped and rapidly growing sources of data for patient benefit. Despite much promising research currently being undertaken, particularly in imaging, the literature as a whole lacks transparency, clear reporting to facilitate replicability, exploration for potential ethical concerns, and clear demonstrations of effectiveness. Among the many reasons why these problems exist, one of the most important (for which we provide a preliminary solution here) is the current lack of best practice guidance specific to machine learning and artificial intelligence. However, we believe that interdisciplinary groups pursuing research and impact projects involving machine learning and artificial intelligence for health would benefit from explicitly addressing a series of questions concerning transparency, reproducibility, ethics, and effectiveness (TREE). The 20 critical questions proposed here provide a framework for research groups to inform the design, conduct, and reporting; for editors and peer reviewers to evaluate contributions to the literature; and for patients, clinicians and policy makers to critically appraise where new findings may deliver patient benefit. {$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC             BY-NC. No commercial re-use. See rights and permissions. Published by             BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\Y25LGJ4S\\vollmer_et_al_2020_machine_learning_and_artificial_intelligence_research_for_patient_benefit.pdf;C\:\\Users\\erik_\\Zotero\\storage\\G5RQPHFE\\bmj.html},
  journal = {BMJ},
  keywords = {coverletter},
  language = {en},
  pmid = {32198138}
}

@techreport{Walck2007,
  title = {Hand-Book on {{STATISTICAL DISTRIBUTIONS}} for Experimentalists},
  author = {Walck, Christian and Group, Particle Physics},
  year = {2007},
  pages = {26--35},
  issn = {\textexclamdown null\textquestiondown},
  doi = {10.1002/etep.2265},
  abstract = {Internal Report SUF-PFY/96-01 Stockholm (Handbook)},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TFTCD5VP\\walck_group_2007_hand-book_on_statistical_distributions_for_experimentalists.pdf},
  isbn = {\textexclamdown null\textquestiondown},
  number = {September}
}

@article{Wall2017,
  title = {Key Developments That Impacted the Field of Mechanobiology and Mechanotransduction},
  author = {Wall, Michelle and Butler, David and Haj, Alicia El and Bodle, Josephine C. and Loboa, Elizabeth G. and Banes, Albert J.},
  year = {2017},
  pages = {20--22},
  issn = {07360266},
  doi = {10.1002/jor.23707},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\9FR85A4C\\wall_et_al_2017_key_developments_that_impacted_the_field_of_mechanobiology_and.pdf},
  isbn = {9197321591},
  journal = {Journal of Orthopaedic Research},
  keywords = {1,1836,1902,4 he was,and models and remodels,d,forms load-bearing struts,interstitially,julius wolff,m,mechanobiology,mechanoreception,observed that trabecular bone,signal transduction,the german surgeon}
}

@article{Wallace2014,
  title = {The Effect of Body Mass Index on the Risk of Post-Operative Complications during the 6 Months Following Total Hip Replacement or Total Knee Replacement Surgery.},
  author = {Wallace, G and Judge, A and {Prieto-Alhambra}, D and {de Vries}, F and Arden, N K and Cooper, C},
  year = {2014},
  month = jul,
  volume = {22},
  pages = {918--27},
  issn = {1522-9653},
  doi = {10.1016/j.joca.2014.04.013},
  abstract = {OBJECTIVE To assess the effect of obesity on 6-month post-operative complications following total knee (TKR) or hip (THR) replacement. DESIGN Data for patients undergoing first THR or TKR between 1995 and 2011 was taken from the Clinical Practice Research Datalink. Logistic regression was used to assess whether body mass index (BMI) was associated with 6-month post-operative complications [deep vein thrombosis or pulmonary embolism (DVT/PE), myocardial infarction (MI), stroke, respiratory infection, anaemia, wound infection, urinary tract infection or death] after controlling for the effects of age, gender, smoking, drinking, socio-economic status (SES), co-morbidities and medications. RESULTS 31,817 THR patients and 32,485 TKR patients were identified for inclusion. Increasing BMI was associated with a significantly higher risk of wound infections, from 1.6\% to 3.5\% in THR patients (adjusted P \textexclamdown{} 0.01), and from 3\% to 4.1\% (adjusted P \textexclamdown{} 0.05) in TKR patients. DVT/PE risk also increased with obesity from 2.2\% to 3.3\% (adjusted P \textexclamdown{} 0.01) in THR patients and from 2.0\% to 3.3\% (adjusted P \textexclamdown{} 0.01) in TKR patients. Obesity was not associated with increased risk of other complications. CONCLUSION Whilst an increased risk of wound infection and DVT/PE was observed amongst obese patients, absolute risks remain low and no such association was observed for MI, stroke and mortality. However this is a selected cohort (eligible for surgery according to judgement of NHS GPs and surgeons) and as such these results do not advocate surgery be given without consideration of BMI, but indicate that universal denial of surgery based on BMI is unwarranted.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R7YZBMET\\wallace_et_al_2014_the_effect_of_body_mass_index_on_the_risk_of_post-operative_complications.pdf},
  journal = {Osteoarthritis and cartilage},
  keywords = {Arthroplasty,Electronic health records,Epidemiology,Obesity,Post-operative complications},
  number = {7},
  pmid = {24836211}
}

@article{Walraven2009,
  title = {A Modification of the Elixhauser Comorbidity Measures into a Point System for Hospital Death Using Administrative Data},
  author = {Walraven, Carl Van and Austin, Peter C and Jennings, Alison and Quan, Hude and Alan, J Forster and Walraven, Carl Van and Austin, Peter C and Jennings, Alison},
  year = {2009},
  volume = {47},
  pages = {626--633},
  journal = {Med},
  keywords = {\#nosource},
  number = {6}
}

@article{Wang1999,
  title = {Asymptotic Properties of M-Estimators Based on Estimating Equations and Censored Data},
  author = {Wang, Jane-Ling},
  year = {1999},
  volume = {26},
  pages = {297--318},
  issn = {0303-6898},
  doi = {10.1111/1467-9469.00151},
  abstract = {Properties of Huber's M-estimators based on estimating equations have been studied extensively and are well understood for complete (i.i.d.) data. Although the concepts of M-estimators and in\textasciimacron uence curves have been extended for some time by Reid (1981) to incomplete data that are subject to right censoring, results on the general behavior of M-estimators based on incomplete data remain scattered and restrictive. This paper establishes a general large sample theory for M-estimators based on censored data. We show how to extend any asymptotic result available for M-estimators based on complete data to the case of censored data. The extensions are usually straightforward and include the multiparameter situation. Both the lifetime and censoring distributions may be discontinuous. We illustrate several extensions which provide simple and tractable suf\textregistered cient conditions for an M-estimator to be strongly consistent and asymptotically normal. The in\textasciimacron uence curves and asymptotic variance of the M-estimators are also derived. The applicability of the new suf\textregistered cient conditions is demonstrated through several examples, including location and scale M-estimators.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3PU7WXSC\\wang_1999_asymptotic_properties_of_m-estimators_based_on_estimating_equations_and.pdf},
  journal = {Scandinavian Journal of Statistics},
  keywords = {asymptotic normality of m-estimators,functionals of kaplan,in,meier estimator,one-step m-estimator,strong consistency,uence curve},
  number = {2}
}

@article{Wang2007,
  title = {Is the Pearson r 2 Biased, and If so, What Is the Best Correction Formula?},
  author = {Wang, Zhongmiao and Thompson, Bruce},
  year = {2007},
  volume = {75},
  pages = {109--125},
  issn = {0022-0973},
  doi = {10.3200/JEXE.75.2.109-125},
  abstract = {In this study the authors investigated the use of 5 (i.e., Claudy, Ezekiel, Olkin-Pratt, Pratt, and Smith) R[squared] correction formulas with the Pearson r[squared]. The authors estimated adjustment bias and precision under 6 x 3 x 6 conditions (i.e., population {$\rho$} values of 0.0, 0.1, 0.3, 0.5, 0.7, and 0.9; population shapes normal, skewness = kurtosis = 1, and skewness = -1.5 with kurtosis = 3.5; ns = 10, 20, 40, 60, 100, and 200 respectively). Results indicate that the sample Pearson r[squared] is marginally biased at small sample sizes and small population effect sizes, and that the Ezekiel and the Smith R[squared] corrections work well in controlling this bias. (Contains 5 tables.)},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\R9666XHR\\wang_thompson_2007_is_the_pearson_r_2_biased,_and_if_so,_what_is_the_best_correction_formula.pdf},
  journal = {The Journal of Experimental Education},
  keywords = {Bivariate relationship,Correlation,Effect sizes,Pearson r,Statistical bias},
  number = {2}
}

@article{Wang2015,
  title = {Large Unbalanced Credit Scoring Using Lasso-Logistic Regression Ensemble},
  author = {Wang, Hong and Xu, Qingsong and Zhou, Lifeng},
  editor = {{Emmert-Streib}, Frank},
  year = {2015},
  month = feb,
  volume = {10},
  pages = {e0117844},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pone.0117844},
  abstract = {Recently, various ensemble learning methods with different base classifiers have been proposed for credit scoring problems. However, for various reasons, there has been little research using logistic regression as the base classifier. In this paper, given large unbalanced data, we consider the plausibility of ensemble learning using regularized logistic regression as the base classifier to deal with credit scoring problems. In this research, the data is first balanced and diversified by clustering and bagging algorithms. Then we apply a Lasso-logistic regression learning ensemble to evaluate the credit risks. We show that the proposed algorithm outperforms popular credit scoring models such as decision tree, Lasso-logistic regression and random forests in terms of AUC and F-measure. We also provide two importance measures for the proposed model to identify important variables in the data.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\6DYREX9Z\\wang_et_al_2015_large_unbalanced_credit_scoring_using_lasso-logistic_regression_ensemble.pdf},
  journal = {PLOS ONE},
  number = {2}
}

@article{Wang2018,
  title = {Big Data Analytics: {{Understanding}} Its Capabilities and Potential Benefits for Healthcare Organizations},
  author = {Wang, Yichuan and Kung, LeeAnn and Byrd, Terry Anthony},
  year = {2018},
  volume = {126},
  pages = {3--13},
  issn = {0040-1625},
  doi = {10.1016/j.techfore.2015.12.019},
  abstract = {To date, health care industry has not fully grasped the potential benefits to be gained from big data analytics. While the constantly growing body of academic research on big data analytics is mostly technology oriented, a better understanding of the strategic implications of big data is urgently needed. To address this lack, this study examines the historical development, architectural design and component functionalities of big data analytics. From content analysis of 26 big data implementation cases in healthcare, we were able to identify five big data analytics capabilities: analytical capability for patterns of care, unstructured data analytical capability, decision support capability, predictive capability, and traceability. We also mapped the benefits driven by big data analytics in terms of information technology (IT) infrastructure, operational, organizational, managerial and strategic areas. In addition, we recommend five strategies for healthcare organizations that are considering to adopt big data analytics technologies. Our findings will help healthcare organizations understand the big data analytics capabilities and potential benefits and support them seeking to formulate more effective data-driven analytics strategies.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\M27JJMB8\\wang_et_al_2018_big_data_analytics.pdf},
  journal = {Technological Forecasting and Social Change},
  keywords = {Big data analytics,Big data analytics architecture,Big data analytics capabilities,Business value of information technology (IT),Health care}
}

@article{Wang2018,
  title = {Modeling Restricted Mean Survival Time under General Censoring Mechanisms},
  author = {Wang, Xin and Schaubel, Douglas E.},
  year = {2018},
  month = jan,
  volume = {24},
  pages = {176--199},
  publisher = {{Springer New York LLC}},
  issn = {15729249},
  doi = {10.1007/s10985-017-9391-6},
  abstract = {Restricted mean survival time (RMST) is often of great clinical interest in practice. Several existing methods involve explicitly projecting out patient-specific survival curves using parameters estimated through Cox regression. However, it would often be preferable to directly model the restricted mean for convenience and to yield more directly interpretable covariate effects. We propose generalized estimating equation methods to model RMST as a function of baseline covariates. The proposed methods avoid potentially problematic distributional assumptions pertaining to restricted survival time. Unlike existing methods, we allow censoring to depend on both baseline and time-dependent factors. Large sample properties of the proposed estimators are derived and simulation studies are conducted to assess their finite sample performance. We apply the proposed methods to model RMST in the absence of liver transplantation among end-stage liver disease patients. This analysis requires accommodation for dependent censoring since pre-transplant mortality is dependently censored by the receipt of a liver transplant.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5PFJ5LY9\\wang_schaubel_2018_modeling_restricted_mean_survival_time_under_general_censoring_mechanisms.pdf},
  journal = {Lifetime Data Analysis},
  keywords = {Dependent censoring,Generalized linear model,Inverse weighting,Pre-treatment survival,Restricted mean lifetime,Transplantation},
  number = {1}
}

@article{Wang2019,
  title = {Computationally Efficient Inference for Center Effects Based on Restricted Mean Survival Time},
  author = {Wang, Xin and Zhong, Yingchao and Mukhopadhyay, Purna and Schaubel, DouglasE.},
  year = {2019},
  volume = {38},
  pages = {5133--5145},
  issn = {0277-6715},
  doi = {10.1002/sim.8356},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KRHURDMX\\wang_et_al_2019_computationally_efficient_inference_for_center_effects_based_on_restricted_mean.pdf},
  journal = {Statistics in Medicine},
  number = {26}
}

@book{Wannheden2016,
  title = {Kvalitetsregister Och Beslutsst\"od- {{Tv\aa}} Sidor Av Samma Mynt},
  author = {Wannheden, Carolina},
  year = {2016},
  isbn = {978-91-982324-1-7},
  keywords = {\#nosource}
}

@article{Warren1971,
  title = {Correlation or Regression: {{Bias}} or Precision},
  author = {Warren, W. G.},
  year = {1971},
  volume = {20},
  pages = {148},
  issn = {00359254},
  doi = {10.2307/2346463},
  abstract = {A quantitative study is made of the bias in the usual estimate of the linear correlation coefficient and of the relative efficiency of the estimated regression, when a certain type of selective sampling is employed. A good compromise seems difficult to obtain and it is the author's thesis that the simultaneous presentation of regression equations and correlation coefficients is, in a sense, contradictory.},
  isbn = {0035-9254},
  journal = {Applied Statistics},
  keywords = {\#nosource},
  number = {2}
}

@article{Warton2018,
  title = {Why You Cannot Transform Your Way out of Trouble for Small Counts},
  author = {Warton, David I.},
  year = {2018},
  volume = {74},
  pages = {362--368},
  issn = {15410420},
  doi = {10.1111/biom.12728},
  abstract = {While data transformation is a common strategy to satisfy linear modeling assumptions, a theoretical result is used to show that transformation cannot reasonably be expected to stabilize variances for small counts. Under broad assumptions, as counts get smaller, it is shown that the variance becomes proportional to the mean under monotonic transformations g({$\cdot$}) that satisfy g(0) = 0, excepting a few pathological cases. A suggested rule-of-thumb is that if many predicted counts are less than one then data transformation cannot reasonably be expected to stabilize variances, even for a well-chosen transformation. This result has clear implications for the analysis of counts as often implemented in the applied sciences, but particularly for multivariate analysis in ecology. Multivariate discrete data are often collected in ecology, typically with a large proportion of zeros, and it is currently widespread to use methods of analysis that do not account for differences in variance across observations nor across responses. Simulations demonstrate that failure to account for the mean\textendash variance relationship can have particularly severe consequences in this context, and also in the univariate context if the sampling design is unbalanced.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IGF7X6BW\\warton_2018_why_you_cannot_transform_your_way_out_of_trouble_for_small_counts.pdf},
  journal = {Biometrics},
  keywords = {Community composition,Ecology,Generalized linear models,Multivariate analysis,Variance stabilizing transformation},
  number = {1}
}

@article{Wasserstein2016,
  title = {The {{ASA}}'s Statement on p-Values: Context, Process, and Purpose},
  author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
  year = {2016},
  month = mar,
  pages = {00--00},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\HYFKMLK5\\wasserstein_lazar_2016_the_asa's_statement_on_p-values.pdf},
  journal = {The American Statistician}
}

@article{Weinstein2007,
  title = {Perspective: {{Informed}} Patient Choice: {{Patient}}-Centered Valuing of Surgical Risks and Benefits},
  author = {Weinstein, James N. and Clay, Kate and Morgan, Tamara S.},
  year = {2007},
  volume = {26},
  pages = {726--730},
  issn = {02782715},
  doi = {10.1377/hlthaff.26.3.726},
  abstract = {The risks and benefits of any health care intervention are valued differently by stakeholders. One of the ethical imperatives of patient-centered care is the balanced, evidence-based presentation of risks and benefits by providers to patients. Using the example of musculoskeletal surgery with devices, we advocate the use of shared decision-making tools and processes known to improve knowledge, adjust unrealistic expectations, and elicit values about benefits desired and the degree of acceptable risks for individual patients. We describe feasibility and efficacy within our organization and address ways to foster the further adoption of this approach.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\KCQLVJ9W\\weinstein_et_al_2007_perspective.pdf},
  isbn = {1544-5208 (Electronic){\r  }0278-2715 (Linking)},
  journal = {Health Affairs},
  number = {3},
  pmid = {17485750}
}

@article{Weir2015,
  title = {The Past, Present, and Future of Cancer Incidence in the {{United States}}: 1975 through 2020},
  author = {Weir, Hannah K. and Thompson, Trevor D. and Soman, Ashwini and M\o ller, Bj\o rn and Leadbetter, Steven},
  year = {2015},
  volume = {121},
  pages = {1827--1837},
  issn = {10970142},
  doi = {10.1002/cncr.29258},
  abstract = {BACKGROUND: The overall age-standardized cancer incidence rate continues to decline whereas the number of cases diagnosed each year increases. Predicting cancer incidence can help to anticipate future resource needs, evaluate primary prevention strategies, and inform research. METHODS: Surveillance, Epidemiology, and End Results data were used to estimate the number of cancers (all sites) resulting from changes in population risk, age, and size. The authors projected to 2020 nationwide age-standardized incidence rates and cases (including the top 23 cancers). RESULTS: Since 1975, incident cases increased among white individuals, primarily caused by an aging white population, and among black individuals, primarily caused by an increasing black population. Between 2010 and 2020, it is expected that overall incidence rates (proxy for risk) will decrease slightly among black men and stabilize in other groups. By 2020, the authors predict annual cancer cases (all races, all sites) to increase among men by 24.1\% (-3.2\% risk and 27.3\% age/growth) to \textquestiondown 1 million cases, and by 20.6\% among women (1.2\% risk and 19.4\% age/growth) to \textquestiondown 900,000 cases. The largest increases are expected for melanoma (white individuals); cancers of the prostate, kidney, liver, and urinary bladder in males; and the lung, breast, uterus, and thyroid in females. CONCLUSIONS: Overall, the authors predict cancer incidence rates/risk to stabilize for the majority of the population; however, they expect the number of cancer cases to increase by \textquestiondown 20\%. A greater emphasis on primary prevention and early detection is needed to counter the effect of an aging and growing population on the burden of cancer.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\43JP6JMA\\weir_et_al_2015_the_past,_present,_and_future_of_cancer_incidence_in_the_united_states.pdf},
  isbn = {0008-543X},
  journal = {Cancer},
  keywords = {cancer,cancer registries,incidence,predictions,projections,surveillance},
  number = {11},
  pmid = {25649671}
}

@techreport{Weiss2000,
  title = {Learning to Predict Extremely Rare Events},
  author = {Weiss, Gary M and Hirsh, Haym},
  year = {2000},
  abstract = {This paper describes Timeweaver, a genetic-based machine learning system that predicts events by identifying temporal and sequential patterns in data. This paper then focuses on the issues related to predicting rare events and discusses how Timeweaver addresses these issues. In particular, we describe how the genetic algorithm's fitness function is tailored to handle the prediction of rare events, by factoring in the precision and recall of each prediction rule.},
  keywords = {\#nosource}
}

@article{Wells2013,
  title = {Exploring Robust Methods for Evaluating Treatment and Comparison Groups in Chronic Care Management Programs.},
  author = {Wells, Aaron R and Hamar, Brent and Bradley, Chastity and Gandy, William M and Harrison, Patricia L and Sidney, James A and Coberley, Carter R and Rula, Elizabeth Y and Pope, James E},
  year = {2013},
  month = feb,
  volume = {16},
  pages = {35--45},
  publisher = {{Mary Ann Liebert, Inc.}},
  issn = {1942-7905},
  doi = {10.1089/pop.2011.0104},
  abstract = {Evaluation of chronic care management (CCM) programs is necessary to determine the behavioral, clinical, and financial value of the programs. Financial outcomes of members who are exposed to interventions (treatment group) typically are compared to those not exposed (comparison group) in a quasi-experimental study design. However, because member assignment is not randomized, outcomes reported from these designs may be biased or inefficient if study groups are not comparable or balanced prior to analysis. Two matching techniques used to achieve balanced groups are Propensity Score Matching (PSM) and Coarsened Exact Matching (CEM). Unlike PSM, CEM has been shown to yield estimates of causal (program) effects that are lowest in variance and bias for any given sample size. The objective of this case study was to provide a comprehensive comparison of these 2 matching methods within an evaluation of a CCM program administered to a large health plan during a 2-year time period. Descriptive and statistical methods were used to assess the level of balance between comparison and treatment members pre matching. Compared with PSM, CEM retained more members, achieved better balance between matched members, and resulted in a statistically insignificant Wald test statistic for group aggregation. In terms of program performance, the results showed an overall higher medical cost savings among treatment members matched using CEM compared with those matched using PSM (-25.57 versus -19.78, respectively). Collectively, the results suggest CEM is a viable alternative, if not the most appropriate matching method, to apply when evaluating CCM program performance.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\G65K9YR3\\wells_et_al_2013_exploring_robust_methods_for_evaluating_treatment_and_comparison_groups_in.pdf},
  journal = {Population health management},
  number = {1},
  pmid = {22788834}
}

@article{Wendel2017,
  title = {Etikpr\"ovning Av Studentarbeten 135 {{ETIKPR\"OVNING AV STUDENTARBETEN}}},
  author = {Wendel, Lotta},
  year = {2017},
  journal = {F\"orvaltningsr\"attslig tidskrift},
  keywords = {\#nosource}
}

@techreport{Westerberg2012,
  title = {Registerdata F\"or Forskning},
  author = {Westerberg, Bengt},
  year = {2012},
  institution = {{Regeringen}},
  city = {Stockholm},
  isbn = {9789138237366},
  keywords = {\#nosource}
}

@techreport{Westerberg2014,
  title = {Unik Kunskap Genom Registerforskning},
  author = {Westerberg, Bengt},
  year = {2014},
  pages = {45},
  isbn = {9789138241332},
  keywords = {\#nosource}
}

@article{Westreich2013,
  title = {The Table 2 Fallacy: {{Presenting}} and Interpreting Confounder and Modifier Coefficients},
  author = {Westreich, Daniel and Greenland, Sander},
  year = {2013},
  volume = {177},
  pages = {292--298},
  issn = {00029262},
  doi = {10.1093/aje/kws412},
  abstract = {It is common to present multiple adjusted effect estimates from a single model in a single table. For example, a table might show odds ratios for one or more exposures and also for several confounders from a single logistic regression. This can lead to mistaken interpretations of these estimates. We use causal diagrams to display the sources of the problems. Presentation of exposure and confounder effect estimates from a single model may lead to several interpretative difficulties, inviting confusion of direct-effect estimates with total-effect estimates for covariates in the model. These effect estimates may also be confounded even though the effect estimate for the main exposure is not confounded. Interpretation of these effect estimates is further complicated by heterogeneity (variation, modification) of the exposure effect measure across covariate levels. We offer suggestions to limit potential misunderstandings when multiple effect estimates are presented, including precise distinction between total and direct effect measures from a single model, and use of multiple models tailored to yield total-effect estimates for covariates.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\UHA2I4D2\\westreich_greenland_2013_the_table_2_fallacy.pdf},
  isbn = {1476-6256 (Electronic){\r  }0002-9262 (Linking)},
  journal = {American Journal of Epidemiology},
  keywords = {causal diagrams,causal inference,confounding,direct effects,epidemiologic methods,mediation analysis,regression modeling},
  number = {4},
  pmid = {23371353}
}

@article{Wherry1931,
  title = {A New Formula for Predicting Shrikage of the Coefficient of Multiple Correlation},
  author = {Wherry, RJ},
  year = {1931},
  volume = {2},
  pages = {440--451},
  issn = {00034851},
  doi = {DOI 10.1214/aoms/1177732951},
  abstract = {The use of transformations to stabilize the variance of binomial or Poisson data is familiar(Anscombe 1, Bartlett 2, 3, Curtiss 4, Eisenhart 5). The comparison of transformed binomial or Poisson data with percentage points of the normal distribution to make approximate significance tests or to set approximate confidence intervals is less familiar. Mosteller and Tukey 6 have recently made a graphical application of a transformation related to the square-root transformation for such purposes, where the use of "binomial probability paper" avoids all computation. We report here on an empirical study of a number of approximations, some intended for significance and confidence work and others for variance stabilization. For significance testing and the setting of confidence limits, we should like to use the normal deviate K exceeded with the same probability as the number of successes x from n in a binomial distribution with expectation np, which is defined by frac12pi int\textsuperscript{K}-infty e{$^-$}frac12t{$^2$} dt = operatornameProb x leq k mid operatornamebinomial, n, p. The most useful approximations to K that we can propose here are N (very simple), N{$^+$} (accurate near the usual percentage points), and N\textsuperscript{a}stast (quite accurate generally), where N = 2 (sqrt(k + 1)q - sqrt(n - k)p). (This is the approximation used with binomial probability paper.) N{$^+$} = N + fracN + 2p - 112sqrtE,quad E = textlesser of np textand nq, N\textsuperscript{a}st = N + frac(N - 2)(N + 2)12 big(frac1sqrtnp + 1 - frac1sqrtnq + 1big), N\textsuperscript{a}stast = N\textsuperscript{a}st + fracN\textsuperscript{a}st + 2p - 112 sqrtEcdotquad E = textlesser of np textand nq. For variance stabilization, the averaged angular transformation sin{$^-$}1sqrtfracxn + 1 + sin{$^-$}1 sqrtfracx + 1n+1 has variance within pm 6\% of frac1n + frac12 text(angles in radians), frac821n + frac12 text(angles in degrees), for almost all cases where np geq 1. In the Poisson case, this simplifies to using sqrtx + sqrtx + 1 as having variance 1.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZP2PXZQM\\wherry_1931_a_new_formula_for_predicting_shrikage_of_the_coefficient_of_multiple_correlation.pdf},
  isbn = {0003-4851},
  journal = {Annals of Mathematical Statistics},
  number = {4}
}

@article{Wherry1931,
  title = {A New Formula for Predicting the Shrinkage of the Coefficient of Multiple Correlation},
  author = {Wherry, R},
  year = {1931},
  volume = {2},
  pages = {440--457},
  abstract = {44\textquestiondown{} hORMULA POR (6) ?*.\textexclamdown{} *\textquestiondown ' \guillemotright{} \cyrchar\cyre\cyrchar\cyrg\cyrchar\cyro\cyrchar\cyrg{} NM and since 2 , by (2) above, we have s0 equa we have {$^($}7) -\cyrchar\cyrg{} f N(lt?z) f i-p2 1 N equal to (1 - {$^2$} ), which is, exactly, the BB Smith (1). This has been widely used during the last few},
  journal = {The annals of mathematical statistics},
  keywords = {\#nosource},
  number = {4}
}

@article{White2011,
  title = {Multiple Imputation Using Chained Equations: {{Issues}} and Guidance for Practice},
  author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
  year = {2011},
  volume = {30},
  pages = {377--399},
  issn = {02776715},
  doi = {10.1002/sim.4067},
  abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VBHFCUY9\\white_et_al_2011_multiple_imputation_using_chained_equations.pdf},
  isbn = {1097-0258 (Electronic)0277-6715 (Linking)},
  journal = {Statistics in Medicine},
  keywords = {Fully conditional specification,Missing data,Multiple imputation},
  number = {4},
  pmid = {21225900}
}

@article{Whitmore2014,
  title = {{{ASA}} Grade and {{Charlson Comorbidity Index}} of Spinal Surgery Patients: Correlation with Complications and Societal Costs.},
  author = {Whitmore, Robert G and Stephen, James H and Vernick, Coleen and Campbell, Peter G and Yadla, Sanjay and Ghobrial, George M and Maltenfort, Mitchell G and Ratliff, John K},
  year = {2014},
  month = jan,
  volume = {14},
  pages = {31--8},
  issn = {1878-1632},
  doi = {10.1016/j.spinee.2013.03.011},
  abstract = {BACKGROUND CONTEXT The Charlson Comorbidity Index (CCI) and the American Society of Anesthesiologists (ASA) Physical Status Classification System (ASA grade) are useful for predicting morbidity and mortality for a variety of disease processes. PURPOSE To evaluate CCI and ASA grade as predictors of complications after spinal surgery and examine the correlation between these comorbidity indices and the cost of care. STUDY DESIGN/SETTING Prospective observational study. PATIENT SAMPLE All patients undergoing any spine surgery at a single academic tertiary center over a 6-month period. OUTCOME MEASURES Direct health-care costs estimated from diagnosis related group and Current Procedural Terminology (CPT) codes. METHODS Demographic data, including all patient comorbidities, procedural data, and all complications, occurring within 30 days of the index procedure were prospectively recorded. Charlson Comorbidity Index was calculated from International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) codes and ASA grades determined from the operative record. Diagnosis related group and CPT codes were captured for each patient. Direct costs were estimated from a societal perspective using Medicare rates of reimbursement. A multivariable analysis was performed to assess the association of the CCI and ASA grade to the rate of complication and direct health-care costs. RESULTS Two hundred twenty-six cases were analyzed. The average CCI score for the patient cohort was 0.92, and the average ASA grade was 2.65. The CCI and ASA grade were significantly correlated, with Spearman {$\rho$} of 0.458 (p\textexclamdown.001). Both CCI and ASA grade were associated with increasing body mass index (p\textexclamdown.01) and increasing patient age (p\textexclamdown.0001). Increasing CCI was associated with an increasing likelihood of occurrence of any complication (p=.0093) and of minor complications (p=.0032). Increasing ASA grade was significantly associated with an increasing likelihood of occurrence of a major complication (p=.0035). Increasing ASA grade showed a significant association with increasing direct costs (p=.0062). CONCLUSIONS American Society of Anesthesiologists and CCI scores are useful comorbidity indices for the spine patient population, although neither was completely predictive of complication occurrence. A spine-specific comorbidity index, based on ICD-9-CM coding that could be easily captured from patient records, and which is predictive of patient likelihood of complications and mortality, would be beneficial in patient counseling and choice of operative intervention.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\7HQC87YB\\whitmore_et_al_2014_asa_grade_and_charlson_comorbidity_index_of_spinal_surgery_patients.pdf},
  journal = {The spine journal : official journal of the North American Spine Society},
  keywords = {American Society of Anesthesiologists grade,Charlson Comorbidity Index,Complications,Societal costs,Spinal surgery},
  number = {1},
  pmid = {23602377}
}

@article{Wickham2014,
  title = {Tidy Data},
  author = {Wickham, Hadley},
  year = {2014},
  volume = {59},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  abstract = {In this paper we present the R package gRain for propagation in graphical indepen- dence networks (for which Bayesian networks is a special instance). The paper includes a description of the theory behind the computations. The main part of the paper is an illustration of how to use the package. The paper also illustrates how to turn a graphical model and data into an independence network.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\3HW95529\\wickham_2014_tidy_data.pdf},
  isbn = {9780387781662},
  journal = {Journal of Statistical Software},
  keywords = {data cleaning,data tidying,r,relational databases},
  number = {10},
  pmid = {18291371}
}

@book{Wickham2015,
  title = {Advanced r},
  author = {Wickham, Hadley.},
  year = {2015},
  publisher = {{CRC Press}},
  abstract = {An Essential Reference for Intermediate and Advanced R Programmers Advanced R presents useful tools and techniques for attacking many types of R programming problems, helping you avoid mistakes and dead ends. With more than ten years of experience programming in R, the author illustrates the elegance, beauty, and flexibility at the heart of R. The book develops the necessary skills to produce quality code that can be used in a variety of circumstances. You will learn: The fundamentals of R, including standard data types and functions Functional programming as a useful framework for solving wide classes of problems The positives and negatives of metaprogramming How to write fast, memory-efficient code This book not only helps current R users become R programmers but also shows existing programmers what's special about R. Intermediate R programmers can dive deeper into R and learn new strategies for solving diverse problems while programmers from other languages can learn the details of R and understand why R works the way it does. Introduction \textendash{} Foundations. Data structures \textendash{} Subsetting \textendash{} Vocabulary \textendash{} Style guide \textendash{} Functions \textendash{} OO field guide \textendash{} Environments \textendash{} Debugging, condition handling, and defensive programming \textendash{} Functional programming. Functional programming \textendash{} Functionals \textendash{} Function operators \textendash{} Computing on the language. Non-standard evaluation \textendash{} Expressions \textendash{} Domain specific languages \textendash{} Performance. Performance \textendash{} Optimising code \textendash{} Memory \textendash{} High performance functions with Rcpp \textendash{} R's C interface.},
  isbn = {978-1-4665-8696-3},
  keywords = {\#nosource}
}

@book{Wickham2015,
  title = {R Packages},
  author = {Wickham, Hadley},
  year = {2015},
  publisher = {{O'Relly}},
  abstract = {First edition. Includes index. Turn your R code into packages that others can easily download and use. This practical book shows you how to bundle reusable R functions, sample data, and documentation together by applying author Hadley Wickham's package development philosophy. In the process, you'll work with devtools, roxygen, and testthat, a set of R packages that automate common development tasks. Devtools encapsulates best practices that Hadley has learned from years of working with this programming language. Ideal for developers, data scientists, and programmers with various backgrounds, this book starts you with the basics and shows you how to improve your package writing over time. You'll learn to focus on what you want your package to do, rather than think about package structure. Learn about the most useful components of an R package, including vignettes and unit testsAutomate anything you can, taking advantage of the years of development experience embodied in devtoolsGet tips on good style, such as organizing functions into filesStreamline your development process with devtoolsLearn the best way to submit your package to the Comprehensive R Archive Network (CRAN)Learn from a well-respected member of the R community who created 30 R packages, including ggplot2, dplyr, and tidyr. Machine generated contents note: pt. I Getting Started \textendash{} 1. Introduction \textendash{} Philosophy \textendash{} Getting Started \textendash{} Conventions \textendash{} Colophon \textendash{} 2. Package Structure \textendash{} Naming Your Package \textendash{} Requirements for a Name \textendash{} Strategies for Creating a Name \textendash{} Creating a Package \textendash{} RStudio Projects \textendash{} What Is an RStudio Project File? \textendash{} What Is a Package? \textendash{} Source Packages \textendash{} Bundled Packages \textendash{} Binary Packages \textendash{} Installed Packages \textendash{} In-Memory Packages \textendash{} What Is a Library? \textendash{} pt. II Package Components \textendash{} 3.R Code \textendash{} R Code Workflow \textendash{} Organizing Your Functions \textendash{} Code Style \textendash{} Object Names \textendash{} Spacing \textendash{} Curly Braces \textendash{} Line Length \textendash{} Indentation \textendash{} Assignment \textendash{} Commenting Guidelines \textendash{} Top-Level Code \textendash{} Loading Code \textendash{} The R Landscape \textendash{} When You Do Need Side Effects \textendash{} S4 Classes, Generics, and Methods \textendash{} CRAN Notes \textendash{} 4. Package Metadata \textendash{} Dependencies: What Does Your Package Need? \textendash{} Versioning \textendash{} Other Dependencies \textendash{} Title and Description: What Does Your Package Do? \textendash{} Author: Who Are You? \textendash{} On CRAN \textendash{} License: Who Can Use Your Package? \textendash{} On CRAN \textendash{} Version \textendash{} Other Components \textendash{} 5. Object Documentation \textendash{} The Documentation Workflow \textendash{} Alternative Documentation Workflow \textendash{} Roxygen Comments \textendash{} Documenting Functions \textendash{} Documenting Datasets \textendash{} Documenting Packages \textendash{} Documenting Classes, Generics, and Methods \textendash{} S3 \textendash{} S4 \textendash{} RC \textendash{} Special Characters \textendash{} Do Repeat Yourself \textendash{} Inheriting Parameters from Other Functions \textendash{} Documenting Multiple Functions in the Same File \textendash{} Text Formatting Reference Sheet \textendash{} Character Formatting \textendash{} Links \textendash{} Lists \textendash{} Mathematics \textendash{} Tables \textendash{} 6. Vignettes: Long-Form Documentation \textendash{} Vignette Workflow \textendash{} Metadata \textendash{} Markdown \textendash{} Sections \textendash{} Lists \textendash{} Inline Formatting \textendash{} Tables \textendash{} Code \textendash{} Knitr \textendash{} Options \textendash{} Development Cycle \textendash{} Advice for Writing Vignettes \textendash{} Organization \textendash{} CRAN Notes \textendash{} Where to Go Next \textendash{} 7. Testing \textendash{} Test Workflow \textendash{} Test Structure \textendash{} Expectations \textendash{} Writing Tests \textendash{} What to Test \textendash{} Skipping a Test \textendash{} Building Your Own Testing Tools \textendash{} Test Files \textendash{} CRAN Notes \textendash{} 8. Namespace \textendash{} Motivation \textendash{} Search Path \textendash{} The NAMESPACE \textendash{} Workflow \textendash{} Exports \textendash{} S3 \textendash{} S4 \textendash{} RC \textendash{} Data \textendash{} Imports \textendash{} R Functions \textendash{} S3 \textendash{} S4 \textendash{} Compiled Functions \textendash{} 9. External Data \textendash{} Exported Data \textendash{} Documenting Datasets \textendash{} Internal Data \textendash{} Raw Data \textendash{} Other Data \textendash{} CRAN Notes \textendash{} 10.Compiled Code \textendash{} C++ \textendash{} Workflow \textendash{} Documentation \textendash{} Exporting C++ Code \textendash{} Importing C++ Code \textendash{} Best Practices \textendash{} C \textendash{} Getting Started with .Call() \textendash{} Getting Started with C() \textendash{} Workflow \textendash{} Exporting C Code \textendash{} Importing C Code \textendash{} Best Practices \textendash{} Debugging Compiled Code \textendash{} Makefiles \textendash{} Other Languages \textendash{} Licensing \textendash{} Development Workflow \textendash{} CRAN Issues \textendash{} 11. Installed Files \textendash{} Package Citation \textendash{} Other Languages \textendash{} 12. Other Components \textendash{} Demos \textendash{} pt. III Best Practices \textendash{} 13. Git and GitHub \textendash{} RStudio, Git, and GitHub \textendash{} Initial Setup \textendash{} Creating a Local Git Repository \textendash{} Seeing What's Changed \textendash{} Recording Changes \textendash{} Best Practices for Commits \textendash{} Ignoring Files \textendash{} Undoing Mistakes \textendash{} Synchronizing with GitHub \textendash{} Benefits of Using GitHub \textendash{} Working with Others \textendash{} Issues \textendash{} Branches \textendash{} Making a Pull Request \textendash{} Submitting a Pull Request to Another Repo \textendash{} Reviewing and Accepting Pull Requests \textendash{} Learning More \textendash{} 14. Automated Checking \textendash{} Workflow \textendash{} Checks \textendash{} Check Metadata \textendash{} Package Structure \textendash{} Description \textendash{} Namespace \textendash{} R Code \textendash{} Data \textendash{} Documentation \textendash{} Demos \textendash{} Compiled Code \textendash{} Tests \textendash{} Vignettes \textendash{} Checking After Every Commit with Travis \textendash{} Basic Config \textendash{} Other Uses \textendash{} 15. Releasing a Package \textendash{} Version Number \textendash{} Backward Compatibility \textendash{} The Submission Process \textendash{} Test Environments \textendash{} Check Results \textendash{} Reverse Dependencies \textendash{} CRAN Policies \textendash{} Important Files \textendash{} README.md \textendash{} README. Rmd \textendash{} NEWS.md \textendash{} Release \textendash{} On Failure \textendash{} Binary Builds \textendash{} Prepare for Next Version \textendash{} Publicizing Your Package \textendash{} Congratulations!},
  isbn = {1-4919-1059-3},
  keywords = {\#nosource}
}

@book{Wickham2017,
  title = {R for Data Science : Import, Tidy, Transform, Visualize, and Model Data},
  author = {Wickham, Hadley and Grolemund, Garrett},
  year = {2017},
  abstract = {First edition. "This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience"\textendash Page 4 of cover. Part I. Explore. Data visualization with ggplot2 \textendash{} Workflow: basics \textendash{} Data transformation with dplyr \textendash{} Workflow: scripts \textendash{} Exploratory data analysis \textendash{} Workflow: projects \textendash{} Part II. Wrangle. Tibbles with tibble \textendash{} Data import with readr \textendash Tidy data with tidyr \textendash{} Relational data with dplyr \textendash{} Strings with stringr \textendash{} Factors with forcats \textendash{} Dates and times with lubridate \textendash{} Part III. Program. Pipes with magrittr \textendash{} Functions \textendash{} Vectors \textendash{} Iteration with purrr \textendash{} Part IV. Model. Model basics with modelr \textendash{} Model building \textendash{} Many models with purrr and broom \textendash{} Part V. Communicate. R Markdown \textendash{} Graphics for communication with ggplot2 \textendash{} R Markdown formats \textendash{} R Markdown workflow.},
  isbn = {1-4919-1039-9},
  keywords = {\#nosource}
}

@article{Wild2005,
  title = {Principles of Good Practice for the Translation and Cultural Adaptation Process for Patient-Reported Outcomes ({{PRO}}) Measures: Report of the {{ISPOR}} Task Force for Translating Adaptation},
  author = {Wild, Diane and Grove, Alyson and Martin, Mona and Eremenco, Sonya and McElroy, Sandra and {Verjee-Lorenz}, Aneesa and Erikson, Pennifer},
  year = {2005},
  volume = {8},
  pages = {94--104},
  issn = {1098-3015},
  doi = {10.1111/j.1524-4733.2005.04054.x},
  abstract = {In 1999, ISPOR formed the Quality of Life Special Interest{\r  }(QoL-SIG)\textemdash Translation and Cultural Adaptation{\r  }(TCA group) to stimulate discussion on and{\r  }guidelines and standards for the translation and{\r  }adaptation of patient-reported outcome (PRO){\r  }. After identifying a general lack of consistency{\r  }current methods and published guidelines, the TCA{\r  }saw a need to develop a holistic perspective that{\r  }the full spectrum of published methods. This{\r  }resulted in the development of Translation and{\r  }Adaptation of Patient Reported Outcomes{\r  }\textemdash Principles of Good Practice (PGP), a report on{\r  }methods, and an appraisal of their strengths and{\r  }. The TCA Group undertook a review of evidence{\r  }current practice, a review of the literature and{\r  }guidelines, and consideration of the issues facing{\r  }pharmaceutical industry, regulators, and the broader{\r  }research community. Each approach to translation{\r  }cultural adaptation was considered systematically{\r  }terms of rationale, components, key actors, and{\r  }potential benefits and risks associated with each{\r  }and step. The results of this review were subjected{\r  }discussion and challenge within the TCA group,{\r  }well as consultation with the outcomes research{\r  }at large. Through this review, a consensus{\r  }on a broad approach, along with a detailed critique{\r  }the strengths and weaknesses of the differing{\r  }. The results of this review are set out{\r  }``Translation and Cultural Adaptation of Patient{\r  }Outcomes Measures\textemdash Principles of Good Practice''{\r  }are reported in this document.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FCEWRKDD\\wild_et_al_2005_principles_of_good_practice_for_the_translation_and_cultural_adaptation_process.pdf},
  isbn = {1098-3015 (Print){\r  }1098-3015 (Linking)},
  journal = {Value in Health},
  keywords = {cultural adaptation,good practice,guidelines,linguistic validation,patient reported outcomes measures},
  number = {2},
  pmid = {15804318}
}

@techreport{Wilkerson2019,
  title = {{{ConsensusClusterPlus}} ( Tutorial )},
  author = {Wilkerson, Matthew D},
  year = {2019},
  pages = {1--12},
  keywords = {\#nosource}
}

@book{Wilkinson2005,
  title = {The Grammar of Graphics},
  author = {Wilkinson, Leland},
  year = {2005},
  isbn = {978-0-387-24544-7},
  keywords = {\#nosource}
}

@article{Wille2010,
  title = {Development of the {{EQ}}-{{5D}}-{{Y}}: {{A}} Child-Friendly Version of the {{EQ}}-{{5D}}},
  author = {Wille, Nora and Badia, Xavier and Bonsel, Gouke and Burstr{\"o}m, Kristina and Cavrini, Gulia and Devlin, Nancy and Egmar, Ann Charlotte and Greiner, Wolfgang and Gusi, Narcis and Herdman, Michael and Jelsma, Jennifer and Kind, Paul and Scalone, Luciana and {Ravens-Sieberer}, Ulrike},
  year = {2010},
  volume = {19},
  pages = {875--886},
  issn = {09629343},
  doi = {10.1007/s11136-010-9648-y},
  abstract = {PURPOSE: To develop a self-report version of the EQ-5D for younger respondents, named the EQ-5D-Y (Youth); to test its comprehensibility for children and adolescents and to compare results obtained using the standard adult EQ-5D and the EQ-5D-Y. METHODS: An international task force revised the content of EQ-5D and wording to ensure relevance and clarity for young respondents. Children's and adolescents' understanding of the EQ-5D-Y was tested in cognitive interviews after the instrument was translated into German, Italian, Spanish and Swedish. Differences between the EQ-5D and the EQ-5D-Y regarding frequencies of reported problems were investigated in Germany, Spain and South Africa. RESULTS: The content of the EQ-5D dimensions proved to be appropriate for the measurement of HRQOL in young respondents. The wording of the questionnaire had to be adapted which led to small changes in the meaning of some items and answer options. The adapted EQ-5D-Y was satisfactorily understood by children and adolescents in different countries. It was better accepted and proved more feasible than the EQ-5D. The administration of the EQ-5D and of the EQ-5D-Y causes differences in frequencies of reported problems. CONCLUSIONS: The newly developed EQ-5D-Y is a useful tool to measure HRQOL in young people in an age-appropriate manner.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\J8ZGPT5E\\wille_et_al_2010_development_of_the_eq-5d-y.pdf},
  isbn = {1573-2649 (Electronic){\r  }0962-9343 (Linking)},
  journal = {Quality of Life Research},
  keywords = {Adolescent health,Child health,EQ-5D,HRQOL,Measurement},
  number = {6},
  pmid = {20405245}
}

@article{Williams2002,
  title = {Hospital Episode Statistics: Time for Clinicians to Get Involved?},
  author = {Williams, J. G. and Mann, R. Y.},
  year = {2002},
  volume = {2},
  pages = {34--37},
  issn = {14702118},
  doi = {10.7861/clinmedicine.2-1-34},
  abstract = {Hospital episode statistics contain clinical data. They are used for many purposes, including monitoring activity in the NHS and the allocation of funds. More recently they have been applied to monitoring performance, and it is intended that they will inform consultant appraisal and revalidation. The validity of hospital episode statistics was questioned by K\"orner in 1982. Recent publications have shown that problems persist in England and Wales, and that the quality of the data is inadequate for the task. The lack of involvement of clinicians in the process of data collection and validation is no longer acceptable. To rectify the situation there should be a change of process and culture, supported by education and investment. NHS data definitions of terms such as 'spells', 'episodes' and 'diagnoses' need to be reviewed. The development of separate data processes to monitor national service frameworks is regrettable.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\DH7B7XVT\\williams_mann_2002_hospital_episode_statistics.pdf},
  journal = {Clinical medicine (London, England)},
  keywords = {clinicians,hospital episode statistics},
  number = {1}
}

@article{Williamson2003,
  title = {Marginal Analyses of Clustered Data When Cluster Size Is Informative},
  author = {Williamson, John M. and Datta, Somnath and Satten, Glen A.},
  year = {2003},
  month = mar,
  volume = {59},
  pages = {36--42},
  publisher = {{Blackwell Publishing, Inc.}},
  issn = {0006341X},
  doi = {10.1111/1541-0420.00005},
  abstract = {We propose a new approach to fitting marginal models to clustered data when cluster size is informative. This approach uses a generalized estimating equation (GEE) that is weighted inversely with the cluster size. We show that our approach is asymptotically equivalent to within-cluster resampling (Hoffman, Sen, and Weinberg, 2001, Biometrika 73, 13-22), a computationally intensive approach in which replicate data sets containing a randomly selected observation from each cluster are analyzed, and the resulting estimates averaged. Using simulated data and an example involving dental health, we show the superior performance of our approach compared to unweighted GEE, the equivalence of our approach with WCR for large sample sizes, and the superior performance of our approach compared with WCR when sample sizes are small.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\FQBG6AA3\\williamson_et_al_2003_marginal_analyses_of_clustered_data_when_cluster_size_is_informative.pdf},
  isbn = {0006-341X (Print){\r  }0006-341X (Linking)},
  journal = {Biometrics},
  keywords = {Cluster-weighted GEE,Generalized estimating equation (GEE),Within-cluster resampling (WCR)},
  number = {1},
  pmid = {12762439}
}

@article{Willis-Owen2010,
  title = {Factors Affecting the Incidence of Infection in Hip and Knee Replacement: {{AN ANALYSIS OF}} 5277 {{CASES}}},
  shorttitle = {Factors Affecting the Incidence of Infection in Hip and Knee Replacement},
  author = {{Willis-Owen}, C. A. and Konyves, A. and Martin, D. K.},
  year = {2010},
  month = aug,
  volume = {92-B},
  pages = {1128--1133},
  issn = {0301-620X, 2044-5377},
  doi = {10.1302/0301-620X.92B8.24333},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RWYAX2X5\\Willis-Owen et al_2010_Factors affecting the incidence of infection in hip and knee replacement.pdf},
  journal = {The Journal of Bone and Joint Surgery. British volume},
  language = {en},
  number = {8}
}

@article{Wilson2017,
  title = {Good Enough Practices in Scientific Computing},
  author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
  editor = {Ouellette, Francis},
  year = {2017},
  month = jun,
  volume = {13},
  pages = {e1005510},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005510},
  abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\RTLD9GRF\\wilson_et_al_2017_good_enough_practices_in_scientific_computing.pdf},
  journal = {PLOS Computational Biology},
  number = {6}
}

@article{Wingert2016a,
  title = {The {{ACS NSQIP Risk Calculator Is}} a {{Fair Predictor}} of {{Acute Periprosthetic Joint Infection}}:},
  shorttitle = {The {{ACS NSQIP Risk Calculator Is}} a {{Fair Predictor}} of {{Acute Periprosthetic Joint Infection}}},
  author = {Wingert, Nathaniel C. and Gotoff, James and Parrilla, Edgardo and Gotoff, Robert and Hou, Laura and Ghanem, Elie},
  year = {2016},
  month = jul,
  volume = {474},
  pages = {1643--1648},
  issn = {0009-921X},
  doi = {10.1007/s11999-016-4717-3},
  abstract = {Background Periprosthetic joint infection (PJI) is a severe complication from the patient's perspective and an expensive one in a value-driven healthcare model. Risk stratification can help identify those patients who may have risk factors for complications that can be mitigated in advance of elective surgery. Although numerous surgical risk calculators have been created, their accuracy in predicting outcomes, specifically PJI, has not been tested.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\BIU3HUNK\\Wingert et al. - 2016 - The ACS NSQIP Risk Calculator Is a Fair Predictor .pdf},
  journal = {Clinical Orthopaedics and Related Research},
  language = {en},
  number = {7}
}

@article{Wishart1931,
  title = {The Mean and Second Moment Coefficient of the Multiple Correlation Coefficient, in Samples from a Normal Population},
  author = {Wishart, Author J and Kondo, T and Elderton, E M},
  year = {1931},
  volume = {22},
  pages = {353--376},
  issn = {00063444},
  doi = {10.2307/2332101},
  isbn = {00063444},
  journal = {Biometrika},
  keywords = {\#nosource},
  number = {3/4}
}

@article{Wojtowicz2019,
  title = {Is {{Parkinson}}'s {{Disease Associated}} with {{Increased Mortality}}, {{Poorer Outcomes Scores}}, and {{Revision Risk After THA}}? {{Findings}} from the {{Swedish Hip Arthroplasty Register}}:},
  shorttitle = {Is {{Parkinson}}'s {{Disease Associated}} with {{Increased Mortality}}, {{Poorer Outcomes Scores}}, and {{Revision Risk After THA}}?},
  author = {Wojtowicz, Alex Leigh and Mohaddes, Maziar and Odin, Daniel and B{\"u}low, Erik and Nemes, Szilard and Cnudde, Peter},
  year = {2019},
  month = jun,
  volume = {477},
  pages = {1347--1355},
  issn = {0009-921X},
  doi = {10.1097/CORR.0000000000000679},
  journal = {Clinical Orthopaedics and Related Research},
  keywords = {coder},
  language = {en},
  number = {6}
}

@techreport{Wolpert1997,
  title = {No Free Lunch Theorems for Optimization},
  author = {Wolpert, David H and Macready, William G},
  year = {1997},
  volume = {1},
  pages = {67},
  abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZEQ6U8LK\\wolpert_macready_1997_no_free_lunch_theorems_for_optimization.pdf},
  keywords = {Index Terms-Evolutionary algorithms,information theory,optimization},
  number = {1}
}

@article{Wood1986,
  title = {Think {{Before}} You {{Square Correlations}}\textemdash or Do Anything with Them},
  author = {Wood, Robert},
  year = {1986},
  volume = {12},
  pages = {249--255},
  issn = {14693518},
  doi = {10.1080/0141192860120303},
  isbn = {0141192860},
  journal = {British Educational Research Journal},
  keywords = {\#nosource},
  number = {3}
}

@article{Wright1999,
  title = {Writing for the Journal of Orthopaedic Research},
  author = {Wright, Timothy M and Buckwalter, Joseph A and Hayes, C and Wright, M},
  year = {1999},
  volume = {17},
  pages = {459--466},
  publisher = {{Bone and Joint Surgery, Inc}},
  abstract = {Good scientific writing requires good science and good writing. Unfortunately, the last time most of us were asked to think about the mechanics of writing was in grade school. As a result, many of us have forgotten the rules of grammar, the weakness of the passive voice, and the need for topic sentences and transitional phrases in the construction of a paragraph. In addition, few of us have been taught to write a scientific manuscript. Instead, we learn by emulating available (and sometimes imperfect) literature and by the slow and often painful process of writing and publishing our work. Furthermore, of the many texts and articles about scientific writing, few deal in practical terms with the form and content of biomedical research papers. Thus, when planning to publish our research results, we can be faced with a series of questions. What should be included in the Introduction? How much literature should be reviewed? How many reference citations are too many? What order should be followed and what tense should be used in the Materials and Methods section? How should figures be cited in the Results section? How should the Discussion be organized? What constitutes a good title? What should be covered in the summary? When an article is being written for a particular journal, especially one like the Journal of Orthopaedic Research that has two editorial offices, questions of format and style can be even more confusing. If different editors expect different editorial style, published manuscripts may exhibit stylistic differences that further confuse authors trying to model their papers on recent issues of the journal. The consequence is all too often the submission of manuscripts that do not conform to a particular editorial vision, even if they reflect good science and writing. This can result in author frustration, delays in resubmissions, and extra cycles of review. Moreover, especially with first-time authors, the editors must write editorial decision letters that},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\GSC5BQB3\\wright_et_al_1999_writing_for_the_journal_of_orthopaedic_research.pdf},
  journal = {Journal of Orthopaedic Research}
}

@article{Wright2017,
  title = {Ranger : {{A}} Fast Implementation of Random Forests for High Dimensional Data in {{C}}++ and r},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2017},
  month = mar,
  volume = {77},
  pages = {1--17},
  doi = {10.18637/jss.v077.i01},
  abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\5EKXUKGP\\wright_ziegler_2017_ranger.pdf},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{Wu2017,
  title = {Effects of Higher Quality of Care on Initiation of Long-Term Dialysis in Patients with {{CKD}} and Diabetes},
  author = {Wu, Hon Yen and Fukuma, Shingo and Shimizu, Sayaka and Norton, Edward C. and Tu, Yu Kang and Hung, Kuan Yu and Chen, Mei Ru and Chien, Kuo Liong and Fukuhara, Shunichi},
  year = {2017},
  volume = {70},
  pages = {666--674},
  publisher = {{Elsevier Inc}},
  issn = {15236838},
  doi = {10.1053/j.ajkd.2017.05.020},
  abstract = {Background The burden of diabetes-related chronic kidney disease (CKD) on individuals and society is increasing, shifting attention toward improving the quality of care for patients with CKD and diabetes. We assessed the quality of CKD care and its association with long-term dialysis, acute kidney injury (AKI), and death. Study Design Retrospective cohort study (2004-2011). Setting \& Participants Adults in Taiwan with incident CKD enrolled in the Longitudinal Cohort of Diabetes Patients. Predictors 3 CKD-care quality indicators based on medical and pharmacy claims data were studied: prescription of renin-angiotensin system inhibitors, testing for proteinuria, and nutritional guidance. Each was examined individually, and all were summed into an overall quality score. Outcomes The primary outcome was initiation of long-term dialysis therapy. Secondary outcomes were hospitalization due to AKI and death from any cause. Measurements Using instrumental variables related to the quality indicators to minimize both unmeasured and measured confounding, we fit a 2-stage residual inclusion model to estimate HRs and 95\% CIs for each outcome. Results Among the 63,260 patients enrolled, 43.9\% were prescribed renin-angiotensin system inhibitors, 60.6\% were tested for proteinuria, and 13.4\% received nutritional guidance. During a median follow-up of 37.9 months, 1,471 patients started long-term dialysis therapy, 2,739 patients were hospitalized due to AKI, and 4,407 patients died. Higher overall quality scores were associated with lower hazards for long-term dialysis in instrumental variable analyses (HR of 0.62 [95\% CI, 0.40-0.98] per 1-point greater score) and hospitalization due to AKI (HR of 0.69 [95\% CI, 0.50-0.96] per 1-point greater score). The hazard for all-cause death was nonsignificantly lower (HR of 0.80 [95\% CI, 0.62-1.03] per 1-point greater score). Limitations Potential misclassification and uncontrolled confounding by indication. Conclusions Our findings suggest potential opportunities to improve long-term outcomes among patients with diabetes and CKD by improving the quality of their CKD care.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\TT674GR5\\wu_et_al_2017_effects_of_higher_quality_of_care_on_initiation_of_long-term_dialysis_in.pdf},
  journal = {American Journal of Kidney Diseases},
  keywords = {acute kidney injury (AKI),chronic kidney disease (CKD),diabetes,Diabetic kidney disease,disease progression,end-stage renal disease (ESRD),healthcare quality of care,incident dialysis,instrumental variable analysis,quality indicators},
  number = {5},
  pmid = {28764919}
}

@article{Wuerz2014,
  title = {A {{Nomogram}} to {{Predict Major Complications After Hip}} and {{Knee Arthroplasty}}},
  author = {Wuerz, Thomas H. and Kent, David M. and Malchau, Henrik and Rubash, Harry E.},
  year = {2014},
  month = jul,
  volume = {29},
  pages = {1457--1462},
  issn = {08835403},
  doi = {10.1016/j.arth.2013.09.007},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EPU349SA\\Wuerz et al_2014_A Nomogram to Predict Major Complications After Hip and Knee Arthroplasty.pdf},
  journal = {The Journal of Arthroplasty},
  language = {en},
  number = {7}
}

@phdthesis{Wynants2016,
  title = {Clinical Risk Prediction Models Based on Multicenter Data Methods for Model Development and Validation},
  author = {Wynants, Laure},
  year = {2016},
  keywords = {\#nosource}
}

@article{Wynants2018,
  title = {Random-Effects Meta-Analysis of the Clinical Utility of Tests and Prediction Models},
  author = {Wynants, L. and Riley, R.D. and Timmerman, D. and Van Calster, B.},
  year = {2018},
  month = may,
  volume = {37},
  pages = {2034--2052},
  issn = {02776715},
  doi = {10.1002/sim.7653},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\S56S428Q\\sim.7653.pdf},
  journal = {Statistics in Medicine},
  keywords = {acta review},
  language = {en},
  number = {12}
}

@article{Wynants2020,
  title = {Prediction Models for Diagnosis and Prognosis of Covid-19 Infection: Systematic Review and Critical Appraisal},
  shorttitle = {Prediction Models for Diagnosis and Prognosis of Covid-19 Infection},
  author = {Wynants, Laure and Calster, Ben Van and Bonten, Marc M. J. and Collins, Gary S. and Debray, Thomas P. A. and Vos, Maarten De and Haller, Maria C. and Heinze, Georg and Moons, Karel G. M. and Riley, Richard D. and Schuit, Ewoud and Smits, Luc J. M. and Snell, Kym I. E. and Steyerberg, Ewout W. and Wallisch, Christine and van Smeden, Maarten},
  year = {2020},
  month = apr,
  volume = {369},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m1328},
  abstract = {Objective To review and critically appraise published and preprint reports of prediction models for diagnosing coronavirus disease 2019 (covid-19) in patients with suspected infection, for prognosis of patients with covid-19, and for detecting people in the general population at risk of being admitted to hospital for covid-19 pneumonia.
Design Rapid systematic review and critical appraisal.
Data sources PubMed and Embase through Ovid, Arxiv, medRxiv, and bioRxiv up to 24 March 2020.
Study selection Studies that developed or validated a multivariable covid-19 related prediction model.
Data extraction At least two authors independently extracted data using the CHARMS (critical appraisal and data extraction for systematic reviews of prediction modelling studies) checklist; risk of bias was assessed using PROBAST (prediction model risk of bias assessment tool).
Results 2696 titles were screened, and 27 studies describing 31 prediction models were included. Three models were identified for predicting hospital admission from pneumonia and other events (as proxy outcomes for covid-19 pneumonia) in the general population; 18 diagnostic models for detecting covid-19 infection (13 were machine learning based on computed tomography scans); and 10 prognostic models for predicting mortality risk, progression to severe disease, or length of hospital stay. Only one study used patient data from outside of China. The most reported predictors of presence of covid-19 in patients with suspected disease included age, body temperature, and signs and symptoms. The most reported predictors of severe prognosis in patients with covid-19 included age, sex, features derived from computed tomography scans, C reactive protein, lactic dehydrogenase, and lymphocyte count. C index estimates ranged from 0.73 to 0.81 in prediction models for the general population (reported for all three models), from 0.81 to more than 0.99 in diagnostic models (reported for 13 of the 18 models), and from 0.85 to 0.98 in prognostic models (reported for six of the 10 models). All studies were rated at high risk of bias, mostly because of non-representative selection of control patients, exclusion of patients who had not experienced the event of interest by the end of the study, and high risk of model overfitting. Reporting quality varied substantially between studies. Most reports did not include a description of the study population or intended use of the models, and calibration of predictions was rarely assessed.
Conclusion Prediction models for covid-19 are quickly entering the academic literature to support medical decision making at a time when they are urgently needed. This review indicates that proposed models are poorly reported, at high risk of bias, and their reported performance is probably optimistic. Immediate sharing of well documented individual participant data from covid-19 studies is needed for collaborative efforts to develop more rigorous prediction models and validate existing ones. The predictors identified in included studies could be considered as candidate predictors for new models. Methodological guidance should be followed because unreliable predictions could cause more harm than benefit in guiding clinical decisions. Finally, studies should adhere to the TRIPOD (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis) reporting guideline.
Systematic review registration Protocol https://osf.io/ehc47/, registration https://osf.io/wy245.},
  chapter = {Research},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC                 BY. No commercial re-use. See rights and permissions. Published by                 BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\V6VJ44LU\\wynants_et_al_2020_prediction_models_for_diagnosis_and_prognosis_of_covid-19_infection.pdf;C\:\\Users\\erik_\\Zotero\\storage\\STBK4YC6\\bmj.html},
  journal = {BMJ},
  keywords = {coverletter},
  language = {en},
  pmid = {32265220}
}

@article{Wyrwich2013,
  title = {Methods for Interpreting Change over Time in Patient-Reported Outcome Measures},
  author = {Wyrwich, K. W. and Norquist, J. M. and Lenderking, W. R. and Acaster, S.},
  year = {2013},
  volume = {22},
  pages = {475--483},
  issn = {09629343},
  doi = {10.1007/s11136-012-0175-x},
  abstract = {PURPOSE: Interpretation guidelines are needed for patient-reported outcome (PRO) measures' change scores to evaluate efficacy of an intervention and to communicate PRO results to regulators, patients, physicians, and providers. The 2009 Food and Drug Administration (FDA) Guidance for Industry Patient-Reported Outcomes (PRO) Measures: Use in Medical Product Development to Support Labeling Claims (hereafter referred to as the final FDA PRO Guidance) provides some recommendations for the interpretation of change in PRO scores as evidence of treatment efficacy.: This article reviews the evolution of the methods and the terminology used to describe and aid in the communication of meaningful PRO change score thresholds.: Anchor- and distribution-based methods have played important roles, and the FDA has recently stressed the importance of cross-sectional patient global assessments of concept as anchor-based methods for estimation of the responder definition, which describes an individual-level treatment benefit. The final FDA PRO Guidance proposes the cumulative distribution function (CDF) of responses as a useful method to depict the effect of treatments across the study population.: While CDFs serve an important role, they should not be a replacement for the careful investigation of a PRO's relevant responder definition using anchor-based methods and providing stakeholders with a relevant threshold for the interpretation of change over time.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\PV4GNR4Q\\wyrwich_et_al_2013_methods_for_interpreting_change_over_time_in_patient-reported_outcome_measures.pdf},
  isbn = {1573-2649 (Electronic){\r  }0962-9343 (Linking)},
  journal = {Quality of Life Research},
  keywords = {Anchor-based,Change over time,Cumulative distribution function,Distribution-based,Interpretation,Minimal important difference,Patient-reported outcome,Quality of life,Responder definition},
  number = {3},
  pmid = {22528240}
}

@article{Yeh2007,
  title = {Psychometric Properties of the {{Chinese}} Version of Copenhagen Burnout Inventory among Employees in Two Companies in {{Taiwan}}},
  author = {Yeh, Wan Yu and Cheng, Yawen and Chen, Chiou Jong and Hu, Pei Yi and Kristensen, Tage S.},
  year = {2007},
  volume = {14},
  pages = {126--133},
  issn = {10705503},
  doi = {10.1007/BF03000183},
  abstract = {This study examined the psychometric properties of two selected scales\textendash 'personal burnout' and 'work-related burnout'\textendash from the Chinese version of the Copenhagen Burnout Inventory (C-CBI) in 384 employees from two companies in Taiwan. A self-administered questionnaire was used that included the two C-CBI scales, the scales of mental health, vitality and general health from the Short Form 36 (SF-36), perceived level of job stress, job satisfaction, working hours, as well as measures for psychological job demands, job control, work-related social support, and over-commitment to work. Both the C-CBI personal burnout scale and work-related burnout scale had high internal consistency and were correlated well with other health, job characteristics, and perception of work measures;furthermore, exploratory factor analysis extracted two empirical factors. However, the two C-CBI scales were highly correlated in the present population and appeared to measure overlapping concepts. Some comments and suggestions were raised for further improvement.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\856BVRUT\\yeh_et_al_2007_psychometric_properties_of_the_chinese_version_of_copenhagen_burnout_inventory.pdf},
  isbn = {1070-5503},
  journal = {International Journal of Behavioral Medicine},
  keywords = {Burnout,Copenhagen Burnout Inventory (CBI),Occupational health,Reliability,Taiwan,Validity},
  number = {3},
  pmid = {18062055}
}

@article{Yeo2000,
  title = {A New Family of Power Transformations to Improve Normality or Symmetry},
  author = {Yeo, I.-K. and Johnson, Richard A.},
  year = {2000},
  month = dec,
  volume = {87},
  pages = {954--959},
  publisher = {{Oxford University Press}},
  issn = {0006-3444},
  doi = {10.1093/biomet/87.4.954},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\F2SMCQH9\\yeo_johnson_2000_a_new_family_of_power_transformations_to_improve_normality_or_symmetry.pdf},
  journal = {Biometrika},
  number = {4}
}

@article{Yin2001,
  title = {Estimating r 2 Shrinkage in Multiple Regression: {{A}} Comparison of Different Analytical Methods},
  author = {Yin, Ping and Fan, Xitao},
  year = {2001},
  volume = {69},
  pages = {203--224},
  issn = {0022-0973},
  doi = {10.1080/00220970109600656},
  abstract = {Abstract The effectiveness of various analytical formulas for estimating R 2 shrinkage in multiple regression analysis was investigated. Two categories of formulas were identified: estimators of the squared population multiple correlation coefficient ({$\rho$}2) and those of the squared population cross-validity coefficient ({$\rho$}c 2). The authors conducted a Monte Carlo experiment to investigate the effectiveness of the analytical formulas for estimating R 2 shrinkage, with 4 fully crossed factors (squared population multiple correlation coefficient, number of predictors, sample size, and degree of multicollinearity) and 500 replications in each cell. The results indicated that the most widely used Wherry formula (in both SAS and SPSS) is probably not the most effective analytical formula for estimating {$\rho$}2. Instead, the Pratt formula and the Browne formula outperformed other analytical formulas in estimating {$\rho$}2 and {$\rho$}c 2, respectively.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\IML2Y9YL\\yin_fan_2001_estimating_r_2_shrinkage_in_multiple_regression.pdf},
  isbn = {0022097010960},
  journal = {The Journal of Experimental Education},
  keywords = {Cross-validation,Monte Carlo method,multiple regression,R 1 shrinkage,statistical bias},
  number = {2}
}

@article{Yu2013,
  title = {Projections of Cancer Prevalence by Phase of Care: A Potential Tool for Planning Future Health Service Needs},
  author = {Yu, Xue Qin and Clements, Mark and O'Connell, Dianne},
  year = {2013},
  month = dec,
  volume = {7},
  pages = {641--651},
  issn = {1932-2259},
  doi = {10.1007/s11764-013-0303-9},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VWEIFWQ4\\yu_et_al_2013_projections_of_cancer_prevalence_by_phase_of_care.pdf},
  journal = {Journal of Cancer Survivorship},
  number = {4}
}

@article{Yu2014,
  title = {A Population-Based Study of Breast Cancer Prevalence in {{Australia}}: Predicting the Future Health Care Needs of Women Living with Breast Cancer},
  author = {Yu, Xue Qin and Angelis, Roberta De and Luo, Qingwei and Kahn, Clare and Houssami, Nehmat and O'Connell, Dianne L},
  year = {2014},
  month = jun,
  volume = {14},
  publisher = {{BioMed Central}},
  issn = {0732-183X},
  doi = {10.1200/JCO.2008.20.8983},
  abstract = {Breast cancer places a heavy burden on the Australian healthcare system, but information about the actual number of women living with breast cancer and their current or future health service needs is limited. We used existing population-based data and innovative statistical methods to address this critical research question in a well-defined geographic region. Breast cancer data from the New South Wales (NSW) Central Cancer Registry and PIAMOD (Prevalence and Incidence Analysis MODel) software were used to project future breast cancer prevalence in NSW. Parametric models were fitted to incidence and survival data, and the modelled incidence and survival estimates were then used to estimate current and future prevalence. To estimate future healthcare requirements the projected prevalence was then divided into phases of care according to the different stages of the survivorship trajectory. The number of women in NSW living with a breast cancer diagnosis had increased from 19,305 in 1990 to 48,754 in 2007. This number is projected to increase further to 68,620 by 2017. The majority of these breast cancer survivors will require continued monitoring (31,974) or will be long-term survivors (29,785). About 9\% will require active treatment (either initial therapy, or treatment for subsequent metastases or second cancer) and 1\% will need end of life care due to breast cancer. Extrapolating these projections to the national Australian population would equate to 209,200 women living with breast cancer in Australia in 2017, many of whom will require active treatment or post-treatment monitoring. Thus, careful planning and development of a healthcare system able to respond to this increased demand is required.},
  journal = {BMC Cancer},
  keywords = {\#nosource,Biomedicine general,Cancer Research,general,Health Promotion and Disease Prevention,Medicine/Public Health,Oncology,Surgical Oncology}
}

@article{Yuan2006,
  title = {Model Selection and Estimation in Regression with Grouped Variables},
  author = {Yuan, Ming and Lin, Yi},
  year = {2006},
  volume = {68},
  pages = {49--67},
  abstract = {Accessed: 23-04-2018 16:02 UTC JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. This content downloaded from 81.227.239.144 on Mon, 23 Apr 2018 16:02:22 UTC All use subject to http://about.jstor.org/terms Summary. We consider the problem of selecting grouped variables (factors) for accurate pre-diction in regression. Such a problem arises naturally in many practical situations with the multi-factor analysis-of-variance problem as the most important and well-known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non-negative garrotte for factor selection. The lasso, the LARS algorithm and the non-negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose effi-cient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods.},
  journal = {Source Journal of the Royal Statistical Society. Series B (Statistical Methodology) J. R. Statist. Soc. B},
  keywords = {\#nosource},
  number = {1}
}

@article{Yurkovich2015,
  title = {A Systematic Review Identifies Valid Comorbidity Indices Derived from Administrative Health Data},
  author = {Yurkovich, Marko and {Avina-Zubieta}, J. Antonio and Thomas, Jamie and Gorenchtein, Mike and Lacaille, Diane},
  year = {2015},
  month = jan,
  volume = {68},
  pages = {3--14},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2014.09.010},
  abstract = {OBJECTIVES To conduct a systematic review of studies reporting on the development or validation of comorbidity indices using administrative health data and compare their ability to predict outcomes related to comorbidity (ie, construct validity). STUDY DESIGN AND SETTING We conducted a comprehensive literature search of MEDLINE and EMBASE, until September 2012. After title and abstract screen, relevant articles were selected for review by two independent investigators. Predictive validity and model fit were measured using c-statistic for dichotomous outcomes and R2 for continuous outcomes. RESULTS Our review includes 76 articles. Two categories of comorbidity indices were identified: those identifying comorbidities based on diagnoses, using International Classification of Disease codes from hospitalization or outpatient data, and based on medications, using pharmacy data. The ability of indices studied to predict morbidity-related outcomes ranged from poor (C statistic {$\leq$}0.69) to excellent (C statistic \textquestiondown 0.80) depending on the specific index, outcome measured, and study population. Diagnosis-based measures, particularly the Elixhauser Index and the Romano adaptation of the Charlson Index, resulted in higher ability to predict mortality outcomes. Medication-based indices, such as the Chronic Disease Score, demonstrated better performance for predicting health care utilization. CONCLUSION A number of valid comorbidity indices derived from administrative data are available. Selection of an appropriate index should take into account the type of data available, study population, and specific outcome of interest.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\4WY6ZL7G\\yurkovich_et_al_2015_a_systematic_review_identifies_valid_comorbidity_indices_derived_from.pdf},
  journal = {Journal of Clinical Epidemiology},
  number = {1}
}

@article{Zellner2004,
  title = {Variable Selection in Logistic Regression Models},
  author = {Zellner, Dietmar and Keller, Frieder and Zellner, G{\"u}nter E},
  year = {2004},
  volume = {33},
  pages = {787--805},
  issn = {1532-4141},
  doi = {10.1081/SAC-200033363},
  abstract = {In the statistical analysis the selection of independent (predictor) variables in a regression model that might influence the outcome variable is an important task. To overcome the problems with selection procedures to obtain these authentic variables, we compare the performance of stepwise selection procedures with a bagging method proposed by Sauerbrei [Sauerbrei, W. (1999). The use of resampling methods to simplify regression models in medical statistics. Appl. Statist. 48:313-329]. Furthermore, the bootstrap method with a variable selection from the full logistic regression model was applied. Logistic regression models were conducted to compare the performance of these selection procedures. Similar results were obtained for the different selection procedures such as backward, forward or stepwise selection with the same entry=retention criterion for the ORDER REPRINTS ''simple'' and the bagging method, respectively. Our simulations show better results for small entry and=or retention criterion, in particularly when the predictor variables were correlated. The bagging procedures were substantial better than the ''simple'' stepwise selection procedures. However, the problems remain, for instance that the degree of correlation between the predictor variables affects the frequency with which authentic variables found their way into the final model.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\EBBUVSQW\\zellner_et_al_2004_variable_selection_in_logistic_regression_models.pdf},
  journal = {www.dekker.com COMMUNICATIONS IN STATISTICS Simulation and Computation \~O},
  keywords = {Bagging,Bootstrap,Logistic regression,Selection procedures},
  number = {3}
}

@article{Zervoudakis2011,
  title = {Reproductive History and Risk of Colorectal Cancer in Postmenopausal Women.},
  author = {Zervoudakis, Alice and Strickler, Howard D and Park, Yikyung and Xue, Xiaonan and Hollenbeck, Albert and Schatzkin, Arthur and Gunter, Marc J},
  year = {2011},
  month = may,
  volume = {103},
  pages = {826--34},
  publisher = {{Oxford University Press}},
  issn = {1460-2105},
  doi = {10.1093/jnci/djr101},
  abstract = {BACKGROUND There are conflicting data regarding the role of sex hormones in colorectal cancer development. Whereas clinical trials data indicate that hormone therapy use reduces the risk of colorectal cancer, data from prospective cohort studies suggest that circulating estrogen levels are positively associated with colorectal cancer risk. A surrogate measure of lifetime estrogen exposure is reproductive history. We investigated the relationship between reproductive factors and the risk of colorectal cancer. METHODS Subjects were postmenopausal women enrolled in the National Institutes of Health-American Association of Retired Persons Diet and Health Study, a cohort of 214,162 individuals (aged 50-71 years) that included 2014 incident cases of colorectal cancer that occurred over a mean follow-up of 8.2 years. Questionnaires were used to collect data on reproductive factors, including ages at menarche, birth of first child, and menopause; parity, and use of oral contraceptives. Multivariable Cox proportional hazards models were constructed to examine associations between these reproductive factors and the risk of colorectal cancer, with adjustment for established colorectal cancer risk factors. All statistical tests were two-sided. RESULTS Age at menopause ({$\geq$} 55 vs \textexclamdown{} 40 years: hazard ratio [HR] = 1.50, 95\% confidence interval [CI] = 1.23 to 1.83; P(trend) = .008) and age at birth of first child ({$\geq$} 30 vs {$\leq$} 19 years: HR = 1.26, 95\% CI = 1.01 to 1.58; P(trend) = .05) were positively associated with the risk of colorectal cancer. Among women with no history of hormone therapy use, age at menarche ({$\geq$} 15 vs 11-12 years: HR = 0.73, 95\% CI = 0.57 to 0.94; P(trend) = .02) and parity ({$\geq$} 5 children vs no children: HR = 0.80, 95\% CI = 0.63 to 1.02; P(trend) = .10) were inversely associated with the risk of colorectal cancer. CONCLUSION These data support a role for sex hormones in colorectal tumorigenesis and suggest that greater endogenous estrogen exposure may increase the risk of colorectal cancer in postmenopausal women.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\2CRVK3XQ\\zervoudakis_et_al_2011_reproductive_history_and_risk_of_colorectal_cancer_in_postmenopausal_women.pdf},
  journal = {Journal of the National Cancer Institute},
  number = {10},
  pmid = {21447807}
}

@book{zetterstromOffentlighetOchSekretess2010,
  title = {Offentlighet Och Sekretess},
  author = {Zetterstr{\"o}m, Stefan},
  year = {2010},
  keywords = {\#nosource}
}

@article{Zhang2012,
  title = {An Exploratory Study of Response Shift in Health-Related Quality of Life and Utility Assessment among Patients with Osteoarthritis Undergoing Total Knee Replacement Surgery in a Tertiary Hospital in {{Singapore}}},
  author = {Zhang, Xu Hao and Li, Shu Chuen and Xie, Feng and Lo, Ngai Nung and Yang, Kwang Ying and Yeo, Seng Jin and Fong, Kok Yong and Thumboo, Julian},
  year = {2012},
  volume = {15},
  pages = {72--78},
  issn = {10983015},
  doi = {10.1016/j.jval.2011.11.011},
  abstract = {Objective: To investigate the influence of response shift (RS) on health-related quality of life (HRQOL) and utility assessment among patients undergoing total knee replacement. Methods: Consenting patients undergoing total knee replacement were interviewed to determine their HRQOL by using the six-dimensional health state short form, derived from SF-36, and the EuroQol five-dimensional questionnaire at baseline (pretest 1) and the six-dimensional health state short form, derived from SF-36, at 6 (pretest 2) and 18 months after surgery (post-test). RS was studied by using a "then-test" approach by contacting participants 18 months after surgery and asking them to evaluate their HRQOL at baseline (then-test 1) and at 6 (then-test 2) and 18 months after surgery. RS was calculated as the score difference between pretest and then-test scores for a given time point. Relationships between RS and external variables were explored by using univariate and multiple liner regression analyses. Results: In 74 subjects (63\% response rate, median age 68 years), median (interquantile range) six-dimensional health state short form, derived from SF-36, scores for then-tests at baseline (0.48 [0.420.49]) and at 6 months (0.72 [0.660.79]) after surgery were significantly different from respective pretest scores (0.61 [0.580.68] at baseline, P = 0.000; 0.69 [0.630.72] at 6 months, P = 0.000), showing RS at both time points. RS at baseline (0.14 [0.080.20]) was significantly larger than that at 6 months (-0.05 [0.14 to 0.00], P = 0.000). EuroQol five-dimensional questionnaire pretest and then-test scores at baseline also differed significantly (0.69 [0.170.73] vs. -0.18 [-0.23 to 0.00], P = 0.000). RS at baseline was not affected by assessed demographic or medical variables. RS at 6 months was greater in subjects with more years of education (16\% of variance in multiple liner regression, P \textexclamdown{} 0.01). Conclusion: RS was present and impacted HRQOL and utility assessment among patients undergoing total knee replacement before and 6 months after surgery. \textcopyright{} 2012 International Society for Pharmacoeconomics and Outcomes Research (ISPOR).},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\83LDHKX6\\zhang_et_al_2012_an_exploratory_study_of_response_shift_in_health-related_quality_of_life_and.pdf},
  journal = {Value in Health},
  keywords = {health-related quality of life,response shift,total knee replacement,utility assessment},
  number = {1 SUPPL.},
  pmid = {22265071}
}

@article{Zhao2016,
  title = {On the Restricted Mean Survival Time Curve in Survival Analysis},
  author = {Zhao, Lihui and Claggett, Brian and Tian, Lu and Uno, Hajime and Pfeffer, Marc A. and Solomon, Scott D. and Trippa, Lorenzo and Wei, L. J.},
  year = {2016},
  month = mar,
  volume = {72},
  pages = {215--221},
  publisher = {{John Wiley \& Sons, Ltd (10.1111)}},
  issn = {15410420},
  doi = {10.1111/biom.12384},
  abstract = {For a study with an event time as the endpoint, its survival function contains all the information regarding the temporal , stochastic profile of this outcome variable. The survival probability at a specific time point, say t, however, does not transparently capture the temporal profile of this endpoint up to t. An alternative is to use the restricted mean survival time (RMST) at time t to summarize the profile. The RMST is the mean survival time of all subjects in the study population followed up to t, and is simply the area under the survival curve up to t. The advantages of using such a quantification over the survival rate have been discussed in the setting of a fixed-time analysis. In this article, we generalize this approach by considering a curve based on the RMST over time as an alternative summary to the survival function. Inference, for instance, based on simultaneous confidence bands for a single RMST curve and also the difference between two RMST curves are proposed. The latter is informative for evaluating two groups under an equivalence or noninferiority setting, and quantifies the difference of two groups in a time scale. The proposal is illustrated with the data from two clinical trials, one from oncology and the other from cardiology.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\WLX93GY4\\zhao_et_al_2016_on_the_restricted_mean_survival_time_curve_in_survival_analysis.pdf},
  isbn = {1541-0420},
  journal = {Biometrics},
  keywords = {Equivalence/noninferiority study,Gaussian process,Martingale,Simultaneous confidence band,Survival function},
  number = {1},
  pmid = {26302239}
}

@article{Zimmerli2006,
  title = {Prosthetic-Joint-Associated Infections},
  author = {Zimmerli, Werner},
  year = {2006},
  month = dec,
  volume = {20},
  pages = {1045--1063},
  issn = {15216942},
  doi = {10.1016/j.berh.2006.08.003},
  journal = {Best Practice \& Research Clinical Rheumatology},
  language = {en},
  number = {6}
}

@article{Zimmerman2003,
  title = {Bias in Estimation and Hypothesis Testing of Correlation},
  author = {Zimmerman, D and Zumbo, B and Williams, R},
  year = {2003},
  volume = {24},
  pages = {133--158},
  issn = {02112159},
  abstract = {This study examined bias in the sample correlation coefficient, r, and its correction by unbiased estimators. Computer simulations revealed that the expected value of correlation coefficients in samples from a normal population is slightly less than the population correlation, \&\#961;, and that the bias is almost eliminated by an estimator suggested by R.A. Fisher and is more completely eliminated by a related estimator recommended by Olkin and Pratt. Transformation of initial scores to ranks and calculation of the Spearman rank correlation, rS, produces somewhat greater bias. Type I error probabilities of significance tests of zero correlation based on the Student t statistic and exact tests based on critical values of rS obtained from permutations remain fairly close to the significance level for normal and several non-normal distributions. However, significance tests of non-zero values of correlation based on the r to Z transformation are grossly distorted for distributions that violate bivariate normality. Also, significance tests of non-zero values of rS based on the r to Z transformation are distorted even for normal distributions.},
  journal = {Psicologica},
  keywords = {\#nosource},
  number = {24}
}

@article{Zou2004,
  title = {A Modified Poisson Regression Approach to Prospective Studies with Binary Data},
  author = {Zou, Guangyong},
  year = {2004},
  volume = {159},
  pages = {702--706},
  issn = {00029262},
  doi = {10.1093/aje/kwh090},
  abstract = {Relative risk is usually the parameter of interest in epidemiologic and medical studies. In this paper, the author proposes a modified Poisson regression approach (i.e., Poisson regression with a robust error variance) to estimate this effect measure directly. A simple 2-by-2 table is used to justify the validity of this approach. Results from a limited simulation study indicate that this approach is very reliable even with total sample sizes as small as 100. The method is illustrated with two data sets.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\ZQVEJ4FI\\zou_2004_a_modified_poisson_regression_approach_to_prospective_studies_with_binary_data.pdf},
  isbn = {0002-9262},
  journal = {American Journal of Epidemiology},
  keywords = {Clinical trials,Cohort studies,Logistic regression,Mantel-Haenszel,Odds ratio,Relative risk},
  number = {7},
  pmid = {15033648}
}

@article{Zou2006,
  title = {The Adaptive Lasso and Its Oracle Properties},
  author = {Zou, Hui},
  year = {2006},
  volume = {101},
  pages = {1418--1429},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. The lasso is a popular technique for simultaneous estimation and variable selection. Lasso variable selection has been shown to be consistent under certain conditions. In this work we derive a necessary condition for the lasso variable selection to be consistent. Consequently, there exist certain scenarios where the lasso is inconsistent for variable selection. We then propose a new version of the lasso, called the adaptive lasso, where adaptive weights are used for penalizing different coefficients in the l penalty. We show that the adaptive lasso enjoys the oracle properties; namely, it performs as well as if the true underlying model were given in advance. Similar to the lasso, the adaptive lasso is shown to be near-minimax optimal. Furthermore, the adaptive lasso can be solved by the same efficient algorithm for solving the lasso. We also discuss the extension of the adaptive lasso in generalized linear models and show that the oracle properties still hold under mild regularity conditions. As a byproduct of our theory, the nonnegative garotte is shown to be consistent for variable selection.},
  journal = {Source Journal of the American Statistical Association},
  keywords = {\#nosource},
  number = {476}
}

@article{Zou2006,
  title = {Interface Foundation of America Sparse Principal Component Analysis Sparse Principal Component Analysis},
  author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
  year = {2006},
  volume = {15},
  pages = {265--286},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. Principal component analysis (PCA) is widely used in data processing and dimension ality reduction. However, PCA suffers from the fact that each principal component is a linear combination of all the original variables, thus it is often difficult to interpret the results. We introduce a new method called sparse principal component analysis (SPCA) using the lasso \{elastic net) to produce modified principal components with sparse loadings. We first show that PCA can be formulated as a regression-type optimization problem; sparse loadings are then obtained by imposing the lasso (elastic net) constraint on the regression coefficients. Efficient algorithms are proposed to fit our SPCA models for both regular multivariate data and gene expression arrays. We also give a new formula to compute the total variance of modified principal components. As illustrations, SPCA is applied to real and simulated data with encouraging results.\vphantom\}},
  journal = {Source Journal of Computational and Graphical Statistics},
  keywords = {\#nosource},
  number = {2}
}

@article{Zou2007,
  title = {Toward Using Confidence Intervals to Compare Correlations.},
  author = {Zou, Guang Yong},
  year = {2007},
  volume = {12},
  pages = {399--413},
  publisher = {{American Psychological Association}},
  issn = {1082-989X},
  doi = {http://dx.doi.org/10.1037/1082-989X.12.4.399},
  abstract = {Confidence intervals are widely accepted as a preferred way to present study results. They encompass significance tests and provide an estimate of the magnitude of the effect. However, comparisons of correlations still rely heavily on significance testing. The persistence of this practice is caused primarily by the lack of simple yet accurate procedures that can maintain coverage at the nominal level in a nonlopsided manner. The purpose of this article is to present a general approach to constructing approximate confidence intervals for differences between (a) 2 independent correlations, (b) 2 overlapping correlations, (c) 2 nonoverlapping correlations, and (d) 2 independent R2s. The distinctive feature of this approach is its acknowledgment of the asymmetry of sampling distributions for single correlations. This approach requires only the availability of confidence limits for the separate correlations and, for correlated correlations, a method for taking into account the dependency between correlations. These closed-form procedures are shown by simulation studies to provide very satisfactory results in small to moderate sample sizes. The proposed approach is illustrated with worked examples. (PsycINFO Database Record (c) 2013 APA, all rights reserved)(journal abstract)},
  city = {Department of Epidemiology and Biostatistics, Schulich School of Medicine and Dentistry, University of Western Ontario, London, ON, Canada gzou@robarts.ca; Zou, Guang Yong,London,Canada,N6A 5C1,Department of Epidemiology and Biostatistics, Schulich School},
  journal = {Psychological Methods},
  keywords = {\#nosource,2200:Psychometrics \& Statistics \& Methodology,article,bootstrap,coefficient of determination,confidence interval,Confidence Limits (Statistics),correlations,hypothesis testing,Hypothesis Testing,multiple regression,Multiple Regression,Psychology,Statistical Correlation},
  number = {4}
}

@book{Zuur2009,
  title = {Mixed Effects Models and Extensions in Ecology with r},
  author = {Zuur, A. F. and Leno, E. N. and Walker, N. J. and Saveliev, A. A. and Smith, G. M.},
  year = {2009},
  volume = {36},
  issn = {18715125},
  doi = {10.1016/B978-0-12-387667-6.00013-0},
  abstract = {This greatly expanded second edition of Survival Analysis- A Self-learning Text provides a highly readable description of state-of-the-art methods of analysis of survival/event-history data. This text is suitable for researchers and statisticians working in the medical and other life sciences as well as statisticians in academia who teach introductory and second-level courses on survival analysis. The second edition continues to use the unique "lecture-book" format of the first (1996) edition with the addition of three new chapters on advanced topics: Chapter 7: Parametric Models Chapter 8: Recurrent events Chapter 9: Competing Risks. Also, the Computer Appendix has been revised to provide step-by-step instructions for using the computer packages STATA (Version 7.0), SAS (Version 8.2), and SPSS (version 11.5) to carry out the procedures presented in the main text. The original six chapters have been modified slightly to expand and clarify aspects of survival analysis in response to suggestions by students, colleagues and reviewers, and to add theoretical background, particularly regarding the formulation of the (partial) likelihood functions for proportional hazards, stratified, and extended Cox regression models David Kleinbaum is Professor of Epidemiology at the Rollins School of Public Health at Emory University, Atlanta, Georgia. Dr. Kleinbaum is internationally known for innovative textbooks and teaching on epidemiological methods, multiple linear regression, logistic regression, and survival analysis. He has provided extensive worldwide short-course training in over 150 short courses on statistical and epidemiological methods. He is also the author of ActivEpi (2002), an interactive computer-based instructional text on fundamentals of epidemiology, which has been used in a variety of educational environments including distance learning. Mitchel Klein is Research Assistant Professor with a joint appointment in the Department of Environmental and Occupational Health (EOH) and the Department of Epidemiology, also at the Rollins School of Public Health at Emory University. Dr. Klein is also co-author with Dr. Kleinbaum of the second edition of Logistic Regression- A Self-Learning Text (2002). He has regularly taught epidemiologic methods courses at Emory to graduate students in public health and in clinical medicine. He is responsible for the epidemiologic methods training of physicians enrolled in Emorya??s Master of Science in Clinical Research Program, and has collaborated with Dr. Kleinbaum both nationally and internationally in teaching several short courses on various topics in epidemiologic methods.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\8AQHPPFZ\\zuur_et_al_2009_mixed_effects_models_and_extensions_in_ecology_with_r.pdf},
  isbn = {978-0-387-87457-9},
  pmid = {22469268}
}

@book{Zwillinger2001,
  title = {Standard Probability and Statistics Tables and Formulae},
  author = {Zwillinger, Daniel},
  year = {2001},
  volume = {43},
  issn = {0040-1706},
  doi = {10.1198/tech.2001.s620},
  abstract = {Whether you are a statistician, engineer, or businessperson, you need statistics. You want to be able to easily reference tables, find formulas, and know how to use them so you can extract information from data without getting bogged down by advanced statistical methods. Your goal is to determine the appropriate statistical procedures and interpret the results. Standard Probability and Statistics: Tables and Formulae provides the tools you need to do just that. Logically organized and reaching far beyond a mere catalog, a textual description accompanies each entry- most include an example. The topics addressed are directly applicable to modern business and engineering as well as to statistics, including regression analysis, ANOVA, decision theory, signal processing, and control theory. The result is an accessible, example-oriented handbook that supplies the basic principles, the most commonly used values, and the information to make them work for you. It is easy to fill a statistics reference with hundreds of pages of tables - sometimes for just one test. This handbook is much more. With topics ranging from classical statistics to modern applications, Standard Probability and Statistics fills the need for an up-to-date, authoritative statistics reference.},
  file = {C\:\\Users\\erik_\\Zotero\\storage\\VHKI2ICG\\zwillinger_2001_standard_probability_and_statistics_tables_and_formulae.pdf},
  isbn = {1-58488-059-7},
  pmid = {11785548}
}


